{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a847404e-196d-4314-832c-ef9a48113a0a",
   "metadata": {},
   "source": [
    "Goal: Match all files date wise and find missing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4e086f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import pickle\n",
    "from random import randint\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b133b1b3-0e14-414a-84c6-64e08fa3be6a",
   "metadata": {},
   "source": [
    "input:\n",
    "test_str - base string\n",
    "list2check - list of possible strings\n",
    "output:\n",
    "closest_match - sorted list of most similar strings to base string\n",
    "max(scores_values) - the most similat string to base_str from the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e56b9eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closet_match(test_str, list2check):\n",
    "    scores = {}\n",
    "    for ii in list2check:\n",
    "        cnt = 0\n",
    "        if len(test_str)<=len(ii):\n",
    "            str1, str2 = test_str, ii\n",
    "        else:\n",
    "            str1, str2 = ii, test_str\n",
    "        for jj in range(len(str1)):\n",
    "            cnt += 1 if str1[jj]==str2[jj] else 0\n",
    "        scores[ii] = cnt\n",
    "    scores_values        = np.array(list(scores.values()))\n",
    "    closest_match_idx    = np.argsort(scores_values, axis=0, kind='quicksort')[-1]\n",
    "    closest_match        = np.array(list(scores.keys()))[closest_match_idx]\n",
    "    return closest_match,max(scores_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ae89c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read main table from google sheets\n",
    "tech_df=pd.read_csv('https://docs.google.com/spreadsheets/d/1BZ_NP8PJbDsIXz4cbjSHlILQ8yBfy0vXcqm5Zw4fNoU/export?format=csv',\n",
    "                   # Set first column as rownames in data frame\n",
    "                   index_col=0,\n",
    "                  )\n",
    "tech_list=tech_df.loc[tech_df['Emerging Tech'].notnull(),'Emerging Tech'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145c1bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors=['Lithium ion battery',\n",
    " 'Cryptocurrency',\n",
    " '5g',\n",
    " 'Open source model',\n",
    " 'Facial recognition',\n",
    " 'Cloud computing',\n",
    " 'Streaming television',\n",
    " 'e-Reader',\n",
    " 'Capsule endoscopy',\n",
    " 'Quadcopter',\n",
    " 'Electronic cigarette',\n",
    " 'Miniaturized satellite',\n",
    " 'Electric vehicle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37170029",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run over each file in feature folder and check if the index (the tech list) contain all technologies from main list\n",
    "# print any file with missing technologies (togather with the missing technologies)\n",
    "\n",
    "#the commented sections are there to handle specific featuire groups e.g. wikipedia or google news\n",
    "\n",
    "from glob import glob\n",
    "for file in Path(r\"C:\\Users\\nehor\\Google Drive\\Neura machine\\Impact features\").rglob(\"*.csv\"):\n",
    "    print(file)\n",
    "    df=pd.read_csv(file,index_col=0)\n",
    "    diff=list(set(list(df.index))-set(tech_list))\n",
    "    print(len(diff))\n",
    "#     if \"wiki\" in dict_list:\n",
    "#         files = Path(dict_list).rglob(\"*.csv\")\n",
    "#     #     print(dict_list)\n",
    "#         for file in files:\n",
    "#             df=pd.read_excel(file,index_col=0)\n",
    "#             diff=list(set(list(df.index))-set(tech_list))\n",
    "#             if diff:\n",
    "# #                 diff.sort()\n",
    "#                 print(file,len(diff))\n",
    "#                 print(diff)\n",
    "#                 for d in diff:\n",
    "#                     print(d)\n",
    "# #                 sys.exit()\n",
    "# #                 df.index=df.index.str[:-1]\n",
    "                \n",
    "#                 df=df.rename(index=wiki_dict)\n",
    "# #                 diff=list(set(list(df.index))-set(tech_list))\n",
    "# # #                 print(file,len(diff))\n",
    "# # #                 print(diff)\n",
    "# # #                 sys.exit()\n",
    "#                 diff2=list(set(list(df.index))-set(tech_list))\n",
    "#                 df=df[~df.index.isin(diff2)]\n",
    "#                 df.to_excel(file)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd45b7a-e23d-4d60-bb6f-e08cf3fad609",
   "metadata": {},
   "source": [
    "Dictionaries for matching the name from the features to the name from the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53cd588",
   "metadata": {},
   "outputs": [],
   "source": [
    "kobo_dict={\n",
    "'3-d printing':'3D printing',\n",
    "    'Small satellite':'Miniaturized satellite',\n",
    "'5G':'5g',\n",
    "'Machinelearning':'Machine learning',\n",
    "'Adaptive learning technology':'Adaptive Learning Technology',\n",
    "'Physical internet':'Physical Internet',\n",
    "'Plasma propulsion engline':'Plasma propulsion engine',\n",
    "    'Electronic_nose':'Electronic nose'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f97b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "soc_dict={\n",
    "'3D printing':'3D printing',\n",
    "'Magnetorheological_fluid':'Magnetorheological fluid',\n",
    "    \n",
    "    'Magnetorheological_fluid':'Magnetorheological',\n",
    "    'Magnetorheological_fluid':'Magnetorheological',\n",
    "    'Magnetorheological_fluid':'Magnetorheological',\n",
    "    \n",
    "'Machine learning':'Machine learning',\n",
    "'Adaptive learning technology':'Adaptive Learning Technology',\n",
    "'Physical internet':'Physical Internet',\n",
    "'Plasma propulsion engline':'Plasma propulsion engine',\n",
    "    'Electronic_nose':'Electronic nose'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171119dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_dict={\n",
    "'3-d printing':'3D printing',\n",
    "'5G':'5g',\n",
    "'Machinelearning':'Machine learning',\n",
    "'Adaptive learning technology':'Adaptive Learning Technology',\n",
    "'Physical internet':'Physical Internet',\n",
    "'Plasma propulsion engline':'Plasma propulsion engine',\n",
    "    'Electronic_nose':'Electronic nose'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eefad3d-2146-46dc-95f9-31616de0fdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "voy_dict={\n",
    "    '3Dprinting':'3D printing',\n",
    "'Genome Editing':'Gene Editing',\n",
    "'Machinelearning':'Machine learning',\n",
    "'Plasma Medicine(1)':'Plasma Medicine',\n",
    "'Reusablelaunchsystem':'Reusable launch system',\n",
    "'Videoconferencing':'Video conferencing',\n",
    "'Wifi':'wi-fi',\n",
    "'bluetooth':'Bluetooth',\n",
    "'messengerRNAvaccination':'mRNA vaccination',\n",
    "'osteoodontokeratoprosthesis':'OOKP',\n",
    "'smallsatellite':'Miniaturized satellite',\n",
    "'unmannedaerialvehicle':'unmanned aerial vehicle'\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
