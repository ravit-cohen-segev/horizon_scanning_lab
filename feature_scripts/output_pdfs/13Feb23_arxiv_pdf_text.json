{"arxiv0": "Received February 2, 2020, accepted March 1, 2020, date of publication March 11, 2020, date of current version March 20, 2020.\nDigital Object Identifier 10.1 109/ACCESS.2020.2980085\nSaferCross: Enhancing Pedestrian Safety Using\nEmbedded Sensors of Smartphone\nMYOUNGGYU WON\n1, (Member, IEEE), AAWESH SHRESTHA\n2,\nKYUNG-JOON PARK\n3, (Member, IEEE), AND YONGSOON EUN\n3, (Senior Member, IEEE)\n1Department of Computer Science, University of Memphis, Memphis, TN 38152, USA\n2Department of Electrical Engineering and Computer Science, South Dakota State University, Brookings, SD 57006, USA\n3Information and Communication Engineering Department, Daegu Gyeongbuk Institute of Science and Technology (DGIST), Daegu 42988, South Korea\nCorresponding authors: Kyung-Joon Park (kjp@dgist.ac.kr) and Yongsoon Eun (yeun@dgist.ac.kr)\nThis work was supported in part by the Competitive Research Grant Program (CRGP) of South Dakota Board of Regents (SDBoR), in part\nby the Global Research Laboratory Program through the NRF under Grant 2013K1A1A2A02078326, and in part by the DGIST Research\nand Development Program (CPS Global Center) funded by the Ministry of Science, ICT & Future Planning of South Korea.\nABSTRACT The number of pedestrian accidents continues to keep climbing. Distraction from smartphone\nis one of the biggest causes for pedestrian fatalities. In this paper, we develop SaferCross, a mobile\nsystem based on the embedded sensors of smartphone to improve pedestrian safety by preventing distraction\nfrom smartphone. SaferCross adopts a holistic approach by identifying and developing essential system\ncomponents that are missing in existing systems and integrating the system components into a ``fully-\nfunctioning'' mobile system for pedestrian safety. Speci\u001ccally, we create algorithms for improving the\naccuracy and energy ef\u001cciency of pedestrian positioning, effectiveness of phone activity detection, and\nreal-time risk assessment. We demonstrate that SaferCross, through systematic integration of the developed\nalgorithms, performs situation awareness effectively and provides a timely warning to the pedestrian based on\nthe information obtained from smartphone sensors and Direct Wi-Fi-based peer-to-peer communication with\napproaching cars. Extensive experiments are conducted in a department parking lot for both component-level\nand integrated testing. The results demonstrate that the energy ef\u001cciency and positioning accuracy of\nSaferCross are improved by 52% and 72% on average compared with existing solutions with missing\nsupport for positioning accuracy and energy ef\u001cciency, and the phone-viewing event detection accuracy is\nover 90%. The integrated test results show that SaferCross alerts the pedestrian timely with an average\nerror of 1.6sec in comparison with the ground truth data, which can be easily compensated by con\u001cguring\nthe system to \u001cre an alert message a couple of seconds early.\nINDEX TERMS Mobile computing, pedestrian safety, Wi-Fi direct.\nI. INTRODUCTION\nThe number of pedestrian accidents continues to keep climb-\ning. In 2018, 6,283 pedestrians were killed which accounted\nfor an increase of 3% compared with pedestrian fatalities\nin 2017, the highest number of pedestrian fatalities since\n1990 [1].\nMany sources point out that smartphone distraction is\none of the major causes for pedestrian fatalities [2]\u0015[4].\nMany pedestrians use their mobile phones while walking on\nsidewalks and crossing the street [5], [6]. A recent study\nshows that more than a third of pedestrians use their mobile\nphones while crossing streets [7], and 16% of pedestrian\nThe associate editor coordinating the review of this manuscript and\napproving it for publication was Yufeng Wang\n .accidents were caused by distraction due to phone use [8].\nAnother study shows that 85% have seen distracted pedes-\ntrians, and 26% of the respondents were actually involved\nwith distracted-walking accidents [9]. According to the report\nfrom US Consumer Product Safety Commission, the per-\ncentage of pedestrian injuries involving smartphones are\nincreasing steadily [10]. Interestingly, the signi\u001ccant rise in\nthe pedestrian injuries started in 2009, and this is exactly\nwhen smartphones started to take hold [11]. These dis-\ntracted pedestrians are even called ``smartphone zombies'' in\nrecent scienti\u001cc publications to stress the seriousness of the\nproblem [12].\nIn this paper, we aim to develop a mobile system that\nenhances pedestrian safety by preventing distracted phone\nuse. Numerous approaches have been designed and deployedFIGURE 1. (a) Signage in Delaware, (b) Signage in NYC, (c) LED stoplight\nin Israel, (d) Ground flashlight in Seoul. Numerous pedestrian safety\nsystems have been developed.\nto protect distracted pedestrians, e.g., using a signage [13],\nand LED spotlights [14] as shown in Fig. 1. However, paint-\ning road signs and installing LED lights at every crosswalk\nnot only involves huge cost, but it can even be distraction\nto drivers especially at night. With a myriad of embedded\nsensors such as accelerometers, cameras, microphones, and\nGPS, smartphones have opened the new opportunities for var-\nious applications [15]; especially, those sensors can be used\nto improve pedestrian safety by directly alerting pedestrians.\nThe camera of smartphone is used to detect approaching\nvehicles posing danger to pedestrians [16]. Some mobile\nsystems utilize communication between cars and pedestrians.\nFor example, Wu et al. adopt the Dedicated Short Range\nCommunication (DSRC) to enable the vehicle to pedestrian\ncommunication [17], and Lin et al. utilize the cellular net-\nwork [18] to perform risk analysis and alert the pedestrian\naccordingly.\nAlthough existing solutions contribute to improving pedes-\ntrian safety, most solutions are focused on a certain aspect\nof a mobile system for pedestrian safety such as detection of\napproaching cars, communication between cars and pedes-\ntrians. However, a number of essential system components\nare still missing to build a complete mobile system for\npedestrian safety. In this paper, we aim to develop a ``fully-\nfunctioning'' mobile system for pedestrian safety by develop-\ning these critical system components for precise pedestrian\npositioning, energy ef\u001cciency, accurate phone activity detec-\ntion, and effective risk assessment. To this end, we present\nSaferCross, a mobile system for pedestrian safety based on\nthe embedded sensors and WiFi Direct of smartphone [19].\nSaferCross effectively senses approaching cars, performs\nreal-time risk assessment, and alerts drivers and pedestrians\nin a timely and energy-ef\u001ccient manner without requiring any\nmodi\u001ccations to the host mobile system. The key contribu-\ntions of SaferCross are development of the essential sys-\ntem components that can be adopted for developing mobile\nsystems for pedestrian safety, ultimately to spark the mobile\ncomputing research focused on protecting pedestrians from\naccidents. We note that it is ideal to force pedestrians not to\nuse their phones while walking. At the same time, however,\nwe admit that there are still a lot of pedestrians who are\ntempted to use their phones. In fact, a huge number of pedes-\ntrian involved accidents happen every year. As such, we argue\nthatSaferCross is developed as an assistive technology for\nthose distracted pedestrians and is not intended to encourage\nblind reliance on the technology.\nSaferCross is built upon fundamental technologies\nfocused on enhancing the effectiveness of pedestrianlocalization, energy ef\u001cciency of smartphone, phone activ-\nity detection, and situation awareness. More speci\u001ccally,\nthe pedestrian localization module of SaferCross is\nspeci\u001ccally designed to accurately localize slow-moving\npedestrians. This module is particularly useful for localizing\npedestrians in urban areas with skyscrapers where accurate\npositioning based on GPS is very challenging. Based on the\nobservation that pedestrians walk along a sidewalk, a map\nmatching algorithm is adopted and customized for accurately\nlocalizing slow-moving pedestrians. To mitigate the impact\nof signi\u001ccant power consumption of the GPS module and\nimprove the energy ef\u001cciency, a dynamic approach is pro-\nposed to activate the GPS module adaptively depending on\nthe estimated time that the user is expected to be geograph-\nically close to a nearby crosswalk. Additionally, a novel\nalgorithm is designed to detect the user activities effectively\nso that the system is activated at the exactly right time. The\ncommunication module of SaferCross is built based on the\nWiFi Direct technology. A new technique based on oppor-\ntunistic overhearing of WiFi Direct messages is developed to\naddress the challenge of allowing for n-to-n communication\nfor WiFi Direct. Finally, a collision probability model is\ndesigned based on real-world data collected via WiFi Direct\nto effectively perform risk assessment. SaferCross system-\natically structures these novel system components to build the\n\u001crst fully functioning mobile system for pedestrian safety.\nExtensive experiments were conducted in which both the\nmodule-level test and the integrated test were performed to\nevaluate the effectiveness of the proposed system modules\nindividually and the system performance as a whole. The\nresults demonstrate that the localization accuracy was sig-\nni\u001ccantly improved by up to 72%; the user phone viewing\nevent was accurately detected with the accuracy of over 90%;\nand the energy consumption was reduced by 50.2%. An inte-\ngrated test was performed to evaluate the effectiveness of the\ninterplay of the individual system components. The results\nshow that all modules effectively cooperate to provide an\nalert message to the user in a timely manner with an error\nof 1.6sec on average in comparison with the ground truth data.\nSuch a small error can be easily compensated by con\u001cguring\nthe system to \u001cre an alert message a couple of seconds\nearly. The contributions of this paper are summarized as\nfollows.\n\u000fA Hidden Markov Model-based map matching algo-\nrithm is designed for accurately localizing pedestrians.\n\u000fAn adaptive algorithm is developed to improve the\nenergy ef\u001cciency of a mobile system for pedestrian\nsafety.\n\u000fAn effective algorithm is created to detect the pedestrian\nphone viewing event accurately.\n\u000fA novel approach is developed to perform risk assess-\nment effectively based on Wi-Fi Direct-based commu-\nnication between cars and pedestrians.\n\u000fExperiments are performed in a parking lot to demon-\nstrate the effectiveness of individual system components\nand the proposed mobile system as a whole.This paper is organized as follows. Section IIpresents a lit-\nerature review on related approaches designed for improving\npedestrian safety. In Section III, we describe an overview of\nthe proposed app followed by the details of each system com-\nponent. The performance of the proposed app is evaluated in\nSection IV. We then conclude in Section V.\nII. RELATED WORK\nWang et al. develop an app that uses the rear camera of a\nphone to monitor approaching vehicles to alert the pedes-\ntrian [16]. A machine-learning-based image processing algo-\nrithm is designed to capture approaching cars for pedestrian\nsafety assessment. This approach, however, raises the privacy\nissue as it takes photos of cars without acquiring permission\nof drivers. Additionally, the energy ef\u001cciency is another prob-\nlem as this system is based on continuously executing image\nprocessing algorithms which consume much energy.\nA cellular network is used to enable car-to-pedestrian\ncommunication [18]. However, this approach based on a\ncellular network not only incurs high cost but also results\nin non-negligible message delay compared with the direct\npeer to peer communication. Especially, even a small mes-\nsage delay is critical in mobile systems for pedestrian safety.\nDedicated Short Range Communication (DSRC) is a wireless\ncommunication standard speci\u001ccally designed for vehicle-to-\nvehicle communication (V2V). Researchers utilize DSRC as\na means to enable vehicle-to-person (V2P) communication\nfor pedestrian safety [17]. However, implementing DSRC on\na phone requires signi\u001ccant modi\u001ccations to the host sys-\ntem \u001crmware, and extra device support is needed to operate\nDSRC on vehicles.\nSpecialized hardware is designed to enhance pedestrian\nsafety. For example, sensors are adhered to the pedestrians'\nshoes to detect whether the pedestrian is crossing at a cross-\nwalk [20]. Those sensors are used to calculate the slope\nbetween the sidewalk and the roadway as an indicator to \u001cnd\nwhether the pedestrian is about to cross the street. Another\nexample is to exploit an electronic transponder that is attached\nto the pedestrian's body to determine whether the pedestrian\nis visible or not [21]. However, typically asking the users\nto attach these types of specialized hardware is not easy,\npreventing widespread adoption of such technology.\nWiFi has been actively considered as an appropriate alter-\nnative technology to enable vehicle to pedestrian communi-\ncation for pedestrian safety [22]\u0015[24]. In particular, WiHonk\nis quite similar to the Communication module of our\nwork [23]. However, WiHonk is based on the modi\u001ccation\nof the beacon frame of IEEE 802.11 which requires the root\nprivilege that makes it dif\u001ccult for common use. Additionally,\nno details are provided regarding when to exchange mes-\nsages with cars, potentially resulting in unnecessary network\nbottleneck. WiSafe is another WiFi-based pedestrian safety\nsystem which resembles our Communication module [24].\nOur work is different in that the system design involves both\nthe driver and pedestrian while WiSafe utilizes only one-way\ncommunication from a pedestrian to cars.\nFIGURE 2. Different pedestrian safety levels of SaferCross. SaferCross can\nbe configured to support various pedestrian safety levels.\nIII. SYSTEM DESIGN\nA. SYSTEM OVERVIEW\nSaferCross has two modes of operation: the driver mode\nand pedestrian mode. In the driver mode, SaferCross keeps\nmonitoring the speed and location of the vehicle, and sends\nthe speed and location information to the pedestrians within\nthe communication range of WiFi Direct. In the pedestrian\nmode, SaferCross keeps track of the pedestrian location\nand activity to detect if the user is attempting to cross a\ncrossing while viewing their phone. It communicates with\napproaching cars, i.e.,driver phones of those cars, to obtain\nthe speed and location information of the cars and estimates\nthe probability of collision. Depending on the calculated\nprobability of collision, the pedestrian is alerted. To minimize\ndriver distraction, the driver is only alerted when the pedes-\ntrian ignores the alert message several times.\nSaferCross also supports the stand-alone mode where it\nworks without requiring to communicate with driver phones.\nIn other words, it can be con\u001cgured to alert the pedestrian\nbased only on the distance to the crossing and the pedestrian's\nwalking direction with varying safety levels (Fig. 2). More\nspeci\u001ccally, the user will be alerted if he is close to the\ncrossing and his phone screen is on (Level 3); if the phone\nscreen is on and he is viewing the phone (Level 2); and if\nthe phone screen is on and he is viewing the phone and he is\nwalking toward the crossing (Level 1).\nSaferCross consists of \u001cve main system modules, namely\nLocation, Energy, Context, Alert, and Communication\n(Fig. 3(a)). Speci\u001ccally, the Location module is developed\nto improve the positioning accuracy of the pedestrian. The\nresulting pedestrian location information is distributed to\nother system modules. The Energy module is designed to\nsave energy by adaptively controlling the operation of the\nGPS module. Taking the user location as input from the Loca-\ntionmodule, the Context module identi\u001ces the user activity,\ne.g.,whether the user is walking, running, and viewing their\nphone. In particular, the module addresses the challenge of\neffectively detecting the `phone viewing' activity. The Alert\nmodule is where the collision probability is calculated. As can\nbe seen in Fig. 3(a), it interacts with the Location and\nCommunication modules to obtain necessary information\nin calculating the collision probability. The Alert module then\nmakes a decision to send an alert message to the user based\non the resulting collision probability. The Communication\nmodule enables P2P communication between pedestrians and\napproaching cars using WiFi Direct.\nTo explain the operation of SaferCross in more detail,\na \u001dowchart (Fig. 3(b)) is used. When the system is started,FIGURE 3. (a) System structure of SaferCross; (b) Flow chart representing the operation of SaferCross.\nit identi\u001ces whether the user is a driver or not. For this,\nwe adopt an existing driver phone detection algorithm [25].\nIf the user is a driver, using WiFi Direct, SaferCross starts\nto scan on the predetermined channel to be connected with\npedestrians. Once it is connected, SaferCross sends the\nvehicle information to the pedestrian so that the pedestrian\ncan calculate the collision probability. More speci\u001ccally,\ntheautonomous mode of WiFi Direct is adopted to mini-\nmize the connection establishment time and to alert the user\ntimely [19].\nIf the user is a pedestrian, the Location module is activated\nto obtain the calibrated user location. This location informa-\ntion is distributed to the Energy, Context, and Alert mod-\nules. The Energy module in turn \u001cnds if the user is located\nwithin an alert zone, a region around a crossing\u0015detailed\ndescription about the alert zone will be presented when we\nexplain the Energy module in Section III-C. If the user is\nin an alert zone, the Context module kicks in and detects\nwhether the user is actually walking/running while viewing\ntheir phone. If the phone-viewing-event is detected, the Con-\ntextmodule triggers the Communication module. And then\ntheCommunication module is used to create a P2P group\nfor Wi-Fi Direct to initiate communication with cars and\nobtain necessary information for the Alert module to perform\nrisk assessment. Notations used to explain the modules of\nSaferCross throughout this paper are summarized in Table 1.\nB. IMPROVING POSITIONING ACCURACY\nAttaining high positioning accuracy of the pedestrian is cru-\ncial for SaferCross to estimate the collision probability\naccurately and alert the pedestrian timely. However, achiev-\ning precise localization using the GPS module of smartphone\nis a challenging problem, especially in urban canyons with\nsigni\u001ccant multipath and non-line-of-sight effects. To under-\nstand the localization accuracy of the smartphone that we\nFIGURE 4. Location measurement in a metropolitan area. The result\ndemonstrates significantly large location errors in a typical city\nenvironment.\nused in our experiments, we collected GPS locations in a\nmetropolitan area. Fig. 4shows the collected GPS locations.\nThe red-colored dots represent the measured GPS locations.\nThe green arrow indicates the ground-truth trajectory. The\nmean location error was very large as 12.9m.\nThe Location module of SaferCross is designed to\nimprove the positioning accuracy. It \u001cnds highly erroneous\nGPS locations and replaces them with newly estimated loca-\ntions. The Location module is developed based on the obser-\nvation that pedestrians walk along a sidewalk, and therefore\na GPS location that is geographically far from a sidewalk can\nbe considered as an outlier. Speci\u001ccally, a Hidden Markov\nModel-based map matching algorithm is designed to infer\nthe current sidewalk segment using preceding user locations\nand to remove/replace erroneous GPS locations. In contrast\nto existing map matching algorithms, an unique approach is\ndeveloped speci\u001ccally for `slow-moving' pedestrians. Fig. 5\ndepicts an overview of the Location module. The currentTABLE 1. Notations used in this paper.\nFIGURE 5. Overview of the Location module of SaferCross. The module is\ndeveloped based on a customized map matching algorithm.\nGPS location is provided as input to the map matching algo-\nrithm. The algorithm then estimates the current sidewalk seg-\nment based on the preceding user locations. Once the current\nsidewalk segment is identi\u001ced, the algorithm calculates the\nlocation error and rejects or replaces the GPS location with a\nnewly estimated location.\nTheLocation module identi\u001ces the current sidewalk seg-\nment using a Hidden Markov Model (HMM). Let us de\u001cne a\nset of states SDfr 1;r2;:::; rNgwhere each state represents\na sidewalk segment with Nbeing the total number of states.\nNote that only the sidewalk segments in the surrounding area\nof the current user location are considered in \u001cnding the cur-\nrent sidewalk segment in order to reduce the computational\noverhead. Now we exploit HMM to \u001cnd the most probable\nsidewalk segment ri2S;1\u0014i\u0014Ngiven the observation\nof a set of the preceding GPS locations in a sliding window\nexamined at time t, which is denoted by Zt. A unique aspect\nof the proposed map-matching algorithm based localization\nmethod compared to other map matching algorithms is that a\nset of preceding locations are taken into account rather than\na single location to account for the low speed of a pedestrian.More formally, a HMM is modeled as \u0015D(S;Zt;A;B;\u0019),\nwhere Sis the state set. Ztis an observation that is represented\nas a sliding window of size !consisting of the preceding GPS\nlocations, i.e., Z tDfz 1;:::z!g, where zjis a GPS location\nmeasured at time j.Ais the observation probabilities denoted\nbyP(Z tjri);1\u0014i\u0014N. It de\u001cnes the likelihood that the\nuser is actually on sidewalk segment ri.Bis the transition\nprobabilities denoted by P(rjjri);i6Dj(i;jD1:::N).\nIt represents the likelihood of the user moving from one\nsegment rito another rj.\u0019is the initial state probabilities\nwhich are de\u001cned as P(Z1jri);1\u0014i\u0014N.\nThe probability models A,B, and\u0019are designed to decide\nthe most probable current sidewalk segment. First, the obser-\nvation probabilities Aare computed based on the fact that a\nGPS location geographically far from the current sidewalk\nsegment is less likely to occur [26]. An observation probabil-\nityP(ztjri) for a GPS location ztthus can be modeled as the\nprobability distribution of the geodetic distance between zt\nandzt;i. Here zt;iis the geographically closest location from\non a sidewalk segment rifrom zt. Let us denote this geodetic\ndistance byjzt\u0000zt;ijgeo. Since the geodetic distance repre-\nsents the GPS positioning error which is known to follow the\nzero-mean Gaussian [27], the observation probability can be\nwritten asV\nP(ztjri)D1p\n2\u0019\u001b ze\u00000:5(jzt\u0000zt;ijgeo\n\u001bz)2; (1)\nwhere\u001bzis the standard deviation of GPS measurements,\nwhich can be obtained empirically. Note that our system regu-\nlarly updates \u001bzbased on previously measured GPS locations\nsince\u001bzmay change depending on the environment. Now\nconsidering a set of GPS locations ZtDfz 1;:::z!gstored in\na sliding window, the observation probabilities ADP(Z tjri)\ncan be de\u001cned as follows.\nP(Z tjri)DP!\ntD1P(ztjri)\n!; (2)\nwhich represents the likelihood that the user is on sidewalk\nsegment rigiven the set of preceding GPS positions Zt.\nNext we model the transition probabilities Bwhich de\u001cne\nthe likelihood that the user transitions to another sidewalk\nsegment. For this, let us de\u001cne the moving distance between\ntwo GPS locations ztandztC1, denoted byjztC1\u0000ztjmov. The\nmoving distance refers to the geographic distance between\nthe two GPS locations along the shortest sidewalk trajec-\ntory. Fig. 4 illustrates the geodetic and moving distance\nbetween two GPS locations ztandztC1. Newson and Krumm\nnoted that the transition probability depends on the difference\nbetween the moving distance and the geodetic distance [26].\nMore speci\u001ccally, the transition probability becomes higher\nwhen the difference is larger, and vice versa. It was also\nshown by [26] that the difference follows the exponential\ndistribution. A trick that we make to account for the slow\nmoving speed of the pedestrian is to use the GPS location\nmeasured\u000ftime ago (i.e., z t\u0000\u000f) rather than using the preced-\ning GPS location (i.e., z t\u00001) in calculating the moving and\ngeodetic difference. Now by denoting the distance difference\nas\u000eDjjz t\u0000zt\u0000\u000fjmov\u0000jz t\u0000zt\u0000\u000fjgeoj, we obtain p(\u000e)D1\n\fe\u0000\u000e\n\f.\nFinally, since the transition probabilities Bdepend on the\ndistance difference, we obtain: BDP(rjjri)\u0019p(\u000e). We also\nnote that using Eqs. 1and2, the initial state probabilities\n\u0019DP(Z1jri) can be easily calculated. Given these prob-\nability models A,B, and\u0019, the proposed map matching\nalgorithm identi\u001ces the current sidewalk segment. Once the\ncurrent sidewalk segment is identi\u001ced, the ``valid'' region is\ncalculated. Any GPS location that is outside this region is\neither rejected, or projected onto the region. More precisely,\nthe width of the region is de\u001cned as `\u000b \u0001(max walking speed) \u0001\n(GPS measurement interval)' and the height of it is de\u001cned as\n`\u000b\u0001(the sidewalk width)'. Here, the parameter \u000bis adopted to\nallow the user to adjust the tolerance to location errors. In our\nexperiments, we used 15m as the threshold to reject a GPS\nlocation. If the distance between a measured GPS location\nand the valid region is greater than 15m, we rejected the GPS\nlocation, and if not, the GPS location is projected onto the\nclosest point on the valid region.\nC. IMPROVING ENERGY EFFICIENCY\nThe GPS module of smartphone is one of the most power hun-\ngry sensors [28]. We develop the Energy module to improve\nthe energy ef\u001cciency of SaferCross that heavily utilizes\nthe GPS module. To characterize the energy consumption\nof the Location module of SaferCross, an experiment was\nperformed using the Monsoon Power Monitor [29]. Fig. 6\nshows the experimental setup. We connected the power mon-\nitor's probes to the phone's battery terminals so that the\nmonitor provides current to the phone. And then, a laptop\nwas connected to the power monitor via USB and mea-\nFIGURE 6. Experimental setup for power measurement. The power\nmonitor is directly connected to the phone's battery terminals.\nFIGURE 7. Power consumption of the GPS module. The result indicates\nthat significant energy savings are possible by adaptively activating the\nGPS module.\nsured the samples of current drawn and the voltage at a rate\nof 5KHz.\nFig. 7 shows that a large amount of power was consumed\nfor a short period of time when the app was started to load\nand display the app on the screen. After that, the app used\nabout 1.5 watt for updating and calibrating the position.\nAn interesting observation was that the GPS module con-\nsumed very a small amount of energy, as low as the baseline\nenergy consumption, when the GPS module was put into\nthe sleep mode, indicating that signi\u001ccant energy savings\ncan be achieved by putting the GPS module into the sleep\nmode. It is worth to note that the sleep mode depends on\nmobile operating systems. For example, by the sleep mode\nin Android, we mean that we stop receiving position update,\nwhile the GPS module maintains the lock on the acquired\nsatellites, so that when we resume position update, the GPS\nmodule does not need to re-acquire and lock on satellites.\nTheEnergy module determines dynamically when to turn\non the GPS module and when to put it into the sleep mode.\nTo explain the mechanism, we need to de\u001cne the alert zone.\nThe alert zone is a 2D region, the boundary of which is\nequidistant from a nearest crosswalk (Fig. 8). This alertFIGURE 8. An illustration of an alert zone which is a 2D region,\nthe boundary of which is equidistant from a nearest crosswalk. The\nsystem components of SaferCross are activated when the user is within\nan alert zone.\nzone is important for SaferCross as system components\nare activated only when the user is within an alert zone.\nAn interesting aspect of this alert zone is that it can also\nbe set up for non-crosswalk areas to prevent accidents for\njaywalkers. The basic mechanism for saving energy is to\nestimate the time when the user will be at an alert zone and\nput the GPS module into the sleep mode until that time. More\nspeci\u001ccally, the estimated time is calculated asd\nvmaxwhere\ndis the shortest geodetic distance between the current user\nlocation and the closest alert zone, and vmaxis the maximum\nbrisk human walking speed [30]. An interesting aspect of\ntheEnergy module is that GPS is adaptively controlled in\ncoordination with the provided map and the associated alert\nzones, considering the user walking direction. The walking\ndirection can be monitored even if the GPS is off based on\na known technology [31] so that the GPS will be turned\nback on when the user direction is reversed to re-estimate the\ntime.\nD. DETECTING PEDESTRIAN PHONE USE\nThe Context module is developed to effectively detect\nthe user- phone-viewing event. However, detecting the\nphone-viewing event is hard because it is associated with lim-\nited user interactions such as tapping on the phone. There is\nan approach that utilizes the camera of the phone to detect the\nphone viewing event by recognizing the user's face/eyes [32].\nA limitation of this approach is the privacy concerns. Fur-\nthermore, the phone orientation information is insuf\u001ccient\nto determine whether the user is viewing the phone or\nnot.\nIn order to develop a novel approach for detecting the\nphone-viewing event, we hinge on the observation that when\nthe user views their phone while walking, they tend to try\nto minimize phone shaking to better read email/text mes-\nsages, and watch videos. Based on this motivational obser-\nvation, we quantify phone shaking using the variance of the\nacceleration magnitude of phone. We then use the quanti-\n\u001ced data to detect the phone-viewing event. More precisely,\ngiven an accelerometer reading (a x;ay;az) of phone in x,\ny, and zdirections respectively, we remove random noise\nFIGURE 9. MAD values measured with a 10sec window. The two events\nare clearly distinguished.\nusing the standard low-pass \u001cltering. As a result, we obtain\n\u001cltered accelerometer data denoted by Oax;Oay;Oaz. The mag-\nnitude of the acceleration vector mis then calculated as\nmDq\nOax2COay2COaz2.\nA sliding window WDfm 1;m2;:::m\u001egis used to store\na sequence of acceleration magnitude values collected over\na period of time. The variation of the magnitude values in a\nwindow is represented as the mean absolute deviation (MAD)\nwhich is used to quantify the shaking of phone. Fig. 9 displays\nan example of MAD values for both phone-viewing and\nnon-viewing events with a 10-sec sliding window. Leveraging\nthe clear difference between the MAD values of the two\nevents, we design a simple threshold-based method to detect\nthe phone-viewing event. More speci\u001ccally, a threshold 0is\nde\u001cned as the average of the mid points of MAD values for\nphone-viewing event and non-phone viewing event. Given\ntraining data, i.e.,the MAD values for the phone viewing\nevent XDfx 1;x2;:::; xng, and the MAD values for the non-\nphone-viewing event YDfy 1;y2;:::; yng, the threshold is\ncalculated asP\niD1::n (yiCxi\n2)\nn. A more advanced AI-based and\ndynamic mechanism to determine the threshold is left as a\nfuture work.\nAn experiment was performed to evaluate the feasibility\nof the proposed approach. Five volunteers participated in\nthis experiment. They were asked to walk with viewing their\nphones. They were also asked to walk without viewing their\nphones. Figs. 9 and 10 show the results for different sizes\nof the sliding windows, i.e.,10sec and 20sec, respectively.\nAs it can be seen, MAD values for the phone-viewing sce-\nnario were signi\u001ccantly smaller than that for the non-phone-\nviewing scenario, allowing us to clearly differentiate the two\nscenarios. The proposed method turns out to be quite accurate\nwith detection accuracy over 90%.\nIt is also worth to note that since the Context module is\nonly activated when the user is within an alert zone, and the\naccelerometer consumes signi\u001ccantly less amount of power\nthan the GPS module, the energy ef\u001cciency issue for the\nContext module is less critical than the Location module.FIGURE 10. MAD values measured with a 20sec window. The two events\nare more clearly distinguished with a larger window size.\nE. DETERMINING WHEN TO ALERT THE USER\nTheAlert module of SaferCross is developed to determine\nwhen to alert the user by estimating the collision probability.\nThis module is activated when the user is within an alert zone.\nIt sends a REQ message to approaching vehicles via WiFi\nDirect. In response to the REQ message, vehicles send a REP\nmessage to the user. The REP message contains information\nrequired to estimate the collision probability including the\nvehicle speed vc, vehicle mass m, cross-sectional area of the\nvehicle A, and time for the vehicle to reach the crossing\ndenoted by tc(Fig. 11). The vehicle and the pedestrian keep\nexchanging these messages to update the collision probability\nin real time to account for the changing motion of the vehicle\nand the user.\nIn estimating the collision probability, the time for the\npedestrian to reach at the crossing is calculated, i.e., t pDdp\nvp\nwhere dpis the shortest geodetic distance between the pedes-\ntrian and the crossing, and vpis the user walking speed. The\nAndroid context API is used to determine vp. Speci\u001ccally,\nwe use a brisk walking speed [30] when the API detects\nthat the user is walking; if the user is running, vpis set to a\npredetermined running speed. In particular, if the user is not\nwalking or running, the collision probability is not calculated.\nIt is important to note that to provide the near real-time\ncomputation of the collision probability, when the user in an\nalert zone, the calculation of the current sidewalk segment of\ntheLocation module is suppressed, which is based on the\nobservation that the user stays in the same sidewalk segment\nwhen she is in the same alert zone.\nGiven vc,m,tc,A, and tp, the Alert module is ready to\nestimate the collision probability. Let vc(i),m(i), tc(i), and\nA(i) be the vehicle speed, vehicle mass, amount of time to\nreach at a crossing, and cross-sectional area for vehicle i,\nrespectively. If tp\u001dmax(t c(i));8i,i.e.,if the user is expected\nto reach at the crossing long after all approaching vehicles\nhave passed, the user is not alerted. On the other hand,\niftp<max(t c(i));9i,i.e.,there is at least one approaching\nvehicle around the crossing by the time the user reaches at\nthe crossing, the module estimates the collision probability.\nFIGURE 11. An illustration of how the Alert module works. The message\nexchanged between the pedestrian and the driver contains information to\nestimate the probability of collision.\nConsequently, if the following two conditions are satis\u001ced,\nan alert message is generated for the user: (a) The pedestrian\nis walking/running while viewing the phone; (b) The prob-\nability of collision is greater than a threshold. Note that the\nestimation of the collision probability is continually updated\nas the REQ and REP messages are kept being exchanged\nbetween vehicles and the user. Thus, if there is any new vehi-\ncle within the range of WiFi Direct, the collision probability\nfor that new vehicle will be calculated and updated.\nMore details are presented on how the collision probability\nis calculated. First, we de\u001cne a term `user warning time'\ndenoted by twarningDmin(t c(i))\u0000tpthat represents the\namount of time allowed for the driver to avoid an accident\nafter he sees the pedestrian who is about to cross the street.\nAnd then, the collision probability is estimated as P(tdelayC\ntreactCtskid>twarning ), where tdelayis the round-trip message\ndelay for a single-hop 802.11 link. treactis the driver reaction\ndelay, and tskidis the amount of time from the point when the\ndriver applies brakes until the car completely stops. If the sum\nof these time delays is greater than twarning , the likelihood of\ncollision is deemed high. In particular, we disregard the WiFi\nDirect connection establishment time since the connection\nhas been already established before the \u001crst alert message is\nsent from the user to the approaching cars.\nMore speci\u001ccally, tdelay is empirically obtained as the\npedestrian continuously exchanges messages with approach-\ning vehicles, i.e., t delayis the average of measured round-trip\nmessage delays. In calculating treact, we leverage the obser-\nvation that the log-normal probability model \u001cts the driver\nreaction time well [33]. Thus, treactis de\u001cned based on the\nlog-normal distribution [34] as followsV\nf(xj\u0016;\u001b )D1\nx\u001bp\n2\u0019e\u0000(ln x\u0000\u0016)2\n2\u001b2; (3)\nwhere we select the mean and standard deviation of the driver\nreaction time as \u0016D1:14 and\u001bD0:32, respectively accord-\ning to the experimental data collected by Gaziz et al. [35].\nTo calculate tskid, we \u001crst compute dskidthat is the distance\nthat a car moved until it is completely stopped after brakes are\napplied as follows: dskidDmv2\np\n2f, where mis the vehicle mass,\nandvpis the vehicle speed, which we obtain from the REP\nmessage. fis the resistance force, which is calculated basedon the model proposed by Ho and Chen [24].\nfD\u0016kmgC\u001aACdv2\nr\n2Cf0; (4)\nwhere\u001ais the density of air, Ais the cross-sectional area\nof the vehicle, Cdis the drag coef\u001ccient, vris the speed of\nthe vehicle relative to the air, and f0is the other resistance\nforce. In our experiments performed on a sunny day on a good\nconditioned road with Volkswagen Passat 2013, we used the\nparameter: mD1400kg,\u0016kD0:8,AD2:7m2,CdD0:25,\n\u001aD1:23kg=m3according to [36]\u0015[38]. vrwas approximated\nas the current vehicle speed vdue to the slow wind speed.\nThus, tskidDdskid\nv.\nOnce tdelay,tskid, and twarning are known, the collision\nprobability can be written as: P(treact>twarning\u0000tdelay\u0000tskid)\nwhich can be calculated leveraging the fact that treactfollows\nthe log-normal distribution speci\u001ced in Eq. 3. Note that we\nare very careful in sending an alert message to approaching\ncars. The reason is that alert messages may disturb safe driv-\ning. In designing the Alert module, thus, we give an emphasis\non alerting the user \u001crst in an hope that the user will stop and\nlook up when they receive the alert message. However, if the\nuser ignores the alert message (e.g., by clicking the cancel\nbutton), an alert message is eventually sent to the driver.\nF. ENABLING COMMUNICATION BETWEEN PEDESTRIAN\nAND CARS\nTo enable direct communication between the user and\napproaching cars, WiFi Direct is used. WiFi Direct is a\nstandard designed by the WiFi alliance to facilitate device-\nto-device (D2D) communication between nearby devices\nwithout involving an access point [19]. In WiFi Direct,\ndevices communicate by establishing a group. One of them\nis the group owner (GO), and the others are the group mem-\nbers (GM). These roles are negotiated by the devices in the\ndevice discovery phase. The GO implements the AP-like\nfunctionality, and the GMs act like clients. Speci\u001ccally,\nthe GO advertises to its GMs and allows new GMs to join\nthe group. The GO runs a Dynamic Host Con\u001cguration Pro-\ntocol (DHCP) server to provide IP addresses to joining GMs\nafter going through the WiFi Protected Setup (WPS) phase.\nInSaferCross, the pedestrian is the GO, and approaching\ncars are the GMs. An approaching car scans a prede\u001cned\nchannel to search for the GO. Once the GO is discovered,\nthe car joins the group immediately. There are two main chal-\nlenges. The \u001crst one is that these scanning and negotiation\nprocesses take too much time. The literature shows that it can\ntake about 8 to 9 seconds [19]. Fortunately, WiFi Direct pro-\nvides the autonomous mode in which the negotiation process\nis not required as the GO is predetermined. The autonomous\nmode \u001cts perfectly with SaferCross because there are clear\nroles, i.e.,the user and the cars. Our experiments show that\nthe average time to form a group in the autonomous mode is\n2.8 seconds, which coincide with the results of the previous\nresearch [19].\nFIGURE 12. A department parking lot used as an experimental site. The\nacceleration zone is used to reach the desired vehicle speed.\nAnother challenge is that WiFi Direct is essentially\ndesigned to support 1-to-1 or 1-to-many communication. For\nexample, consider Fig. 11in which the user PedAforms a\ngroup (1-to-many) with two cars Car AandCar B. However,\nthere may be other users around, say PedBin this \u001cgure who\nwants to communicate with the cars. Basically, the challenge\nis how to allow the GMs (cars) to join more than one groups.\nAccording to the WiFi Direct Speci\u001ccation, operating GMs\nfor more than one groups is not precluded, but the implemen-\ntation is not described [39].\nWe address this challenge by allowing the user to overhear\non the operating channel for a very brief moment, if the user\nis not the GO. For example, PedBoverhears the message\nexchanges between PedAand the cars. PedBthen \u001cnds that\nthe cars have already formed a group with PedA. Since there\nis already a group, PedBjoins as a GM and communicates\nwith PedAinstead of the cars. Now the trick is that the REP\nmessages received from the GO (i.e., Ped A) are forwarded to\nPedB. As a result, although PedBis not the GO, it still can\nreceive the vehicle information that it needs to compute the\ncollision probability. Essentially, the proposed solution effec-\ntively establishes the virtual n-to-n communication based on\na single group.\nIV. EXPERIMENTAL RESULTS\nWe implemented SaferCross on a Samsung Galaxy\nS6 which is equipped with 1.5GHz octa-core processor and\n3GB RAM running on Android 5.0. We performed exper-\niments in a department parking lot (Fig. 12). To charac-\nterize the experimental environment, the packet delivery\nrates (PDR) were measured for both Pedestrian !Driver,\nand Driver!Pedestrian. The average PDR was over 90%\nwhen the distance between the car and the pedestrian was\nsmaller than 60m (Fig. 13). Based on the results, the length\nof the emulated road segment was set to 75m including the\n20m acceleration zone.\nA driver ran SaferCross in the driver mode. A Volk-\nswagon Passat'13 was used which moved along the 75m\nroad segment. The driver was asked to accelerate the car\nto reach the desired vehicle speed in the 20m accelera-\ntion zone (Fig. 12). After reaching the desired speed, theFIGURE 13. PDR for WiFi Direct in the experimental site. The length of the\nroad segment was determined based on the measured PDR.\nvehicle's cruise control was used to maintain the same speed.\nAnother participant was asked to act as a pedestrian with\nSaferCross in the pedestrian mode and walk toward the\ncrossing. To ensure safety, we made sure that the pedestrian\nalways stops at the crossing.\nWe performed the module-level test \u001crst to evaluate the\nperformance of individual system components. We then con-\nducted the integrated test to evaluate the overall performance\nofSaferCross. The main parameter used for this experiment\nwas the vehicle speed, and we used the `user warning time'\ntwarning as the main metric because it effectively measures the\nperformance of SaferCross as a whole. Speci\u001ccally, we can\nget the accurate user warning time only if all other system\ncomponents work correctly and the interplay of these compo-\nnents functions effectively. The measured user warning time\nwas compared with the ground truth data.\nThe experimental environment serves effectively the pur-\npose of evaluating the performance of SaferCross in com-\nparison with conducting the experiment in real roads. The\nindividual module test can be done readily without account-\ning for real traf\u001cc conditions. Also, the integrated test would\neffectively approximate the performance of SaferCross in\nreal roads, because eventually the pedestrian maintains com-\nmunication only with the foremost vehicle for estimating the\ncollision probability regardless of the traf\u001cc of approaching\nvehicles, and the vehicle used in the experiment effectively\nrepresents the foremost vehicle. It should be noted, however,\nthat in order to understand better the effect of other real-world\nfactors such as obstacles, weather conditions, lighting con-\nditions, and human factors, performing experiments in real\nroads would be valuable. Due to the space limitation and\nrestricted access to public roads, we had to leave the extension\nof the experiment as future work.\nA. POSITIONING ACCURACY\nPositioning accuracy was measured in both rural and city\nareas without using the Location module \u001crst. Five differ-\nent trajectories were used in each area. In each experiment,\nFIGURE 14. CDF of measured location error. The results show that the\nLocation module significantly improves the positioning accuracy.\na participant was asked to walk along the trajectories to\nmeasure the GPS locations and calculate the location errors.\nSpeci\u001ccally, the location error was de\u001cned as the shortest\ngeodetic distance from the measured GPS location to the\nground-truth trajectory. Fig. 14 shows the cumulative distri-\nbution graph of the location errors for both the rural and city\nenvironments. The mean location error for the rural area was\n0.9m. The location error for the city area was signi\u001ccantly\ngreater than the rural area as 12.9m due to many obstacles\nthat disturbed reception of signals from satellites.\nTo improve the localization accuracy, the Location module\nwas activated, and the experiment was performed under the\nsame conditions. In particular, other system modules were\nturned off in order to focus on evaluating the effectiveness\nof the Location module. The results show that the Location\nmodule signi\u001ccantly reduced the location errors (Fig. 14).\nThe average location errors for the rural and city areas\nafter applying the Location module were 0.8m and 3.5m,\nrespectively. Although the improvement was not signi\u001ccant\nfor the rural area because the location accuracy was already\nhigh without the Location module, the module success-\nfully decreased the location error by 72% in the urban area.\nOf course, an average error of 3.5m in the urban area is not\nnegligible; yet, it can be compensated by increasing the size\nof the alert zone, i.e.,by providing an alert message to the\nuser a bit early.\nB. ENERGY EFFICIENCY\nWe evaluate the performance of the Energy module focusing\non two key questions: (1) Is GPS reactivated timely, and (2)\nhow much energy savings are achieved. To answer the \u001crst\nquestion, we measured the shortest geodetic distance between\nthe pedestrian and the alert zone when GPS was reactivated\nby the Energy module. If the distance is small, it means that\nGPS is reactivated timely. This experiment was performed\nwith both the actual walking speed and the brisk walking\nspeed. The actual walking speed was measured by asking the\nparticipant to walk for 5mins. Fig. 15shows the histogram\nof the actual walking speed. We then calculated the average\nwalking speed and integrated it into the Energy module.FIGURE 15. The histogram of walking speed data. The data was used by\nthe Energy module in the experiments.\nFIGURE 16. A scenario designed for measuring energy savings by using\nthe Location module. The alert zones are set up around the crossings.\nThe pedestrian was asked to walk from 30 meters away\nfrom the alert zone toward the alert zone. We then measured\nthe geodetic distance when GPS was reactivated. The results\nare shown in Fig. 15. The shortest geodetic distance between\nthe pedestrian and the alert zone was about 1m when the\naverage of the actual walking speed was used by the module.\nIn contrast, when the module used the brisk walking speed,\nthe shortest geodetic distance was about 4m. The results may\nseem that using the actual walking speed for estimating the\ntime to reactive GPS is better. However, we note that reac-\ntivating GPS several seconds early actually would not affect\nmuch the energy ef\u001cciency, and in fact, it could improve the\nsafety of the pedestrian since other system components are\nactivated several seconds early to allow for more time for the\npedestrian to respond to the alert message.\nAssuming the brisk walking speed, we evaluated energy\nsavings resulting from the Energy module.\nWe then performed experiments to understand how much\nenergy savings can be achieved. In this experiment, we used\nthe brisk walking speed. Speci\u001ccally, we created 8 alert zones\nalong a 850m sidewalk and asked the pedestrian to walk along\nthe sidewalk repeating 5 times (Fig. 16). In this experiment,\nonly the Location module was turned on to provide the cal-\nibrated location information. We then measured energy con-\nsumption with and without the Energy module. The results\nare depicted in Fig. 17demonstrating that Location module\ndecreased energy consumption by 50.2%.\nC. CONTEXT DETECTION ACCURACY\nWe measured the accuracy of detecting the phone viewing\nevent. The accuracy is de\u001cned as the sum of true positives\nand true negatives divided by the total number of event\nFIGURE 17. Energy savings by using the Energy module. The results\nindicate that significant energy savings are achieved by using the Energy\nmodule.\ndetection. In this experiment, 7 volunteers participated. They\nwere asked to walk with and without viewing their phones for\n10mins each to collect the training data.\nThe size of the sliding window is determined before mea-\nsuring the accuracy. We should choose the sliding win-\ndow size that makes clear distinction between the phone\nviewing and non-phone viewing events. To quantify how\nwell the two events are differentiated, a new metric 1D P\niD1::n (jyi\u0000xij)\nnis de\u001cned, where XDfx 1;x2;:::; xngandYD\nfy1;y2;:::; yngare MAD values for the phone-viewing and\nnon-phone-viewing events, respectively. Thus, higher 1val-\nues are preferred because it will lead to higher event detection\naccuracy due to the fact that the two events are more clearly\ndifferentiated. However, note that higher accuracy does not\nnecessarily mean higher 1values because the phone-viewing\nevent will be detected even if the difference between the\nMAD values of the two events is small, which is the reason\nwhy this new metric is de\u001cned to determine the window size.\nTo decide an appropriate window size, we measured 1by\nvarying the window size. Fig. 18 shows the results which\nindicate that using a larger window distinguishes the two\nevents better because of more samples contained in the win-\ndow. A downside of using a large window size is, however,\nthe increased delay to \u001cll up the window with samples.\nAn interesting observation is that even if we use a small\nwindow,1does not decrease too much. For example, 1for\nthe window size of 3sec is only 12% smaller than that for the\nwindow size of 60sec. In this experiment, we decided to use\nthe window size of 3sec.\nWith the window size, we measured the event detection\naccuracy. This time the volunteers were asked to walk with\nand without viewing their phones for another 5 mins. Fig. 18\nshows the results. The accuracy was varied depending on the\nindividual as each participant had a different walking style.\nHowever, it can be noted that the accuracy for all participants\nwas greater than 90%, validating that the Context module\neffectively detects the phone viewing event.\nD. INTEGRATED TEST\nWe perform an integrated test to evaluate the performance of\nSaferCross as a whole by putting together all the individual\nmodules. We use the user warning time twarning as a main\nmetric for performance evaluation based on the observation\nthat accurate twarning can only be obtained if all system mod-\nules perform effectively. Speci\u001ccally, in this experiment, tc\nandtpwere recorded to calculate the user warning time, i.e.,\njtc\u0000tpj. However, measured twarning may be different fromFIGURE 18. Effect of the window size on the accuracy of detecting the\nphone viewing event. The accuracy is over 90% for all participants.\nFIGURE 19. The ground-truth distance to the crossing. It varies due to the\nnondeterministic nature of the user walking speed, GPS locations, and\nmessage delay.\nthe ground-truth time to collision denoted by tGT\nwarningdue to\nvarious factors such as the positioning error (for both the car\nand the pedestrian), processing delay, and transmission delay\nfor delivering the warning message to the driver. We focus on\ncapturing the difference, i.e.,jtwarning\u0000tGT\nwarningin evaluating\nthe overall system performance.\nIn this experiment, a participant was asked to walk toward\nthe crossing while viewing his smartphone. At the same time,\na driver was asked to drive a car toward the crossing. twarning\nwas measured for different vehicle speeds. For each vehicle\nspeed, we repeated measurement of twarning \u001cve times and\nobtained the average value of twarning . At the same time, the\nlocations where an alert message was actually sent (pedes-\ntrian) and received (driver) were recorded based on an LED\nindicator and a camera to calculate tGT\nwarning. Fig. 19 shows\nthe ground-truth distance to the crossing when the vehicle\nreceived an alert message, which varies due to the nondeter-\nministic nature of the user walking speed, GPS locations, and\nmessage delay.\nFig.20shows the user warning times for different vehi-\ncle speed and the corresponding probabilities of collision.\nThe \u001cgure also shows the ground-truth user warning time.\nThe results indicate that when the vehicle speed was high,\nFIGURE 20. User warning time and collision probability. The estimated\nuser warning time is very close to the ground-truth value. The difference\ncan be used to calibrate SaferCross for better pedestrian safety.\nthe vehicle was closer to the crossing when the alert message\nwas generated, leading to the small user warning time and\ngreater collision probability. We compared the measured user\nwarning time calculated based on tcandtpwith the ground\ntruth user warning time. The difference was between 0sec\nand 3sec, and the average difference was 1.6sec. Although\nthe max difference of 3sec is a non-negligible amount of time\nconsidering the fast moving vehicle, it can be compensated\nby con\u001cguring the system to \u001cre an alert message several sec-\nonds early.\nV. CONCLUSION\nWe have presented SaferCross, a \u001crst fully functioning\nprototype mobile system for preventing distracted phone use.\nWe develop critical system components for mobile systems\nfor pedestrian safety focusing on the positioning accuracy,\nenergy ef\u001cciency, activity detection, and effective risk assess-\nment, laying the foundation for future research and devel-\nopment of mobile systems for pedestrian safety. We demon-\nstrated that SaferCross effectively performs risk assessment\nof pedestrian safety via systematic integration of various\nsoftware components for pedestrian positioning, phone use\nactivity detection, energy ef\u001cciency, and car-to-pedestrian\ncommunication. We expect that the technical contributions\nmade in this paper will be useful assets for various other\ntransportation research involving pedestrians. A potential\nextension of this work is to enhance the pedestrian positioning\naccuracy as well as the proposed energy ef\u001cciency algorithm\nutilizing the recently arising 5G network [40]. Another inter-\nesting future direction is to understand how pedestrians and\ndrivers respond to a warning sent by the proposed system,\nwhich is an important research problem as noted by a recent\nresearch [41] that pedestrians tend to reduce their attention\nwhen receiving a warning, and they sometimes do not respond\nto a warning once they initiated a crossing.\nREFERENCES\n[1] NHTSA. (2015). Traf\u001cc Safety Facts. Accessed: Sep. 1, 2019. [Online].\nAvailable: https://crashstats.nhtsa.dot.gov/Api/Public/ViewPublication/\n812375[2] MarketWatch. (2019). Inattention is Leading Cause of Deadly Pedestrian\nAccidents in el Paso. Accessed: Sep. 1, 2019. [Online]. Available:\nhttps://kfoxtv.com/news/local/inattention-leading-cause-of-deadly-\npedestrian-accidents-in-el-paso-say-police\n[3] Fox TV. (2019). Pedestrian Deaths Could Hit a 30-Year High.\nAccessed: Sep. 1, 2019. [Online]. Available: https://www.marketwatch.\ncom/story/pedestrian-deaths-could-hit-a-40-year-high-2019-02-28\n[4] C. Tribune. (2019). Look Up From Your Phone: Pedestrian Deaths\nHave Spiked. Accessed: Sep. 1, 2019. [Online]. Available: https://www.\nchicagotribune.com/news/opinion/editorials/ct-edit-pedestrian-deaths-\nrise-20190301-story.html\n[5] C. H. Basch, D. Ethan, P. Zybert, and C. E. Basch, ``Pedestrian behavior at\n\u001cve dangerous and busy manhattan intersections,'' J. Community Health,\nvol. 40, no. 4, pp. 789\u0015792, Aug. 2015.\n[6] L. L. Thompson, F. P. Rivara, R. C. Ayyagari, and B. E. Ebel, ``Impact\nof social and technological distraction on pedestrian crossing behaviour:\nAn observational study,'' Injury Prevention, vol. 19, no. 4, pp. 232\u0015237,\nAug. 2013.\n[7] M. Castillo. (2012). CBS News. Accessed: Sep. 1, 2019. [Online].\nAvailable: http://www.cbsnews.com/news/1-in-3-use-phones-text-while-\ncrossing-the-r oad/\n[8] AndroidPIT. (2019). If You're Not Careful, Your Smartphone May Kill\nYou. Accessed: Sep. 1, 2019. [Online]. Available: https://www.androidpit.\ncom/if-youre-not-careful-your-smartphone-may-kill-you\n[9] M.-I. B. Lin and Y.-P. Huang, ``The impact of walking while using a\nsmartphone on pedestrians' awareness of roadside events,'' Accident Anal.\nPrevention, vol. 101, pp. 87\u001596, Apr. 2017.\n[10] J. L. Nasar and D. Troyer, ``Pedestrian injuries due to mobile phone use in\npublic places,'' Accident Anal. Prevention, vol. 57, pp. 91\u001595, Aug. 2013.\n[11] AndroidPIT. (2019). If You Are Not Careful Your Smartphone May Kill You.\nAccessed: Jan. 30, 2020. [Online]. Available: https://www.androidpit.com/\nif-youre-not-careful-your-smartphone-may-kill-you\n[12] E. Duke and C. Montag, ``Smartphone addiction and beyond: Initial\ninsights on an emerging research topic and its relationship to Internet\naddiction,'' in Internet Addiction. Cham, Switzerland: Springer, 2017,\npp. 359\u0015372.\n[13] T. N. Y. Times. (2012). A Reminder to Look(!) Both Ways. Accessed:\nJan. 30, 2020. [Online]. Available: https://www.nytimes.com/2012/09/\n20/nyregion/in-new-york-city-curbside-signs-to-look-both-ways.html\n[14] A. News. (2019). Tel Aviv Deploys `Zombie Lights' for Mobile-\nObsessed Walkers. Accessed: Jan. 30, 2020. [Online]. Available:\nhttps://apnews.com/4defdfd4939e40ac9ed5ac7496f059d1\n[15] M. Fahim, T. Baker, A. M. Khattak, and O. Alfandi, ``Alert me: Enhancing\nactive lifestyle via observing sedentary behavior using mobile sensing\nsystems,'' in Proc. IEEE 19th Int. Conf. e-Health Netw., Appl. Services\n(Healthcom), Oct. 2017, pp. 1\u00154.\n[16] T. Wang, G. Cardone, A. Corradi, L. Torresani, and A. T. Campbell,\n``WalkSafe: A pedestrian safety app for mobile phone users who walk and\ntalk while crossing roads,'' in Proc. 12th Workshop Mobile Comput. Syst.\nAppl. (HotMobile), 2012, pp. 1\u00156.\n[17] X. Wu, R. Miucic, S. Yang, S. Al-Stouhi, J. Misener, S. Bai, and\nW.-H. Chan, ``Cars talk to phones: A DSRC based vehicle-pedestrian\nsafety system,'' in Proc. IEEE 80th Veh. Technol. Conf. (VTC-Fall),\nSep. 2014, pp. 1\u00157.\n[18] C.-H. Lin, Y.-T. Chen, J.-J. Chen, W.-C. Shih, and W.-T. Chen, ``pSafety:\nA collision prevention system for pedestrians using smartphone,'' in Proc.\nIEEE 84th Veh. Technol. Conf. (VTC-Fall), Sep. 2016, pp. 1\u00155.\n[19] D. Camps-Mur, A. Garcia-Saavedra, and P. Serrano, ``Device-to-device\ncommunications with Wi-Fi direct: Overview and experimentation,'' IEEE\nWireless Commun., vol. 20, no. 3, pp. 96\u0015104, Jun. 2013.\n[20] S. Jain, C. Borgiattino, Y. Ren, M. Gruteser, Y. Chen, and C. F. Chiasserini,\n``Lookup: Enabling pedestrian safety services via shoe sensing,'' in Proc.\nMobiSys, 2015, pp. 257\u0015271.\n[21] A. Fackelmeier, C. Morhart, and E. Biebl, ``Dual frequency methods for\nidentifying hidden targets in road traf\u001cc,'' in Advanced Microsystems for\nAutomotive Applications. Berlin, Germany: Springer, 2008, pp. 11\u001520.\n[22] J. J. Anaya, P. Merdrignac, O. Shagdar, F. Nashashibi, and J. E. Naranjo,\n``Vehicle to pedestrian communications for protection of vulnerable\nroad users,'' in Proc. IEEE Intell. Vehicles Symp. Proc., Jun. 2014,\npp. 1037\u00151042.\n[23] K. Dhondge, S. Song, B.-Y. Choi, and H. Park, ``WiFiHonk: Smartphone-\nbased beacon stuffed WiFi Car2X-communication system for vulnerable\nroad user safety,'' in Proc. IEEE 79th Veh. Technol. Conf. (VTC Spring),\nMay 2014, pp. 1\u00155.[24] P.-F. Ho and J.-C. Chen, ``WiSafe: Wi-Fi pedestrian collision avoid-\nance system,'' IEEE Trans. Veh. Technol., vol. 66, no. 6, pp. 4564\u00154578,\nJun. 2017.\n[25] Y. Wang, J. Yang, H. Liu, Y. Chen, M. Gruteser, and R. P. Martin, ``Sensing\nvehicle dynamics for determining driver phone use,'' in Proc. Proc. 11th\nAnnu. Int. Conf. Mobile Syst., Appl., Services (MobiSys), 2013, pp. 41\u001554.\n[26] P. Newson and J. Krumm, ``Hidden Markov map matching through noise\nand sparseness,'' in Proc. 17th ACM SIGSPATIAL Int. Conf. Adv. Geo-\ngraphic Inf. Syst. (GIS), 2009, pp. 336\u0015343.\n[27] S. S. Chawathe, ``Segment-based map matching,'' in Proc. IEEE Intell.\nVehicles Symp., Jun. 2007, pp. 1190\u00151197.\n[28] J. Paek, J. Kim, and R. Govindan, ``Energy-ef\u001ccient rate-adaptive GPS-\nbased positioning for smartphones,'' in Proc. 8th Int. Conf. Mobile Syst.,\nAppl., Services (MobiSys), 2010, pp. 299\u0015314.\n[29] Monsoon. (2018). Power Monitor. Accessed: Sep. 1, 2019. [Online]. Avail-\nable: https://www.msoon.com/\n[30] W. Bumgardner. (2018). Brisk Walking Speed. Accessed: Sep. 1, 2019.\n[Online]. Available: https://www.verywell.com/how-fast-is-brisk-\nwalking-3436887\n[31] N. Roy, H. Wang, and R. Roy Choudhury, ``I am a smartphone and i can\ntell my user's walking direction,'' in Proc. 12th Annu. Int. Conf. Mobile\nSyst., Appl., Services (MobiSys), 2014, pp. 329\u0015342.\n[32] C. Dickie, R. Vertegaal, C. Sohn, and D. Cheng, ``eyeLook: Using atten-\ntion to facilitate mobile media consumption,'' in Proc. UIST, Oct. 2005,\npp. 103\u0015106.\n[33] G. T. Taoka, ``Brake reaction times of unalerted drivers,'' ITE J., vol. 59,\nno. 3, pp. 19\u001521, 1989.\n[34] W. Feller, An Introduction to Probability Theory and its Applications,\nvol. 2. Hoboken, NJ, USA: Wiley, 2008.\n[35] D. Gazis, R. Herman, and A. Maradudin, ``The problem of the amber signal\nlight in traf\u001cc \u001dow,'' Operations Res., vol. 8, no. 1, pp. 112\u0015132, Feb. 1960.\n[36] D. R. Ankrum, ``Ivhs-smart vehicles, smart roads,'' Traf\u001cc Saf. (Chicago),\nvol. 92, no. 3, pp. 6\u00159, 1992.\n[37] R. W. Rivers, Evidence in Traf\u001cc Crash Investigation and Reconstruction:\nIdenti\u001ccation, Interpretation and Analysis of Evidence, and the Traf\u001cc\nCrash Investigation and Reconstruction Process. Spring\u001celd, IL, USA:\nCharles C Thomas, 2006.\n[38] W. Hugemann. (2002). Driver Reaction Times in Road Traf\u001cc. Accessed:\nJan. 30, 2020. [Online]. Available: https://www.unfallrekonstruktion.de/\npdf/evu_2002_reaction_english.pdf\n[39] P. T. G. Wi-Fi Alliance. (2018). Wi-Fi Peer-to-Peer (P2P) Technical\nSpeci\u001ccation, Version 1.7. Accessed: Sep. 1, 2019. [Online]. Available:\nhttps://www.wi-\u001c.org\n[40] M. Dighriri, A. S. D. Alfoudi, G. M. Lee, T. Baker, and R. Pereira, ``Com-\nparison data traf\u001cc scheduling techniques for classifying QoS over 5G\nmobile networks,'' in Proc. 31st Int. Conf. Adv. Inf. Netw. Appl. Workshops\n(WAINA), Mar. 2017, pp. 492\u0015497.\n[41] P. Rahimian, E. E. O'Neal, S. Zhou, J. M. Plumert, and J. K. Kearney, ``Har-\nnessing vehicle-to-pedestrian (V2P) communication technology: Sending\ntraf\u001cc warnings to texting pedestrians,'' Hum. Factors, vol. 60, no. 6,\npp. 833\u0015843, Sep. 2018.\nMYOUNGGYU WON (Member, IEEE) received\nthe Ph.D. degree in computer science from Texas\nA&M University at College Station, in 2013. He is\ncurrently an Assistant Professor with the Depart-\nment of Computer Science, University of Mem-\nphis, Memphis, TN, USA. Prior to joining the\nUniversity of Memphis, he was an Assistant Pro-\nfessor with the Department of Electrical Engi-\nneering and Computer Science, South Dakota\nState University, Brookings, SD, USA, from\nAugust 2015 to August 2018, and he was a Postdoctoral Researcher with\nthe Department of Information and Communication Engineering, Daegu\nGyeongbuk Institute of Science and Technology (DGIST), South Korea,\nfrom July 2013 to July 2014. His research interests include smart sensor\nsystems, connected vehicles, mobile computing, wireless sensor networks,\nand intelligent transportation systems. He received the Graduate Research\nExcellence Award from the Department of Computer Science and Engineer-\ning at Texas A&M University\u0016College Station, in 2012.AAWESH SHRESTHA received the B.S. degree\nfrom the Computer Engineering Department,\nKathmandu University, Kathmandu, Nepal,\nin 2014, and the M.S. degree from the Department\nof Computer Science, South Dakota State Uni-\nversity, Brookings, USA, in 2018. He is currently\nworking as an Associate at Deutsche Bank.\nKYUNG-JOON PARK (Member, IEEE) received\nthe B.S. and M.S. degrees in electrical engi-\nneering and the Ph.D. degree in electrical engi-\nneering and computer science from the School\nof Electrical Engineering, Seoul National Uni-\nversity, Seoul, South Korea, in 1998, 2000, and\n2005, respectively. From 2005 to 2006, he was a\nSenior Engineer with Samsung Electronics, South\nKorea. From 2006 to 2010, he was a Postdoctoral\nResearch Associate with the Department of Com-\nputer Science, University of Illinois at Urbana\u0015Champaign, Champaign, IL,\nUSA. He is currently a Professor with the Department of Information and\nCommunication Engineering, Daegu Gyeongbuk Institute of Science and\nTechnology, Daegu, South Korea. His research interests include resilient\ncyber-physical systems and smart factory.\nYONGSOON EUN (Senior Member, IEEE)\nreceived the B.A. degree in mathematics and the\nB.S. and M.S.E. degrees in control and instru-\nmentation engineering from Seoul National Uni-\nversity, Seoul, South Korea, in 1992, 1994, and\n1997, respectively, and the Ph.D. degree in elec-\ntrical engineering and computer science from the\nUniversity of Michigan, Ann Arbor, MI, USA,\nin 2003. From 2003 to 2012, he was a Research\nScientist with the Xerox Innovation Group, Web-\nster, NY, USA, where he was involved in a number of subsystem technologies\nin the xerographic marking process and image registration method in pro-\nduction inkjet printers. He is currently a Professor with the Department of\nInformation and Communication Engineering, Daegu Gyeongbuk Institute\nof Science and Technology, Daegu, South Korea. His research interests\ninclude control systems with nonlinear sensors and actuators, geometric\ncontrol of quadrotors, communication networks, and resilient cyber-physical\nsystems.\n", "arxiv10": "Received July 2, 2020, accepted August 1, 2020, date of publication August 11, 2020, date of current version August 21, 2020.\nDigital Object Identifier 10.1 109/ACCESS.2020.3015686\nIMDfence: Architecting a Secure Protocol for\nImplantable Medical Devices\nMUHAMMAD ALI SIDDIQI\n1, CHRISTIAN DOERR2,\nAND CHRISTOS STRYDIS\n1, (Senior Member, IEEE)\n1Department of Neuroscience, Erasmus Medical Center, 3015 CN Rotterdam, The Netherlands\n2Cyber Threat Intelligence Laboratory, Hasso Plattner Institute, University of Potsdam, 14482 Potsdam, Germany\nCorresponding author: Muhammad Ali Siddiqi (m.siddiqi@erasmusmc.nl)\nThis work was supported by the European-Union-funded Project SDK4ED (Software Development ToolKit for Energy Optimization and\nTechnical Debt Elimination) under Grant 780572.\nABSTRACT Over the past decade, focus on the security and privacy aspects of implantable medical\ndevices (IMDs) has intensi\u001ced, driven by the multitude of cybersecurity vulnerabilities found in various\nexisting devices. However, due to their strict computational, energy and physical constraints, conventional\nsecurity protocols are not directly applicable to IMDs. Custom-tailored schemes have been proposed instead\nwhich, however, fail to cover the full spectrum of security features that modern IMDs and their ecosystems so\ncritically require. In this paper we propose IMDfence, a security protocol for IMD ecosystems that provides a\ncomprehensive yet practical security portfolio, which includes availability, non-repudiation, access control,\nentity authentication, remote monitoring and system scalability. The protocol also allows emergency access\nthat results in the graceful degradation of offered services without compromising security and patient safety.\nThe performance of the security protocol as well as its feasibility and impact on modern IMDs are extensively\nanalyzed and evaluated. We \u001cnd that IMDfence achieves the above security requirements at a mere less than\n7% increase in total IMD energy consumption, and less than 14 ms and 9 kB increase in system delay and\nmemory footprint, respectively.\nINDEX TERMS Authentication protocol, battery-depletion attack, battery DoS, denial-of-service attack,\nIMD, implantable medical device, non-repudiation, smart card, zero-power defense.\nI. INTRODUCTION\nModern implantable medical devices (IMDs), such as cardiac\npacemakers and de\u001cbrillators, neurostimulators, and more,\nare equipped with wireless connectivity in order to aid in\ntreatment-related recon\u001cguration, patient-health monitoring,\ndevice testing etc. [1], [2]. However, wireless links have\nmade IMDs susceptible to various attacks by malicious\nentities.\nEarlier-generation IMDs had little or no security provisions\nwhatsoever, as con\u001crmed by numerous ethical-hacking inci-\ndents over the past decade [3]\u0015[5]. The research community\nhas responded with a wealth of new schemes and, eventually,\ntop IMD manufacturers now claim to have recti\u001ced the\nsecurity weaknesses over the past few years [6], [7].\nHowever, due to the constraints imposed by an IMD's\nscant computational, storage and energy resources, most\nproposed schemes in research have refrained from taking\nThe associate editor coordinating the review of this manuscript and\napproving it for publication was Mohamed Elhoseny\n .proven security approaches. Moreover, since these schemes\nhave been speci\u001ccally tailored for IMDs, they have missed\nthe big picture and resulted in limited coverage of the security\nproperties essential to a modern IMD. Speci\u001ccally, most\nfocus has been drawn on con\u001cdentiality, integrity, authen-\ntication and emergency access (e.g., [8]\u0015[11] etc.), while\nnon-repudiation, remote monitoring and system scalability\nhave been left unaddressed for the most part. Besides being\ndif\u001ccult to tackle, prior seminal work has not identi\u001ced or\nstressed the importance of these additional requirements.\nIn this paper, we debunk the myth that advanced security\nis impossible in modern IMDs. To this end, we collect\nboth well-studied and overlooked security requirements,\nimpose strict design constraints, and propose IMDfence,\na novel security protocol for IMD ecosystems. This works\ncontributes:\n\u000fA comprehensive security protocol for a modern IMD\necosystem, IMDfence, which addresses crucial, yet\npreviously ignored requirements, i.e., non-repudiation,\nremote monitoring and system scalability.\u000fA realistic solution for accessing the IMD during\nemergencies without compromising security or patient\nsafety.\n\u000fA rigorous evaluation of IMDfence paying special atten-\ntion to the protection against battery denial-of-service\n(DoS) attacks.\nThe rest of the paper is organized as follows: We enumerate\nmodern IMD-system requirements in Section II, and then\ndiscuss existing systems and related works in Sections III\nandIV, respectively. Section Vdetails our proposed security\nprotocol. We evaluate IMDfence in Section VIand provide\nconcluding remarks in Section VII.\nII. IMD-SECURITY REQUIREMENTS\nIn this section, we collect and present the necessary security\nand related functional requirements that should be satis\u001ced\nin modern IMD systems. These requirements form the basis\nof the IMD-speci\u001cc security protocol, to be detailed in\nSection V.\nIn order to evaluate the IMD-system security, we consider\nan implant that is capable of communicating wirelessly with a\nreader/programmer.1We assume an attacker whose aim could\nbe to either (1) modify or sabotage IMD operation in order\nto prevent patient treatment, (2) manipulate patient-related\ndata, or (3) steal patient data. Furthermore, we assume that\nthe attacker has full control of the wireless channel between\nthe reader and IMD. This means that he/she can eavesdrop,\nmodify, insert, block or replay messages between these two\nentities at will. As a result, the IMD-security system has to\nsatisfy certain security requirements (SRs):\nA. BASIC SECURITY SERVICES (SR1 & SR2)\nAs in other domains, the IMD-security system should provide\nthe fundamental security services: Con\u001cdentiality, Integrity\nandAvailability. The \u001crst two services (SR1) are usually\naddressed through the use of lightweight block-ciphers and\nmessage-authentication codes (MAC) [12]. More speci\u001c-\ncally, the commands sent from the reader to the IMD and\nthe associated responses (e.g., data logs) should be treated\nas con\u001cdential and it should be ensured that such data is not\nmodi\u001ced in transit.\nAvailability ensures that the IMD is always available for\npatient treatment whenever required (SR2). This implies that\nthe device should be protected against Denial-of-Service\n(DoS) attacks. One of the highest-likelihood and lowest-cost\nattacks is the battery-depletion attack (or battery DoS attack),\nas indicated in the IMD-speci\u001cc threat-modeling analysis\nin [1] and practically demonstrated in [3], [4].\nB. NON-REPUDIATION (SR3)\nNon-repudiation ensures that the sender of a message is\nnot able to deny (or repudiate) its creation. Since there\nis always a possibility of malpractices, medical mistakes\n1The term reader will be used for any device that is able to directly\ncommunicate with the implant.or insider attacks, we require non-repudiation to aid in\ncomputer forensics in case a patient experiences medical\nissues as a direct consequence of such actions. This security\nservice ensures that a physician, paramedic or nurse is\nnot able to deny his/her involvement in such scenarios.\nNon-repudiation has not been given due consideration by\nthe research community when it comes to IMD systems.\nOne of the reasons is that true non-repudiation can only\nbe achieved through the use of public-key (or asymmetric)\ncryptography for computing digital signatures [13], which\nhas traditionally been considered to be too resource-costly for\nIMDs [12], [14]. Another, very important, reason is that past\ngenerations of IMDs could only be accessed by one person,\ni.e., the physician. Nowadays, the IMDs can be accessed by\nmultiple people, including the patients themselves [15]\u0015[17].\nHence, there is a need to introduce user accountability.\nMost of the existing IMD-security works have looked into\nstrict reader-IMD communication (without the involvement\nof a trusted third party). Even if we assume that the\nresource-constrained IMD is able to support public-key com-\nputations, this reader-IMD con\u001cguration makes it impossible\nfor the IMD to effectively use public-key cryptography since\nit cannot keep track of the validity of the reader certi\u001ccates\n(due to lack of Internet connectivity). What is more, these\ndevices do not have suf\u001ccient memory to store the required\ncerti\u001ccates [18]. For instance, the IMD must store all possible\nreader certi\u001ccates if we want to support access during travels\nor when the patient is visiting abroad. Hence, a scheme is\nrequired that employs additional architectural components\n(as will be discussed in Section V) to solve these issues.\nAnother complication is the legal aspect. Since non-\nrepudiation is there to provide evidence, it should be\nincorporated based on the assumption that such evidence\nwill be scrutinized by a hostile legal expert [19]. One\nmain limitation of cryptography-based non-repudiation is\nthat there is no formally-veri\u001cable link between the device\nthat signs the digital signature and its user. For example,\nthe user, i.e., the private-key owner, can falsely claim that the\nsignature has been generated by a malware program without\nhis/her consent, or that the private key has been stolen. There\nis no technical mechanism that can determine whether such a\nclaim is false [20]. The IMD security protocol should address\nthis limitation, which we term as the Non-repudiation gap.\nC. EMERGENCY ACCESS (SR4)\nPatient safety always outweighs device security. Hence,\nduring emergencies the security protocol should not hinder\nor delay paramedic access to the IMD [2], [21]. Although\nit seems reasonable to drop security altogether in such\nsituations, this can be a problem if, while in a normal\nmode, an adversary fools the IMD into entering the\nemergency-access mode. The security protocol must be\ncapable of allowing the IMD to accurately classify whether a\ncommunication attempt is an emergency or a normal access.\nThis ensures that the adversary is unable to trigger and\nexploit the emergency-access mode. Furthermore, since there\nis a high likelihood of the patient losing control of his/her\nactions in emergencies, the emergency-access mode should\nbe independent of patient participation.\nD. MULTI-MANUFACTURER ENVIRONMENT (SR5)\nPast works on emergency access have ignored the fact\nthat, in emergencies, it is unlikely for the paramedic to\nknow the IMD make and model beforehand. Moreover,\nit is not possible to preemptively stock all the readers from\nall the manufacturers in the ambulance. Hence, to achieve\ntrueemergency access, the IMD-security system should be\nmanufacturer-independent, i.e., all manufacturers need to\nagree on a uni\u001ced standard for secure reader-IMD commu-\nnication. This way, an ambulance can use one generic reader\nregardless of the IMD manufacturer and type. It follows\nthat an emergency-access scheme should be adoptable by all\nIMD types. E.g., an emergency-access solution that requires\nan IMD measuring the cardiac signal [21], can be easily\nincorporated in pacemakers, but it will require signi\u001ccant\nmodi\u001ccations in neurostimulators.\nAs things stand, true emergency access does not exist in\ncommercial IMDs. As long as this remains acceptable to\nthe medical community, SR5 can be relaxed. This is further\ndiscussed in Section V-D2.\nE. ACCESS CONTROL (SR6)\nThe access privileges of the reader should be differentiated\nbased on the type of user. For example, nurses, patients or\npatient relatives may only be allowed to read status data\nfrom the implant, whereas a physician and a paramedic\nmay further be allowed to modify the implant con\u001cguration\nfor therapy updates, suspend or resume its operation.\nSimilarly, a technician may be allowed to modify the\nimplant \u001crmware in addition to tasks of the above user\nroles.\nF. USER AND READER-IMD AUTHENTICATION (SR7)\nIn order to aid in non-repudiation and access control, the IMD\nsystem should be able to identify the physician, nurse,\nparamedic etc. who is using the reader to communicate with\nthe implant. Similarly, the reader should also be able to\nauthenticate the IMD in order to prevent spoo\u001cng attacks\non the reader. Hence, there is a requirement for performing\nmutual authentication instead of just authenticating the reader\nunilaterally [12]. Furthermore, said authentication is required\nto be strong, i.e., it should imply both message andentity\nauthentication, and guarantee message freshness, or in other\nwords replay protection.\nG. FLEXIBILITY AND SCALABILITY (SR8)\nThe IMD should not be limited to communicating with only a\n\u001cxed amount of readers since this severely limits portability,\ne.g., during emergencies when a paramedic reader is used,\nor when there is a need for treatment at some hospital during\ntravels. Hence, there should not be any pre-shared secrets\nbetween the reader and IMD.H. BEDSIDE-READER OPERATION FOR REMOTE\nMONITORING (SR9)\nSome of the modern IMD systems also include a bedside\nreader, which enables remote monitoring [22]. It establishes\ncommunication with the IMD when the patient is asleep\nand sends treatment status to a back-end server via an\nInternet connection. However, this additional connection\nrepresents an increase in the attack surface, which imposes\nadditional security requirements. We predict that the use of\nsuch readers will become more widespread over time due to\ntheir time- and cost-saving features. Hence, this phenomenon\nshould proactively be considered when designing secure IMD\nsystems.\nIII. EXISTING SYSTEMS\nIMD manufacturers have typically relied on ``security\nthrough obscurity''; they choose to hide the communication-\nprotocol speci\u001ccations in order to enhance security. This\nis not a recommended practice, and as a consequence\nof using this approach, we have seen several successful\nblackbox-hacking attempts over the past few years [3], [4].\nSome of the latest commercial IMDs, including neu-\nrostimulators [17], insertable cardiac monitors [16] and\neven pacemakers [15] offer a Bluetooth Low Energy (BLE)\nconnection between the patient smart-phone and the implant.\nThe initial pairing between these devices is based on the BLE\nstandard in addition to proprietary protocols [17]. However,\nthey do not disclose the association models used in these\npairings, which makes these devices vulnerable to attacks\ndue to the reasons mentioned above. In most of the cardiac\ndevices, in the absence of an IMD-programmer, a magnet\ncan be used to disable therapy or to switch to a default\nbehavior [23]. This mode, however, can be easily exploited\nby adversaries through the use of a strong magnet when in\nclose proximity to the patient (e.g., in public transport).\nIV. RELATED WORK\nFrom the perspective of the research community, we observe\na steep rise in the number of works proposed over the last\nfew years [31]. For data con\u001cdentiality, integrity and message\nauthentication, the use of lightweight primitives has been\nproposed. Early works focused on basic security protocols\nbased on symmetric ciphers, which rely on a common\npre-shared key between the reader and the IMD [12].\nHowever, such approaches are not scalable in terms of adding\nnew readers that can access the implant. They also do\nnot allow paramedic access during emergencies. Therefore,\nmost of the existing works deal with emergency access,\nin addition to entity authentication and key exchange. For\nentity authentication, these works rely on a touch-to-access\npolicy, which ensures that only the entities that can physically\ntouch the patient for a prolonged period of time are allowed\naccess to the implant [1], [21]. In other words, it is infeasible\nfor an attacker to get in close proximity to the patient, and\neven if that is the case, the patient can detect this and reject\nphysical contact. Also, the attacker would then have far easierTABLE 1. Overview of related works.\nmethods to harm the patient than via accessing the implant,\ne.g., by physically attacking the patient. These works can be\nbroadly categorized as follows [2]:\nBiometric-based: These approaches (such as [21], [32])\nrely on both the reader and IMD to measure a physiological\nsignal from different parts of the patient's body. The devices\nare paired based on the similarity of these measurements.\nProxy-based: These works propose to use an additional\ndevice in the possession of the patient, such as a smart phone,\nwatch, etc [33], [34]. The device is paired with the IMD and is\nused to authenticate the reader that is trying to communicate\nwith the implant. In case of emergency, the device can be\nphysically distanced from the patient in order to grant the\nreader unsecured access to the IMD.\nDistance-based: These works (e.g., [35], [36]) employ\nweak or out-of-band (OOB) signals for reader-IMD commu-\nnication. These can either involve direct transfer of a session\nkey, which would be hard for an attacker to eavesdrop, or they\ncan require the devices to mutually prove proximity to one\nanother.\nToken-based: This is the simplest approach, which relies\non the patients having the IMD-access key or password\nwith them, which is stored e.g., on a bracelet. During an\nemergency, a paramedic can access the IMD using this token.\nWe now present a brief overview of the latest works from\nliterature that were speci\u001ccally tailored for IMDs.\nBuet al. propose a low-energy IMD-security scheme called\nBulwark [8], which, in addition to satisfying SR1, also allows\nIMD access in emergencies (SR4). This emergency access\nscheme is based on Shamir's secret sharing, which relies\non the users (including the paramedics) to register with the\nmanufacturer of the speci\u001cc IMD in advance in order to\nretrieve the access key in case of an emergency. As evident,\nsuch a requirement inhibits IMD access in case the patient is\nout of town (SR8).\nChiet al. [10] propose a protocol that relies on the patient's\nsmartphone for the reader access. However, requiring the\npatient to be in possession of this additional device (i.e.,\nthe smartphone) all the time, including during emergencies,\nputs a signi\u001ccant burden on the patient.\nBelkhouja et al. [11] propose a symmetric crypto system\nin which they use a Chaotic key generator that is employed\nby both the reader and IMD to generate the symmetric\nkey. However, in order for this key generator to work,both entities are required to have similar pre-installed initial\nconditions/values. Hence, this scheme cannot function in an\nemergency scenario, or when the patient is traveling, since\nthe IMD and the reader will not be sharing the same initial\nconditions.\nWazid et al. [24] and Mao et al. [25] propose three-factor\nprotocols, which rely on passwords, smart cards, and\nbiometrics. Their protocols rely on a reader-registration phase\nbefore the IMD deployment in the \u001celd. This inhibits SR4\nand SR8 since it is unlikely for the paramedic/doctor to\npossess a pre-registered reader during an emergency or when\nthe patient is visiting abroad. Rathore et al. [26] propose a\nscheme in which the identi\u001cers of each user (including the\npatient) are derived from their cardiac signals and are stored\nin the implant. Hence, it requires a user-registration phase\nsimilar to the above protocols. However, their scheme allows\nemergency access since the paramedic can measure patient's\ncardiac signal, which is compared by the IMD against the\nstored identi\u001cer in order to grant access. The three-factor\nprotocol from Fu et al. [27] also provides emergency access.\nHowever, the patient is required to always be in possession of\na personal smart card so that the paramedic is able to use it\nduring an emergency.\nA few works [3], [12], [28] have also focused on the IMD\navailability (SR2). In these works, RF energy harvesting\nis employed to protect the IMD against battery-depletion\nattacks. In addition, quite a few authentication and\nemergency-access schemes have been proposed recently\nthat rely on static biometrics (such as \u001cngerprints) [37],\ndynamic biometrics (such as cardiac signals) [28], [29] and\ncombination of both [9]. The interested reader can refer\nto [31], [38]\u0015[41] to get an overview of prior works in this\narea.\nOverall, the above works address only parts of the\nIMD security requirements (SR1, SR2, SR4, SR6, SR7\nand SR8), which is also summarized in Table 1. For\ninstance, non-repudiation is not considered and the\nemergency-access schemes do not take into account\nthe (current) multi-manufacturer environment, as discussed in\nSection II. To the best of our knowledge, there is no protocol\nthat provides all the services highlighted in Section II.\nThe work from literature that came closest to ful\u001clling the\nabove requirements was proposed by Park [30]. It establishes\na session key between the IMD and a personalized reader\nbased on shared secrets between these entities and a trusted\nthird party (hospital server). The use of public-key crypto\nin the personalized reader and the server facilitates non-\nrepudiation. However, the work lacks a few additional pieces\nin order to properly close the non-repudiation gap (as will be\ndiscussed in Section V-C5). The protocol addresses access\ncontrol by \u001crst allowing only read access to the implant\nvia the server. Based on the result of the read-out data,\nthe server provides write keys to the reader-IMD pair which\nallows the user to change IMD settings. The personalization\nprocess involves the physician inserting a personal smart card\ninto the reader. However, since it resembles a single-factor\nauthentication for the user (i.e., through the use of a smart\ncard without PIN), any person in possession of a valid (stolen)\ncard can access the implant by getting hold of a reader. The\nserver maintains a list of primary-care physicians authorized\nto access each registered implant. If the physician is a\nmember of this list, then a read-key is granted to the\nphysician. We believe that maintaining such a user list is\nnot scalable, it inhibits \u001dexibility, and hence, should not be\nemployed. As an example, such a scheme will not work\nin case the patient requires some treatment at a hospital\nabroad. Besides, the proposed emergency-access scheme uses\na bracelet that has a secret key. However, such token-based\nsecurity schemes are single points of failure (e.g., in case\nthe token is stolen or the contents are disclosed). Also,\nit requires the patient to wear the bracelet at all times,\nwhich is inconvenient. Moreover, in the emergency scenario,\nthe scheme drops access control and non-repudiation. Lastly,\nthis work excludes battery DoS from its adversarial model,\nand it does not consider bedside-reader operation.\nV. IMDfence: SECURITY PROTOCOL FOR IMD\nECOSYSTEMS\nThe absence of a complete security solution for IMD\nsystems has led us to propose IMDfence, a novel\nsecure-communication protocol that satis\u001ces the extensive\nand strict requirements enumerated in Section II. As will be\nshown, IMDfence addresses the complete IMD ecosystem.\nFIGURE 1. Proposed IMD ecosystem.\nA. CONFIGURATION AND ASSUMPTIONS\nThe IMDfence con\u001cguration includes a smart card (C ) for\nthe user (U ) trying to access the IMD (e.g., a physician),TABLE 2. Table of Notations.\nand a trusted third party (TTP), i.e., a hospital server (S ),\nin addition to the implant (I ) and the reader (R); see Fig. 1.\nThe list of notations used in this paper is summarized\nin Table 2. The extra components, CandS, are employed\nto facilitate non-repudiation (SR3), access control (SR6)\nanduser authentication (SR7), as identi\u001ced in Section II.\nEach personal smart card, which is inserted in R, supports\npublic-key cryptography. Its private key, which is unique to\neach card/user, enables digital-signature computation, thus\nproviding non-repudiation. Since RandCare untrusted with\nrespect to each other, a TTP (S ) is required to mutually\nauthenticate the two entities. Non-repudiation can technically\nalso be provided through the use of a personal reader that\nsupports public-key computations in order to get rid of C\nandS. However, such a solution would be highly impractical\nand expensive since it would require all the doctors and\nnurses to be in possession of their personal readers at all\ntimes. Moreover, the use of Salso enables access control\nand facilitates bedside-reader operation (SR9). Every user\nrequires their own Cand should know the associated PIN\n(two-factor authentication). Since patients are only allowed\nread-only access (as discussed in Section II-E), losing or\nmisplacing their Cwill not inhibit any future treatment. To\navoid additional attack vectors, we propose to not support the\nuse of contactless smart cards and magnetic-strip cards.\n1) INTERFACES\nFor tackling \u001dexibility and scalability (SR8), there is no\npre-shared key between R$I,R$C,S$R, and C$I.\nThe only pre-shared symmetric keys that exist are between\nS$I(KSI) and S$C(KSC). A unique KSIis installedin the implant at the time of manufacturing, which is then\nshared with the server of the hospital where the implantation\nsurgery is going to take place. During this IMD-registration\nprocess, the implant is also assigned a unique and random\nidenti\u001cer IDI, which is stored in the implant. Likewise, KSC\nis installed in the smart card and is shared with the hospital\nwhere the card user is registered. Moreover, S,IandCcan\nonly talk to Rdirectly and only indirectly with each other.2\nThe secure communication between S$Ris made\npossible by employing public-key-based key exchange in\nwhich the public/private key pairs of these entities are used.\nThis con\u001cguration helps in making Rindependent of the need\nto pre-share keys with the hospital, which aids in scalability.\nAs a result, a patient can use his/her personal reader from\nany location, and/or buy a new reader from the manufacturer\nwithout the need of registering it \u001crst at the hospital.\nIn our proposed con\u001cguration, each smart card also has\nits own public/private key pair. Technically, Rhas the capa-\nbility of maintaining a comprehensive certi\u001ccate-revocation\nlist (CRL) of smart cards due to frequent Internet connec-\ntivity. Hence, it is able to verify smart-card certi\u001ccates. On\nthe other hand, due to the limited on-board memory and\nless-frequent Internet connectivity, Ccan only maintain a\nsmall CRL that does not change frequently. Hence, Ccan not\nverify the authenticity of the multitude of reader certi\u001ccates.\nAs a result, public-key-based key exchange cannot be used\nto establish a session key between R$C. However, it will\nbe shown in Section V-C that the session key between R$\nCwill be established using Sas a TTP. The same will be\ndone for establishing a session key between R$I. Lastly,\nno session key is required between C$I.\n2) CENTRALIZATION AND PUBLIC-KEY INFRASTRUCTURE\nThe public keys of S,RandCare signed by a trusted\ncerti\u001ccation authority (CA) belonging to the manufacturer.\nThe smart-card certi\u001ccates, in addition, also include the user\nprivileges.\nWe consider the precise implementation details of\npublic-key infrastructure (PKI) and certi\u001ccate revocation\noutside the scope of this paper. In case of a smart card,\ncerti\u001ccate revocation would be needed when a card is stolen,\na user leaves, or he/she changes roles (e.g., from nurse to\nparamedic). For a reader, certi\u001ccate revocation would be\nrequired in case Ris stolen or deemed as out-of-service. The\nserver is given the responsibility to verify the certi\u001ccates of R\nandCand hence, it is assumed that it maintains an up-to-date\nCRL.\n3) MODES OF OPERATION\nWe propose two modes of operating in IMDfence, one for\nregular (online) operation and the other in the absence of an\nactive Internet connection (of\u001dine), e.g., during emergencies\n(SR4); see Fig. 2. Online mode offers the full security- and\n2The routing details of the messages communicated via the reader have\nbeen omitted for brevity.functional-requirement portfolio highlighted in Section II,\nwhereas of\u001dine mode results in the graceful degradation of\noffered services without compromising security and patient\nsafety. Since Sis not available in of\u001dine mode, RandIwill\nbe required to undergo an out-of-band (OOB) pairing phase\nin order to securely exchange a short-term session key. These\nmodes and the constituent phases will be elaborated in the\nfollowing sections.\nFIGURE 2. IMDfence flow under online and offline scenarios.\nB. THREAT MODEL\nAs discussed in Section II, we assume an attacker Athat\nhas full control of the wireless channel between RandI.\nRis assumed to be untrustworthy by I,CandS, and vice\nversa. Moreover, we assume that if Asteals a personal\nsmart card or a valid reader, then the user or hospital staff\nshould notify the hospital server so that it is blacklisted.\nAdditionally, we assume that Acan hack the reader to read\nout or modify data at the interface of the inserted smart\ncard. However, Adoes not have access to the keys stored in\nRandC. This implies that protection against side-channel\nattacks is considered outside the scope of this work since\nsuch attacks are typically addressed through specialized\ncountermeasures. Moreover, due to the assumption that Sis\nnoti\u001ced of a lost/stolen device, Ahas a limited time window\nto perform such attacks after stealing a device. We also\nassume that the hospital personal do not have access to the\nkeys stored in the server since such attacks can be prevented\nby employing standard practices, such as hardware security\nmodules (HSM) etc.\nC. REGULAR (ONLINE) MODE\nThe regular mode of IMDfence is shown in Figures 3 to 6. It\nstarts with the R$C mutual authentication phase after the\nphysician (or any other user) inserts their smart card into the\nreader.\n1)R$CMUTUAL AUTHENTICATION\nIn this phase, R\u001crst tries to establish a secure connection\nwith Sby sending its identi\u001cer and a nonce (which is a\nfreshly generated number that is used only once). In order\nto deter distributed-denial-of-service (DDoS) attacks against\nS(to ensure server availability (SR2)), a basic client-puzzle\nprotocol (CPP) is employed [42]. CPP is a proof-of-work\nsystem in which any client (or in this case a reader) thatFIGURE 3. Reader-card authentication. Steps that are common with\nbedside-reader mode are marked in blue.\nwants to access the server (during high load) is required to\ncorrectly solve a cryptographic puzzle. For a single client the\ncosts of solving this puzzle are negligible. However, in order\nto launch a successful DDoS by initiating a large number\nof simultaneous connections, it would be computationally\ninfeasible for the attacker to solve a multitude of such puzzles.\nSinitiates CPP ifit senses a DDoS attack or it is\ndealing with an abnormally high number of simultaneous\nconnections. It \u001crst calculates x, which is the n-bit hash\nofIDR, the current time stamp tand its long-term secret KS.\nIt then computes a second hash (h(x )).Ssends h(x) and x\nexcluding the \u001crst kbits of x, along with the t.Rcomputes the\nsolution, i.e., the missing kbits of x, and sends it along with\nIDRand the received time stamp. krepresents the dif\u001ccultyof solving the puzzle. Scalculates xagain and veri\u001ces that\nthe solution indeed corresponds to the missing bits. It also\nveri\u001ces, with the help of t, that the puzzle has not expired. Sis\nprotected against memory exhaustion since it is not required\nto store any data for the veri\u001ccation of the puzzle solution. In\ncase these checks are successful, Ssends its nonce to R.\nRthen performs a Dif\u001ce\u0015Hellman (DH)-based handshake\nwith Sin which a session key is established between them\nbased on their public/private key pairs (see Fig. 3). During\nthis handshake, both verify each other's certi\u001ccates and,\nadditionally, Schecks if Ris valid (i.e., it is not reported as\nstolen or out-of-service).\nIn order to achieve authentication between RandC,Rthen\ninitiates a \u001cve-pass, mutual-authentication protocol borrowed\nfrom the ISO/IEC 9798-2 standard [43] with Sacting as\na TTP (see Fig. 3).Rand Censure message freshness\nby exchanging their nonces in the \u001crst messages between\nthem, and then verifying the existence of these nonces in\nthe subsequent messages. Rgenerates its nonce and sends\nit along with its identi\u001cer and NStoC.Cresponds by\ngenerating NCand sending a cryptogram (m SC1) that includes\nauthenticated encryption of its certi\u001ccate, IDRand nonces,\nalong with IDCandNCin plaintext. This cryptogram is\ncalculated using KSCsince it is intended for the server. R\nstores IDCandNC, and forwards the cryptogram to the server,\nwhich establishes that it originated from Cand that it is\nalso tied to R. The server then veri\u001ces Cert Cand checks\nthe validity of C, in case it has been reported stolen or\nhas expired. It then determines the required privileges (P C)\nfor the particular user (e.g., physician, paramedic, nurse\netc) from Cert C. It also calculates tokens for both these\nentities using the respective symmetric keys. These tokens\ninclude the nonces and identi\u001cers of RandCand a fresh\nsymmetric key K0\nRC. Additionally, token Ralso contains T\n(reader-card-authentication lifetime). Based on these tokens,\nRandCcan ascertain each other's trustworthiness.\nRdecrypts token R, retrieves K0\nRC, calculates the MAC of\nthe nonces, and forwards it along with token CtoC. The smart\ncard similarly decrypts token Cand veri\u001ces the received MAC\nusing K0\nRC. It stores the nonces and K0\nRCin its internal \u001dash\nmemory3so that it can verify and create messages in the\nsubsequent stages. Cthen sends a MAC that is calculated\nover NRandNC(including an addition by 1 to protect against\nreplay of the previous message). Rveri\u001ces the received\nMAC using K0\nRC. At this point, both RandChave mutually\nauthenticated each other.\nRthen sets its internal real-time clock to Tand starts it\nto track the period over which the subsequent phases can\nexecute without the need of reader-card authentication. Since\nit is possible that Ris not connected to the Internet during its\noperation (e.g., in emergencies), this scheme enforces that R,\nby design, shall only be usable for a certain duration until it\n3There can be a time gap between this and the next stage (in of\u001dine mode).\nSince smart cards can only be powered by R, the above data has to be stored\nin the non-volatile (\u001dash) memory so that Ccan be taken out of Rduring this\nperiod.has \u001crst established an Internet connection. This makes sure\nthatRreceives critical \u001crmware updates in time, if there are\nany. The selection and con\u001cguration of Twill be discussed\nin Section VI-A4.\nFIGURE 4. User authentication at the reader.\n2) USER AUTHENTICATION\nThis phase is shown in Fig. 4 and its objective is to\nauthenticate the card holder. The physician enters his/her\nPIN using a keypad on the reader. Rthen checks its internal\nreal-time clock to verify the validity of its token. Rencrypts\nthe PIN and the nonces (in order to prevent replays) using\nK0\nRC.Cdecrypts the message using the same key, veri\u001ces the\nPIN by comparing it with the stored one and sends back a\ncryptogram intended for the server, which is encrypted with\nKSC. It contains the con\u001crmation of success in addition to the\nnonces.\n3) SESSION-KEY (K0\nRI) ESTABLISHMENT\nRthen initiates a TTP-based key established protocol with\nSandIin order to acquire a symmetric session key K0\nRI\nfor providing con\u001cdentiality and integrity (SR1), as shown\nin Fig. 5.R\u001crst exchanges the nonces and identi\u001cers with I\nand then sends the nonces and identi\u001cers of all parties to S\nalong with mSC2.S\u001crst veri\u001ces mSC2. It then generates K0\nRI,\nencrypts it in two independent messages mRandmIintended\nforRandIrespectively, and then sends these to R.Rdecrypts\nmRand veri\u001ces its contents. It then encrypts NRandNIusing\nK0\nRI(to form mRI) and then sends it along with mItoI.I\n\u001crst retrieves K0\nRIby decrypting mI, and then decrypts mRIto\nverify that Rhas the knowledge of K0\nRIand that the nonces\nare valid. I\u001cnally creates a MAC using the new session\nkey for Rto validate. At the end of this protocol, both R\nandIare mutually authenticated (SR7) and have arrived at a\nfresh session key in addition to performing key con\u001crmation.\nSimilar to the reader-card authentication stage, this phase is\nalso based on the \u001cve-pass protocol from ISO/IEC 9798-2\nsince it involves a TTP.\nTo protect against battery-DoS attacks (which impact\navailability (SR2)), steps 1 to 4 of session-key establishment\nshould be as lightweight as possible so that the IMD is able\nto execute it using harvested RF energy. This will be further\ndiscussed in Section VI-B.\nFIGURE 5. Session-key establishment between RandIviaS. Operations\nthat are not relevant to bedside-reader mode are marked in orange.\n4) MAIN PHASE\nAfter session-key establishment, Rallows the user to enter a\ncommand on the reader interface (see Fig. 6). The command\nis encrypted along with the nonces (to prevent replay attacks)\nusing K0\nRCand is sent to C. The card decrypts the command,\ndigitally signs the message using KprC(to form sig) and sends\nit toR.Rre-encrypts the command using K0\nRIand sends it to\nthe implant along with sig.\nIdecrypts the command and veri\u001ces if it corresponds to\nthe privileges information received in mIduring the previous\nphase, hence ensuring access control. sigand CMD are\nFIGURE 6. Main phase. Steps that are common with bedside-reader\nmode are marked in blue. Operations that are unique to bedside-reader\nmode are marked in green.\nstored by the IMD next to IDC,NCandNR, which were\nstored during session-key establishment. This is required\nto ensure non-repudiation since sigwas signed using a\npersonal private key. For example, in the case of a medical\nmistake (e.g., an incorrect command) that led to patient death,\nthe physician will not be able to deny his/her involvement\nsince this signature can always be retrieved from the IMD and\nsubsequently veri\u001ced using the associated data. It follows that\nsignature storage is not required for read-only commands.\nSince the implant trusts the reader at this point, there is\nno need for Ito verify the signature since the associated\nMAC has already been veri\u001ced by R. This relieves Iof\nthe need to employ public-key cryptography and to track\nuser certi\u001ccates. After processing the command, the implant\nresponds with an answer message encrypted with K0\nRI.R\ndisplays it on its screen for the convenience of the user. The\nsession keys expire after a \u001cnish command and its associated\nresponse, or after a period T.\n5) ADDRESSING THE NON-REPUDIATION GAP\nAs discussed in Section II, the use of a signature alone is not\nsuf\u001ccient to address the legal aspects of non-repudiation. In\norder to bridge the non-repudiation gap, one option could be\nto enforce that the user protects Cand the associated PIN,\nor immediately reports in case it is lost. However, due to the\npossibility of human error in general, this is too much of a\nlegal responsibility for the user.\nA realistic way of bridging this gap is by introduc-\ning additional checks in the implementation of reader-\ncard-authentication and session-key-establishment phases\n(see Figures 3and5, respectively). The server can ensure that\nthe implant write access (determined from PC) is requested\nfrom within the hospital network andduring the working\nhours of the user. On the other hand, the server can allow read-\nonlyaccesses from external networks, e.g., in case the access\nis made by the patient or their bedside reader. The user just\nhas to ensure that Ris issued from a certi\u001ced repository, and\nthatRshould only be connected to a trusted Ethernet/Wi-Fi\nnetwork (i.e., in a hospital or patient home). With these\nprecautions, which a responsible user can easily follow,\nprotection can be ensured against the malicious replacement\nof a command using a compromised reader, or against an\nattacker sending a malicious command him/herself in order\nto frame said user. Due to the above risk-based, multi-factor\nauthentication, a user cannot falsely deny his/her involvement\nin a certain implant access because the alternative explanation\nimplies that (1) the attacker stole a valid reader, card and\npin, (2) accessed the implant from within the hospital and\nduring the user's working hours, and (3) RandCwere not\nreported as stolen. The combined probabilities of all these\nevents occurring at once is extremely small, or, in other\nwords, the non-repudiation gap is effectively bridged by the\nintroduction of above checks.6) BEDSIDE-READER OPERATION\nThe online mode also facilitates bedside-reader operation\n(see Fig. 1). Here, only the CPP and DH-based handshake\nbetween the bedside RandS(from reader-card authentication\nphase), the session-key establishment phase, and the main\nphase (with a few differences, as indicated in Fig. 5\nand Fig. 6, respectively) need to be executed, since the\ncommands and responses are only sent and read by S.\nMoreover, since the remote monitoring done in practice\nis only read only, i.e., with the lowest access privileges,\nthere is no need for non-repudiation ifthe read-only access\ncontrol is implemented correctly. This can be done if sig\nin step 6 is replaced by MAC of CMD from S(i.e.,\nMAC KSI(CMD; NR;NI)). Using this MAC, Iis able to verify\nthat the command came from the server, and hence, it can be\nexecuted with read-only privileges. Finally, the hospital staff\ncan retrieve the critical treatment data by logging into S. It\ncan be argued that this remote-access mode should support\nread/write access instead of just read-only in order to enable\nremote \u001crmware updates. However, we stress that such\nupdates should always occur in the presence of a quali\u001ced\nprofessional. This is important in case patient health suddenly\ndeteriorates due to the update process. Moreover, in practice\nit is quite common and acceptable to get the IMD \u001crmwares\nupdated at the clinic in the presence of a physician [7].\nThis mode is also useful for securely retrieving the stored\nsignatures pertaining to previous programming sessions in\norder to free up limited IMD memory.\n7) IMD ACCESS FROM A NON-LOCAL LOCATION\nIn Section V-A1, we discussed that CandIare registered\nat the local hospital (S L), or in other words, they share their\nrespective symmetric keys with the hospital server. During\ntravels or when the patient is out of town, a situation may\narise that requires access to the IMD for status monitoring.\nIn this case, the scheme from Fig. 1, can still work if the\npatient is in possession of Rand his/her C. However, for\ntreatment updates, which require higher access privileges,\nthe patient would need to visit a nearby (remote) hospital (S R).\nIn this case, the above scheme would not work straightaway\nsince the IMD is not registered at SRand the remote-location\nphysician's Cis not registered at SL. Hence, minor extensions\nare required (see Fig. 7), in which SRestablishes a secure\nconnection with SLvia an IMD-manufacturer server SM.SM\nmaintains a list of all the IMDs in service and the hospitals\nat which they are registered. Based on IDIsent by RtoSR\n(and then SRtoSM) during the session-key establishment\nphase (see Fig. 5),SMdetermines SLand establishes a secure\nconnection with it. SRsends K0\nRI, the relevant identi\u001cers,\nnonces and PCtoSL(via SM) so that SLis able to\nconstruct mIand send it back to SR. The protocol then\nproceeds normally and the IMD eventually retrieves K0\nRIafter\ndecrypting mI.FIGURE 7. Scenario when the patient is out of town.\nD. OFFLINE MODE\nIn the absence of an active Internet connection and hence,\nthe TTP (S ), e.g., during emergencies, Rand Ineed to\nestablish a temporary shared key so that they can commu-\nnicate directly in a secure manner. We propose to employ an\nOOB-channel-based key exchange while using the principle\noftouch-to-access (as discussed in Section IV). This principle\nis employed by Ito establish trust with Rsince we assume\nRto be untrustworthy from the perspective of the IMD. We\npropose to either use ultrasound communication orgalvanic\ncoupling as the OOB channel (between RandI) since they\nresult in virtually zero information leakage compared to\nother coupling methods, such as capacitive coupling [44].\nMoreover, they have an advantage over biometric-based\ntouch-to-access mechanisms (mentioned in Section IV) in\nthat they do not require any initial RF communication\nmessages before the IMD is sure that the external entity is\nin close proximity. This provides an additional security layer,\nwhich is critical for the pre-deployment con\u001cguration that\nwill be discussed in Section V-D1.\nAssuming that galvanic coupling is used, the paramedic\nplaces the OOB interface of the reader on the patient skin4\nat a point that is nearest to the IMD. The patient is assumed\nto thwart advances of a stranger trying to place a reader on\nhis/her skin, if there is no emergency or a need for treatment.\nHence, the implant assumes that the message received from\nthe OOB interface is from a trustworthy source. In other\nwords, in of\u001dine mode, the IMD-system security hinges on\nthis OOB pairing and favors availability over security but in\na more controlled fashion than state of the art.\nThe protocol is shown in Fig. 8. The paramedic is required\nto perform reader-card authentication when starting his/her\nduty, so that both RandCobtain their respective tokens\nfrom S. When IMD access is required in an of\u001dine setting,\nR\u001crst initiates user authentication with the paramedic smart\ncard in the same way as in the regular mode. During user\nauthentication, Rveri\u001ces that its internal real-time-clock\nvalue is less than T. Through the OOB channel, Rsends\na request for of\u001dine access along with its identi\u001cer. Upon\nreceiving this request, the implant assumes that this is an\nof\u001dine scenario since this channel is activated only in such\nextraordinary circumstances. As a result, it generates a\n4Touching the skin is mandatory for the galvanic channel to function.\nFIGURE 8. IMDfence (Offline mode).\nrandom key K0\nRIand its nonce and sends them along with IDI\nto the reader using the same channel.\nR, then, initiates session-key con\u001crmation with Iin which\nboth entities verify each other's MACs that are generated\nusing K0\nRI. In order to update or inquire about the implant\noperation, the paramedic enters the command on the reader\ninterface, which is encrypted using K0\nRCand is sent to C.\nThe card digitally signs this command and sends it back\ntoR.Rencrypts the command using K0\nRI, calculates its MAC\nand sends it to Ialong with sigKprC(CMD; NR;NC). This\nsignature and CMD are stored by the IMD and are required to\nensure non-repudiation, as already discussed in Section V-C.\nThe IMD responds with an answer encrypted by the same\nsession key, which is subsequently displayed on the reader\ndisplay. The session key expires in a manner similar to that in\nthe regular mode.\nIn of\u001dine mode, the user is only allowed paramedic-level\nprivileges, which have less access rights compared to a\ntechnician (see Section II). The use of the OOB channel\nmakes it straightforward for the IMD to decide on granting\nonly paramedic-role commands.\n1) OFFLINE ACCESS WITH/WITHout NON-REPUDIATION\nAND ACCESS CONTROL\nWe also propose a second \u001davor of the of\u001dine mode\nin which non-repudiation and user authentication are not\na requirement. This is suitable for less critical implants,\nsuch as neurostimulators. This \u001davor does not require a\nsmart card, and as a result we do not require the reader-\ncard- and user-authentication phases in addition to signature\ngeneration. This improves usability, since the paramedic\nis not required to perform reader-card authentication when\nstarting their duty. In this scheme, the touch-to-access\nprinciple is deemed to be suf\u001ccient in order to ensure trust\nestablishment. It is important to note that, for IMDfence,\nsupporting non-repudiation during of\u001dine mode has to be\ndecided before IMD-system deployment since it cannot be\ncon\u001cgured at runtime, so as to avoid exploitation.\n2) OFFLINE ACCESS WITH/WITHout READER-INTERFACE\nSTANDARDIZATION\nAs indicated in Section II, supporting emergency access in the\n\u001celd requires a standardized reader interface, which demands\ncollaboration between major IMD manufacturers. In order to\nfacilitate this multi-manufacturer environment (SR5), there\nhas to be one agreed-upon root CA that grants certi\u001ccates to\nthe manufacturers, who can then act as intermediate CAs that\nsign public keys of S,RandC. As things stand, however,\ntrueemergency access does not exist in commercial IMDs. As\nlong as this remains an open issue, the above standardization\nis not required, and as a result, IMDfence can be simpli\u001ced by\neliminating the need for a global root CA. Emergency-access\nsupport in IMDfence is intended to be there in anticipation of\nany future changes in this regard.\nE. SUMMARY OF PROTOCOL CONFIGURATIONS\nThe different con\u001cgurations of IMDfence are highlighted\nin Fig. 9. The dotted boxes indicate (\u001cxed) pre-deployment\ncon\u001cgurations, which cannot be changed at run-time. Such\ncon\u001cgurations were discussed in Sections V-D1 and V-D2.\nIMDfence is designed in such a way that an attacker\ncannot target one mode over another for exploitation. For\ninstance, the of\u001dine mode is only triggered after an OOB\naccess, which is protected by the touch-to-access principle.\nMoreover, the sub-modes of online access only come about\nby disabling certain IMDfence steps instead of switching to\na totally independent behavior.\nVI. EVALUATION\nIn this section, we evaluate our system in terms of security\nfeasibility and also look into the handling of battery-DoS\nprotection for IMDs.\nA. SECURITY ANALYSIS\n1) AUTOMATIC VALIDATION USING AVISPA TOOL\nFor the automated and formal validation of IMDfence,\nwe used AVISPA (Automated Validation of Internet Security\nFIGURE 9. IMDfence configurations and use cases.\nProtocols and Applications) [45]. Any protocol to be\nvalidated using this tool is speci\u001ced using the High-Level\nProtocol Speci\u001ccation Language (HLPSL). An HLPSL spec-\ni\u001ccation consists of a description of the principals (i.e., R,I,\nC,Sand the user in our case), security goals of the protocol,\nand the details of the session(s) to be analyzed. AVISPA\nintegrates four back-end engines that provide different types\nof automatic analysis of an HLPSL speci\u001ccation [45].\nThe tool helps in detecting vulnerabilities against Man-in-\nthe-middle and replay attacks. It also detects whether the\nHLPSL speci\u001ccation is executable, i.e., all the speci\u001ced\nprotocol states are traversable. Using AVISPA, we can also\noptimize our protocols by removing certain parameters from\nthe messages in order to reduce communication overhead and\nanalyze if this results in a new vulnerability.\nThe analysis of IMDfence using AVISPA is summarized\nin Table 3. The handshake-speci\u001cc protocol requirements\n(SR1, SR3, SR6 and SR7) are satis\u001ced by specifying the\nappropriate goals. In phase III, Sextracts user privileges from\nCert Cafter successful authentication of C, based on NSin\nmSC2.Ithen veri\u001ces Sbased on NIto complete the chain\nfrom the card to the implant in order to ensure access control.\nIn order to check non-repudiation using the tool, the server\nveri\u001ces that the retrieved sigfrom the IMD originated from\nCduring the session corresponding to NS.\nTABLE 3. Summary of AVISPA analysis.\n2) READER-SPECIFIC ATTACKS\nWhen considering all possible attack scenarios, we de\u001cne the\nfollowing reader typesV\n1)Valid R (R valid):This is a legitimate device, which is\nnotreported as stolen.\n2)Stolen R (R stolen):A legitimate device which is reported\nas stolen.\n3)Hacked R (R hacked ):A stolen reader which is also\nmodi\u001ced by Ain order to e.g., replace the signature or\nCMD.\n4)Forged R (R forged ):A custom-built or software-de\u001cned\nradio used by Ain order to communicate with an\nimplant. This reader does not have any pre-shared keys\nwith S.\nThe following scenarios are possible in terms of\nuser-reader combinations (which are also summarized\nin Table 4):\nTABLE 4. Enumeration of attack scenarios Sn in terms of user-reader\ncombinations.\nS1 \u0015 Any user & Rvalid:This is the most common\nscenario, which must be handled by IMDfence. Acannot\ninsert a false signature remotely (in order to frame someone)\nsince the connection between Rand Cis protected by\nMAC-based integrity checks. Moreover, an insider attack\n(from a legitimate, malicious user) should be detected by the\nnon-repudiation check. However, after sending a malicious\ncommand, such a user can attempt multiple harmless write\ncommands in order to eventually overwrite the signature\ncorresponding to the malicious command. We term this as\nthesignature-overwrite attack . For each command, 72 bytes\nof \u001dash space is required to store the signature and the\nassociated session parameters. As an example, if a 32-kB\n\u001dash memory is allocated for signature storage, 456 attempts\nwill be required to successfully overwrite the targeted\nsignature, which is highly impractical. Even if the user\nmanages to achieve this, the signature record will still\npoint to an abnormally high number of write commands\ncorresponding to a single session, which will raise suspicions.\nS2 \u0015 Any user or attacker & Rstolen:No individual will\nbe able to use Rstolen because of the checks involved in the\nreader-card-authentication phase.\nS3 \u0015 Trusted, honest user & Rhacked /Rforged :In order\nto frame someone, Ahas to force the legitimate user to\nuse a hacked reader, which replaces the command with an\nincorrect one. As a guideline, Rmust be issued from a trusted\nrepository, which rules out the use of Rhacked andRforged for\ntrusted users.\nS4 \u0015 Trusted, malicious user & Rhacked :Legitimate\nmalicious users can cover their tracks by using a hackedreader that can replace the signature corresponding to a\nmalicious command, which is to be stored in the IMD, with\nthe one corresponding to a safe command. Such an attack is\nquite costly to execute and is time-critical since it will involve\ncolluding with someone who has advanced engineering skills\nwhile requiring that Rhacked is not reported as stolen. Since,\nthe user is considered trusted by the patient and can thus be in\nclose proximity, he/she has far easier and inexpensive means\nto harm the patient without getting caught.\nS5 \u0015 Trusted, malicious user & Rforged :Such a user\ncannot send commands using a forged reader in an online\ncase since Rforged does not share a key with S. In the of\u001dine\ncase, however, such a user can use a forged reader that is\nable to create a bogus sigand hence does not require any\ninvolvement of C. Moreover, he/she can use the OOB-pairing\ninterface because of being considered as trusted by the\npatient. Similar to S4, such a scenario also requires hiring an\nadvanced attacker to develop such a reader, and based on the\ntouch-to-access assumption, the user has signi\u001ccantly easier\nmethods to harm the patient.\nS6 \u0015 Attacker & Rvalid:For online access, the security\nprotocol will break if Agets hold of a valid reader, card and\nits associated PIN, accesses the IMD from within the hospital\nand during the user's working hours, and C is not reported as\nstolen. It is recommended that the user protects her card and\nPIN, or immediately reports it in case it is lost. Moreover, as a\nguideline, the user should never lend or sell Rto a third party.\nThe protocol will also break if Agets hold of an OOB-paired\nreader and a card with valid respective tokens, andknows\nthe PIN. We assume that the paramedic resets the pairing\nafter treatment. Overall, Acannot effectively launch the above\nattacks since the likelihood of all the dependencies being true\nis extremely low.\nS7 \u0015 Attacker & Rhacked /Rforged :For online access, Awill\nnot be able to use Rhacked because of the reasons mentioned\nin S6 above. Similarly, Acannot use Rforged since it does not\nhave a shared key with S. Moreover, for an of\u001dine scenario,\ngetting hold of these readers will not help an attacker Asince\nthe main symmetric key (K RI) comes from Iin the OOB\npairing process. Hence, to gain advantage using these readers,\nAwould still need to get close to I(touch-to-access).\n3) SMART-CARD-SPECIFIC ATTACKS\nSince IMDfence employs smart cards, it is important to\nensure that it is safe from the weaknesses [13], [46] present\nin another widely used smart-card system: EMV (Europay,\nMastercard, and Visa). These vulnerabilities exist due to the\navailability of less secure options for backward compatibility\nand due to a problematic threat model, in which the reader\n(i.e., the POS terminal) is assumed to be uncorrupted.\nOne major issue is that most of the important data is\nexchanged in plain-text (e.g., account data, amount etc.) since\nthe terminal and the card do not share a symmetric key.\nMoreover, in the of\u001dine use of the cards that do not support\npublic-key cryptography, the PIN is also sent as plain-text. An\nattacker can modify the unencrypted initialization messages\nto force the terminal to use this mode [13]. The PIN can\nbe recorded using e.g., a hacked terminal that has additional\nprobes to read data from the smart card interface. In case of an\nof\u001dine-encrypted PIN, the terminal can be hacked to record\nthe keystrokes. Using the account data and PIN, the attacker\ncan create a magnetic-strip card for use in a country that does\nnot support chip-based smart cards [47].\nAnother issue is that the terminal cannot use MAC to\nauthenticate messages from the card since they do not\nshare a symmetric key. Cards following the Combined-\nData-Authentication (CDA) scheme from EMV address this\nby employing signatures. However, in the schemes prior\nto CDA, the terminal is unable to verify the authenticity\nof all the card messages either due to unavailability of\nsignatures (in the case of Static Data Authentication, SDA)\nor the signature-less transaction messages (in the case of\nDynamic Data Authentication, DDA). As a result, an SDA\ncard can be cloned for use in of\u001dine transactions [13],\nand a stolen DDA card can be employed in a two-card\nattack, in which the attacker uses his/her own card for\nPIN veri\u001ccation and uses the stolen card in the transaction\nphase [48]. Moreover, the card response at the end of PIN\nveri\u001ccation is unauthenticated. As a result, this response can\nbe modi\u001ced to deceive the terminal into assuming that the\nentered PIN is correct.\nAll these attacks exist because in EMV some of the\ncritical data is left unencrypted or not signed. In contrast,\nin both the online and of\u001dine modes of IMDfence, all data\nbetween RandCis encrypted and is authenticated using\nMACs. Additionally, our recommendation to avoid magnetic-\nstrip-based cards rules out cloning. Similarly, avoiding\ncontactless cards removes an additional attack vector.\nAnother far more advanced type of attack is the relay\nattack [46], [47], which exploits the fact that the card\nusers cannot know for sure if the display of the terminal\nis showing correct information. It is a time-critical attack\nwhere two transactions are simultaneously taking place. The\nvictim inserts his/her card in a counterfeit terminal (e.g., at a\nrestaurant), which is connected to a fake card of the attacker\nthat is inserted in a valid terminal (e.g. at a jewelry store).\nThe details of the fraudulent transaction are forwarded to the\nvictim's terminal. Her screen shows the correct information,\nbut in effect she pays the amount for the other party.\nWe observe that the relay attack is far less likely in the case\nof IMDfence since it requires a legitimate user operating a\nforged reader. This corresponds to scenario S3 discussed in\nSection VI-A2.\n4) SELECTION OF T\nThe touch-to-access principle guarantees that an unreason-\nably high T(reader-card-authentication lifetime) value does\nnot cause a security vulnerability in IMDfence, as evident\nfrom Section VI-A2. However, the careful reader may have\nnoticed that a prolonged of\u001dine operation enabled by such\na large value may result in R's and/or IMD's \u001crmwares\nbecoming outdated. On the other hand, a very smallvalue hinders legitimate access, i.e., availability. Therefore,\nthe hospital server should ensure that Tis assigned an\nappropriate value (within maximum and minimum limits)\nbased on the patient's location and the reader-IMD usage\npatterns.\nRegarding the patient's locality, the probability of having\nstable Internet connectivity is higher when the patient is\nbased in an urban area compared to a rural setting. Moreover,\nit stands to reason that the chances of attacker presence\nought to be higher in an urban environment. Hence, it makes\nsense to assign a lower Tvalue for urban areas compared to\nrural environments. When assigning the Tvalue, reader-IMD\nusage patterns should also be taken into consideration, which\ndepend on the patient condition and IMD type, ranging from\ncritical implants, such as cardiac de\u001cbrillators, to less critical\nones, such as neurostimulators. The IMDs requiring frequent\nreader access should be granted a larger Tvalue. Further\ninvestigation on this topic is interesting but is considered\noutside the scope of this work.\nIt should be noted that the (re)setting of Tcan be performed\nthroughout the operational lifetime of the IMD. The physician\nis required to manually modify this parameter (in S) based on\nthe above guidelines, which then ultimately take effect in the\nreader-card authentication phase (see Fig. 3).\nB. AVAILABILITY \u0015 DoS PROTECTION\nAs highlighted in Section II, one of the system requirements\nis to ensure that the IMD is always available for treat-\nment. One high-likelihood and low-cost attack that affects\nthis requirement is the battery-DoS attack, as practically\ndemonstrated in [3], [4]. This attack forces the IMD\nto continuously run energy-consuming operations, which\nresults in battery depletion and ultimately causes device\nshutdown. For example, the attacker can repeatedly try\nto establish a connection with the implant using incorrect\ncredentials. The IMD will scrutinize each invalid request\nthrough energy-consuming authentication operations, which\nwill drain its battery despite failing to authenticate properly.\nThe IMD can defend against battery DoS by employing\nazero-power defense (ZPD) scheme in which the authen-\ntication operation is executed using borrowed energy [3].\nThis energy can be harvested from the incoming RF\ncommunication messages from the external reader. The IMD\nswitches to battery power only after it has successfully\nauthenticated the external entity.\nAnother type of DoS attack can occur when the attacker\nsends repeated communication requests to the implant. For\nan IMD with a single-processor, such requests may block\nthe device from performing its primary medical functionality.\nTo protect against this, a dual-CPU paradigm can be\nemployed, in which the \u001crst CPU executes the original\nmedical functionality, while the second CPU is responsible\nfor dealing with the (secure) communication requests.\nThis dual-core organization offers, then, both functional\nand power decoupling, which effectively shields the IMDmain functionality from battery-DoS attacks, as previously\nshowcased in [12].\nIn order to assess the viability of IMDfence under\nenergy-harvesting conditions (be it in single- or dual-CPU\ncon\u001cguration), we construct the following experimental\nsetup:\n(I) Computational costs: Similarly to [49], we employ\nan ARM Cortex-M0+ based 32-bit MCU [50]. Due to its\nultra-low-power capabilities, and the on-board hardware-\naccelerated, security building blocks (i.e., encryption, MAC,\nhash function, random-number generator etc.), this MCU\nis becoming increasingly employed in IoT and WBAN\nsettings [51], and hence, is a plausible choice for this\nevaluation. The security-related computations, i.e., authen-\nticated encryption (AES-128), cipher-based MAC and\nrandom-number generation were performed using the MCU's\ndedicated peripherals (``CRYPTO'' and ``TRNG''); thus,\nin our energy measurements, hardware-accelerated primitives\nare considered. However, as a reference, we also include a\nsoftware-only MCU implementation of IMDfence.\n(II) Wireless-communication costs: Commercial trans-\nceiver ZL70103 speci\u001ccally designed for IMDs has been\nused [52]. To get reasonable energy costs for (encrypted)\ndata transmission, we chose packet-size lengths similar to\nthe ones used in low-cost RFID tags, due to their similarities\nwith IMDs in terms of computational, memory and energy\nconstraints [12]. Hence N,ID,CMD andANS were set to\n32, 96, 32 and 64 bits, respectively. The sigsize was set at\n384 bits, which corresponds to an ECDSA (Elliptic-Curve\nDigital-Signature Algorithm) signature with a 96-bit security\nlevel.\nFIGURE 10. IMD energy consumption and performance per\nIMDfence-protocol step while using hardware-accelerated security\nprimitives.\nThe protocol sequence executed by the IMD is shown\nas numbered steps in Figures 5 and 6. In the case of\nhardware-accelerated primitives, the energy consumption\nfor these steps is shown in Fig. 10using a supply\nvoltage of 3.3 V, and the default MCU and transceiver\nclock frequencies of 19 MHz and 24 MHz, respectively.\nThe transceiver data rate is set at 400 kbps (with an effective\nrate of 265 kbps). We observe that the energy required\nfor authentication (E auth), i.e., for steps 1 to 4 in Fig. 5,is only 59.6 \u0016J. In the case of software implementation,\nhowever, Eauthis only 119.4 \u0016J, as shown in Fig. 11. For\nsuch a low harvested-energy requirement (E auth), it has been\ndemonstrated before in [49] that real-time performance is\npossible in the IMD with or without hardware acceleration.\nTotal IMD energy consumption per type of activity is also\nshown Fig. 12.\nFIGURE 11. IMD energy consumption and performance per\nIMDfence-protocol step when implementing the security primitives in\nsoftware.\nFIGURE 12. IMD energy consumption per IMDfence-protocol activity.\nC. IMD LIFETIME\nIn the previous section, we discussed the feasibility of\nIMDfence under energy-harvesting conditions to defend\nagainst battery-DoS attacks. In this section, we wish to assess\nthe total energy costs that the IMDfence protocol incurs over\nthe whole lifetime of a modern IMD. To do so, we need\nto consider realistic usage patterns of actual devices, drawn\nfrom medical practice. There are two prominent IMD classes:\nneurostimulators and cardiac implants. Neurostimulators\ntypically consume more power than cardiac devices [53]\nand, therefore, often come with rechargeable batteries which\nwould pose no challenge for IMDfence. Cardiac implants,\non the other hand, are not rechargeable due to their critical\nnature [49], and represent more pessimistic devices to\nassess IMDfence against. Thus, for our evaluation here,\nwe consider a communication session between a pacemaker\nand a commercial bedside reader (Merlin@homeTM) [22].\nWe consider different data volumes being transferred\nbetween the reader and IMD, ranging from a daily two-\nminute5communication session to a two-minute weekly\nsession. Since this reader is intended for monitoring the IMD\nstatus, it is assumed that most of the communicated data\nis transferred from the implant to the reader (e.g., in the\nform of data logs). Hence, the size of ANS is increased from\n64 bits (for a basic session) to roughly 3 MB in order to\nform a two-minute session. However, for worst-case analysis,\nthe transceiver is considered to be enabled throughout this\nsession and we do not assume the use of energy harvesting\nfor ZPD. Moreover, without loss of generality and in order\nto more accurately (and pessimistically) quantify the cost\nof adding IMDfence to an existing system, we consider a\ndual-CPU IMD, as discussed in the previous section. In this\ncon\u001cguration, the security CPU is assumed to execute the\ncomplete IMDfence protocol, while the medical CPU is set\nto a 5% duty cycle (active vs. sleep mode), based on typical\npacemaker usage [54], and consumes 20 \u0016J per heartbeat\nto provide electrical-stimulation impulses, based on reported\n\u001cgures of commercial devices [55].\nFIGURE 13. IMD-battery lifetime with respect to cryptographic primitive\nused. Boxplot variation is due to different data-transfer volumes.\nWith the above consideration, the impact of IMDfence\non IMD-battery lifetime can be visualized using Fig. 13for\ndifferent implantable-grade battery sizes [56]. The variability\nin each data point captures the different volumes of data\ntransfer between the reader and IMD.\nSince the majority of the cryptographic operations in the\nprotocol (authenticated encryption and MAC) are based on\nsymmetric block ciphers, as shown in Figures 5 and 6,\nit is very interesting to investigate the impact of different\ncipher versions and/or implementations thereof on IMD\nlifetime, e.g., a pacemaker. More box plots have, thus, been\nadded to Fig. 13, where we readily notice that the hardware\nimplementation of AES-128 signi\u001ccantly outperforms the\nsoftware AES-128 implementation, plus other lightweight\nsoftware ciphers such as SPECK and MISTY1. It is also\ninteresting to observe that the energy impact of the hardware\n5This corresponds to an unencrypted session. An equivalent secure session\n(by employing IMDfence) will take longer than two minutes due to the\nadditional data transferred.AES-128-based protocol is not signi\u001ccant when comparing\nwith an unsecured communication.\nD. IMD PERFORMANCE\nTo study the impact of IMDfence on performance during\nnormal operation, we will only analyze the bottleneck of\nthe reader-IMD system in this regard, i.e., the IMD itself.\nThis is because modern readers, such as tablets [17], have\nfar superior computational resources (and battery autonomy)\nthan implants. As far as the smart card is concerned,\nthe amount of computations performed by it is approximately\nthe same as that in commercial uses (e.g., EMV), which we\nknow to exhibit adequate performance.\nAs far as the IMD is concerned, the performance \u001cgure of\nmerit that is crucial to capture here is the delay that IMDfence\nincurs to the system, both for security computations and\ndata transmission over the air. For unsecured data transfer,\nthe wireless transceiver incurs a delay of 2.2 ms. As shown\nin Fig. 10, for (hardware-accelerated) secure data transfer the\ntime delay incurred by each (numbered) protocol step is no\nhigher than 6 ms, for a total protocol delay of 15.7 ms. There-\nfore, for the time scales involved in biological processes,\nwe can safely assume that the IMDfence delay overhead is\nnegligible.\nTABLE 5. Summary of costs for running the IMDfence protocol on an IMD.\nE. SUMMARY OF INTRODUCED OVERHEADS\nTable 5 summarizes the impact of IMDfence on an IMD\nin terms of energy, performance and program-memory\nfootprint. For the hardware implementation of IMDfence,\nit can be observed that, although the energy requirements\nincrease by more than 6 times for a basic session, the total\ndaily IMD consumption (that includes a two-minute com-\nmunication session and electrical-stimulation costs) increases\nfrom 16.60 J to just 17.69 J, which amounts to a mere\n6.57% increase, as previously shown in Fig. 13. The\nreason for this small increase is that the basic medical\nfunctionality, e.g., the continuous electrical stimulation of\na pacemaker, dominates the security provisions since the\nreader accesses are far less frequent. In the case of software\n(AES-128) implementation of IMDfence, the total daily IMD\nconsumption increases by 19.82% (as shown in Fig. 13).\nMoreover, there is a minimal increase in the computational\ndelay and required program-memory size. In the contextof current MCU technology, 8.22\u001510.48 kB of additional\nmemory size is negligible. Hence, we conclude that there is\nno noticeable change in the IMD costs when IMDfence is\nemployed.\nVII. CONCLUSION\nIn this paper, we have proposed a novel security protocol\nfor IMD ecosystems, IMDfence. We have demonstrated\nthat our approach offers a meticulous coverage of security\nrequirements that are critical to these systems. This becomes\npossible through the use of a personal smart card and a trusted\nthird party, which helps in facilitating access control, non-\nrepudiation, user authentication, bedside-reader operation\nand system scalability. We have also shown that IMDfence\ndoes not introduce any noticeable overheads in the implant,\nand it has the ability to support zero-power defense against\nbattery-DoS attacks. It is observed that our proposed protocol\nincreases the total IMD energy consumption by just 6.57%,\nwhich is minimal in the context of the IMD lifespan. We have\nalso proposed an OOB-channel-based version of IMDfence,\nwhich enables of\u001dine or emergency access.\nREFERENCES\n[1] M. A. Siddiqi, R. M. Seepers, M. Hamad, V. Prevelakis, and C. Strydis,\n``Attack-tree-based threat modeling of medical implants,'' in Proc. 7th Int.\nWorkshop Secur. Proofs Embedded Syst., 2018, pp. 32\u001549.\n[2] R. M. Seepers, ``Implantable medicalevices: Device security and emer-\ngency access,'' Ph.D. dissertation, Dept. Neurosci., Erasmus Univ. Medical\nCenter, Rotterdam, The Netherlands, Dec. 2016.\n[3] D. Halperin, T. S. Heydt-Benjamin, B. Ransford, S. S. Clark, B. Defend,\nW. Morgan, K. Fu, T. Kohno, and W. H. Maisel, ``Pacemakers and\nimplantable cardiac de\u001cbrillators: Software radio attacks and zero-\npower defenses,'' in Proc. IEEE Symp. Secur. Privacy (SP), May 2008,\npp. 129\u0015142.\n[4] E. Marin, D. Singel\u00e9e, F. D. Garcia, T. Chothia, R. Willems, and\nB. Preneel, ``On the (in)security of the latest generation implantable cardiac\nde\u001cbrillators and how to secure them,'' in Proc. 32nd Annu. Conf. Comput.\nSecur. Appl., Dec. 2016, pp. 226\u0015236.\n[5] E. Marin, D. Singel\u00e9e, B. Yang, V. Volski, G. A. E. Vandenbosch, B. Nuttin,\nand B. Preneel, ``Securing wireless neurostimulators,'' in Proc. 8th ACM\nConf. Data Appl. Secur. Privacy, Mar. 2018, pp. 287\u0015298.\n[6]Security Bulletin\u0016Conexus Telemetry and Monitoring Accessories,\nMedtronic, Dublin, Ireland, 2019.\n[7]Firmware Update to Address Cybersecurity Vulnerabilities Identi\u001ced in\nAbbott's (Formerly St. Jude Medical's) Implantable Cardiac Pacemakers:\nFDA Safety Communication, FDA, Silver Spring, MD, USA, 2019.\n[8] L. Bu, M. G. Karpovsky, and M. A. Kinsy, ``Bulwark: Securing implantable\nmedical devices communication channels,'' Comput. Secur., vol. 86,\npp. 498\u0015511, Sep. 2019.\n[9] T. Belkhouja, X. Du, A. Mohamed, A. K. Al-Ali, and M. Guizani,\n``Biometric-based authentication scheme for implantable medical devices\nduring emergency situations,'' Future Gener. Comput. Syst., vol. 98,\npp. 109\u0015119, Sep. 2019.\n[10] H. Chi, L. Wu, X. Du, Q. Zeng, and P. Ratazzi, ``E-SAFE: Secure, ef\u001ccient\nand forensics-enabled access to implantable medical devices,'' in Proc.\nIEEE Conf. Commun. Netw. Secur. (CNS), May 2018, pp. 1\u00159.\n[11] T. Belkhouja, X. Du, A. Mohamed, A. Al-Ali, and M. Guizani, ``Sym-\nmetric encryption relying on chaotic henon system for secure hardware-\nfriendly wireless communication of implantable medical systems,'' J.\nSensor Actuator Netw., vol. 7, no. 2, p. 21, May 2018.\n[12] C. Strydis, R. M. Seepers, P. Peris-Lopez, D. Siskos, and I. Sourdis,\n``A system architecture, processor, and communication protocol for secure\nimplants,'' ACM Trans. Archit. Code Optim., vol. 10, no. 4, p. 57, 2013.\n[13] J. van den Breekel, D. A. Ortiz-Yepes, E. Poll, and J. de Ruiter, ``Emv in a\nnutshell,'' KPMG, Amstelveen, The Netherlands, Tech. Rep., 2016.[14] M. A. Siddiqi and C. Strydis, ``IMD security vs. Energy: Are we tilting at\nwindmills?: POSTER,'' in Proc. 16th ACM Int. Conf. Comput. Frontiers,\nApr. 2019, pp. 283\u0015285.\n[15] Azure S SR MRI SureScan W3SR01\u0016Device Manual, Medtronic, Dublin,\nIreland, 2017.\n[16] Con\u001crm Rx Model DM3500 Insertable Cardiac Monitor\u0016User's Guide,\nSt. Jude Medical, Saint Paul, MN, USA, 2016.\n[17] Proclaim Implantable Pulse Generator\u0016Clinician's Manual, St. Jude\nMedical, Saint Paul, MN, USA, 2017.\n[18] E. Mar\u00edn F\u00e0bregas, ``Security and privacy of implantable medical devices,''\nPh.D. dissertation, Dept. Comput. Secur. Ind. Cryptogr. Group, KU\nLeuven, Belgium, Leuven, Belgium, 2018.\n[19] R. J. Anderson, ``Liability and computer security: Nine principles,'' in\nProc. Eur. Symp. Res. Comput. Secur. Berlin, Germany: Springer, 1994,\npp. 231\u0015245.\n[20] M. Roe, ``Cryptography and evidence,'' Univ. Cambridge, Comput.\nLab., Cambridge, U.K., Tech. Rep. UCAM-CL-TR-780, May 2010.\n[Online]. Available: https://www.cl.cam.ac.uk/techreports/UCAM-CL-\nTR-780.pdf\n[21] M. Rostami, A. Juels, and F. Koushanfar, ``Heart-to-heart (H2H):\nAuthentication for implanted medical devices,'' in Proc. ACM SIGSAC\nConf. Comput. Commun. Secur. CCS, 2013, pp. 1099\u00151112.\n[22] FAQs\u0016Merlin.Net Patient Care Netw. (PCN) 8.0 Q&A, St. Jude Medical,\nSaint Paul, MN, USA, 2015.\n[23] Ellipse, Fortify Assura ICD, Quadra Assura, Quadra Assura MP , Unify\nAssura CRT-D User Manual, St. Jude Medical, Saint Paul, MN, USA,\n2017.\n[24] M. Wazid, A. K. Das, N. Kumar, M. Conti, and A. V. Vasilakos,\n``A novel authentication and key agreement scheme for implantable\nmedical devices deployment,'' IEEE J. Biomed. Health Informat., vol. 22,\nno. 4, pp. 1299\u00151309, Jul. 2018.\n[25] D. Mao, L. Zhang, X. Li, and D. Mu, ``Trusted authority assisted three-\nfactor authentication and key agreement protocol for the implantable\nmedical system,'' Wireless Commun. Mobile Comput., vol. 2018, pp. 1\u001516,\nJul. 2018.\n[26] H. Rathore, C. Fu, A. Mohamed, A. Al-Ali, X. Du, M. Guizani, and Z. Yu,\n``Multi-layer security scheme for implantable medical devices,'' Neural\nComput. Appl., vol. 32, pp. 4347\u00154360, Oct. 2018.\n[27] C. Fu, X. Du, L. Wu, Q. Zeng, A. Mohamed, and M. Guizani, ``POKs\nbased secure and energy-ef\u001ccient access control for implantable medical\ndevices,'' in Security and Privacy in Communication Networks. Cham,\nSwitzerland: Springer, 2019, pp. 105\u0015125.\n[28] N. Ellouze, S. Rekhis, N. Boudriga, and M. Allouche, ``Powerless security\nfor cardiac implantable medical devices: Use of wireless identi\u001ccation\nand sensing platform,'' J. Netw. Comput. Appl., vol. 107, pp. 1\u001521,\nApr. 2018.\n[29] C. Camara, P. Peris-Lopez, J. M. De Fuentes, and S. Marchal, ``Access\ncontrol for implantable medical devices,'' IEEE Trans. Emerg. Topics\nComput., early access, Mar. 23, 2020, doi: 10.1109/TETC.2020.2982461.\n[30] C.-S. Park, ``Security mechanism based on hospital authentication server\nfor secure application of implantable medical devices,'' BioMed Res. Int.,\nvol. 2014, pp. 1\u001512, Jul. 2014.\n[31] M. Rushanan, A. D. Rubin, D. F. Kune, and C. M. Swanson,\n``SoK: Security and privacy in implantable medical devices and body\narea networks,'' in Proc. IEEE Symp. Secur. Privacy, May 2014,\npp. 524\u0015539.\n[32] R. M. Seepers, J. H. Weber, Z. Erkin, I. Sourdis, and C. Strydis, ``Secure\nkey-exchange protocol for implants using heartbeats,'' in Proc. ACM Int.\nConf. Comput. Frontiers CF, 2016, pp. 119\u0015126.\n[33] V. Pournaghshband, M. Sarrafzadeh, and P. Reiher, ``Securing legacy\nmobile medical devices,'' in Proc. Int. Conf. Wireless Mobile Commun.\nHealthcare. Berlin, Germany: Springer, 2012, pp. 163\u0015172.\n[34] J. Sorber, M. Shin, R. Peterson, C. Cornelius, S. Mare, A. Prasad,\nZ. Marois, E. Smithayer, and D. Kotz, ``An amulet for trustworthy wearable\nmHealth,'' in Proc. 12th Workshop Mobile Comput. Syst. Appl. HotMobile,\n2012, p. 7.\n[35] K. B. Rasmussen, C. Castelluccia, T. S. Heydt-Benjamin, and S. Capkun,\n``Proximity-based access control for implantable medical devices,'' in\nProc. 16th ACM Conf. Comput. Commun. Secur. CCS, 2009, pp. 410\u0015419.\n[36] Y. Kim, W. S. Lee, V. Raghunathan, N. K. Jha, and A. Raghunathan,\n``Vibration-based secure side channel for medical devices,'' in Proc. 52nd\nAnnu. Design Autom. Conf. DAC, 2015, p. 32.\n[37] G. Zheng, W. Yang, C. Valli, L. Qiao, R. Shankaran, M. A. Orgun, and\nS. C. Mukhopadhyay, ``Finger-to-heart (F2H): Authentication for wireless\nimplantable medical devices,'' IEEE J. Biomed. Health Informat., vol. 23,\nno. 4, pp. 1546\u00151557, Jul. 2019.\n[38] L. Wu, X. Du, M. Guizani, and A. Mohamed, ``Access control schemes for\nimplantable medical devices: A survey,'' IEEE Internet Things J., vol. 4,\nno. 5, pp. 1272\u00151283, Oct. 2017.\n[39] G. Zheng, R. Shankaran, M. A. Orgun, L. Qiao, and K. Saleem, ``Ideas and\nchallenges for securing wireless implantable medical devices: A review,''\nIEEE Sensors J., vol. 17, no. 3, pp. 562\u0015576, Feb. 2017.\n[40] R. Altawy and A. M. Youssef, ``Security tradeoffs in cyber physical\nsystems: A case study survey on implantable medical devices,'' IEEE\nAccess, vol. 4, pp. 959\u0015979, 2016.\n[41] C. Camara, P. Peris-Lopez, and J. E. Tapiador, ``Security and privacy issues\nin implantable medical devices: A comprehensive survey,'' J. Biomed.\nInformat., vol. 55, pp. 272\u0015289, Jun. 2015.\n[42] A. Juels and J. Brainard, ``Client puzzles: A cryptographic countermeasure\nagainst connection depletion attacks,'' in Proc. Netw. Distrib. Syst. Secur.\nSymp., 1999. [Online]. Available: https://www.ndss-symposium.org/\nndss1999/cryptographic-defense-against-connection-depletion-attacks/\n[43] Information Technology\u0016Security Techniques\u0016Entity Authentication\u0016\nPart 2: Mechanisms Using Symmetric Encipherment Algorithms, docu-\nment ISO/IEC 9798-2:2008, 2008.\n[44] W. J. Tomlinson, S. Banou, C. Yu, M. Stojanovic, and K. R. Chowdhury,\n``Comprehensive survey of galvanic coupling and alternative intra-body\ncommunication technologies,'' IEEE Commun. Surveys Tuts., vol. 21,\nno. 2, pp. 1145\u00151164, 2nd Quart., 2019.\n[45] The AVISPA Team. (2006). AVISPA V1.1 User Manual. [Online].\nAvailable: http://www.avispa-project.org/package/user-manual.pdf\n[46] J. van den Breekel, ``A security evaluation and proof-of-concept relay\nattack on dutch emv contactless transactions,'' M.S. thesis, Dept. Comput.\nSci. Eng., Eindhoven Univ. Technol., Eindhoven, The Netherlands, 2014.\n[47] B. Adida, M. Bond, J. Clulow, A. Lin, S. Murdoch, R. Anderson, and\nR. Rivest, ``Phish and chips,'' in Proc. Int. Workshop Secur. Protocols.\nBerlin, Germany: Springer, 2006, pp. 40\u001548.\n[48] R. Anderson, Security Engineering. Hoboken, NJ, USA: Wiley, 2008.\n[49] M. A. Siddiqi and C. Strydis, ``Towards realistic battery-DoS protection\nof implantable medical devices,'' in Proc. 16th ACM Int. Conf. Comput.\nFrontiers, Apr. 2019, pp. 42\u001549.\n[50] EFM32 Tiny Gecko 11 Family\u0016Reference Manual, Silicon Labs, Austin,\nTX, USA, 2018.\n[51] Businesswire. (2015). Silicon Labs Secures IoT Nodes with New\nEFM32 Jade and Pearl Gecko Microcontrollers. [Online]. Available:\nhttps://www.businesswire.com/news/home/20151214005228/en/Silicon-\nLabs-S%ecures-IoT-Nodes-New-EFM32\n[52] ZL70103 Medical Implantable RF Transceiver\u0016Datasheet Revision 2,\nMicrosemi, Aliso Viejo, CA, USA, 2015.\n[53] N. Mehta, ``When to consider getting a rechargeable SCS,'' Veritas Health,\nSep. 2018. [Online]. Available: https://www.spine-health.com/treatment/\npain-management/when-consider-getting-rechargeable-scs\n[54] P. Lindqvist, ``Compression and storage of medical data in pacemakers,''\nM.S. thesis, Dept. Numer. Anal. Comput. Sci., Roy. Inst. Technol.\nStockholm, Sweden, 2005.\n[55] M. Deterre, ``Toward an energy harvester for leadless pacemakers,''\nM.S. thesis, Universit\u00e9 Paris Sud Paris XI, Orsay, France, Jul. 2013.\n[Online]. Available: https://tel.archives-ouvertes.fr/tel-00868838\n[56] Eaglepicher Technologies. (2018). Medical Power. [Online]. Available:\nhttps://www.eaglepicher.com/markets/medical-power/\nMUHAMMAD ALI SIDDIQI received the B.E.\ndegree in electrical (telecommunication) engineer-\ning from the National University of Sciences and\nTechnology, Islamabad, Pakistan, in 2009, and\nthe Joint M.Sc. degree in embedded computing\nsystems from the Norwegian University of Sci-\nence and Technology, Trondheim, Norway, and\nthe University of Southampton, U.K., in 2012.\nHe is currently pursuing the Ph.D. degree with\nthe Neuroscience Department, Erasmus Medical\nCenter, The Netherlands.\nFrom 2012 to 2017, he was a Design Engineer with Silicon Labora-\ntories, Norway, on ultra-low-power MCU design. His research interests\ninclude development of security protocols and architectures for heavily\nresource-constrained embedded systems, such as implantable medical\ndevices.\nCHRISTIAN DOERR received the Ph.D. degree\nin computer science and cognitive science from\nthe University of Colorado Boulder, in 2008.\nHe is currently a Professor with the Hasso Plattner\nInstitute, University of Potsdam, Germany. He is\nthe Director of the Cyber Threat Intelligence\nLaboratory, which analyses techniques and tactics\nused by adversaries. His group operates a network\ntelescope, which is used to track and quantify\nthe nature and type of attacks on the Internet.\nHis research interests include network security, speci\u001ccally cyber threat\nintelligence and situational awareness, and protection of critical information\ninfrastructures.\nCHRISTOS STRYDIS (Senior Member, IEEE)\nreceived the M.Sc. (magna cum laude) and Ph.D.\ndegrees in computer engineering from the Delft\nUniversity of Technology. He is currently a\ntenured Assistant Professor in computer engi-\nneering and the Head of the NeuroComputing\nLaboratory, Neuroscience Department, Erasmus\nMedical Center, The Netherlands. He has pub-\nlished work in well-known international confer-\nences and journals. He has delivered invited talks\nin various venues. His current research interests include brain-simulations,\nhigh-performance computing, low-power embedded (implantable) systems,\nand functional ultrasound imaging.\n", "arxiv102": "\nIoT based Smart Water Quality Prediction for Biofloc \nAquaculture  \nMd. Mamunur Rashid1 \nDepartment of CSE , Univer sity of Liberal Arts Bangladesh  \nDhaka, Bangladesh  \nAl-Akhir Nayan2, Md. Obaidur  Rahman5 \nDepartment of CSE , European University of Bangladesh  \nDhaka, Bangladesh  \nSabrina Afrin Simi3 \nDept. of Human Computer Interaction  \nUniversity of Siegen , Siegen, Germany  Joyeta Saha4 \nDepartment of ECE , North South University  \nDhaka, Bangladesh  \nMuhammad  Golam Kibria6 \nDepartment of CSE, IoT Lab , University of Liberal Arts \nBangladesh , Dhaka, Bangladesh  \n \n \nAbstract \u2014Traditional fish farming faces several challenges , \nincluding water pollution, temperature imbalance, feed, space, \ncost, etc. Biofloc technology in aquaculture transforms the \nmanual into an advanced system that allows the reuse of unused \nfeed by converting them into microbial protein. The o bjective of \nthe research is to propose an IoT-based solution to aquaculture \nthat increases efficiency and productivity. The article pr esent ed a \nsystem that collects data using sensors , analyzes them using a \nmachine learning model, generates decisions with the help of \nArtificial Intelligence (AI), and  sends notifications to the user. \nThe proposed system has been implemented and tested to \nvalidate and  achieve a satisfactory result.  \nKeywords \u2014Smart aquaculture system ; biofloc technology ; \nmachine learning ; life below water  \nI. INTRODUCTION  \nIn biofloc aquaculture, it is inevitable to be more intelligent  \nto monitor the water quality in real -time and feed accurately. \nHowever, due to real -time water quality monitoring , the \nbalance of bacteria in the aquaculture environment might be \nharmed ; hence fish\u2019s disease- resistant ability is decreased. It is \nimpossible to measure the water quality accurately based on \nexperience only  [1, 2]. An intelligen t system could help the \nfarmers by reading the water parameters on time  to monitor \nand maintain the quality accordingly . Hence, identifying the \nwater parameters suitable for the biofloc aquaculture, a water quality prediction model for the dynamic changes in water parameters, and accordingly are essential . \nBiofloc technology can reduce food cost s, while a smart \naquaculture system can reduce labor cost. It is a good option that is cheaper and  beneficial to fish\u2019s health [ 3, 4]. Being a \nlow-lying country, several natural calamities like floods, \ncyclones, etc. , have a significan t effect on aquaculture at both \nthe ponds and marine waters. Fish farmers must  bear a \nsubstantial  loss due to the polluted water and increasing \nsalinity of the coastal water for those disasters. Traditional fish \nfarming leads to several other problems , such as water pollution caused by carbon dioxide, ammonia, and nitrogen. \nExternal filtration is needed for detoxifying , which is costly \nand time -consuming. Biofloc technology is a n excellent  \nalternative to the cost -effective traditional aquaculture system. \nBiofloc itself helps to purify the water naturally, hence the use \nof external tools or ingredients might be reduced. Maintaining water quality can ensure increasing production, decreasing the \ndeath of fish. Water quality parameters are the most important \nfactors to maint ain a fish farm using Bioflocs.  \nThis article mainly focuses on water level parameters. A n \nautomated system has been implemented to collect data through sensors, analyze them using a machine learning method, analyze the water quality. The a pplic ation of IoT \nmakes it easier to monitor the water and m aintain the ecology \nin biofloc aquaculture.  \nIn this article, data collected from the fish farm has been \nused for training and testing purpose s. A machine learning \nmethod has been applied to develop the  model. The water \nquality parameters , including pH,  have been analyzed, and the \ncorrelation between them is obtained. The water quality prediction model is trained based on the collected data . \nII. R\nELATED WORKS  \nDeep learning (DL) technology is used in numerous  fields . \nX. Yang  et al.  focused on DL applications  in aquaculture . They \nworked on identifying  live and dea d fish, classifi ed species , \nperformed  behavioral analysis,  and feeding decisions. The \nalgorithm and the results of the method were applied to the \nsmar t fish farm . The findings showed  that the deep learning \nmethod could extract features automatically . They made  the \nmost valuable contribution to the field of agriculture . But  the \ntechnique  was failed  to address  complex data in aquaculture  \n[5]. \nS. Liu et al. did an experiment on \u201c Ras Carpio'' using the \nRecirculating Aquaculture System (RAS) [6]. In 2011,  RAS \nwas an intelligen t alternative to traditional aquaculture in ponds. The water parameters were being continually \nmonitored,  and whenever the parameter\u2019s value got out of the \nfish\u2019s versati le range, the water was recirculated. For this \npurpose, there were two drainage systems. DO, pH, and the temperature w as monitored by WATT TriO M atic 700IQ \n(SW), WATT Sensolyt 700 IQ (SW), an d WATT Tri \noxyTherm type sensors. Though the  system had many benefits \nand was replaced rapidly with a regular aquaculture system , it \nhad some disadvantages . It needs water exchange which is a \nlengthy and costly process.  \nM. I. Dzulqornain et al. implemented  an innovative  IoT-\nbased system on the IFTTT model  [7]. They used dissolved \noxygen, water temperature, the potential of hydrogen (pH)  as \nparameters. The w ater level was sensed with sensors,  and for \ncontrolling the system , an aerator system was utilized \nintegrating with  microcontroller NodeMCU v3, relay, power \nsupply, and propeller. The sensor data was uploaded to the \ncloud,  and the client could visualize them from anywhere. The \napplication was both web- based and android -based . The \nsystem was well enough,  but its process was manual.  \nA. A. Nayan et al. worked on measuring river water quality \nfor agriculture and fishing purpose s [8] and identified fish \ndiseases  by detecting the change s in water quality  [9]. They \nused a machine learning technique that evaluated  the water \nquality  and processed intelligen t suggestions . They utilized pH, \nDO, BOD, COD, TSS, TDS, EC, PO43 -, NO3 -N, and NH3 -N \nto calculate the water quality and predicted the result using boosting technique. But the study  only focused on big water \nsource s like rivers and did not suggest any solution for small \nwater sources like ponds.  \nTo minimize the gap of previous studies and to provide a \nbetter understanding of the current state of the art of DL in aquaculture , we have worked on this project. The work offer s \ngood support for deploying applications for smart fish farming \nwhich is entirely new compar ed with other result s. An \nautomatic system with Biofloc technology has be en introduced. \nWe have tried to decrease feed costs by reducing FCR (feed conversion ratio). The nutrients used in this technology can be \nrecycled and reused easily.  \nIII. M\nATERIALS AND METHODS  \nA. Biofloc Technology (BFT)  \nBiofloc is a new technology introduced in aquaculture for \nlow-cost fish farming. Bioflocs are used to make reusable food \nfrom organic waste nutrients. It is a thin layer made up of beneficial bacteria, microorganisms, and algae that filters the water. Bacteria is cultured for this technology because it \nproduces flocs or algae , breaking  ammonia  to minimize water \npollution. The biofloc method of fish farming can be helpful  to \ngrow vegetables and fish together in the yard. This method requires tanks, oxygen supply pumps, and round -the-clock \nelectricity . It needs  less amount of food and  reduces the \nchances  of the disease. Being an eco-friendly system, it reduces \nthe impact on the environment and improves productivity. Water must  be exchanged to minimal or zero in this system.  It \nis cost-effective by reducing the usage of protein -rich feed [ 10, \n11, 12].  Fig. 1 shows a general image c aptured from a biofloc \nfarm.   \nFig. 1.  Biofloc Technology in Aquaculture.  \nB. Hardware Components  \nIoT innovation has brought \u201c Sensor Development \u201d to a \nnew stage. IoT systems operate and use a range of sensors to provide different kinds of information and data. It  helps to \ngather info rmation , drive,  and distribute it to a network of \nsimilar gadgets. Th e collected data allows it possible for the \ndevices to work autonomously, and every day the whole world turns to be \"smarter.\" By integrating sensors, microcontrollers, and other smart gadgets, the project was implemented.  We \nhave used the following hardware components to run  the \nproject.  \n\u2022 Arduino UNO  [13]. \n\u2022 White Breadboard.  \n\u2022 pH sensor  [14]. \n\u2022 Temperature Sensor  [15]. \n\u2022 Total Dissolved Solids (TDS) Sensor  [16].  \n\u2022 Computer.  \n\u2022 Wires . \nC. System Architecture  \nFig. 2 shows the architecture of our Smart  Aquaculture \nWater Monitoring System . The system  monitor s continuously \nand sends notifications through a Wi -Fi [17] module to an \nandroid application . The project's primary function is to check \nthe water parameters: pH, temperature, and TDS. We have \ncollected  samples  from different  farms that use  Biofloc \ntechnology. Processing data from the samples, we trained  the \nartificial neural network . The sensor s connected with the \nsystem provide a continuous  reading of the water parameter s. \nThe system generates output evaluating the trained data and the \nreading provided by the sensors . It predict s the water quality , \ndetermines the situation, and process wise decision. It  sends the \nresult and decision as a no tification to the u ser through an \nandroid application . Fig. 3 shows the flow diagram of the \nproject.  \nD. Hardware Connection  \nWe collected the required hardware , tools and connected \nthem according to the diagram  shown in Fig. 4. The figure \nmentions  the pin diagram of Arduino Uno with Temperature \nsensor and pH sensor.  \n\n \nFig. 2.  System Architecture.  \n \nFig. 3.  Flow Diagram . \n \nFig. 4.  Hardware Connection . \nFew farms  have already adopted biofloc technology . We \nfound many  projects  in Bangladesh and visited there . The first \ncenter  named \u201cBiotech Aquaculture\u201d  introduced the  \ntechnology in Bangladesh. The  center is situated at \nDakshinkhan, Uttara, Dhaka where Tilapia, Golsha, Pabda, \nKoi, and Shing  (Bengali name of the fishes)  are cultivated . The \nproject has been established on the \u201c No Water Exchange\u201d  \nprinciple. We visited  there in September 2020.  Investigating \ntheir working procedure, we found that t hey examine the water \ntwo times every day and collect the pH, water temperature, total dissol ved oxygen (TDS), ammonia (NH3), and floc \n(molasses).  Fig. 5 shows a comp lete picture of the study area.  \nSuppose the water parameters get out of the suitable range. \nIn that cas e, they control them by taking necessary steps for \nexample: filtering out the excess bioflocs (as it tends to \nincrease generally), adding baking soda in  a safe amount , and \nremov ing the fish from the tank before  raising the pH.  The \ntank's water  is matured , so the parameters do not  change  \nfrequently,  and the water is adaptable for the f ish species.  \nAnother center  is located at Bosila , Dhaka named \n\u201cMatsabid Biofloc Aquaculture Farm\u201d . They are using the  \nsame technology  but do  not follow the \u201cNo Water Exchange\u201d \nmethod. It is a big project of 15 large tanks and two large \nponds. The whole system is continuously  monitored manually \nby a famil y residing there . The a erator is mandatory  for the \nbioflocs to survive, so the aerator is turned on 24 hours a day. \nOnly three water param eters (pH, salinity , and the number of \nflocs ) are monitored in th e farm and whenever one gets \nincreased or decreased,  they change the water. For this \nexchange, they have a drainage system and a water pump. So, \nthe water is not matured here. The image of th e study area is \nshown in Fig. 6 and 7. \nF. Data Collection  \nWe collected samples  from different  centers. We bought  \ninstruments and sensors for data collection purposes.  We used \npH, temperature, and TDS sensor s to measure the values. \nSample collection was more manageable, but the data \nprocessing was difficult and time -consuming. We worked for \nmore than three months to process the necessary data from the samples. Tables  I and II  show  the details of the collected data.  \n \nFig. 5.  Study Area 1 at \u201cBiotech Aquaculture\u201d.  \n\n \nFig. 6.  Study Area 2 at \u201cMatshyabid Biofloc Aquaculture Farm\u201d  \n \nFig. 7.  Fish Tank at \u201cMatshyabid Biofloc Aquaculture Farm\u201d . \nTABLE I.  COLLECTED DATA FROM STUDY AREA 1 \nDay Date  pH Temp  TDS NH3  Floc \n1 08/06/20  7 30 1.75 2 10 ml  \n2 09/06/20  7 30 1.6 4 20 ml  \n3 10/06/20  7 28 1.3 2 8 ml \n4 11/06/20  7 29 1.35 2 10 ml  \n5 12/06/20  7 28 1.32 0.25 13 ml  \n6 15/06/20  7 28 1.32 1 10 ml  \n7 16/06/20  7 30 1.59 0.25 8 ml \n8 18/06/20  7 29 1.58 2 10 ml  \n9 19/06/20  7 28 1.33 2 20 ml  \n10 20/06/20  7 28 1.56 0.5 15 ml  \n11 21/06/20  7 30 1.60 1 20 ml  \n12 22/06/20  7 30 1.55 0 12 ml  \n13 23/06/20  7 29 1.54 0 20 ml  \n14 25/06/20  7 30 1.75 0 8 ml \nDate  Time  pH TDS Floc \n18/10/20  7.00 am  8.2 652 45 gm  \n18/10/20  8.00 pm  8.2 684 55 gm  \n19/10/20  7.00 am  8.2 684 43 gm  \n20/10/20    8.3 684 54 gm  \n21/10/20  7.00 am  8.3 659 22 gm  \n21/10/20  8.00 pm  8.4 654 25 gm  \n22/10/20  7.00 am  8.5 682 25 gm  \n22/10/20  8.00 pm  7.1 678 50 gm  \n23/10/20  7.00 am  7.9 654 45 gm  \n25/10/20  9.00 am  8.3 658 30 gm  \n26/10/20  7.00 am  8.3 684 29 gm  \n26/10/20  8.00 pm 8.4 681 35 gm  \n27/10/20  9.00 am  7.9 652 30 gm  \n28/10/20  7.00 am  8.3 685 33 gm  \n28/10/20  8.00 pm  8.2 682 45 gm  \nG. Data Preprocessing  \nWe collected data from water using  different  instruments  \nand stored it in a CSV  file. The CSV  file contains six  various  \nlabels , including temperature, TDS, pH,  and flocs. pH is \nconsidered  as the output data by which the model was tested \nand the rest five are regarded as  the input data  by which the \nmodel was trained . A glimpse of our dataset  is shown in \nTable III. \nH. Machine Le arning Algorithm for Decision Making  \nArtificial Neural Networks  (ANN) function  as the neurons  \nof the human brain. The network contains  nodes that receive \nthe input signal and pass it to the previous nodes as the synapse \nof a nerve cell does [ 18, 19]. The covariates and input variables \nare weighted, and these weighted signals are then passed through activation functions. Let y be output signal and be the activation function, the mathematical expression of signal processing in ANN is:  \ny( x ) = \u03a6( \u2211 i = 1 w i  \n\u22c5 x i)  \nThe network contains  an input layer, an output layer , and \none or more hidden layers. The hidden layers are responsible for the performance of the model . We used five hidden layers \nfor faster execution. More layers slow down the training and testing process.  \nI. Dependencies  \nWe trained the  model on Ubuntu 20.04 LTS and used  \npython 3.8. These were  dependencies and libraries . We \ninstalled and imported the following libraries to run the  code \nand train the model . \n\u2022 Tensor flow  \n\u2022 Keras  \n\u2022 Pandas  \n\n\u2022 Numpy  \n\u2022 Boxp lot Analysis  \nJ. Parameters and Algorithms  \nThe whole dataset was splatted into two different parts  that \nare training and testing.  We took  80% of the data for t raining , \nand the rest  20% was used for testing purposes . The model was  \ntrained  several times using  different epoch sizes . We \nencountered the overfeeding condition. Lastly , utilizing batch \nsize 32 and epoch size 150 , the model  achieved  the best \naccuracy.  The model consists of 5 hidden layers. The layers \nhelp to increase the model\u2019s performance. T he work flow of the \nlayers  is shown in Fig. 8. \nTo vanish the gradient problem and allow the model to run \nfaster and perform well, we used ReLu (Rectified Linear Unit) \n[20, 21] with the hidden layers.  Softmax was utilized as an \nactivation function in  the output layer. The n umber of classes \nwas 4 for the output  [22]. 0 denotes a shallow DO level, 1 \nrepresents a low DO level, 2 denotes an average DO level, and 3 denotes a  high DO level.  \nTABLE III.  PROCESSED DATA \n A B C D E \n1 Temp  D.O. (mg)  pH TDS Flocs (ml)  \n2 29.5  6.3 6.9 1.7 10 \n3 29.7 5.7 6.9 3.8 50 \n4 29.5 5.8 7.3 1.9 40 \n5 30 5.5 7.4 1.5 10 \n6 29.2 6.1 6.7 1.4 30 \n7 29.1 7.3 7 1 10 \n8 28.7 7 6.9 1.2 30 \n9 28.7 7.3 6.7 1.5 10 \n10 29.5 7.2 6.8 1.2 30 \n11 29 5.3 6.4 1.6 120 \n12 30.5 6.3 7.5 1.5 10 \n13 29.1 5.5 6.3 1.4 10 \n14 30.1 7.3 7.8 2 30 \n15 29.2 6.5 7.9 1.5 40 \n16 25.1 7.2 7.7 4.9 30 \n17 29.6 6.6 7.8 5 60 \n18 27.4 6.9 7.3 5.2 30 \n19 27.8 6.8 7.9 4.9 180 \n20 30.6 6.7 7.6 10.3 190 \n21 25 5.1 7.6 3.6 60 \n22 28.1 5.6 7.7 4.6 70 \n23 28.6 6.3 6.9 4.7 40 \n24 26.9 6.6 6.8 5 30 \n25 28.2 6.8 6.5 5.2 60  \nFig. 8.  Workflow of the Layers . \nIV. SIMULATION  AND RESULT  \nA. Training and Testing  \nAfter collecting and processing the dataset , we trained the \nmodel . The model  was trained  with the 80% data and later \ntested with the rest 20% data. We utilized a completely \ndifferent  type of  data for training and testing purpose s. The \nmodel scored 0.773 testing accuracy , which was well enough \nto maintain good performance. The loss was calculated with \nthe increasing number of epochs . After 55 epochs , the loss was \nminimized rapidly. We calculated the loss between 0 to 1.2 range. The minimum testing loss was 0.5,  and the training loss \nwas 0.7. The training and testing accura cy and loss have been \nshown in Fig. 9 and 10 . \n \nFig. 9.  Training and Testing Accuracy . \n\n \nFig. 10.  Training and Testing L oss. \nB. System Output  \nEvaluating the parameter\u2019s value, the system provides an \noutput. Depending on the DO level (shallow, low, average, or \nhigh) in the water, the system generates a message and \nprovides a decision analyzing the current output. To make the system more user -friendly, we have designed a smartphone \napplication to notify the user about the result and determination that the machine generates.  \nA user needs the android application, an ubuntu droplet, \nand a droplet\u2019s IP address for the push notification. We used GCM (Google Cloud Messaging) [23] for android, where we enabled the API for our project first and then linked the \nandroid App through it. We deployed an Ubuntu droplet and \nset up a python GCM simple server on Ubuntu. Lastly, a push \nnotification was displayed on the Android app generated by the system. A snapshot of the smartphone application is shown in Fig. 11. \nC. Performance Comparison  \nMany r esearchers have worked on intelligen t biofloc \ntechnology.  pH, DO, BOD, COD, TSS, TDS, EC, PO43 -, \nNO3 -N, and NH3 -N are the standard  parameters  utilized by \nmost researchers for measuring water quality and its changes. The Artificial Neural Network (ANN)  [24], Group Data \nHandling Method (GMDH)  [25], Support Vector Machine \n(SVM) [26], Least -Squares Support Vector Regression \ncost. It needs not to use big ponds or a wide r area. Our project \ncan help anyone to produce  plenty of fishes in a small \ncontainer or house  at a small cost . We have compared our  \napproach  with other  existing technique s. For compa ring, we \nprovided significant  importance to the proposed method, \naccuracy, cost reduction rate,  parameters, real -time monitoring \ncapability , prediction capability, decision -making capability , \nand user satisfaction  level . The comparison is shown in table  4. \nThe information  mentioned in the table is  collected from \ndifferent  published articles. Here we did not compare among \nthe methods. We have reach ed the performances of different \napproaches  only.  \n \nFig. 11.  Notif ication to the Smartphone Application . \nTABLE IV.  PERFORMANCE COMPARISON  \nMethod \nUsed Testing \nAccuracy \n(Percentage)  Real- time \nMonitoring  Parameters  Automatic Solution Decision- Making \nAbility  User satisfaction  \nAAN  72 %  Monitors 24 \nx 7 Temperature, DO, TDS, \npH, BOD, COD, TSS  Does not perform \nautomatic solution  Can predict and process \nsmart decision  Medium  \nGMDH  74% Monitors 24 \nx 7 Temperature, DO, TDS, \npH Does not perform \nautomatic solution  Better prediction and \ndecision -making system  High  \nSVM  70% Monitors 24 \nx 7 Temperature, DO, TDS, \npH Does not perform \nautomatic solution  Lower quality prediction  Low \nLSSVR  76% Monitors 24 \nx 7 Temperature, DO, TDS, \npH, EC, PO43 -, NO3 -N Does not perform \nautomatic solution  Can predict and process \nsmart decision  Medium  \nLSTM  82 %  Monitors 24 \nx 7 pH, temperature, DO  Does not perform \nautomatic solution  Better prediction and \ndecision -making system  High  \nOur Approach 77 %  Monitors 24 x 7 Temperature, DO, TDS, pH, Floc  Perform s automatic \nsolution  Can predict and process \nsmart decision  Android application is available \nfor monitoring from anywhere. \nUser satisfaction is measured  as \n\u201cVery High \u201d \nCONCLUSION  \nAquaculture farmers have been surviving from economic \nconstraints, high- paid and even unavailability of human \nresources , tim ely monitoring of water quality , and sudden \nincrease in toxicity for decade after decade. The IoT -based \nwater quality monitoring system monitors the water quality in \nreal-time and  reduces the cost of production, increase s \nefficiency, reduces human dependency, and thus ensures \nsustainable development economically and socially. The proposed system monitors the water quality  in real -time and \nsends a notification to the user instantly , which  reduces the \nrisk. A machine learnin g technique has been applied to trace \nthe water quality. To v alidate the proposed model, experiments \non the implemented functionalities have been performed. The experiments show 0.773 as testing accuracy which was well enough to maintain good performance. Currently, the implementation of identified functionalities ha s been car ried \nout. In the future, we wish to improve the model to achieve higher accuracy and evaluate the performance in terms of the fish population . \nA\nCKNOWLEDGMENT  \nThe IoT Lab has supported this research work , a state -of-art \nspecialized research facility of its kind situated at ULAB, \nimplemented,  and supported by the Bangladesh Hi -Tech Park \nAuthority of ICT Division . \nREFERENCES  \n[1] S. Saha, R. Hasan and S. Kabir, \"IoT Based Smart Farm Monitoring \nSystem\",  International Journal of Recent Technology and Engineering, \nvol. 8, no. 4, pp. 5490- 5494, 2019. Available: \n10.35940/ijrte.d8806.118419 [Accessed 1 November 2020].  \n[2] R. Crab, T. Defoirdt, P. Bossier and W. Verstraete, \"Biofloc technology in aquacultu re: Beneficial effects and future challenges\",  Aquaculture , \nvol. 356- 357, pp. 351- 356, 2012. Available: \n10.1016/j.aquaculture.2012.04.046 [Accessed 1 December 2020].  \n[3] B. Ghose, \"Fisheries and Aquaculture in Bangladesh: Challenges and \nOpportunities.\",  Aquaculture Research , 2014. Bashar, Abul. (2018). \nBiofloc Aquaculture: prospects and challenges in Bangladesh. \n10.13140/RG.2.2.13233.94560.  \n[4] D. SK, \"Biofloc Technology (BFT): An Effective Tool for Remediation \nof Environmental Issues and Cost Effective Novel Techn ology in \nAquaculture\",  International Journal of Oceanography & Aquaculture , \nvol. 2, no. 2, 2018. Available: 10.23880/ijoac -16000135 [Accessed 3 \nNovember 2020].  \n[5] X. Yang, S. Zhang, J. Liu, Q. Gao, S. Dong and C. Zhou, \"Deep learning for smart fish farming: applications, opportunities and challenges\",  Reviews in Aquaculture , vol. 13, no. 1, pp. 66- 90, 2020. \nAvailable: 10.1111/raq.12464 [Accessed 27 December 2020].  \n[6] S. Liu et al., \"Prediction of dissolved oxygen content in river crab culture based on least squares support vector regression optimized by improved particle swarm optimization\",  Computers and Electronics in \nAgriculture, vol. 95, pp. 82- 91, 2013. Available: \n10.1016/j.compag.2013.03.009 [Accessed 20 November 2020].  \n[7] U. Ahmed, R. Mumtaz, H. Anwar, A. Shah, R. Irfan , and J. Garc\u00eda-\nNieto, \"Efficient Water Quality Prediction Using Supervised Machine Learning\", Water , vol. 11, no. 11, p. 2210, 2019. Available: \n10.3390/w11112210 [Accessed 20 November 2020].  \n[8] A. A. Nayan, M. G. Kibria, M. O. Rahman and J. Saha, \"River Water \nQuality Analysis and Prediction Using GBM,\" 2020 2nd International Conference on Advanced Information and Communication Technology (ICAICT), Dhaka, Bangladesh, 2020, pp. 219- 224, DOI: \n10.1109/ICAICT51780.2020.9333492.  \n[9] Technology(Bft)\", Journal Of Fishries And Marine Sciences Education, Vol. 32, No. 6, p p. 1632- 1638, 2020. Available: \n10.13000/Jfmse.2020.12.32.6.1631.  \n[12] J. Jung, J. Hur, K. Kim , and H. Han, \"Evaluation of floc- harve sting \ntechnologies in biofloc technology (BFT) system for aquaculture\", Bioresource Technology, vol. 314, p. 123719, 2020. Available: \n10.1016/j.biortech.2020.123719.  \n[13] \"Arduino - ArduinoBoardUno\", Arduino.cc, 2021. [Online]. Available: \nhttps://www.arduino.cc/en/Main/arduinoBoardUno&gt;. [Accessed: 08 - \nMar- 2021].  \n[14] \"Sensor for pH determination\", Sensor Review, vol. 20, no. 2, 2000. Available: 10.1108/sr.2000.08720bad.016.  \n[15] \"New low temperature ultrasonic ranging sensor\", Sensor Review, vol. 20, no. 1, 2000. Avai lable: 10.1108/sr.2000.08720aad.012.  \n[16] L. Zhang, \"Effects of electrolyte total dissolved solids (TDS) on \nperformance and anodic microbes of microbial fuel cells\", AFRICAN JOURNAL OF BIOTECHNOLOGY, vol. 10, no. 74, 2011. Available: \n10.5897/ajb11.1993.  \n[17] X. Kuan g and H. Huo, \"A Design of WIFI Wireless Transmission \nModule Based on MCU\", Applied Mechanics and Materials, vol. 442, pp. 367- 371, 2013.  \n[18] \"Machine Learning and Artificial Neural Network\", International \nJournal of Recent Trends in Engineering and Research, vol. 4, no. 3, pp. \n660-668, 2018. Available: 10.23883/ijrter.2018.4179.tdtms.  \n[19] R. CVS and N. Pardhasaradhi, \"Analysis of Artificial Neural- Network\", \nInternational Journal of Trend in Scientific Research and Development, \nvol. -2, no. - 6, pp. 418- 428, 2018. A vailable: 10.31142/ijtsrd18482.  \n[20] \"Pattern Recognition Of Numeric Numbers Using Artificial Neural \nNetwork \", International Journal of Recent Trends in Engineering and \nResearch, pp. 242- 244, 2018. Available: 10.23883/ijrter.conf.2017  \n1201.048.kzvk9.  \n[21] C. Banerjee, T. Mukherjee and E. Pasiliao, \"Feature representations \nusing the reflected rectified linear unit (RReLU) activation\", Big Data Mining and Analytics, vol. 3, no. 2, pp. 102- 120, 2020. Available: \n10.26599/bdma.2019.9020024.  \n[22] K. Kaiho, \"Benthic foraminiferal dissolved -oxygen index and dissolved-\noxygen levels in the modern ocean\", Geology , vol. 22, no. 8, p. 719, \n1994.  \n[23] V. Dubey, \"Android Device to Device Messaging using Google Cloud Messaging (GCM)\", SMART MOVES JOURNAL IJOSCIENCE, vol. \n1, no. 1, 2015. Availa ble: 10.24113/ijoscience.v1i1.6.  \n[24] A. Kadam, V. Wagh, A. Muley, B. Umrikar and R. Sankhua, \"Prediction \nof water quality index using artificial neural network and multiple linear \nregression modelling approach in Shivganga River basin, India\", Modeling Earth Systems and Environment, vol. 5, no. 3, pp. 951- 962, \n2019. Available: 10.1007/s40808- 019-00581- 3. \n[25] O. Varis, \"Water Quality Models: Tools For The Analysis Of Data, Knowledge, and Decisions\", Water Science and Technology, vol. 30, no. \n2, pp. 13- 19, 1994. Available: 10.2166/wst.1994.0024.  \n[26] A. Haghiabi, A. Nasrolahi and A. Parsaie, \"Water quality prediction \nusing machine learning methods\", Water Quality Research Journal, vol. \n53, no. 1, pp. 3- 13, 2018. Available: 10.2166/wqrj.2018.025.  \n[27] G. Tan, J. Yan, C. Gao and S. Yang, \"Prediction of water quality time \nseries data based on least squares support vector machine\", Procedia Engineering, vol. 31, pp. 1194- 1199, 2012. Available: \n10.1016/j.proeng.2012.01.1162.  \n[28] Z. Hu et al., \"A Water Quality Prediction Method Based on the Deep \nLSTM Network Considering Correlation in Smart Mariculture\", \nSensors, vol. 19, no. 6, p. 1420, 2019. Available: 10.3390/s19061420.  \n ", "arxiv12": "Received September 22, 2020, accepted October 15, 2020, date of publication November 16, 2020,\ndate of current version December 7, 2020.\nDigital Object Identifier 10.1 109/ACCESS.2020.3037715\nHuman Activity Recognition Using Inertial,\nPhysiological and Environmental Sensors:\nA Comprehensive Survey\nFLORENC DEMROZI\n1, (Member, IEEE), GRAZIANO PRAVADELLI\n1, (Senior Member, IEEE),\nAZRA BIHORAC\n2, AND PARISA RASHIDI\n3, (Senior Member, IEEE)\n1Department of Computer Science, University of Verona, 37134 Verona, Italy\n2Division of Nephrology, Hypertension, and Renal Transplantation, College of Medicine, University of Florida, Gainesville, FL 32610, USA\n3Department of Biomedical Engineering, University of Florida, Gainesville, FL 32610, USA\nCorresponding author: Parisa Rashidi (parisa.rashidi@u\u001d.edu)\nAzra Bihorac and Parisa Rashidi were supported by R01 GM110240 from the National Institute of General Medical Sciences. Parisa\nRashidi has received Grant NIH/NIBIB 1R21EB027344 and NSF CAREER 1750192. The content is solely the responsibility of the\nauthors and does not necessarily represent the of\u001ccial views of the National Institutes of Health or National Science Foundation.\nABSTRACT In the last decade, Human Activity Recognition (HAR) has become a vibrant research area,\nespecially due to the spread of electronic devices such as smartphones, smartwatches and video cameras\npresent in our daily lives. In addition, the advance of deep learning and other machine learning algorithms\nhas allowed researchers to use HAR in various domains including sports, health and well-being applications.\nFor example, HAR is considered as one of the most promising assistive technology tools to support elderly's\ndaily life by monitoring their cognitive and physical function through daily activities. This survey focuses\non critical role of machine learning in developing HAR applications based on inertial sensors in conjunction\nwith physiological and environmental sensors.\nINDEX TERMS Human activity recognition (HAR), deep learning (DL), machine learning (ML), available\ndatasets, sensors, accelerometer.\nI. INTRODUCTION\nHuman Activity Recognition (HAR) has become a popular\ntopic in the last decade due to its importance in many areas,\nincluding health care, interactive gaming, sports, and moni-\ntoring systems for general purposes [1]. Besides, nowadays,\nthe aging population is becoming one of the world's primary\nconcerns. It was estimated that the population aged over\n65 would increase from 461 million to 2 billion by 2050.\nThis substantial increase will have signi\u001ccant social and\nhealth care consequences. To monitor physical, functional,\nand cognitive health of older adults in their home, HAR is\nemerging as a powerful tool [2]\nThe goal of HAR is to recognize human activities in con-\ntrolled and uncontrolled settings. Despite myriad applica-\ntions, HAR algorithms still face many challenges, including\n1) complexity and variety of daily activities, 2) intra-subject\nand inter-subject variability for the same activity, 3) the\ntrade-off between performance and privacy, 4) computational\nThe associate editor coordinating the review of this manuscript and\napproving it for publication was Praveen Gunturi.ef\u001cciency in embedded and portable devices, and 5) dif-\n\u001cculty of data annotation [3]. Data for training and test-\ning HAR algorithms is typically obtained from two main\nsources, 1) ambient sensors, and 2) embedded sensors. Ambi-\nent sensors can be environmental sensors such as tem-\nperature sensors or video cameras positioned in speci\u001cc\npoints in the environment [4], [5]. Embedded sensors are\nintegrated into personal devices such as smartphones and\nsmartwatches, or are integrated into clothes or other spe-\nci\u001cc medical equipment [6]\u0015[9]. Cameras have been widely\nused in the HAR applications, however collecting video\ndata presents many issues regarding privacy and computa-\ntional requirements [10]. While video cameras produce rich\ncontextual information, privacy issues limitations have led\nmany researchers to work with other ambient and embed-\nded sensors, including depth images as a privacy-preserving\nalternative.\nIn terms of algorithmic implementation, HAR research has\nseen an explosion in Deep Learning (DL) methods, result-\ning in an increase in recognition accuracy [5], [7]. While\nDL methods produce high accuracy results on large activityFIGURE 1. (a) Distribution of published papers in HAR research area, for DL vs. CML implementations. (b) The average recognition accuracy of published\npapers, for DL vs. CML implementations.\nFIGURE 2. Distribution of published papers per year in HAR research based on (a) CML and (b) DL.\ndatasets, in many HAR applications Classic Machine Learn-\ning (CML) models might be better suited due to the small\nsize of the dataset, lower dimensionality of the input data,\nand availability of expert knowledge in formulating the prob-\nlem [11]. The increasing interest in HAR can be associated\nwith growing use of sensors and wearable devices in all\naspects of daily life, especially with respect to health and\nwell-being applications. This increasing interest in HAR is\nevident from the number of papers published in the past \u001cve\nyears, from 2015 to 2019. As Figure 1.(a) shows, among\na total of 149 selected published papers on HAR, 53 were\nbased on DL models, and 96 were based on CML mod-\nels. During the same time period were published 46 sur-\nveys and 20 articles proposing not ML-based methodologies\n(e.g., threshold models). Figure 1.(b) shows the average activ-\nity recognition accuracy, among the 53 DL-based papers and\nthe 96 CML-based papers, that as visible (93% DL-based\nand 92.2% CML-based) present almost the same recognitionquality. In addition, Figure 2shows the distribution of the\npublished HAR papers over the past \u001cve years in terms\nof (a) CML and (b) DL models. It shows that the num-\nber of CML-based HAR models was, except 2019, greater\nthan the number of DL-based HAR models. In this article,\nwe will review both DL-based and CML-based methodolo-\ngies. We will limit our review to non-image-based sensors,\nto limit the scope. Interested readers are encouraged to read\nreferences on vision-based HAR [10], [12]\u0015[14].\nFigure 3presents the standard work\u001dow in designing\nHAR-based methodologies. When developing HAR-based\napplication, the \u001crst step is to determine the type of sen-\nsor and device that is used to collect data (device iden-\nti\u001ccation). The second step is to determine the details of\nthe data collection process, including the annotation process\nand possibly any necessary preprocessing (data collection).\nThe third step includes identifying the appropriate machine\nlearning model and training the model, typically a supervisedFIGURE 3. Standard workflow for implementing HAR based application.\nmachine learning model on annotated data (model selection\nand training). However, as shown in Figure 3(indicated by the\nbackwards arrow), the selected model can also in\u001duence the\npreprocessing data step. In the \u001cnal step, the model is evalu-\nated in terms of the activity recognition metrics such as accu-\nracy, precision, recall, and other metrics (model evaluation).\nIn this work, we use accuracy as a comparison metric between\nthe various articles due to the fact that it is the only common\nmetric. Not all articles present the results obtained in terms\nof precision, recall, sensitivity, F1-Score, Area Under the\nCurve (AUC) or Receiver Operating Characteristics (ROC)\ncurve, despite being more representative metrics, especially\nwith unbalanced data. Using this work\u001dow as a reference, this\narticle provides an overview of the state-of-the-art in HAR by\nexamining each phase of the process. Finally, we are particu-\nlarly interested in accelerometer sensors because they have\nshown excellent results in HAR applications and because\ntheir use in conjunction with other sensors is rising rapidly.\nThe proliferation of accelerometer sensors is strongly related\nto their ability to measure directly the movement of the human\nbody. In addition, using accelerometer sensors is affordable,\nand the sensors can be integrated into most wearable elec-\ntronic objects people own.\nThe rest of the paper is organized as follows: Section II\nprovides a brief overview of the existing surveys on HAR\nfrom 2015 to 2019, Section IIIdescribes the article selec-\ntion criteria, Section IVwill provide background material on\nCML, DL, and existing sensors/wearable devices. Section V\nwill introduce the de\u001cnition of human activity, followed by\ncategorization of the published works in terms of sensor\nand device (Section VI). Section VIIwill present available\ndatasets for HAR research activity. Section VIIIwill review\npublished papers based on the model and evaluation metrics.\nSection IXwill discuss the limitations and challenges of\nexisting HAR research, followed by a discussion on future\nresearch direction in Section X. Finally, Section XIreports\nsome concluding remarks.\nII. EXISTING SURVEYS\nSince HAR is emerging as an important research topic, many\nsurveys have been published in the past few years. Among the\ninitial 293 published papers that we identi\u001ced, 46 were survey\npapers published since 2015. The existing survey papers can\nbe categorized based on the data sources and the activity\nrecognition algorithm. The most widely used data sources\nare a) inertial, physiological and environmental devices, and\nb) video recording devices. In terms of the HAR algorithm,\nmost algorithms are based on CML models and more recentlyDL algorithms. Among such 46 survey papers, we excluded\n23 papers which were exclusively video-based HAR papers.\nOur survey paper provides unique contribution to the review\nof literature by providing, a broad vision of the evolution of\nHAR research in the past 5 years. Unlike existing surveys,\nwe do not solely focus on the algorithmic details, rather we\nwill also describe the data sources (aka sensors and devices)\nare used in this context. We are particularly interested in\naccelerometer sensors because they have shown excellent\nresults in HAR applications and because their use in con-\njunction with other sensors such as physiological sensors or\nenvironmental sensors is rising rapidly. The proliferation of\naccelerometer sensors is strongly related to their ability to\ndirectly measure the movement of the human body. In addi-\ntion, using accelerometer sensors is affordable, and the sen-\nsors can be integrated into most wearable devices. Recently,\nWang. J and colleagues [15] (2019) survey existing literature\nbased on three aspects: sensor modality, DL models, and\napplication scenarios, presenting detailed information of the\nreviewed works. Wang. Y and colleagues [2] (2019) present\nthe state-of-the-art sensor modalities in HAR mainly focusing\non the techniques associated with each step of HAR in terms\nof sensors, data preprocessing, feature learning, classi\u001cca-\ntion, activities, including both conventional and DL methods.\nBesides, they present the ambient sensor-based HAR, includ-\ning camera-based, and systems combining wearable and\nambient sensors. Sousa Lima et al. [16] (2019) provide a com-\nplete, state-of-the-art outline of the current HAR solutions in\nthe context of inertial sensors in smartphones, and, Elbasiony\nand Gomaa [17] (2019) introduce a detailed survey on multi-\nple HAR systems on portable inertial sensors (Accelerometer,\nGyroscopes, and Magnetometer), whose temporal signals are\nused for modeling and recognition of different activities.\nNweke et al. [18] (2019) provide a detailed analysis of\ndata/sensors fusion and multiple classi\u001ccation systems tech-\nniques for HAR with emphasis on mobile and wearable\ndevices. Faust et al. [19] (2018), studied 53 papers focused\non physiological sensors used in healthcare applications such\nas Electromyography (EMG), Electrocardiogram (ECG),\nElectrooculogram (EOG), and Electroencephalogram (EEG).\nRamasamy Ramamurthy and Roy [20] (2018) presented an\noverview of ML and data mining techniques used for Activ-\nity Recognition (AR), empathizing with the fundamental\nproblems and challenges. Finally, Morales and Akopian [21]\n(2017) provide an overview of the state-of-the-art concerning:\nrelevant signals, data capturing and preprocessing, calibrating\non-body locations and orientation, selecting the right set of\nfeatures, activity models and classi\u001cers, and ways to evaluateTABLE 1. Existing HAR surveys.\nthe usability of a HAR system. Moreover, it covers the detec-\ntion of repetitive activities, postures, falls, and inactivity.\nTable 1 summarizes 23 surveys on HAR methods sorted\nby chronological order from 2019 to 2015. It should be noted\nthat all these surveys, including those not taken into con-\nsideration (video-based), had not reported their systematic\nreview process (e.g., using Preferred Reporting Items for Sys-\ntematic reviews and Meta-Analyses (PRISMA)). In Table 1,\nColumn \u001cve, we report the start/end publication year of the\nreviewed papers and Column six their approximate number\nof reviewed articles. Most of these HAR reviews focus on\ndata management methods and activity recognition models.\nTo the best of our knowledge, no existing survey article is\n(1) presenting a comprehensive meta-review of the existing\nsurveys, (2) providing a comprehensive overview of different\nsensors, (3) reporting and comparing performance metrics,\nand (4) reporting on dataset availability and popularity.III. SELECTION CRITERIA\nWe used Google Scholar to search for studies published\nbetween January 2015 to September 2019. All searches\nincluded the term ``human activity recognition,'' or ``HAR''\nin combination with ``deep learning'', ``machine learning,''\n``wearable sensors,'' and ``<name>1sensor''. All these pub-\nlished papers where found by using the combination of\nkeywords mentioned above. Our keywords produced a total\nof 249110 records, among which we selected 293 based on\nthe quality of the publication venue. The chosen articles\nwere selected from the following publishers: Institute of\nElectrical and Electronics Engineers (IEEE), Association for\nComputing Machinery (ACM), Elsevier, and Sensors. The\naverage number of citations was 46, and the distribution of the\n1e.g., accelerometer, gyroscope, magnetometer, barometer, light, Global\nPositioning System (GPS)\nTABLE 2. Distribution of the selected published articles for year by\nincluding the following keywords: ``Human Activity Recognition (HAR),\nSensor <Name>, Wearable sensors'' .\nFIGURE 4. PRISMA-based flowchart of the retrieval process.\npapers for each year is shown in Table 2. Figure 4 shows our\nretrieval process based on PRISMA template for systematic\nreviews [37]. First, we excluded all surveys papers and not\naccessible papers ( e.g., requiring paid access) (91 excluded).\nNext, we excluded all books (4 excluded) and all vision-based\npapers (31 excluded). Finally, we excluded all the papers that\ndo not use accelerometers (4 excluded), and all the papers per-\nforming activity recognition different from daily life human\nactivities, such as swimming, riding horses, driving, publica-\ntions prior to 2015, and papers using non-machine learning\ntechniques such as simple thresholding (4 excluded). As a\nresult, 149 were eligible, as Figures 1 and 4 show.\nIV. BACKGROUND\nThe main objective of HAR algorithms is to recognize human\nactivity based on data gathered by wearable and environmen-\ntal sensors [15], [38]. The recognition of these activities is\nmainly based on CML and DL algorithms. Recently, the use\nof a wide variety of sensors, has generated interest in sensor\nfusion techniques. This section introduces basic ML and DL\nconcepts, wearable/environmental sensors market evolution,\nand sensor fusion techniques.\nA. MACHINE LEARNING OVERVIEW\nMachine Learning (ML) is a branch of Arti\u001ccial Intelligence\n(AI), for developing algorithms that can identify and infer\npatterns given a training dataset [39]. Such algorithms fall\ninto two major classesV\n\u000fSupervised learning,\n\u000fUnsupervised learning.\nThe goal of supervised learning is to create a mathematical\nmodel based on the relationship between input and output\ndata and to use the model for predicting future unseendata points. In unsupervised learning, the goal is to iden-\ntify patterns in input data without any knowledge of the\noutput [4]. Typically, one or more preprocessing steps will\nbe also required, including feature extraction, vectorization/\nsegmentation, normalization or standardization, and\nprojection [40].\nSome of the most common supervised CML algorithms\nare: Na\u00efve Bayes (NB), k-Means Clustering, Support Vector\nMachine (SVM), Linear Regression, Logistic Regression,\nRandom Forests (RF), Decision Trees (DT) and k-Nearest\nNeighbours (k-NN). DT's classify data instances by sort-\ning them based on the features/data values. Each node rep-\nresents a feature to be classi\u001ced, and each branch repre-\nsents a value that the node can assume. NB classi\u001cers are\nprobabilistic classi\u001cers based on applying Bayes' theorem\nwith strong independence assumptions between the features.\nSVMs are based on the notion of a margin-either side of\na hyperplane that separates two data classes. Maximizing\nthe margin, thereby creating the most signi\u001ccant possible\ndistance between the separating hyperplane and the instances\non either side, has been proven to reduce an upper bound\non the expected generalization error. Finally, K-NN is a\nCML algorithm that stores all available cases and classi-\n\u001ces new cases based on a similarity measure (e.g., distance\nfunctions as Euclidean, Manhattan, Minkowski) [39]. Fur-\nthermore, since HAR imposes speci\u001cc constraints, such as\nreduced latency, memory constraint, and computational con-\nstraints, these classi\u001cers, except for SVM, are appropriate\nfor low-resource environments given their low computational\nand memory requirements.\nAmong unsupervised and particularly clustering algo-\nrithms, the most well-known algorithms are k-Means, Hier-\narchical clustering, and Mixture models. K-Means clustering\naims to partition groups of samples into k clusters based on\na similarity measure (intra-group) and dissimilarity measure\n(inter-groups). Each sample belongs to the cluster with the\nnearest cluster centers or cluster centroid, serving as a clus-\nter prototype. Hierarchical Clustering Analysis is a cluster\nanalysis method that seeks to build a hierarchy of clusters\nwhere clusters are combined/split based on the measure of\ndissimilarity between sets. A mixture model is a probabilistic\nmodel for representing subpopulations of observations within\nan overall population [4]. These techniques are particularly\nsuitable when working with datasets lacking labels or when\nthe measure of similarity/dissimilarity between classes is a\nprimary outcome [41]\u0015[43].\nB. DEEP LEARNING OVERVIEW\nOn the other side, in recent years, DL algorithms have\nbecome popular in many domains, due to their superior per-\nformance [4]. Since DL is based on the idea of the data\nrepresentation, such techniques can automatically generate\noptimal features, starting from the raw input data, without\nany human intervention, making it possible to identify the\nunknown patterns that otherwise would remain hidden orunknown [44]. However, as already mentioned, DL models\nalso present some limitation [45]:\n\u000fBlack-box models, interpretation is not easy and\ninherent,\n\u000fRequire large datasets for training,\n\u000fHigh computational cost.\nFIGURE 5. Example of a Convolutional Neural Network (CNN) for image\nclassification [44].\nBecause of such limitations, in some areas still CML meth-\nods are preferred, especially when the training dataset is\nquite small, or when fast training is a requirement. Some of\nthe most common DL algorithms are: Convolutional Neural\nNetwork (CNN), Recurrent Neural Networks (RNNs), Long\nShort-Term Memory Networks (LSTMs), Gated Recurrent\nUnit (GRU), Stacked Autoencoders, Temporal Convolutional\nNetwork (TCN) and V Ariational Autoencoders (V AE) [46].\nNowadays, CNNs are a prevalent tool, especially in the image\nprocessing research community. CNN's impose local connec-\ntivity on the raw data extracting more important features by\nviewing the image as a collection of local pixel patches. Fur-\nthermore, a one-dimensional time series can also be viewed\nas a collection of local signal segments. Figure 5 shows an\nexample of CNN architecture with two convolutional lay-\ners, each followed by a pooling layer. Instead, RNNs are a\nproper alternative when data is represented sequentially as\ntime-series data and designed to deal with such long-range\ntemporal dependencies. While one-dimensional sequences\ncan be fed to a CNN, the resulting extracted features are shal-\nlow. Only closely localized relations between a few neighbors\nare factored into the feature representations. LSTM's are an\nRNN variant. Standard RNNs are comprised of intercon-\nnected hidden units, each unit in a Gated RNN is replaced by\na special cell that contains an internal recurrence loop and a\nsystem of gates that controls the \u001dow of information. Figure 6\nshows an RNNs that operates by sequentially updating a\nhidden state Htbased not only on the activation of the current\ninput Xtat time t, but also on the previous hidden state Ht\u00001,\nupdated by Xt\u00001,Ht\u00002. The \u001cnal hidden state after processing\nan entire sequence contains information from all its previous\nelements. LSTM and GRU models are successful RNN vari-\nants, also known as Gated RNNs. Basic RNNs are comprised\nof interconnected hidden units. Each unit in a Gated RNN\nis substituted by a cell that includes an internal recurrence\nloop and a system of gates that manages the information \u001dow.\nGated RNNs have shown advantages in modeling sequential\ndependencies in long-term time-series [44].\nFIGURE 6. Extended representation of a Recurrent Neural Network (RNN)\nfor an example with an input sequence of length three, three hidden\nunits, and a single output [44].\nFIGURE 7. (a) Distribution of published papers in HAR research area\ncategorized by the sensor data source, and, (b) average activity\nrecognition accuracy obtained from the papers using such sensors.\nC. SENSORS\nSensors and wearable devices surround us in our daily life.\nThe most common types of sensors used in activity recog-\nnition are accelerometers, mainly due to their small size and\nlow cost. Figure 7 illustrates the prevalence of accelerometer\nsensors used in HAR. In many cases, accelerometers are\nused in conjunction with others sensors including gyroscopes,\nmagnetometers, compasses, pressure sensors, body tempera-\nture sensors, electromyography, oximetry sensors, and elec-\ntrocardiographs. Many other kinds of sensors have been used\nin different applications. For example, the Global Positioning\nSystem (GPS) sensors or WiFi are used to determine the\nuser's location [47], microphones and Bluetooth are used\nto analyze human interactions [48], and CO2sensors are\nemployed to estimate the air quality [49]. The size of these\nsensors are constantly decreasing, such that they are being\nintegrated into clothes [50], smart glasses [51] and other\nwearable objects [52]. In more advanced applications, objects\nin the daily environment are enriched with Radio Frequency\nIdenti\u001ccation (RFID) tags. The tags make it possible to infer\nthe user's in-house activities (e.g., preparing coffee, doing\nlaundry, washing dishes) [53].\nThese sensors are becoming more and more prevalent in\nour daily life [29]. Shipments of wearable devices, includ-\ning smartwatches, basic watches, and wrist bands, reached\n34.2 million units during the second part of 2019, up 28.8%\nyear over year [54]. Companies as Xiaomi, Apple, Huawei,\nFitbit, or Samsung are pushing forward with new products\ncapturing 65.7% of the market, an almost 12% more than\n2018 [54]. Smart devices lend themselves to increasingly\ncomplex innovations in sensing and actuation. For example,\nwhen acceleration and inertial sensors are available, HAR\nalgorithms can be implemented. Furthermore, by includ-\ning additional electronic modules, such as Bluetooth Low\nEnergy (BLE) and Wireless Local Area Network (WLAN)\nantennas or GPS, wearable devices can be used for real-time\nalerting and determining location to report risky situations\nand identify activity [55]. In addition to smartphones and\nsmartwatches, other types of data collection and sensing\nsystems with communication capabilities are adding to the\nInternet of Things (IoT).\nD. SENSOR FUSION TECHNIQUES\nEach type of sensor provides bene\u001cts and disadvantages.\nFor example, an accelerometer can measure acceleration, but\ncannot accurately evaluate velocity or positional changes.\nSimilarly, the gyroscope can detect angular velocities, and the\nmagnetometer can measure the magnetic \u001celd value. How-\never, most sensors can easily be deceived by environmental\nnoise, hardware noise, or external inputs, resulting in impreci-\nsion and uncertainty. Sensor fusion techniques address these\nlimitations by combining input from various sensors. The use\nof multiple sources (heterogeneous or homogeneous) com-\nbined with data fusion techniques provides several advan-\ntages, including 1) noise reduction, 2) reduced uncertainty,\n3) increased robustness of the fusion phase, 4) robustness\nto interference, and 5) integration of prior knowledge of the\nperceived signals [56], [57]. Generally, as the number of\nsensors increases, the fusion step becomes more challenging.\nThe most common sensor fusion methods are typically based\non Bayesian estimation, Kalman Filters, and Particle Filtering\ntechniques [58]. Nowadays, it is possible to implement these\ntechniques directly at the hardware level inside the sensing\nmodules, standardizing the application input and simplify-\ning application development, maintenance, and extensibility.\nIn the future, the use of sensor fusion techniques will span\na wide range of applications [27]. Sensor fusion techniques\naddress these limitations by combining the input from various\nsensors. The use of multiple sources (heterogeneous or homo-\ngeneous) combined with data fusion techniques provides\nseveral advantages, including 1) noise reduction, 2) lower\nuncertainty, 3) higher robustness, 4) robustness to interfer-\nence, 5) integration of prior knowledge of the perceived\nsignals [56], [57]. Generally, the more the number of sensors,the more challenging is the fusion step. The most common\nsensor fusion methods are typically based on Bayesian,\nKalman Filter and Particle Filtering techniques [58]. Further-\nmore, nowadays, these techniques are directly imprinted at\nthe hardware level inside the sensing modules, standardizing\nthe application input and simplifying application develop-\nment, maintenance, and extensibility. In the future, the use\nof sensor fusion techniques will span a wide range of appli-\ncations, given the speci\u001cc functionality of each sensor and\nthe need to obtain accurate and robust estimations [27].\nV. HUMAN ACTIVITY\nThe de\u001cnition of Activities of Daily Life (ADL's) is broad.\nADL's are the activities that we perform daily, such as eating,\nbathing, dressing, working, homemaking, enjoying leisure\nand all of these activities involving physical movement. Our\nreview of HAR scienti\u001cc literature presents an overview of\nthe most studied ADL's.\nAmong all ADL's, the most popular activities in HAR\nresearch are walking, running, standing, sitting, walking\nupstairs and walking downstairs. However, other type of\nactivities have been explored in the past few years, including\ncomplex activities, such as the different phases of cook-\ning [59], house cleaning [4], [59]\u0015[61], driving [62]\u0015[65],\nsmoking [66], swimming [67], or biking [6], [43], [64], [68].\nSeveral studies focus on activities performed on speci\u001cc loca-\ntions, such as sitting on the ground, lying on bed [69]\u0015[71],\nwalking/standing in the elevator [71]\u0015[74], walking/running\non a treadmill, walking in a parking lot, exercising on a\nstepper [71], or exercising on a cross trainer [71], [75]. Other\ndetailed movement recognition involves speci\u001cc movements\nof the arms, such as carrying/reaching an object, releasing it,\nfrontal elevation, and other activities that people can perform\nin relation to other objects [76]\u0015[78]. A major area of HAR\nresearch involves the aging of population and the increas-\ning of the number of people with physical and cognitive\nfunction impairments. Many HAR models are being used\nto help users recognize and avoid risky situations, such as\nfalls in elderly people [79]\u0015[85] or Freezing of Gait (FoG)\nin Parkinson's disease [38]. Furthermore, activity tracking\ndevices are becoming very popular for monitoring ADLs.\nThose devices are able to approximate physiological and\nphysical parameters such as heart rate, blood pressure, steps,\nlevel changes, and calories consumed. Advanced devices\ncan recognize sleeping and the neurological stages of sleep\n(i.e., cycling through nREM (stages 1-4) and REM) [86];\nfurthermore, all the stored information can be used as input\nto HAR algorithms.\nVI. DATA SOURCE DEVICES IN HAR\nThe \u001crst step of the HAR work\u001dow includes identi\u001ccation\nof the data source sensor/device to be used, and, as shown\nin Figure 7.(a), small, low-cost and non-invasive sensors\nsuch as accelerometers, gyroscopes, and magnetometers are\nthe most commonly used and appropriate sensors in HAR.TABLE 3. Sensor based paper categorization.\nTABLE 4. Device based paper categorization.\nAs depicted in Figure 7.(a), 149 papers used accelerometers,\n83 used gyroscopes in addition to accelerometers, and 27 used\na magnetometer in addition to the accelerometer. Therefore,\nall the selected papers use at least one accelerometer or at\nleast one accelerometer in combination with other sensors.\nFurthermore, Figure 7.(b) shows the average activity recog-\nnition accuracy obtained form combination of such device.\nTable 3and Table 4respectively show the sensor/device\ntype and provide references to the papers using such sen-\nsors/device. Besides, Table 3and Table 4show in Columns\nThree to Five, the average number of recognized activ-\nities, average number of tested datasets and the aver-\nage number of testing subject. These tables illustrate the\nimportance of sensors like accelerometer, gyroscope, and\nmagnetometer. However, other type of sensors as environ-\nmental sensors (temperature [7], [60], [76], [79], [87]\u0015[89],\nhumidity [79], [87], light [60], [90], Passive Infrared\nSensor (PIR) [88]), radio signals (WiFi and Blue-\ntooth [56], [62], [87]), medical equipment (ECG [56], [77],\nEMG [72]) or other type of build in sensors (GPS [7], [43],\n[87], [90]\u0015[93], compass [91], [93], heart rate [89], [94]\u0015[96],\nbarometer [67], [73], [80], stretch [63], [97], audio [62], [90],\n[91], [98]) are common in HAR.\nIn addition to the direct measurements that such sen-\nsors provide, the indirect usage of the measurements in\nform of smart metrics is promising (e.g., energy harvest-\ning of the system [192] or the Received Signal StrengthIndicator (RSSI) [56]) in order to recognize human activity\nrelated to direct measurements from the body or environmen-\ntal variations. Furthermore, the importance of smartphones\nand smartwatches in HAR is increasingly clear, mainly due\nto their explosion among consumers and given that these\ndevices currently contain many of the aforementioned sen-\nsors. Finally, as shown in Figure 8.(a), among all the reviewed\npublished papers, the proposed HAR methods are based\nmostly on standalone devices. However, the total number of\nsmartphone- and smartwatch-based methods are higher than\nthose based on standalone devices. Figure 8.(b) shows that\nin terms of recognition accuracy methodologies based on\nsmartphone and smartwatch devices are in line with those\nobtained from standalone devices. Moreover, smartphones\nand smartwatches [193], unlike standalone devices, provide\ncomputational capabilities that make it possible to directly\nexecute HAR models on the wearable device, and in many\ncases, they have a very high cost (e.g., devices used in the\nmedical \u001celd).\nVII. DATA\nThe second step of the HAR work\u001dow regards the collected\ndata type. Such data can mainly be categorized as follows.\n\u000fInertial sensors data such as accelerometers, gyroscopes,\nmagnetometer, or compass,\n\u000fPhysiological sensors data such as ECG, EMG, Heart\nRate, or blood pressure,\nTABLE 5. Data source used in HAR paper.\nFIGURE 8. (a) Distribution of published papers in HAR research area\ncategorized by the device data source, and (b) Average activity\nrecognition accuracy obtained by the identified devices.\n\u000fEnvironmental sensors data such as temperature, pres-\nsure, CO2, humidity, or PIR.\nA. INERTIAL SENSORS DATA\nAccelerometer, gyroscope, and magnetometer sensors with\na maximum of nine degrees of freedom are commercially\navailable at a very low cost. Besides, acceleration and angu-\nlar velocity are the most common data used to characterize\nhuman activity. This is reinforced by what we described\nin the previous section, given that accelerometers and the\ngyroscopes are the most widely used devices in HAR. Such\ninertial sensors are widely used in clinical and healthcare\napplications [194].\nB. PHYSIOLOGICAL SENSORS DATA\nPhysiological sensors perceive physiological signals, which\nin contradiction with other sources of emotional knowledge\n(facial, gestures, and speech), providing essential advantages.\nThose signals are mostly involuntary and, as such, are quiteinsensitive to deception. They can be used to continuously\nmeasure the affective events. [195] The most used physiologi-\ncal signals are brain electrical activity, heartbeat, muscle elec-\ntrical activity, blood pressure, and skin conductance acquired\nby the following external data acquisition system: Elec-\ntroencephalogram (EEG), Electrocardiogram (ECG), and\nElectromyography (EMG).\nC. ENVIRONMENTAL SENSORS DATA\nThe environmental data covers all the collection of data rep-\nresenting the state of the environment, including temperature,\nhumidity, pressure, or brightness. However, measuring the\nstatus of the environment goes beyond environmental mea-\nsures. It can also include more complex measures related\nto people and objects inside the environment. For example,\nrecognizing the number of people inside the environment and\ntheir position or the actions performed on a certain object\ninside the environment could be useful in many application\nscenarios related to human assistance, healthcare, and service\ndelivery.\nTable 5 shows the categorization of the revised articles\nbased on the type of data, where Column One and Two show\nthe data type and the reference to the articles using such data\ntypes. Columns Three to Five respectively show the average\nnumber of recognized activities, average number of tested\ndatasets, and average number of testing subjects. However,\nas we discussed earlier, the largest amount of data on daily\nlife is collected via electronic devices, such as smartphones,\nsmartwatches, activity trackers, smart thermostats and video\ncameras. As shown in Figure 8, the use of smart devices like\nsmartphone and smartwatch is outnumbering the use of stan-\ndalone devices. It should be noted that the standalone column\nidenti\u001ces all those devices other than smartphones and smart-\nwatches as for example, clinical and dedicated instruments,\nsuch as Actigraph (Actigraph, Florida/USA), or Bioharness3\n(RAE Systems by Honeywell, California/USA). Further-\nmore, during the data collection step, sometimes activities\nare performed in a controlled manner (aka scrippted). That is\nbecause human movement patterns are very hard to recognize\ndue to the large inter-subject and intra-subject variability.\nSuch variability entails a considerable dif\u001cculty in devel-\noping a methodology that manages to generalize among all\nsubjects. Also, the lack of data collected from a very large\nnumber of subjects does not help researchers \u001cnd a solution\nto this problem.\nWith regard to such issue, Table 6 shows some of the best\nknown and open source datasets for HAR studies.TABLE 6. Publicly available datasets for HAR research.\nColumn One refers to the name and the article proposing\nthe dataset. Column Two presents the activity labeled in\nthe dataset, Column Three shows the number of activities.\nColumn Four shows the number and type of the used sensing\ndevices. Column Five and Column Six show the number of\nsubjects from whom the data was collected and the number\nof citations that the dataset received by September 2019. Such\ndatasets are largely based on accelerometer, gyroscope, and\nmagnetometer sensor data. Most of such sensors are embed-\nded into smartphones and smartwatches, and the number ofactivities in these datasets ranges from two [202] to thirty-\nthree [205] (Table 6). The most common studied activities\nare primary activities of daily life, such as walking, running,\nsitting, standing, walking upstairs, walking downstairs, and\nsleeping.\nD. PREPROCESSING AND FEATURE EXTRACTION\nThe mentioned data sources generate time-series information\nidentifying the status of the device. However, data is charac-\nterized by noise, which makes it dif\u001ccult to be used in their\nTABLE 7. Most used time and frequency domain features.\nTABLE 8. Preprocessing and feature extraction on the reviewed papers.\nraw state. The presence of noise is handled by preprocess-\ning the raw data to eliminate this interference and prepare\nthe data for being feed to the recognition models [35]. The\npreprocessing is one of the most important phases in HAR\nand presents different noise management techniques, such as\ndigital and statistical \u001clters, data normalization, and feature\nextraction. The features extraction step explores basically two\ndomains: time and frequency domain. Time-domain features\nare the most used because they are cheaper than the frequency\ndomain features because of the transform from time to fre-\nquency domain [35]. Since standard classi\u001ccation models\nare not suitable for raw data, this phase is anticipated by a\nsegmentation step during which time-series sensor data is\nsegmented before extracting features. Besides, many method-\nologies maintain an overlapping part between two consecu-\ntive segments. This part provides the model with knowledge\nof the previous context. Table 7 presents an overview on the\nmost commonly used time and frequency domain features.\nTable 8 presents a categorization of the reviewed papers\nbased on the utilization of noise removal, time domain, andfrequency domain features extraction techniques. Columns\nOne to Four show: the machine learning category (CML or\nDL), if any noise removal technique is used, if time-domain or\nfrequency-domain features were extracted. Column Five con-\ntains the references to the papers, and Column Six, the num-\nber of papers using such con\u001cguration. Finally, Columns\nSeven and Eight show the average number of used features\nand the average activity recognition accuracy. Concerning\nthe CML-based models, as shown, most of the reviewed\narticles (Tab. 8, row 7) make use of both time and frequency\ndomain features, and the raw data was initially pre-processed\nwith noise removal techniques. Instead, Tab. 8, row 3 shows\narticles that use time and frequency domain features with-\nout applying any noise removal technique. However, other\nmethodologies (Tab. 8, rows 8 and 9) do not make use of\nany features extraction technique, and in some cases, the\npresence of noise is not considered, as in [4], [43], [60],\n[94], [98], [170]. In [4], [60] and [170], the methodologies\nare based on the mining of temporal patterns and their sym-\nbolic representation, or as in [43] were, authors make use ofclustering technique, discriminating between different human\nactivities. About the results obtained in terms of accuracy,\nthe methodologies that make use of noise removal methods\nand feature extraction in the time and frequency domain show\npromising results as also shown by the number of methodolo-\ngies that make use of this con\u001cguration.\nFurthermore, concerning the DL-based methodologies,\nsince DL networks perform automatic feature extraction\nwithout human intervention, unlike traditional machine-\nlearning algorithms, the majority of them do not make use\nof any Noise Removal and Feature Extraction step as shown\nin Tab. 8, rows 10 and 14. The achieved average accu-\nracy, among all these 34 articles, was 93%. Besides, other\nDL-based articles do make use of time-domain (Tab. 8,\nrow 12) features, frequency domain (Tab. 8, row 11) and\nboth time and frequency domain (Tab. 8, rows 13 and 14)\nfeatures. DL-based models eliminate the latency due to the\nneed to process data with the above techniques. However,\nsuch models require a more considerable amount of data than\nML models and longer training times.\nConcerning the Noise Removal step, 48 CML-based arti-\ncles and 12 DL-based articles make use of different noise\nremoval techniques. Among all such techniques the most used\nones are: z-normalization [75], [120], min-max [70], [127],\nand linear interpolation [102], [111] are the most used nor-\nmalization steps, preceded by a \u001cltering step based on the\napplication of outlier detection [70], [117], [163], Butter-\nworth [82], [101], [117], [123], [127], [128], [152], [155],\n[174], [189], median [74], [101], [117], [127], [132], [147],\n[155], [182], [183], high-pass [92], [96], [117], [128], [169],\n[173], [208], or statistical [58] \u001clters.\nVIII. CLASSIFICATION MODEL AND EVALUATION\nThe third and fourth step of the HAR work\u001dow includes\nidenti\u001ccation and evaluation of the classi\u001ccation model that\nis used for activity recognition. As shown in Figure 1and\nFigure 2, CML models still enjoy great popularity com-\npared to those based on the relatively more recent and\nmore advanced models such as the DL models. We point\nout that many articles made use of different classi\u001ccation\nmodels and not just one model for achieving better per-\nformance, and as mentioned in Section Iwe use accu-\nracy as a comparison metric between the various articles.\nThis beacouse accuracy is the only common metric among\nthem.\nA. DEEP LEARNING (DL) BASED METHODOLOGIES\nThe DL models, as shown in Figure 1comprised 54 papers\nof the 149 papers we reviewed. Figure 9shows (a) the distri-\nbution of DL models among the 54 articles, (b) the average\naccuracy, and (c) the average number of recognized daily\nlife activities for each model. The most popular model is\nthe Convolutional Neural Network (CNN), which was ref-\nerenced in 30 papers [7], [32], [73], [77], [81], [88], [90],\n[99], [100], [104], [106], [108], [112], [119], [120], [125],\n[126], [141], [143], [146], [147], [149], [150], [153], [154],\nFIGURE 9. a) Distribution of Deep Learning Models mostly used in HAR,\nb) Average activity recognition accuracy of Deep Learning Models mostly\nused in HAR, and c) Average number of activities of Deep Learning\nModels mostly used in HAR.\n[160], [180], [191], [214], [215]. The CNN models obtained\nan average accuracy of 93.7% in activity recognition over\nan average number of 11 activities of daily life. The second\nmost used model was the Long Short-Term Memory (LSTM)\nmodel, which was used in 17 papers [7], [83], [89], [102],\n[107], [112], [125], [130], [137], [139], [152], [153], [172],\n[176], [213], [216], [218]. It obtained an average accuracy\nof 91.5% over an average number of 17 activities of daily life.\nRecurrent Neural Network (RNN) were used in [8], [56],\n[89], [112], [129], [213], [216], [217], over an average num-\nber of 14 obtaining an average accuracy of 95%. Finally,\nthe rest of the papers (indicated by Other in Figure 9)\nwhere based on models such as Autoencoders [71], [123],\nInception Neural Networks (INN), or the other frame-\nworks [105] for a total of 7 papers with an average accuracy\nof 91.1% and an average number of 17 activities of daily\nlife.\nB. MACHINE LEARNING (ML) BASED METHODOLOGIES\nAmong the 149 reviewed papers, as shown in Figure 1,\n95 presented an HAR methodology based on classical ML.\nFigure 10 shows (a) the distribution of these models, (b) the\nobtained average accuracy and (c) the average number of\nrecognized activities of daily life. Among the different types\nof classical ML models, the most commonly used model\nwas the Support Vector Machine (SVM) model [4], [6], [58],\n[60], [69], [78], [79], [82], [85], [92], [95], [109], [118],\n[127], [131], [132], [136], [138], [142], [145], [155], [168],\n[169], [171], [173], [182], [184], [186], [187], [189], [190],\n[209]\u0015[212] which was used in 35 papers, achieving an\naverage accuracy of 92.3% over an average of 12 activi-\nties. The second most used model is the classical k-Nearest\nNeighbor (kNN) model [4], [6], [42], [60], [61], [69], [78],\n[79], [92], [95], [96], [113], [118], [122], [127], [136],\n[142], [145], [162], [164], [169], [173], [186], which was\nused in 23 papers, achieving an average accuracy of 93.7%\nover an average of 12 activities of daily life. The third\nand fourth most used model are the Decision Tree (DT)\nmodel [6], [78], [85], [94], [95], [113], [136], [142], [145],\n[159], [165], [173], [177], [178], [184], [185], [193], [208],\n[210], [212], which was used in 19 papers, obtaining an\naverage accuracy of 94.2% over an average of 8 activities of\ndaily life, and the Random Forest (RF) [6], [57], [69], [72],\n[78]\u0015[80], [82], [92], [93], [95], [96], [175], [185], [212],\nwhich was used in 15 papers, obtaining an average accuracy\nof 93.3% over an average of 10 activities of daily life. The\n\u001cfth most used model is the Neural Networks (NN) [4], [78],\n[92], [98], [114], [136], [142], [145], [148], [157], [173],\n[183]\u0015[185], which was used in 14 papers, obtaining an\naverage accuracy of 93.5% over an average of 8 activities of\ndaily life. Other used models are the Na\u00efve Bayes (NB) [4],\n[42], [94], [122], [136], [142], [159], [169], [171], [184],\n[185], [210], the Dynamic Bayesian Network (DBN) [101],\n[103], [166], Hidden Markov Models (HMM) [68], [69],\n[151], [179], [182], [208], Extreme Learning Machine\n(ELM) [153], [154], Principal Component Analysis (PCA),\nLinear Discriminant Analysis (LDA), Quadratic Discrimi-\nnant Analysis (QDA) [84], [109], [134] and many others [9],\n[43], [59], [70], [74]\u0015[76], [82], [110], [116], [117], [121],\n[124], [128], [133], [135], [140], [144], [156], [158], [161],\n[163], [170], [174], [188]. It is noteworthy that some of the\narticles have tested their approaches using different models.\nFIGURE 10. a) Distribution of CML Models mostly used in HAR,\nb) Average activity recognition accuracy of CML Models mostly used in\nHAR, and c) Average number of activities of CML Models mostly used\nin HAR.\nIX. DISCUSSION\nIn this paper, we provided an overview of the current HAR\nresearch. HAR is a critical research area in activity recog-\nnition, pervasive computing, and human assistive environ-\nments. In the last decades, with the rise of new technologiesFIGURE 11. Availability of datasets used to evaluate the proposed\nmethodologies.\nand with growing needs such as aging population, HAR is\nbecoming even more essential. In recent years, DL-based\nHAR methods have produced excellent results in terms of\nrecognition performance. However, CML-based approaches\nare still widely used, and they generate outstanding results\nwithout the computational costs. However, in recent years,\nthe reproducibility of ML models has become increasingly\nimportant. Based on our research, for 78% of the proposed\nHAR methodologies, the results are not fully reproducible\ndue to proprietary datasets. This results in barriers for the\nresearch community for the identi\u001ccation of the best models\nand benchmarking the results. As shown in Figure 11, starting\nfrom the initial 293 papers and after the removal of surveys\nand on payment articles, among a total of 142 datasets, only\n30 datasets are publicly available, some of which are shown\nin the Table 6.\nFurthermore, the lack of public heterogeneous datasets\nreduces the possibility of creating HAR models with better\ngeneralization capabilities. This is because the data used in\nthe investigated papers are collected primarily in a controlled\nenvironment. This problem is exacerbated by the inter-subject\nand intra-subject variability absent in such scripted datasets,\nas most proposed HAR models are only tested on a limited\nnumber of activities and captured in a single controlled envi-\nronment. Among the 149 analyzed HAR models, 87 models\nwere tested on a single dataset, with the remaining 62 tested\non more than one dataset. As shown in Figure 12, we found\nthat 28 HAR methodologies were tested on two datasets,\n21 HAR methodologies on three datasets, less than 10 HAR\nmethodologies on 4-6 datasets, and only one methodol-\nogy [219] was tested on a total of 14 datasets. This situation\nshows the challenge of identifying a methodology superior to\nthe others.\nAnother signi\u001ccant issue concerns the interpretability\nof the results, mainly related to papers presenting similar\nmethodologies and tested on the same dataset, claiming to\nachieve almost the same results in terms of activity recogni-\ntion accuracy. Such an issue is related to tests performed using\ncommercial tools, lack of open source code, and authors who\nFIGURE 12. Number of datasets (x-axis) used to test an article and\nnumber articles methodologies (y-axis) tested on such number of\ndatasets (166 articles were tested on only one dataset).\ndo not publicly provide their source code. Besides, the het-\nerogeneity of the data and the de\u001cnition of a HAR method-\nology that can recognize the activities carried out by people\nwith different physical and motor characteristics collides with\nthe data sources used for data collection. As we have seen,\na variety of sensors and devices are used for data collection.\nHowever, the proposed methodologies are usually very rigid\nregarding the data source. Speci\u001ccally, it becomes dif\u001ccult\nto have a methodology tested on a particular individual by\nmaking use of a particular sensor(s) and subsequently chang-\ning the sensor model. Various sensors have different tech-\nnical characteristics, which also entail their speci\u001cc state,\ne.g., the measurement error or the noise that a speci\u001cc sensor\npresents.\nRegarding the HAR models, Figure 9and Figure 10show\nthat CML models are still used more widely than complex\nDL-based models. This is because CML models require a\nsmaller amount of training data, as well as lower computa-\ntional requirements. In addition, DL models are inherently\ndif\u001ccult to interpret. Nonetheless, DL models have a unique\nability to recognize more complex activities, while maintain-\ning high accuracy. In addition, they do not require a data\npreprocessing stage. Figure 13shows a suggested work\u001dow\nfor developing HAR applications based onV\n\u000fthe number of activities to be recognized,\n\u000fthe amount of available (labeled) data,\n\u000flocal or remote computation.\nWe observed that the selection of the precise DL or CML\nmodel is primarily based on the computational requirements\nand the amount of available training (labeled) data. In terms\nof the sensors, the most widely used used, if not indis-\npensable, sensor is the accelerometer, which can be used in\nconjunction with other sensors such as the gyroscope or the\nmagnetometer.\nX. FUTURE RESEARCH DIRECTION\nBased on reviewed papers, a few possible research direc-\ntions are noted below. One of the main limitations of HARFIGURE 13. Model selection diagram. DLDDeep Learning, CML DClassic Machine Learning.\nalgorithms is the lack of standardized methodologies that can\ngeneralize to heterogeneous set of activities performed by a\ndiverse set of users. As a potential solution, transfer learning\ncould reuse the knowledge acquired in one problem to solve\na similar problem. For example, knowledge acquired based\non a speci\u001cc inertial sensor positioned on a speci\u001cc body\nlocation can potentially be reused with a different sensor\nlocation or with a different type of inertial sensor. The extent\nto which transfer learning can be helpful in various scenarios,\nis not investigated in a comprehensive manner and needs to\nbe further studied. Sensor fusion also provides a promising\npath. In particular, merging different sensors could address\nissued related to reliability and accuracy of a single sensor\nand could also enrich collected information. When data from\none modality is not reliable, the system could switch to a\ndifferent sensor modality to ensure robust data collection.\nAnother research direction is \u001cne-grained activity recogni-\ntion based on examining daily object interactions. This will\nallow us to recognize sub-actions and sequence of actions and\nwill provide much richer context information to downstream\napplications. Sensor fusion can also be helpful when a large\nnumber of inertial sensors or proximity sensors are attached\nto daily objects. To further advance the progress in this\narea, we provide a set of recommendations. First, developing\nbenchmark datasets should be a priority for the HAR com-\nmunity. New HAR models should be compared with avail-\nable HAR models on benchmark data to show improvement.\nFurthermore, creation of datasets with an adequate number\nof subjects and diverse set of activities is strongly recom-\nmended. Fine-grained activity recognition also could bene-\n\u001ct from large-scale, standardized benchmarks. Researchers\nworking on HAR algorithms should also pay attention to\nhardware and system issues, besides solely developing and\nimproving HAR algorithms. On-device computation should\nbe a primary goal, as well as analysis of memory, CPU,\nand battery consumption, to explore the trade-off between\nresource utilization and recognition accuracy. Finally, posi-\ntion and orientation dependence should be extensively stud-\nied; otherwise, the design of position/orientation-dependent\ntechniques could result in inconsistent and non-robust down-\nstream applications.\nFIGURE 14. Overview of the proposed survey structure on sensor-based\nHAR research results from 2015 to 2019.\nXI. CONCLUSION\nHAR systems have become a growing research area in\nthe past decade, achieving impressive progress. In particu-\nlar, sensor-based HAR have many advantages compared to\nvision-based HAR methodologies, which pose privacy con-\ncerns and are constrained by computational requirements.\nActivity recognition algorithms based on ML and DL are\nbecoming central in HAR. Figure 14summarizes HAR\nmethodologies between January 2015 and September 2019.\nStarting from a meta-review of the existing HAR surveys,\nwe analyzed the reviewed literature based on the most widely\nstudied human activities (Section V), the most used elec-\ntronic sensors as the data source (Section VII), and the most\nknown devices that integrate with these sensors (Section VI)\nwithout taking into account the video-based methodologies.\nIn detail, sensor-based data perceived by physiological, iner-\ntial, and environmental sensors were of primary interest.\nDevice types were also extensively studied, categorizing them\nin: a) standalone, b) smartphone, and c) smartwatch devices.\nFor each category, results were shown in terms of the aver-\nage number of recognized activities, the average number\nof datasets used to test the methodologies, and the average\naccuracy. This survey also dis-cussed methodologies based\non accelerometer, gyroscope, and magnetometer. We also dis-FIGURE 15. A Systematic Review of Human Activity Recognition (HAR) approaches, published from January 2015 to September 2019, based on Classical\nMachine Learning (CML) and Deep Learning (DL), which make use of data collected by sensors (inertial or physiological), embedded into wearables or\nenvironment. We surveyed methodologies based on sensor type, device type (smartphone, smartwatch, standalone), preprocessing step (noise\nremoval/feature extraction technique), and finally, their DL or CML model. The results are presented in terms of a) average activity recognition accuracy,\nb) the average number of studied activities, and c) the average number of datasets used to test the methodology.\ncussed the preprocessing approaches and their results based\non feature extraction, noise removal, and normalization tech-\nniques. Moreover, we discussed datasets primarily in the\nliterature, emphasizing publicly available datasets. Finally,\nwe presented a description of the recognition models most\nused in HAR. For this purpose, we have presented the most\nwidely used DL and ML models and their results, both from\nthe point of view of quality (accuracy) and quantity (number\nof recognized activities). We concluded that HAR researchers\nstill prefer classic ML models, mainly because they require a\nsmaller amount of data and less computational power than\nDL models. However, the DL models have shown higher\ncapacity in recognizing many complex activities. Future work\nshould focus on the development of methodologies with more\nadvanced generalization capabilities and recognition of more\ncomplex activities. To summarize, Figure 15shows a Graph-\nical Abstract (GA) of the work\u001dow of this survey.\nACKNOWLEDGMENT\nThe content is solely the responsibility of the authors and does\nnot necessarily represent the of\u001ccial views of the National\nInstitutes of Health or National Science Foundation.\nREFERENCES\n[1] R. S. Antunes, L. A. Seewald, V. F. Rodrigues, C. A. D. Costa,\nL. Gonzaga, Jr., R. R. Righi, A. Maier, B. Esko\u001cer, M. Ollenschl\u00e4ger,\nF. Naderi, R. Fahrig, S. Bauer, S. Klein, and G. Campanatti, ``A survey of\nsensors in healthcare work\u001dow monitoring,'' ACM Comput. Surv., vol. 51,\nno. 2, pp. 1\u001537, Jun. 2018.\n[2] Y. Wang, S. Cang, and H. Yu, ``A survey on wearable sensor modality\ncentred human activity recognition in health care,'' Expert Syst. Appl.,\nvol. 137, pp. 167\u0015190, Dec. 2019.\n[3] O. D. Lara and M. A. Labrador, ``A survey on human activity recognition\nusing wearable sensors,'' IEEE Commun. Surveys Tuts., vol. 15, no. 3,\npp. 1192\u00151209, 3rd Quart., 2013.\n[4] Y. Liu, L. Nie, L. Liu, and D. S. Rosenblum, ``From action to\nactivity: Sensor-based activity recognition,'' Neurocomputing, vol. 181,\npp. 108\u0015115, Mar. 2016.[5] M. Zeng, L. T. Nguyen, B. Yu, O. J. Mengshoel, J. Zhu, P. Wu, and\nJ. Zhang, ``Convolutional neural networks for human activity recognition\nusing mobile sensors,'' in Proc. 6th Int. Conf. Mobile Comput., Appl.\nServices, 2014, pp. 197\u0015205.\n[6] A. Stisen, H. Blunck, S. Bhattacharya, T. S. Prentow, M. B. Kj\u00e6rgaard,\nA. Dey, T. Sonne, and M. M. Jensen, ``Smart devices are different:\nAssessing and mitigatingmobile sensing heterogeneities for activity\nrecognition,'' in Proc. 13th ACM Conf. Embedded Netw. Sensor Syst. ,\n2015, pp. 127\u0015140.\n[7] E. Kanjo, E. M. G. Younis, and C. S. Ang, ``Deep learning analysis of\nmobile physiological, environmental and location sensor data for emotion\ndetection,'' Inf. Fusion, vol. 49, pp. 46\u001556, Sep. 2019.\n[8] N. Neverova, C. Wolf, G. Lacey, L. Fridman, D. Chandra, B. Barbello,\nand G. Taylor, ``Learning human identity from motion patterns,'' IEEE\nAccess, vol. 4, pp. 1810\u00151820, 2016.\n[9] L. Liu, Y. Peng, M. Liu, and Z. Huang, ``Sensor-based human activ-\nity recognition system with a multilayered model using time series\nshapelets,'' Knowl.-Based Syst., vol. 90, pp. 138\u0015152, Dec. 2015.\n[10] J. Donahue, L. A. Hendricks, S. Guadarrama, M. Rohrbach, S. Venu-\ngopalan, T. Darrell, and K. Saenko, ``Long-term recurrent convolutional\nnetworks for visual recognition and description,'' in Proc. IEEE Conf.\nComput. Vis. Pattern Recognit., Jun. 2015, pp. 2625\u00152634.\n[11] Y. LeCun, Y. Bengio, and G. Hinton, ``Deep learning,'' Nature, vol. 521,\nno. 7553, pp. 436\u0015444, 2015.\n[12] L. Wang, Y. Qiao, and X. Tang, ``Action recognition with trajectory-\npooled deep-convolutional descriptors,'' in Proc. IEEE Conf. Comput.\nVis. Pattern Recognit., Jun. 2015, pp. 4305\u00154314.\n[13] J. Liu, A. Shahroudy, D. Xu, and G. Wang, ``Spatio-temporal LSTM\nwith trust gates for 3D human action recognition,'' in Computer Vision\u0016\nECCV, B. Leibe, J. Matas, N. Sebe, and M. Welling, Eds. Cham,\nSwitzerland: Springer, 2016, pp. 816\u0015833.\n[14] A. Voulodimos, N. Doulamis, A. Doulamis, and E. Protopapadakis,\n``Deep learning for computer vision: A brief review,'' Comput. Intell.\nNeurosci., vol. 2018, pp. 1\u001513, Feb. 2018.\n[15] J. Wang, Y. Chen, S. Hao, X. Peng, and L. Hu, ``Deep learning for sensor-\nbased activity recognition: A survey,'' Pattern Recognit. Lett., vol. 119,\npp. 3\u001511, Mar. 2019.\n[16] W. Sousa Lima, E. Souto, K. El-Khatib, R. Jalali, and J. Gama, ``Human\nactivity recognition using inertial sensors in a smartphone: An overview,''\nSensors, vol. 19, no. 14, p. 3213, Jul. 2019.\n[17] R. Elbasiony and W. Gomaa, ``A survey on human activity recognition\nbased on temporal signals of portable inertial sensors,'' in Proc. Int. Conf.\nAdv. Mach. Learn. Technol. Appl. (AMLTA), A. E. Hassanien, A. T. Azar,\nT. Gaber, and R. Bhatnagar, and M. F. Tolba, Eds. Cham, Switzerland:\nSpringer, 2019, pp. 734\u0015745.\n[18] H. F. Nweke, Y. W. Teh, G. Mujtaba, and M. A. Al-garadi, ``Data fusion\nand multiple classi\u001cer systems for human activity detection and health\nmonitoring: Review and open research directions,'' Inf. Fusion, vol. 46,\npp. 147\u0015170, Mar. 2019.\n[19] O. Faust, Y. Hagiwara, T. J. Hong, O. S. Lih, and U. R. Acharya,\n``Deep learning for healthcare applications based on physiological sig-\nnals: A review,'' Comput. Methods Programs Biomed., vol. 161, pp. 1\u001513,\nJul. 2018.\n[20] S. Ramasamy Ramamurthy and N. Roy, ``Recent trends in machine\nlearning for human activity recognition\u0016A survey,'' Wiley Interdiscipl.\nRev., Data Mining Knowl. Discovery, vol. 8, no. 4, p. e1254, 2018.\n[21] J. Morales and D. Akopian, ``Physical activity recognition by smart-\nphones, a survey,'' Biocybernetics Biomed. Eng., vol. 37, no. 3,\npp. 388\u0015400, 2017.\n[22] H. F. Nweke, Y. W. Teh, M. A. Al-garadi, and U. R. Alo, ``Deep learning\nalgorithms for human activity recognition using mobile and wearable\nsensor networks: State of the art and research challenges,'' Expert Syst.\nAppl., vol. 105, pp. 233\u0015261, Sep. 2018.\n[23] K. Y. C. Keng, L. Y. Hung, K. S. Nie, S. A. Balakrishnan,\nR. K. Murugesan, and G. W. Wei, ``A review of ambient intelligence\nbased activity recognition for ageing citizens,'' in Proc. 4th Int. Conf. Adv.\nComput., Commun. Autom. (ICACCA), Oct. 2018, pp. 1\u00156.\n[24] R. Miotto, F. Wang, S. Wang, X. Jiang, and J. T. Dudley, ``Deep learning\nfor healthcare: Review, opportunities and challenges,'' Brie\u001cngs Bioinf.,\nvol. 19, no. 6, pp. 1236\u00151246, Nov. 2018.\n[25] J. C. B. Gamboa, ``Deep learning for time-series analysis,'' 2017,\narXiv:1701.01887. [Online]. Available: http://arxiv.org/abs/1701.01887\n[26] J. K. Dhillon, K. Chandni, and A. K. S. Kushwaha, ``A recent survey for\nhuman activity recoginition based on deep learning approach,'' in Proc.\n4th Int. Conf. Image Inf. Process. (ICIIP), 2017, pp. 1\u00156.\n[27] C. Chen, R. Jafari, and N. Kehtarnavaz, ``A survey of depth and inertial\nsensor fusion for human action recognition,'' Multimedia Tools Appl.,\nvol. 76, no. 3, pp. 4405\u00154425, Feb. 2017.\n[28] V. V. Vyas, K. H. Walse, and R. V. Dharaskar, ``A survey on human\nactivity recognition using smartphone,'' Int. J., vol. 5, no. 3, pp. 118\u0015125,\n2017.\n[29] T. Rault, A. Bouabdallah, Y. Challal, and F. Marin, ``A survey of\nenergy-ef\u001ccient context recognition systems using wearable sensors for\nhealthcare applications,'' Pervasive Mobile Comput., vol. 37, pp. 23\u001544,\nJun. 2017.\n[30] P. Patel, B. Bhatt, and B. Patel, ``Human body posture recognition\u0016\nA survey,'' in Proc. Int. Conf. Innov. Mech. Ind. Appl. (ICIMIA), 2017,\npp. 473\u0015477.\n[31] P. Kumari, L. Mathew, and P. Syal, ``Increasing trend of wearables and\nmultimodal interface for human activity monitoring: A review,'' Biosen-\nsors Bioelectron., vol. 90, pp. 298\u0015307, Apr. 2017.\n[32] D. Rav\u00ec, C. Wong, F. Deligianni, M. Berthelot, J. Andreu-Perez, B. Lo,\nand G.-Z. Yang, ``Deep learning for health informatics,'' IEEE J. Biomed.\nhealth Informat., vol. 21, no. 1, pp. 4\u001521, Jan. 2017.\n[33] M. Cornacchia, K. Ozcan, Y. Zheng, and S. Velipasalar, ``A survey\non activity detection and classi\u001ccation using wearable sensors,'' IEEE\nSensors J., vol. 17, no. 2, pp. 386\u0015403, Jan. 2017.\n[34] P. Woznowski, D. Kaleshi, G. Oikonomou, and I. Craddock, ``Classi\u001c-\ncation and suitability of sensing technologies for activity recognition,''\nComput. Commun., vols. 89\u001590, pp. 34\u001550, Sep. 2016.\n[35] M. Shoaib, S. Bosch, O. Incel, H. Scholten, and P. Havinga, ``A survey of\nonline activity recognition using mobile phones,'' Sensors, vol. 15, no. 1,\npp. 2059\u00152085, Jan. 2015.\n[36] G. Ciuti, L. Ricotti, A. Menciassi, and P. Dario, ``MEMS sensor tech-\nnologies for human centred applications in healthcare, physical activities,\nsafety and environmental sensing: A review on research activities in\nitaly,'' Sensors, vol. 15, no. 3, pp. 6441\u00156468, Mar. 2015.\n[37] D. Moher, A. Liberati, J. Tetzlaff, and D. G. Altman, ``Preferred reporting\nitems for systematic reviews and meta-analyses: The PRISMA state-\nment,'' Ann. Internal Med., vol. 151, no. 4, pp. 264\u0015269, 2009.\n[38] F. Demrozi, R. Bacchin, S. Tamburin, M. Cristani, and G. Pravadelli,\n``Towards a wearable system for predicting the freezing of gait in people\naffected by Parkinson's disease,'' IEEE J. Biomed. Health Informat.,\nvol. 24, no. 9, pp. 2444\u00152451, Sep. 2020.\n[39] C. M. Bishop, Pattern Recognition and Machine Learning. Springer,\n2006.\n[40] P. Domingos, ``A few useful things to know about machine learning,''\nCommun. ACM, vol. 55, no. 10, pp. 78\u001587, Oct. 2012.[41] C. Dobbins and R. Rawassizadeh, ``Towards clustering of mobile and\nsmartwatch accelerometer data for physical activity recognition,'' Infor-\nmatics, vol. 5, no. 2, p. 29, Jun. 2018.\n[42] A. Vaughn, P. Biocco, Y. Liu, and M. Anwar, ``Activity detection and\nanalysis using smartphone sensors,'' in Proc. IEEE Int. Conf. Inf. Reuse\nIntegr. (IRI), Jul. 2018, pp. 102\u0015107.\n[43] Z. S. Abdallah, M. M. Gaber, B. Srinivasan, and S. Krishnaswamy,\n``Adaptive mobile activity recognition system with evolving data\nstreams,'' Neurocomputing, vol. 150, pp. 304\u0015317, Feb. 2015.\n[44] B. Shickel, P. J. Tighe, A. Bihorac, and P. Rashidi, ``Deep EHR: A survey\nof recent advances in deep learning techniques for electronic health record\n(EHR) analysis,'' IEEE J. Biomed. Health Informat., vol. 22, no. 5,\npp. 1589\u00151604, Sep. 2018.\n[45] G. Marcus, ``Deep learning: A critical appraisal,'' 2018,\narXiv:1801.00631. [Online]. Available: http://arxiv.org/abs/1801.00631\n[46] J. Brownlee, Master Machine Learning Algorithms: Discover How They\nWork and Implement Them From Scratch. Machine Learning Mastery,\n2016.\n[47] D. H. Kim, Y. Kim, D. Estrin, and M. B. Srivastava, ``SensLoc: Sensing\neveryday places and paths using less energy,'' in Proc. 8th ACM Conf.\nEmbedded Netwo. Sensor Syst., 2010, pp. 43\u001556.\n[48] H. Lu, W. Pan, N. D. Lane, T. Choudhury, and A. T. Campbell, ``Sound-\nSense: Scalable sound sensing for people-centric applications on mobile\nphones,'' in Proc. 7th Int. Conf. Mobile Syst., Appl., Services, 2009,\npp. 165\u0015178.\n[49] Y. Lee, Y. Ju, C. Min, S. Kang, I. Hwang, and J. Song, ``CoMon:\nCooperative ambience monitoring platform with continuity and bene\u001ct\nawareness,'' in Proc. 10th Int. Conf. Mobile Syst., Appl., Services, 2012,\npp. 43\u001556.\n[50] K. Zhan, S. Faux, and F. Ramos, ``Multi-scale conditional random \u001celds\nfor \u001crst-person activity recognition on elders and disabled patients,''\nPervasive Mobile Comput., vol. 16, pp. 251\u0015267, Jan. 2015.\n[51] J. Gummeson, B. Priyantha, and J. Liu, ``An energy harvesting wearable\nring platform for gestureinput on surfaces,'' in Proc. 12th Annu. Int. Conf.\nMobile Syst., Appl., Services, 2014, pp. 162\u0015175.\n[52] V. Leonov, ``Thermoelectric energy harvesting of human body heat for\nwearable sensors,'' IEEE Sensors J., vol. 13, no. 6, pp. 2284\u00152291,\nJun. 2013.\n[53] L. Wang, T. Gu, X. Tao, and J. Lu, ``A hierarchical approach to real-time\nactivity recognition in body sensor networks,'' Pervasive Mobile Comput.,\nvol. 8, no. 1, pp. 115\u0015130, Feb. 2012.\n[54] New Wearables Forecast From IDC Shows Smartwatches\nContinuing Their Ascendance While Wristbands Face Flat Growth.\nAccessed: Sep. 23, 2019. [Online]. Available: https://www.idc.\ncom/getdoc.jsp?containerId=prUS44000018\n[55] F. Demrozi, V. Bragoi, F. Tramarin, and G. Pravadelli, ``An indoor local-\nization system to detect areas causing the freezing of gait in parkinsoni-\nans,'' in Proc. Design, Autom. Test Eur. Conf. Exhib. (DATE) , Mar. 2019,\npp. 952\u0015955.\n[56] M. Z. Uddin, M. M. Hassan, A. Alsanad, and C. Savaglio, ``A body sensor\ndata fusion and deep recurrent neural network-based behavior recogni-\ntion approach for robust healthcare,'' Inf. Fusion, vol. 55, pp. 105\u0015115,\nMar. 2020.\n[57] H. F. Nweke, Y. W. Teh, U. R. Alo, and G. Mujtaba, ``Analysis of\nmulti-sensor fusion for mobile and wearable sensor based human activity\nrecognition,'' in Proc. Int. Conf. Data Process. Appl., 2018, pp. 22\u001526.\n[58] Y. Zhu, J. Yu, F. Hu, Z. Li, and Z. Ling, ``Human activity recognition via\nsmart-belt in wireless body area networks,'' Int. J. Distrib. Sensor Netw.,\nvol. 15, no. 5, 2019, Art. no. 1550147719849357.\n[59] M. Lv, L. Chen, T. Chen, and G. Chen, ``Bi-view semi-supervised learning\nbased semantic human activity recognition using accelerometers,'' IEEE\nTrans. Mobile Comput., vol. 17, no. 9, pp. 1991\u00152001, Sep. 2018.\n[60] Y. Liu, L. Nie, L. Han, L. Zhang, and D. S. Rosenblum, ``Action2activity:\nRecognizing complex activities from sensor data,'' in Proc. 24th Int. Joint\nConf. Artif. Intell., 2015, pp. 1\u00157.\n[61] M. Arif and A. Kattan, ``Physical activities monitoring using wearable\nacceleration sensors attached to the body,'' PLoS ONE, vol. 10, no. 7,\nJul. 2015, Art. no. e0130851.\n[62] S. Bhattacharya and N. D. Lane, ``From smart to deep: Robust activity\nrecognition on smartwatches using deep learning,'' in Proc. IEEE Int.\nConf. Pervasive Comput. Commun. Workshops (PerCom Workshops),\nMar. 2016, pp. 1\u00156.[63] G. Bhat, R. Deb, V. V. Chaurasia, H. Shill, and U. Y. Ogras, ``Online\nhuman activity recognition using low-power wearable devices,'' in Proc.\nInt. Conf. Comput.-Aided Design, Nov. 2018, p. 72.\n[64] S. Yao, S. Hu, Y. Zhao, A. Zhang, and T. Abdelzaher, ``DeepSense: A uni-\n\u001ced deep learning framework for time-series mobile sensing data process-\ning,'' in Proc. 26th Int. Conf. World Wide Web, Apr. 2017, pp. 351\u0015360.\n[65] P. Siirtola, H. Koskim\u00e4ki, and J. R\u00f6ning, ``From user-independent to\npersonal human activity recognition models using smartphone sensors,''\ninProc. ESANN, Apr. 2016, pp. 471\u0015476.\n[66] E. V. A\u00f1azco, P. R. Lopez, S. Lee, K. Byun, and T.-S. Kim, ``Smoking\nactivity recognition using a single wrist IMU and deep learning light,'' in\nProc. 2nd Int. Conf. Digit. Signal Process., 2018, pp. 48\u001551.\n[67] G. Brunner, D. Melnyk, B. Sigf\u00fasson, and R. Wattenhofer, ``Swimming\nstyle recognition and lap counting using a smartwatch and deep learning,''\ninProc. 23rd Int. Symp. Wearable Comput., 2019, pp. 23\u001531.\n[68] R. San-Segundo, H. Blunck, J. Moreno-Pimentel, A. Stisen, and\nM. Gil-Mart\u00edn, ``Robust human activity recognition using smartwatches\nand smartphones,'' Eng. Appl. Artif. Intell., vol. 72, pp. 190\u0015202,\nJun. 2018.\n[69] F. Attal, S. Mohammed, M. Dedabrishvili, F. Chamroukhi, L. Oukhellou,\nand Y. Amirat, ``Physical human activity recognition using wearable\nsensors,'' Sensors, vol. 15, no. 12, pp. 31314\u001531338, 2015.\n[70] D. Wu, Z. Wang, Y. Chen, and H. Zhao, ``Mixed-kernel based weighted\nextreme learning machine for inertial sensor based human activity recog-\nnition with imbalanced dataset,'' Neurocomputing, vol. 190, pp. 35\u001549,\nMay 2016.\n[71] L. Wang, ``Recognition of human activities using continuous autoen-\ncoders with wearable sensors,'' Sensors, vol. 16, no. 2, p. 189, Feb. 2016.\n[72] A. A. Badawi, A. Al-Kabbany, and H. Shaban, ``Multimodal human activ-\nity recognition from wearable inertial sensors using machine learning,''\ninProc. IEEE-EMBS Conf. Biomed. Eng. Sci. (IECBES), Dec. 2018,\npp. 402\u0015407.\n[73] B. Zhou, J. Yang, and Q. Li, ``Smartphone-based activity recognition\nfor indoor localization using a convolutional neural network,'' Sensors,\nvol. 19, no. 3, p. 621, Feb. 2019.\n[74] G. Civitarese, R. Presotto, and C. Bettini, ``Context-driven active and\nincremental activity recognition,'' 2019, arXiv:1906.03033. [Online].\nAvailable: http://arxiv.org/abs/1906.03033\n[75] J. Margarito, R. Helaoui, A. M. Bianchi, F. Sartor, and A. G. Bonomi,\n``User-independent recognition of sports activities from a single wrist-\nworn accelerometer: A template-matching-based approach,'' IEEE Trans.\nBiomed. Eng., vol. 63, no. 4, pp. 788\u0015796, Apr. 2016.\n[76] A. Subasi, D. H. Dammas, R. D. Alghamdi, R. A. Makawi, E. A. Albiety,\nT. Brahimi, and A. Sarirete, ``Sensor based human activity recognition\nusing AdaBoost ensemble classi\u001cer,'' Procedia Comput. Sci., vol. 140,\npp. 104\u0015111, 2018.\n[77] S. Ha and S. Choi, ``Convolutional neural networks for human activity\nrecognition using multiple accelerometer and gyroscope sensors,'' in\nProc. Int. Joint Conf. Neural Netw. (IJCNN), Jul. 2016, pp. 381\u0015388.\n[78] A. Subasi, M. Radhwan, R. Kurdi, and K. Khateeb, ``IoT based mobile\nhealthcare system for human activity recognition,'' in Proc. 15th Learn.\nTechnol. Conf. (L T), Feb. 2018, pp. 29\u001534.\n[79] A. K. Muhammad Masum, A. Barua, E. H. Bahadur, M. R. Alam,\nM. A. U. Z. Chowdhury, and M. S. Alam, ``Human activity recognition\nusing multiple smartphone sensors,'' in Proc. Int. Conf. Innov. Sci., Eng.\nTechnol. (ICISET), Oct. 2018, pp. 468\u0015473.\n[80] G. Ding, J. Tian, J. Wu, Q. Zhao, and L. Xie, ``Energy ef\u001ccient human\nactivity recognition using wearable sensors,'' in Proc. IEEE Wireless\nCommun. Netw. Conf. Workshops (WCNCW), Apr. 2018, pp. 379\u0015383.\n[81] Y. Chen and Y. Xue, ``A deep learning approach to human activity\nrecognition based on single accelerometer,'' in Proc. IEEE Int. Conf. Syst.,\nMan, Cybern., Oct. 2015, pp. 1488\u00151492.\n[82] D. Micucci, M. Mobilio, and P. Napoletano, ``UniMiB SHAR: A dataset\nfor human activity recognition using acceleration data from smart-\nphones,'' Appl. Sci., vol. 7, no. 10, p. 1101, Oct. 2017.\n[83] A. Nait Aicha, G. Englebienne, K. van Schooten, M. Pijnappels, and\nB. Kr\u00f6se, ``Deep learning to predict falls in older adults based on daily-\nlife trunk accelerometry,'' Sensors, vol. 18, no. 5, p. 1654, May 2018.\n[84] A. S. A. Sukor, A. Zakaria, and N. A. Rahim, ``Activity recognition using\naccelerometer sensor and machine learning classi\u001cers,'' in Proc. IEEE\n14th Int. Colloq. Signal Process. Appl. (CSPA), Mar. 2018, pp. 233\u0015238.\n[85] Y. Tian, X. Wang, W. Chen, Z. Liu, and L. Li, ``Adaptive multiple\nclassi\u001cers fusion for inertial sensor based human activity recognition,''\nCluster Comput., vol. 22, no. 4, pp. 1\u001514, 2018.\n[86] G. Chetty, M. White, and F. Akther, ``Smart phone based data min-\ning for human activity recognition,'' Procedia Comput. Sci., vol. 46,\npp. 1181\u00151187, Jan. 2015.[87] D. De, P. Bharti, S. K. Das, and S. Chellappan, ``Multimodal wearable\nsensing for \u001cne-grained activity recognition in healthcare,'' IEEE Internet\nComput., vol. 19, no. 5, pp. 26\u001535, Sep. 2015.\n[88] J. Yang, M. N. Nguyen, P. P. San, X. L. Li, and S. Krishnaswamy, ``Deep\nconvolutional neural networks on multichannel time series for human\nactivity recognition,'' in Proc. 24th Int. Joint Conf. Artif. Intell., 2015,\npp. 3995\u00154001.\n[89] N. Y. Hammerla, S. Halloran, and T. Pl\u00f6tz, ``Deep, convolutional, and\nrecurrent models for human activity recognition using wearables,'' 2016,\narXiv:1604.08880. [Online]. Available: http://arxiv.org/abs/1604.08880\n[90] I. A. Lawal and S. Bano, ``Deep human activity recognition using wear-\nable sensors,'' in Proc. 12th ACM Int. Conf. Pervasive Technol. Rel.\nAssistive Environ., 2019, pp. 45\u001548.\n[91] Y. Vaizman, K. Ellis, and G. Lanckriet, ``Recognizing detailed human\ncontext in the wild from smartphones and smartwatches,'' IEEE Pervasive\nComput., vol. 16, no. 4, pp. 62\u001574, Oct. 2017.\n[92] F. Cruciani, I. Cleland, C. Nugent, P. McCullagh, K. Synnes, and\nJ. Hallberg, ``Automatic annotation for human activity recognition in free\nliving using a smartphone,'' Sensors, vol. 18, no. 7, p. 2203, Jul. 2018.\n[93] S. K. Polu and S. K. Polu, ``Human activity recognition on smartphones\nusing machine learning algorithms,'' Int. J. Innov. Res. Sci. Technol.,\nvol. 5, no. 6, pp. 31\u001537, 2018.\n[94] C. Rodriguez, D. M. Castro, W. Coral, J. L. Cabra, N. Velasquez,\nJ. Colorado, D. Mendez, and L. C. Trujillo, ``IoT system for human\nactivity recognition using BioHarness 3 and smartphone,'' in Proc. Int.\nConf. Future Netw. Distrib. Syst., 2017, p. 49.\n[95] S. Balli, E. A. Sa\u00a7ba\u00b3, and M. Peker, ``Human activity recognition\nfrom smart watch sensor data using a hybrid of principal component\nanalysis and random forest algorithm,'' Meas. Control, vol. 52, nos. 1\u00152,\npp. 37\u001545, Jan. 2019.\n[96] J. Manjarr\u00e9s, V. Russo, J. Pe\u00f1aranda, and M. Pardo, ``Human activity\nand heart rate monitoring system in a mobile platform,'' in Proc. Con-\ngreso Internacional de Innovaci\u00f3n y Tendencias en Ingenier\u00eda (CONIITI),\nOct. 2018, pp. 1\u00156.\n[97] A. N. K., G. Bhat, J. Park, H. G. Lee, and U. Y. Ogras, ``Sensor-classi\u001cer\nco-optimization for wearable human activity recognition applications,'' in\nProc. IEEE Int. Conf. Embedded Softw. Syst. (ICESS), Jun. 2019, pp. 1\u00154.\n[98] K. T. Nguyen, F. Portet, and C. Garbay, ``Dealing with imbalanced data\nsets for human activity recognition using mobile phone sensors,'' in Proc.\n3rd Int. Workshop Smart Sens. Syst., Jun. 2018, pp. 1\u001511.\n[99] C. A. Ronao and S.-B. Cho, ``Human activity recognition with smart-\nphone sensors using deep learning neural networks,'' Expert Syst. Appl.,\nvol. 59, pp. 235\u0015244, Oct. 2016.\n[100] W. Jiang and Z. Yin, ``Human activity recognition using wearable sensors\nby deep convolutional neural networks,'' in Proc. 23rd ACM Int. Conf.\nMultimedia, 2015, pp. 1307\u00151310.\n[101] M. M. Hassan, M. Z. Uddin, A. Mohamed, and A. Almogren, ``A\nrobust human activity recognition system using smartphone sensors and\ndeep learning,'' Future Gener. Comput. Syst., vol. 81, pp. 307\u0015313,\nApr. 2018.\n[102] F. Ord\u00f3\u00f1ez and D. Roggen, ``Deep convolutional and LSTM recurrent\nneural networks for multimodal wearable activity recognition,'' Sensors,\nvol. 16, no. 1, p. 115, Jan. 2016.\n[103] M. A. Alsheikh, A. Selim, D. Niyato, L. Doyle, S. Lin, and H.-P. Tan,\n``Deep activity recognition models with triaxial accelerometers,'' in Proc.\nWorkshops 13th AAAI Conf. Artif. Intell., 2016, pp. 1\u00157.\n[104] A. Ignatov, ``Real-time human activity recognition from accelerometer\ndata using convolutional neural networks,'' Appl. Soft Comput., vol. 62,\npp. 915\u0015922, Jan. 2018.\n[105] M. A. Alsheikh, D. Niyato, S. Lin, H.-P. Tan, and Z. Han, ``Mobile big\ndata analytics using deep learning and apache spark,'' IEEE Netw., vol. 30,\nno. 3, pp. 22\u001529, May 2016.\n[106] X. Zheng, M. Wang, and J. Ordieres-Mer\u00e9, ``Comparison of data pre-\nprocessing approaches for applying deep learning to human activity\nrecognition in the context of industry 4.0,'' Sensors, vol. 18, no. 7, p. 2146,\nJul. 2018.\n[107] Y. Guan and T. Pl\u00f6tz, ``Ensembles of deep lstm learners for activity\nrecognition using wearables,'' in Proc. ACM Interact., Mobile, Wearable\nUbiquitous Technol., 2017, vol. 1, no. 2, p. 11.\n[108] R. Grzeszick, J. M. Lenk, F. M. Rueda, G. A. Fink, S. Feldhorst, and\nM. ten Hompel, ``Deep neural network based human activity recognition\nfor the order picking process,'' in Proc. 4th Int. Workshop Sensor Activity\nRecognit. Interact., 2017, p. 14.\n[109] Z. Chen, Q. Zhu, Y. C. Soh, and L. Zhang, ``Robust human activ-\nity recognition using smartphone sensors via CT-PCA and online\nSVM,'' IEEE Trans. Ind. Informat., vol. 13, no. 6, pp. 3070\u00153080,\nDec. 2017.\n[110] Z. Chen, C. Jiang, and L. Xie, ``A novel ensemble ELM for human activ-\nity recognition using smartphone sensors,'' IEEE Trans. Ind. Informat.,\nvol. 15, no. 5, pp. 2691\u00152699, May 2019.\n[111] C. Xu, D. Chai, J. He, X. Zhang, and S. Duan, ``InnoHAR: A deep neural\nnetwork for complex human activity recognition,'' IEEE Access, vol. 7,\npp. 9893\u00159902, 2019.\n[112] A. Sathyanarayana, S. Joty, L. Fernandez-Luque, F. O\u001di, J. Srivastava,\nA. Elmagarmid, T. Arora, and S. Taheri, ``Sleep quality prediction from\nwearable data using deep learning,'' JMIR mHealth uHealth, vol. 4, no. 4,\np. e125, Nov. 2016.\n[113] M. Shoaib, S. Bosch, O. Incel, H. Scholten, and P. Havinga, ``Complex\nhuman activity recognition using smartphone and wrist-worn motion\nsensors,'' Sensors, vol. 16, no. 4, p. 426, Mar. 2016.\n[114] J. Suto and S. Oniga, ``Ef\u001cciency investigation of arti\u001ccial neural net-\nworks in human activity recognition,'' J. Ambient Intell. Humanized\nComput., vol. 9, no. 4, pp. 1049\u00151060, Aug. 2018.\n[115] J. Wang, V. W. Zheng, Y. Chen, and M. Huang, ``Deep transfer learning\nfor cross-domain activity recognition,'' in Proc. 3rd Int. Conf. Crowd Sci.\nEng., 2018, p. 16.\n[116] H. D. Nguyen, K. P. Tran, X. Zeng, L. Koehl, and G. Tartare, ``Wear-\nable sensor data based human activity recognition using machine learn-\ning: A new approach,'' 2019, arXiv:1905.03809. [Online]. Available:\nhttp://arxiv.org/abs/1905.03809\n[117] K. Li, R. Habre, H. Deng, R. Urman, J. Morrison, F. D. Gilliland,\nJ. L. Ambite, D. Stripelis, Y. Y. Chiang, Y. Lin, and A. A. Bui, ``Applying\nmultivariate segmentation methods to human activity recognition from\nwearable sensors' data,'' JMIR mHealth uHealth, vol. 7, no. 2, p. e11201,\n2019.\n[118] K.-C. Liu, C.-Y. Yen, L.-H. Chang, C.-Y. Hsieh, and C.-T. Chan, ``Wear-\nable sensor-based activity recognition for housekeeping task,'' in Proc.\nIEEE 14th Int. Conf. Wearable Implant. Body Sensor Netw. (BSN),\nMay 2017, pp. 67\u001570.\n[119] R. Ding, X. Li, L. Nie, J. Li, X. Si, D. Chu, G. Liu, and D. Zhan,\n``Empirical study and improvement on deep transfer learning for human\nactivity recognition,'' Sensors, vol. 19, no. 1, p. 57, Dec. 2018.\n[120] P. Nardi, ``Human activity recognition: Deep learning techniques for\nan upper body exercise classi\u001ccation system,'' Dept. Natural Sci., Kris-\ntianstad Univ., Kristianstad, Sweden, Tech. Rep., 2019, p. 27.\n[121] I. P. Machado, A. Lu\u00edsa Gomes, H. Gamboa, V. Paix\u00e3o, and R. M. Costa,\n``Human activity data discovery from triaxial accelerometer sensor: Non-\nsupervised learning sensitivity to feature extraction parametrization,'' Inf.\nProcess. Manage., vol. 51, no. 2, pp. 204\u0015214, Mar. 2015.\n[122] A. Wang, G. Chen, J. Yang, S. Zhao, and C.-Y. Chang, ``A comparative\nstudy on human activity recognition using inertial sensors in a smart-\nphone,'' IEEE Sensors J., vol. 16, no. 11, pp. 4566\u00154578, Jun. 2016.\n[123] B. Almaslukh, J. AlMuhtadi, and A. Artoli, ``An effective deep autoen-\ncoder approach for online smartphone-based human activity recogni-\ntion,'' Int. J. Comput. Sci. Netw. Secur, vol. 17, no. 4, pp. 160\u0015165, 2017.\n[124] H. Ponce, M. Mart\u00ednez-Villase\u00f1or, and L. Miralles-Pechu\u00e1n, ``A novel\nwearable sensor-based human activity recognition approach using arti-\n\u001ccial hydrocarbon networks,'' Sensors, vol. 16, no. 7, p. 1033, Jul. 2016.\n[125] F. Li, K. Shirahama, M. Nisar, L. K\u00f6ping, and M. Grzegorzek, ``Com-\nparison of feature learning methods for human activity recognition using\nwearable sensors,'' Sensors, vol. 18, no. 3, p. 679, Feb. 2018.\n[126] A. Jordao, L. A. B. Torres, and W. R. Schwartz, ``Novel approaches to\nhuman activity recognition based on accelerometer data,'' Signal, Image\nVideo Process., vol. 12, no. 7, pp. 1387\u00151394, Oct. 2018.\n[127] E. Bulbul, A. Cetin, and I. A. Dogru, ``Human activity recognition using\nsmartphones,'' in Proc. 2nd Int. Symp. Multidisciplinary Stud. Innov.\nTechnol. (ISMSIT), Oct. 2018, pp. 1\u00156.\n[128] L. Cao, Y. Wang, B. Zhang, Q. Jin, and A. V. Vasilakos, ``GCHAR:\nAn ef\u001ccient group-based context\u0016Aware human activity recognition\non smartphone,'' J. Parallel Distrib. Comput., vol. 118, pp. 67\u001580,\nAug. 2018.\n[129] M. Inoue, S. Inoue, and T. Nishida, ``Deep recurrent neural network\nfor mobile human activity recognition with high throughput,'' Artif. Life\nRobot., vol. 23, no. 2, pp. 173\u0015185, Jun. 2018.\n[130] M. Milenkoski, K. Trivodaliev, S. Kalajdziski, M. Jovanov, and\nB. R. Stojkoska, ``Real time human activity recognition on smartphones\nusing LSTM networks,'' in Proc. 41st Int. Conv. Inf. Commun. Technol.,\nElectron. Microelectron. (MIPRO), May 2018, pp. 1126\u00151131.\n[131] P. Lago, T. Okita, S. Takeda, and S. Inoue, ``Improving sensor-based\nactivity recognition using motion capture as additional information,'' in\nProc. ACM Int. Joint Conf. Int. Symp. Pervasive Ubiquitous Comput.\nWearable Comput., 2018, pp. 118\u0015121.[132] A. Mimouna, A. B. Khalifa, and N. E. Ben Amara, ``Human action\nrecognition using triaxial accelerometer data: Selective approach,'' in\nProc. 15th Int. Multi-Conf. Syst., Signals Devices (SSD), Mar. 2018,\npp. 491\u0015496.\n[133] H. Kwon, G. D. Abowd, and T. Pl\u00f6tz, ``Adding structural characteristics to\ndistribution-based accelerometer representations for activity recognition\nusing wearables,'' in Proc. ACM Int. Symp. Wearable Comput., 2018,\npp. 72\u001575.\n[134] P. Siirtola, H. Koskim\u00e4ki, and J. R\u00f6ning, ``From user-independent\nto personal human activity recognition models exploiting the sen-\nsors of a smartphone,'' 2019, arXiv:1905.12285. [Online]. Available:\nhttp://arxiv.org/abs/1905.12285\n[135] M. Willetts, A. Doherty, S. Roberts, and C. Holmes, ``Semi-unsupervised\nlearning of human activity using deep generative models,'' 2018,\narXiv:1810.12176. [Online]. Available: http://arxiv.org/abs/1810.12176\n[136] G. De Leonardis, S. Rosati, G. Balestra, V. Agostini, E. Panero,\nL. Gastaldi, and M. Kna\u001ditz, ``Human activity recognition by wearable\nsensors: Comparison of different classi\u001cers for real-time applications,''\ninProc. IEEE Int. Symp. Med. Meas. Appl. (MeMeA), Jun. 2018, pp. 1\u00156.\n[137] S. Chung, J. Lim, K. J. Noh, G. Kim, and H. Jeong, ``Sensor data\nacquisition and multimodal sensor fusion for human activity recognition\nusing deep learning,'' Sensors, vol. 19, no. 7, p. 1716, Apr. 2019.\n[138] H. Choi, Q. Wang, M. Toledo, P. Turaga, M. Buman, and A. Srivastava,\n``Temporal alignment improves feature quality: An experiment on activity\nrecognition with accelerometer data,'' in Proc. IEEE/CVF Conf. Comput.\nVis. Pattern Recognit. Workshops, Jun. 2018, pp. 349\u0015357.\n[139] T. Zebin, M. Sperrin, N. Peek, and A. J. Casson, ``Human activity recogni-\ntion from inertial sensor time-series using batch normalized deep LSTM\nrecurrent networks,'' in Proc. 40th Annu. Int. Conf. IEEE Eng. Med. Biol.\nSoc. (EMBC), Jul. 2018, pp. 1\u00154.\n[140] T. Hossain, H. Goto, and S. Inoue, ``Improving activity recognition for\nmissing data,'' in Proc. EAI Int. Conf. Mobile Comput., Appl. Services\nStudent Workshop, 2018.\n[141] W. Xu, Y. Pang, Y. Yang, and Y. Liu, ``Human activity recognition\nbased on convolutional neural network,'' in Proc. 24th Int. Conf. Pattern\nRecognit. (ICPR), Aug. 2018, pp. 165\u0015170.\n[142] M. Espinilla, J. Medina, A. Salguero, N. Irvine, M. Donnelly, I. Cleland,\nand C. Nugent, ``Human activity recognition from the acceleration data of\na wearable device. Which features are more relevant by activities?'' Mul-\ntidisciplinary Digit. Publishing Inst., vol. 2, no. 19, p. 1242, Oct. 2018.\n[143] R. Zhu, Z. Xiao, Y. Li, M. Yang, Y. Tan, L. Zhou, S. Lin, and H. Wen,\n``Ef\u001ccient human activity recognition solving the confusing activities via\ndeep ensemble learning,'' IEEE Access, vol. 7, pp. 75490\u001575499, 2019.\n[144] C.-F. Su, L.-C. Fu, Y.-W. Chien, and T.-Y. Li, ``Activity recogni-\ntion system for dementia in smart homes based on wearable sensor\ndata,'' in Proc. IEEE Symp. Ser. Comput. Intell. (SSCI), Nov. 2018,\npp. 463\u0015469.\n[145] S. Rosati, G. Balestra, and M. Kna\u001ditz, ``Comparison of different sets of\nfeatures for human activity recognition by wearable sensors,'' Sensors,\nvol. 18, no. 12, p. 4189, Nov. 2018.\n[146] V. Bianchi, M. Bassoli, G. Lombardo, P. Fornacciari, M. Mordonini, and\nI. De Munari, ``IoT wearable sensor and deep learning: An integrated\napproach for personalized human activity recognition in a smart home\nenvironment,'' IEEE Internet Things J., vol. 6, no. 5, pp. 8553\u00158562,\nOct. 2019.\n[147] M. Nutter, C. H. Crawford, and J. Ortiz, ``Design of novel deep learning\nmodels for real-time human activity recognition with mobile phones,'' in\nProc. Int. Joint Conf. Neural Netw. (IJCNN), Jul. 2018, pp. 1\u00158.\n[148] R.-A. Voicu, C. Dobre, L. Bajenaru, and R.-I. Ciobanu, ``Human physical\nactivity recognition using smartphone sensors,'' Sensors, vol. 19, no. 3,\np. 458, Jan. 2019.\n[149] B. Almaslukh, A. Artoli, and J. Al-Muhtadi, ``A robust deep learn-\ning approach for position-independent smartphone-based human activity\nrecognition,'' Sensors, vol. 18, no. 11, p. 3726, Nov. 2018.\n[150] K. Wang, J. He, and L. Zhang, ``Attention-based convolutional neural\nnetwork for weakly labeled human activities' recognition with wearable\nsensors,'' IEEE Sensors J., vol. 19, no. 17, pp. 7598\u00157604, Sep. 2019.\n[151] A. Malais\u00e9, P. Maurice, F. Colas, F. Charpillet, and S. Ivaldi, ``Activity\nrecognition with multiple wearable sensors for industrial applications,''\ninProc. 11th Int. Conf. Adv. Comput.-Hum. Interact., Mar. 2018, pp. 1\u00157.\n[152] Y. Zhao, R. Yang, G. Chevalier, X. Xu, and Z. Zhang, ``Deep residual\nbidir-LSTM for human activity recognition using wearable sensors,''\nMath. Problems Eng., vol. 2018, pp. 1\u001513, Dec. 2018.\n[153] J. Sun, Y. Fu, S. Li, J. He, C. Xu, and L. Tan, ``Sequential human activity\nrecognition based on deep convolutional network and extreme learn-\ning machine using wearable sensors,'' J. Sensors, vol. 2018, pp. 1\u001510,\nSep. 2018.[154] X. Niu, Z. Wang, and Z. Pan, ``Extreme learning machine-based deep\nmodel for human activity recognition with wearable sensors,'' Comput.\nSci. Eng., vol. 21, no. 5, pp. 16\u001525, Sep. 2019.\n[155] J.-L. Reyes-Ortiz, L. Oneto, A. Sam\u00e0, X. Parra, and D. Anguita,\n``Transition-aware human activity recognition using smartphones,'' Neu-\nrocomputing, vol. 171, pp. 754\u0015767, Jan. 2016.\n[156] Y. Lu, Y. Wei, L. Liu, J. Zhong, L. Sun, and Y. Liu, ``Towards unsu-\npervised physical activity recognition using smartphone accelerometers,''\nMultimedia Tools Appl., vol. 76, no. 8, pp. 10701\u001510719, 2017.\n[157] C. Catal, S. Tufekci, E. Pirmit, and G. Kocabag, ``On the use of ensemble\nof classi\u001cers for accelerometer-based activity recognition,'' Appl. Soft\nComput., vol. 37, pp. 1018\u00151022, Dec. 2015.\n[158] J. Wannenburg and R. Malekian, ``Physical activity recognition from\nsmartphone accelerometer data for user context awareness sensing,''\nIEEE Trans. Syst., Man, Cybern., Syst., vol. 47, no. 12, pp. 3142\u00153149,\nDec. 2017.\n[159] N. A. Capela, E. D. Lemaire, and N. Baddour, ``Feature selection for\nwearable smartphone-based human activity recognition with able bodied,\nelderly, and stroke patients,'' PLoS ONE, vol. 10, no. 4, Apr. 2015,\nArt. no. e0124414.\n[160] T. Zebin, P. J. Scully, and K. B. Ozanyan, ``Human activity recognition\nwith inertial sensors using a deep learning approach,'' in Proc. IEEE\nSENSORS, Oct. 2016, pp. 1\u00153.\n[161] S. Khalifa, G. Lan, M. Hassan, A. Seneviratne, and S. K. Das,\n``HARKE: Human activity recognition from kinetic energy harvesting\ndata in wearable devices,'' IEEE Trans. Mobile Comput., vol. 17, no. 6,\npp. 1353\u00151368, Jun. 2018.\n[162] A. D. Ignatov and V. V. Strijov, ``Human activity recognition using\nquasiperiodic time series collected from a single tri-axial accelerometer,''\nMultimedia Tools Appl., vol. 75, no. 12, pp. 7257\u00157270, Jun. 2016.\n[163] Z. Wang, D. Wu, J. Chen, A. Ghoneim, and M. A. Hossain, ``A tri-\naxial accelerometer-based human activity recognition via EEMD-based\nfeatures and Game-Theory-Based feature selection,'' IEEE Sensors J.,\nvol. 16, no. 9, pp. 3198\u00153207, May 2016.\n[164] P. Paul and T. George, ``An effective approach for human activity recogni-\ntion on smartphone,'' in Proc. IEEE Int. Conf. Eng. Technol. (ICETECH),\nMar. 2015, pp. 1\u00153.\n[165] N. A. Capela, E. D. Lemaire, N. Baddour, M. Rudolf, N. Goljar, and\nH. Burger, ``Evaluation of a smartphone human activity recognition appli-\ncation with able-bodied and stroke participants,'' J. NeuroEng. Rehabil.,\nvol. 13, no. 1, p. 5, Dec. 2016.\n[166] L. Zhang, X. Wu, and D. Luo, ``Recognizing human activities from raw\naccelerometer data using deep neural networks,'' in Proc. IEEE 14th Int.\nConf. Mach. Learn. Appl. (ICMLA), Dec. 2015, pp. 865\u0015870.\n[167] M. Zubair, K. Song, and C. Yoon, ``Human activity recognition using\nwearable accelerometer sensors,'' in Proc. IEEE Int. Conf. Consum.\nElectron.-Asia (ICCE-Asia), Oct. 2016, pp. 1\u00155.\n[168] X. Heng, Z. Wang, and J. Wang, ``Human activity recognition based on\ntransformed accelerometer data from a mobile phone,'' Int. J. Commun.\nSyst., vol. 29, no. 13, pp. 1981\u00151991, Sep. 2016.\n[169] C. Torres-Huitzil and M. Nuno-Maganda, ``Robust smartphone-based\nhuman activity recognition using a tri-axial accelerometer,'' in Proc.\nIEEE 6th Latin Amer. Symp. Circuits Syst. (LASCAS), Feb. 2015,\npp. 1\u00154.\n[170] A. Khan, S. Mellor, E. Berlin, R. Thompson, R. McNaney, P. Olivier, and\nT. Pl\u00f6tz, ``Beyond activity recognition: Skill assessment from accelerom-\neter data,'' in Proc. ACM Int. Joint Conf. Pervasive Ubiquitous Comput.,\n2015, pp. 1155\u00151166.\n[171] Y. Zheng, ``Human activity recognition based on the hierarchical fea-\nture selection and classi\u001ccation framework,'' J. Electr. Comput. Eng.,\nvol. 2015, p. 34, Jan. 2015.\n[172] D. Tao, Y. Wen, and R. Hong, ``Multicolumn bidirectional long short-term\nmemory for mobile devices-based human activity recognition,'' IEEE\nInternet Things J., vol. 3, no. 6, pp. 1124\u00151134, Dec. 2016.\n[173] R. Akhavian and A. H. Behzadan, ``Smartphone-based construction\nworkers' activity recognition and classi\u001ccation,'' Autom. Construct.,\nvol. 71, pp. 198\u0015209, Nov. 2016.\n[174] I. Suarez, A. Jahn, C. Anderson, and K. David, ``Improved activity\nrecognition by using enriched acceleration data,'' in Proc. ACM Int. Joint\nConf. Pervasive Ubiquitous Comput., 2015, pp. 1011\u00151015.\n[175] C. Shen, Y. Chen, and G. Yang, ``On motion-sensor behavior analysis for\nhuman-activity recognition via smartphones,'' in Proc. IEEE Int. Conf.\nIdentity, Secur. Behav. Anal. (ISBA), Feb. 2016, pp. 1\u00156.\n[176] Y. Chen, K. Zhong, J. Zhang, Q. Sun, and X. Zhao, ``LSTM net-\nworks for mobile human activity recognition,'' in Proc. Int. Conf. Artif.\nIntell., Technol. Appl. Amsterdam, The Netherlands: Atlantis Press, 2016,\npp. 50\u001553, doi: 10.2991/icaita-16.2016.13.[177] M. N. S. Zainudin, M. N. Sulaiman, N. Mustapha, and T. Perumal,\n``Activity recognition based on accelerometer sensor using combina-\ntional classi\u001cers,'' in Proc. IEEE Conf. Open Syst. (ICOS), Aug. 2015,\npp. 68\u001573.\n[178] G. Vavoulas, C. Chatzaki, T. Malliotakis, M. Pediaditis, and M. Tsiknakis,\n``The mobiact dataset: Recognition of activities of daily living using\nsmartphones,'' in Proc. ICT AgeingWell, 2016, pp. 143\u0015151.\n[179] R. San-Segundo, J. M. Montero, R. Barra-Chicote, F. Fern\u00e1ndez, and\nJ. M. Pardo, ``Feature extraction from smartphone inertial signals for\nhuman activity segmentation,'' Signal Process., vol. 120, pp. 359\u0015372,\nMar. 2016.\n[180] M. Panwar, S. R. Dyuthi, K. C. Prakash, D. Biswas, A. Acharyya,\nK. Maharatna, A. Gautam, and G. R. Naik, ``CNN based approach\nfor activity recognition using a wrist-worn accelerometer,'' in Proc.\n39th Annu. Int. Conf. IEEE Eng. Med. Biol. Soc. (EMBC), Jul. 2017,\npp. 2438\u00152441.\n[181] L. Zhang, X. Wu, and D. Luo, ``Human activity recognition with HMM-\nDNN model,'' in Proc. IEEE 14th Int. Conf. Cognit. Informat. Cognit.\nComput. (ICCI CC), Jul. 2015, pp. 192\u0015197.\n[182] K. Davis, E. Owusu, V. Bastani, L. Marcenaro, J. Hu, C. Regazzoni,\nand L. Feijs, ``Activity recognition based on inertial sensors for ambient\nassisted living,'' in Proc. 19th Int. Conf. Inf. Fusion (Fusion), 2016,\npp. 371\u0015378.\n[183] P. Lubina and M. Rudzki, ``Arti\u001ccial neural networks in accelerometer-\nbased human activity recognition,'' in Proc. 22nd Int. Conf. Mixed Design\nIntegr. Circuits Syst. (MIXDES), Jun. 2015, pp. 63\u001568.\n[184] X. Yin, W. Shen, J. Samarabandu, and X. Wang, ``Human activity\ndetection based on multiple smart phone sensors and machine learning\nalgorithms,'' in Proc. IEEE 19th Int. Conf. Comput. Supported Cooperat.\nWork Design (CSCWD), May 2015, pp. 582\u0015587.\n[185] G. M. Weiss, J. L. Timko, C. M. Gallagher, K. Yoneda, and\nA. J. Schreiber, ``Smartwatch-based activity recognition: A machine\nlearning approach,'' in Proc. IEEE-EMBS Int. Conf. Biomed. Health\nInformat. (BHI), Feb. 2016, pp. 426\u0015429.\n[186] Q. Zhu, Z. Chen, and Y. C. Soh, ``Smartphone-based human activ-\nity recognition in buildings using locality-constrained linear coding,''\ninProc. IEEE 10th Conf. Ind. Electron. Appl. (ICIEA), Jun. 2015,\npp. 214\u0015219.\n[187] J. Lee and J. Kim, ``Energy-ef\u001ccient real-time human activity recogni-\ntion on smart mobile devices,'' Mobile Inf. Syst., vol. 2016, pp. 1\u001512,\nJan. 2016.\n[188] N. A. Capela, E. D. Lemaire, and N. Baddour, ``Improving classi\u001ccation\nof sit, stand, and lie in a smartphone human activity recognition sys-\ntem,'' in Proc. IEEE Int. Symp. Med. Meas. Appl. (MeMeA), May 2015,\npp. 473\u0015478.\n[189] A. Mannini, M. Rosenberger, W. L. Haskell, A. M. Sabatini, and\nS. S. Intille, ``Activity recognition in youth using single accelerometer\nplaced at wrist or ankle,'' Med. Sci. Sports Exerc., vol. 49, no. 4, p. 801,\n2017.\n[190] R. Dama\u00b2evi\u00a3ius, M. Vasiljevas, J. \u0092alkevi\u00a3ius, and M. Wo\u00b9niak,\n``Human activity recognition in AAL environments using random pro-\njections,'' Comput. Math. Methods Med., vol. 2016, pp. 1\u001517, May 2016.\n[191] J. Huang, S. Lin, N. Wang, G. Dai, Y. Xie, and J. Zhou, ``TSE-CNN:\nA two-stage end-to-end CNN for human activity recognition,'' IEEE J.\nBiomed. Health Informat., vol. 24, no. 1, pp. 292\u0015299, Jan. 2020.\n[192] S. Khalifa, M. Hassan, and A. Seneviratne, ``Pervasive self-powered\nhuman activity recognition without the accelerometer,'' in Proc. IEEE Int.\nConf. Pervasive Comput. Commun. (PerCom), Mar. 2015, pp. 79\u001586.\n[193] M. Kheirkhahan, S. Nair, A. Davoudi, P. Rashidi, A. A. Wanigatunga,\nD. B. Corbett, T. Mendoza, T. M. Manini, and S. Ranka, ``A smartwatch-\nbased framework for real-time and online assessment and mobility mon-\nitoring,'' J. Biomed. Informat., vol. 89, pp. 29\u001540, Jan. 2019.\n[194] T. Tamura, ``Wearable inertial sensors and their applications,'' in Wear-\nable Sensors. Amsterdam, The Netherlands: Elsevier, 2014, pp. 85\u0015104.\n[195] M. Feidakis, ``A review of emotion-aware systems for e-learning in\nvirtual environments,'' in Formative Assessment, Learning Data Ana-\nlytics and Gami\u001ccation. Amsterdam, The Netherlands: Elsevier, 2016,\npp. 217\u0015242.\n[196] J. R. Kwapisz, G. M. Weiss, and S. A. Moore, ``Activity recognition\nusing cell phone accelerometers,'' ACM SIGKDD Explorations Newslett.,\nvol. 12, no. 2, pp. 74\u001582, Mar. 2011.\n[197] D. Roggen, A. Calatroni, M. Rossi, T. Holleczek, K. Forster, G. Troster,\nP. Lukowicz, D. Bannach, G. Pirkl, A. Ferscha, J. Doppler, C. Holzmann,\nM. Kurz, G. Holl, R. Chavarriaga, H. Sagha, H. Bayati, M. Creatura,\nand J. D. R. Millan, ``Collecting complex activity datasets in highly rich\nnetworked sensor environments,'' in Proc. 7th Int. Conf. Netw. Sens. Syst.,\nJun. 2010, pp. 233\u0015240.\n[198] D. Anguita, A. Ghio, L. Oneto, X. Parra, and J. L. Reyes-Ortiz, ``A public\ndomain dataset for human activity recognition using smartphones,'' in\nProc. ESANN, 2013, pp. 437\u0015442.\n[199] M. Zhang and A. A. Sawchuk, ``USC-had: A daily activity dataset for\nubiquitous activity recognition using wearable sensors,'' in Proc. ACM\nConf. Ubiquitous Comput., 2012, pp. 1036\u00151043.\n[200] P. Zappi, T. Stiefmeier, E. Farella, D. Roggen, L. Benini, and G. Troster,\n``Activity recognition from on-body sensors by classi\u001cer fusion: Sensor\nscalability and robustness,'' in Proc. 3rd Int. Conf. Intell. Sensors, Sensor\nNetw. Inf., 2007, pp. 281\u0015286.\n[201] A. Reiss and D. Stricker, ``Introducing a new benchmarked dataset\nfor activity monitoring,'' in Proc. 16th Int. Symp. Wearable Comput.,\nJun. 2012, pp. 108\u0015109.\n[202] M. Bachlin, M. Plotnik, D. Roggen, I. Maidan, J. M. Hausdorff, N. Giladi,\nand G. Troster, ``Wearable assistant for parkinson's disease patients with\nthe freezing of gait symptom,'' IEEE Trans. Inf. Technol. Biomed., vol. 14,\nno. 2, pp. 436\u0015446, Mar. 2010.\n[203] O. Banos, R. Garcia, J. A. Holgado-Terriza, M. Damas, H. Pomares,\nI. Rojas, A. Saez, and C. Villalonga, ``mHealthDroid: A novel framework\nfor agile development of mobile health applications,'' in Ambient Assisted\nLiving and Daily Activities, L. Pecchia, L. L. Chen, C. Nugent, and\nJ. Bravo, Eds. Cham, Switzerland: Springer, 2014, pp. 91\u001598.\n[204] K. Altun, B. Barshan, and O. Tun\u00e7el, ``Comparative study on classifying\nhuman activities with miniature inertial and magnetic sensors,'' Pattern\nRecognit., vol. 43, no. 10, pp. 3605\u00153620, Oct. 2010.\n[205] O. Ba\u00f1os, M. Damas, H. Pomares, I. Rojas, M. A. T\u00f3th, and O. Amft,\n``A benchmark dataset to evaluate sensor displacement in activity recog-\nnition,'' in Proc. ACM Conf. Ubiquitous Comput., 2012, pp. 1026\u00151035.\n[206] Active Miles. Accessed: Nov. 16, 2019. [Online]. Available:\nhttp://hamlyn.doc.ic.ac.uk/activemiles/activemiles.html\n[207] A. Yang, A. Giani, R. Giannatonio, and K. Gilani, ``Distributed human\naction recognition via wearable motion sensor networks,'' J. Ambient\nIntell. Smart Environ., vol. 1, no. 2, pp. 103\u0015115, 2009.\n[208] C. Pham, ``MobiRAR: Real-time human activity recognition using\nmobile devices,'' in Proc. 7th Int. Conf. Knowl. Syst. Eng. (KSE),\nOct. 2015, pp. 144\u0015149.\n[209] S. A. Elkader, M. Barlow, and E. Lakshika, ``Wearable sensors for recog-\nnizing individuals undertaking daily activities,'' in Proc. ACM Int. Symp.\nWearable Comput., 2018, pp. 64\u001567.\n[210] F. B. A. Ramos, A. Lorayne, A. A. M. Costa, R. R. de Sousa,\nH. O. Almeida, and A. Perkusich, ``Combining smartphone and smart-\nwatch sensor data in activity recognition approaches: An experimental\nevaluation,'' in Proc. SEKE, 2016, pp. 267\u0015272.\n[211] A. Mannini and S. S. Intille, ``Classi\u001cer personalization for activity recog-\nnition using wrist accelerometers,'' IEEE J. Biomed. Health Informat.,\nvol. 23, no. 4, pp. 1585\u00151594, Jul. 2019.\n[212] A. Davoudi, A. A. Wanigatunga, M. Kheirkhahan, D. B. Corbett,\nT. Mendoza, M. Battula, S. Ranka, R. B. Fillingim, T. M. Manini, and\nP. Rashidi, ``Accuracy of samsung gear s smartwatch for activity recogni-\ntion: Validation study,'' JMIR mHealth uHealth, vol. 7, no. 2, Feb. 2019,\nArt. no. e11270.\n[213] A. Murad and J.-Y. Pyun, ``Deep recurrent neural networks for human\nactivity recognition,'' Sensors, vol. 17, no. 11, p. 2556, Nov. 2017.\n[214] G. Santos, P. Endo, K. Monteiro, E. Rocha, I. Silva, and T. Lynn,\n``Accelerometer-based human fall detection using convolutional neural\nnetworks,'' Sensors, vol. 19, no. 7, p. 1644, Apr. 2019.\n[215] R. Zhu, Z. Xiao, M. Cheng, L. Zhou, B. Yan, S. Lin, and H. Wen, ``Deep\nensemble learning for human activity recognition using smartphone,'' in\nProc. IEEE 23rd Int. Conf. Digit. Signal Process. (DSP), Nov. 2018,\npp. 1\u00155.\n[216] S. W. Pienaar and R. Malekian, ``Human activity recognition using\nLSTM-RNN deep neural network architecture,'' in Proc. IEEE 2nd Wire-\nless Afr. Conf. (WAC), Aug. 2019, pp. 1\u00155.\n[217] X. Wang, W. Liao, Y. Guo, L. Yu, Q. Wang, M. Pan, and P. Li,\n``PerRNN: Personalized recurrent neural networks for acceleration-based\nhuman activity recognition,'' in Proc. IEEE Int. Conf. Commun. (ICC),\nMay 2019, pp. 1\u00156.\n[218] O. Steven Eyobu and D. Han, ``Feature representation and data augmenta-\ntion for human activity classi\u001ccation based on wearable IMU sensor data\nusing a deep LSTM neural network,'' Sensors, vol. 18, no. 9, p. 2892,\nAug. 2018.\n[219] M. Janidarmian, A. R. Fekr, K. Radecka, and Z. Zilic, ``A comprehensive\nanalysis on wearable acceleration sensors in human activity recognition,''\nSensors, vol. 17, no. 3, p. 529, Mar. 2017.\nFLORENC DEMROZI (Member, IEEE) received\nthe B.S. and M.E. degrees in computer science and\nengineering and the Ph.D. degree in computer sci-\nence from the University of Verona, Italy, in 2014,\n2016, and 2020, respectively. He is currently a\nPostdoctoral Researcher and a Temporary Profes-\nsor with the Department of Computer Science,\nUniversity of Verona, where he is also a member\nof the Electronic Systems Design (ESD) Research\nGroup, working on ambient intelligence (AmI),\nambient assisted living (AAL), and the Internet of Things (IoT).\nGRAZIANO PRAVADELLI (Senior Member,\nIEEE) received the Ph.D. degree in computer sci-\nence. He has been a Full Professor of information\nprocessing systems with the Department of Com-\nputer Science, University of Verona, Italy, since\n2018. In 2007, he cofounded EDALab s. r. l.,\nan SME working on the design of the IoT-based\nmonitoring systems. His main research interests\ninclude system-level modeling, simulation and\nsemi-formal veri\u001ccation of embedded systems,\nas well as on their application to develop the IoT-based virtual coaching\nplatforms for people with special needs. In the previous contexts, he col-\nlaborated in several national and European projects. He has published more\nthan 120 papers in international conferences and journals. He is a member\nof IFIP 10.5 WG.\nAZRA BIHORAC received the M.D. degree from\nthe University of Sarajevo, Bosnia and Herzegov-\nina, the master's degree in clinical science from\nthe University of Florida, the Internal Medicine\nResidency degree from Marmara University, Istan-\nbul, Turkey, and the University of Florida, and the\nfellowships in critical care medicine and nephrol-\nogy from the University of Florida. She is cur-\nrently the R. Glenn Davis Professor of medicine,\nsurgery, anesthesiology and physiology, and func-\ntional genomics at the University of Florida. She leads the Precision and\nIntelligence in Medicine Partnership (PrismaP), a multidisciplinary research\ngroup of experts in data science and informatics, focused on the devel-\nopment and implementation of intelligent systems and technologies to\naugment clinical decisions and optimize health care delivery in surgery,\ncritical care medicine, and nephrology. The team is developing machine\nlearning and informatics tool for real-time risk strati\u001ccation and annotation\nof hospital-acquired complications and kidney disease as well as for the\napplication of omics technologies on urine for predictive enrichment of\npatients with critical illness. Her vision is to develop tools for intelligent\nhuman-centered health care that delivers optimized care tailored to a patient's\n``personal clinical pro\u001cle'' using digital data. Through her work in national\nand international professional organizations in nephrology and critical care\nmedicine, she has advocated for women physicians and scientists, promot-\ning their equality and recognition in health care leadership, research, and\neducation.\nPARISA RASHIDI (Senior Member, IEEE)\nreceived the Ph.D. degree in computer science\nin 2011 with an emphasis on machine learning.\nShe is currently an Associate Professor with the\nJ. Crayton Pruitt Family Department of Biomed-\nical Engineering (BME), University of Florida\n(UF). She is also af\u001cliated with the Department\nof Electrical and Computer Engineering (ECE)\nand the Department of Computer and Information\nScience and Engineering (CISE). She is also the\nDirector of the Intelligent Health Laboratory (i-Heal). Her research interest\nincludes is to bridge the gap between machine learning and patient care. She\nhas served on the technical program committee for several conferences. She\nhas been a Reviewer of numerous IEEE journals.\n", "arxiv22": "Editedby:\nAnupDas,\nDrexelUniversity,UnitedStates\nReviewedby:\nArashAhmadi,\nCarletonUniversity,Canada\nKazukiNakada,\nHiroshimaCityUniversity,Japan\nDebanjanBhowmik,\nIndianInstituteofTechnologyDelhi,\nIndia\n*Correspondence:\nAbhronilSengupta\nsengupta@psu.edu\nSpecialtysection:\nThisarticlewassubmittedto\nNeuromorphicEngineering,\nasectionofthejournal\nFrontiersinNeuroscience\nReceived: 23April2021\nAccepted: 25August2021\nPublished: 12October2021\nCitation:\nGargU,YangKandSenguptaA\n(2021)EmulationofAstrocyteInduced\nNeuralPhaseSynchronyinSpin-Orbit\nTorqueOscillatorNeurons.\nFront.Neurosci.15:699632.\ndoi:10.3389/fnins.2021.699632Emulation of Astrocyte Induced\nNeural Phase Synchrony in\nSpin-Orbit Torque Oscillator Neurons\nUmangGarg1,2,KezhouYang1andAbhronilSengupta1*\n1SchoolofElectricalEngineeringandComputerScience,Dep artmentofMaterialsScienceandEngineering,The\nPennsylvaniaStateUniversity,UniversityPark,PA,Unite dStates,2DepartmentofElectronicsandInstrumentation\nEngineering,BirlaInstituteofTechnologyandScience,Pil ani,India\nAstrocytes play a central role in inducing concerted phase s ynchronized neural-wave\npatterns inside the brain. In this article, we demonstrate t hat injected radio-frequency\nsignal in underlying heavy metal layer of spin-orbit torque oscillator neurons mimic the\nneuron phase synchronization effect realized by glial cell s. Potential application of such\nphase coupling effects is illustrated in the context of a tem poral \u201cbinding problem.\u201d\nWe also present the design of a coupled neuron-synapse-astr ocyte network enabled\nby compact neuromimetic devices by combining the concepts o f local spike-timing\ndependent plasticity and astrocyte induced neural phase sy nchrony.\nKeywords: neuromorphic computing, magnetic tunnel junction, astrocytes, Spintronics, spiking neural networks\n1. INTRODUCTION\nNeuromorphic engineering is emerging to be a disruptive comput ing paradigm in recent times\ndriven by the unparalleled e\ufb03ciency of the brain at solving co gnitive tasks. Brain-inspired\ncomputing attempts to emulate various aspects of the brain\u2019s pro cessing capability ranging\nfrom synaptic plasticity mechanisms, neural spiking behavior toin-situmemory storage in the\nunderlyinghardwaresubstrateandarchitecture.Theworkpr esentedinthisarticleisguidedbythe\nobservationthatcurrentneuromorphiccomputingarchitectu reshavemainlyfocusedonemulation\nof bio-plausible computational models for neuron and synapse\u2014bu t have not focused on other\ncomputationalunitsofthebiologicalbrainthatmightcontri butetocognition.\nOver the past few years, there has been increasing evidence th at glial cells, and in particular,\nastrocytesplayanimportantroleinmultitudeofbrainfuncti ons(Allametal.,2012 ).Itisestimated\nthat glia form \u223c50% of the human brain cells ( M\u00f6ller et al., 2007 ) and participate by modulating\nthe neuronal \ufb01ring behavior, though unable to discharge ele ctrical impulses of their own. Indeed,\nthese glial-cells work in coordination with neural assembli es, to enable information processing\nin the human brain and performing incisive operations. Astroc ytes hold the recipe to potentiate\nor suppress neurotransmitter activity within networks and ar e responsible for phenomenon\nlike synchronous network \ufb01ring ( Fell and Axmacher, 2011; Wade et al., 2011 ) and self-repair\nmechanisms ( Wade et al., 2012; Rastogi et al., 2020 ). It is therefore increasingly important to\ncapturethedynamicsofsuchensembles,asteptowardrealizi ngmoresophisticatedneuromimetic\nmachinesandultimatelyenablingcognitiveelectronics.\nRecently, there has been extensive literature reporting astro cyte computational models and\ntheir impact on synaptic learning ( De Pitt\u00e0 et al., 2012; Manninen et al., 2018 ). Continuing these\nfundamentalinvestigationstodecodeneuro-gliainteract ion,therehavebeenrecentneuromorphic\nimplementations of astrocyte functionality in analog and dig ital Complementary Metal Oxide\nSemiconductor (CMOS) hardware ( M\u00f6ller et al., 2007; Irizarry-\nValle and Parker, 2015; Naeem et al., 2015; Ranjbar and Amiri ,\n2017; Karimi et al., 2018; Faramarzi et al., 2019 ). For instance,\nanalog CMOS circuits capturing the neural-glial transmitter\nbehavior have been demonstrated ( Joshi et al., 2011; Irizarry-\nValle et al., 2013; Irizarry-Valle and Parker, 2015; Lee and\nParker,2016 ).Thereisalsoincreasinginterestinlow-complexity\nFPGA implementation of the astrocyte computation models\n(Nazari et al., 2015; Ranjbar and Amiri, 2016, 2017; Karimi\net al., 2018; Faramarzi et al., 2019 ). However, the primary focus\nhas been on a brain-emulation perspective, i.e., implementing\nastrocytecomputationalmodelswithhighdegreeofdetailin the\nunderlyinghardware.\nOn the other hand, recent advances in emerging post-CMOS\ntechnologies like phase change materials, resistive memori es,\nferromagentic,andferroelectricmaterials( Joetal.,2010;Kuzum\net al., 2011; Ramakrishnan et al., 2011; Jackson et al., 2013 ;\nSengupta and Roy, 2017; Saha et al., 2021 ), among others\nhave resulted in the development of electronic device struct ures\nthat can reproduce various biomimetic characteristics at lo w\noperating voltages through their intrinsic physics. However ,\nwhile there has been extensive work on exploring post-CMOS\ntechnologies for mimicking bio-realistic computations due to\nthe prospects of low-power and compact hardware design,\nthey have been only studied from standalone neuron/synapse\nperspective. Emulation of the neuron-astrocyte crosstalk us ing\nbio-mimetic devices has largely been neglected, and no such\nliteratureexistshitherto,tothebestofourknowledge.Th iswork\nisthereforeane\ufb00orttobridgethisgapand,speci\ufb01cally,eluc idates\nthe emulation of transient synchronous activity resulting from\nneural-glial interactions by utilizing spin-orbit torque i nduced\nphase synchronization of spintronic oscillator neurons. It is\nworthmentioningherethatweabstracttheneuronfunctiona lity\nas a non-linear oscillator, in agreement with prior neurosci ence\nandcomputationalmodels( JaegerandHaas,2004 ).Emulationof\nastrocyte induced neural phase synchrony through the intrin sic\nphysics of spintronic devices will be critical to enable the\nnext generation of resource constrained cognitive intelli gence\nplatforms like robotic locomotion ( Polykretis et al., 2020 ). This\nwork also presents an important addition to the wide variety\nof next-generation computational paradigms like associativ e\ncomputing, vowel-recognition, physical reservoir computing\namong others ( Fan et al., 2015; Torrejon et al., 2017; Romera\net al., 2018, 2020; Riou et al., 2019; Tsunegi et al., 2019 ), being\nimplementedusingspin-torqueoscillatordevices.\n2. NEUROSCIENCE BACKGROUND\nThe human brain houses multiple-independent local neuronal\ngroups which perform dedicated computations in relevance to\ntheir assigned tasks. Besides this general uncorrelated ac tivity\nof neurons, multiple neural spiking data recordings reveal th at\nthe independent signals from these neural assemblies freque ntly\ncoalesce in time to generate a synchronous output ( Fries, 2005;\nFell and Axmacher, 2011 ). Multiple reports on the cause of such\npatternsnowprovidecompellingevidencethatastrocytesaret heagentsofthisphenomenon( Fellinetal.,2004;Wadeetal.,2011 ).\nAstrocytes modulate the concentration of neurotransmitter s\nlike glutamate inside the synaptic clefts in response to its\ninternal Calcium ( Ca2+) oscillations ( Newman, 2003; Garbo\net al., 2007 ). A single astrocyte spans tens of thousands of\nsynapses, where units called microdomains (concentrated Ca2+\nstores within the astrocyte) monitor the activity for a grou p\nof neurons and perform subsequent chemical actions ( Volterra\nand Meldolesi, 2005; Haydon and Carmignoto, 2006 ). The\nastrocyte-derived glutamate binds to extrasynaptic NMDAR\n(N-methyl-D-aspartate) receptor channels, and induce Slow-\ninward Currents (SIC) in the post-synaptic membrane. SICs\nare attributed to triggering a simultaneous response in di\ufb00er ent\nsynapses with high timing precision, and its large amplitude\nand slow-decay rate provide an increased timescale for the\ncorrelated activity ( Fellin et al., 2004; Wade et al., 2011 ). The\nastrocyticunitsin\ufb02uencingsynapses,canactbothindepende ntly\nor in coordination enabling long-distance indirect signali ng\namongindependentneuronalgroups.Furthermore,anincreased\nintensity of synaptic activity can trigger multiple astrocyte s\nto share their information through their gap-junctions and\nelicit coherent behaviors among di\ufb00erent uncorrelated neur onal\nnetworks. We in this paper do not discriminate among the two\nsignalingprocesses.Thus,thetwoastrocytesshownin Figure1A\nfordi\ufb00erentsub-networkscanalsoimplymicrodomainswithina\nsingleastrocyte.Theseunitscontrolthesynchronizations ignalto\nnetworksAandB. Figure1A capturesthebiologicalperspective\nof such a system which controls the neural synchronization\namong neurons present in these di\ufb00erent sub-networks. Sub-\nnetworks A and B each consist of three di\ufb00erent neurons,\nwhichin-turngenerateoscillatoryoutputs.Thetemporalpro\ufb01l es,\nshown in Figure1B , depict the neuron outputs before and\nafter synchronization is initiated by Astrocyte 1 in the net work\nA. Interested readers are referred to Wade et al. (2011) for\ndetails on the astrocyte computational models. It is worth\nmentioning here that unlike CMOS implementations that are\nable to implement computational models with a high degree\nof detail, emerging device based implementations usually focu s\non mimicking key aspects of the neurosynaptic functionality\nnecessary from computing perspective since the exact behavior\nis governed by the intrinsic device physics. In this work, we\nprimarily consider emulating the neural phase synchrony e\ufb00ect\nof astrocytes and evaluate it in the context of a temporal\ninformationbindingapplication.\n3. ASTROCYTIC SYNCHRONIZATION\nEMULATION\n3.1. Device Basics\nIn this work, we utilize Magnetic Tunnel Junctions (MTJs)\n(Julliere, 1975 ) as the core hardware primitive to mimic neural\noscillations. The MTJ consists of two ferromagnetic layers\n(pinnedlayerandfreelayer)withaspaceroxidelayerinbetwe en.\nThe direction of magnetization of the pinned layer (PL) is\n\ufb01xed, while that of the free layer (FL) can be manipulated\nby external stimuli (spin current/magnetic \ufb01eld). The MTJFIGURE 1 | (A) Top-level network depicting the synchronization control b y astrocytic injection. Astrocytes share information amon g their glial network. (B)The curves\nshow the synchronized and unsynchronized outputs of Neuron s 1\u20133 in Network A depending on the astrocyte input.\nstack exhibits a varying resistance depending on the relativ e\nmagnetic orientations of the PL and the FL. The extreme\nresistive states are referred to as the parallel (P) and anti- parallel\n(AP) states depending on the relative FL magnetization. The\nmagnetization dynamics of the FL can be modeled by Landau-\nLifshitz-Gilbert-Slonczewski (LLGS) equation with stoch astic\nthermalnoise( SenguptaandRoy,2017 ):\nd\u02c6m\ndt= \u2212\u03b3(\u02c6m\u00d7He\ufb00)+\u03b1(\u02c6m\u00d7d\u02c6m\ndt)+1\nqNs(\u02c6m\u00d7Is\u00d7 \u02c6m) (1)\nIn Equation (1), \u02c6mis the unit vector representing the\nmagnetizationdirectionofFL, He\ufb00isthee\ufb00ectivemagnetic\ufb01eld\nincluding thermal noise ( Scholz et al., 2001 ), demagnetization\n\ufb01eld and external magnetic \ufb01eld, \u03b3is the gyromagnetic ratio,\n\u03b1is Gilbert\u2019s damping ratio, Isis the spin current, qis the\nelectronic charge, and Ns=MsV\n\u00b5Bis the number of spins in\nfree layer of volume V(Msis saturation magnetization and\n\u00b5Bis Bohr magneton). If the magnitude of spin current and\nexternal magnetic \ufb01eld are chosen appropriately such that the\ndamping due to the e\ufb00ective magnetic \ufb01eld is compensated, a\nsteady procession of the FL magnetization can be obtained. It is\nworthmentioningherethattheintrinsicmagnetizationdyn amics\nin Equation (1) is used to model the oscillator dynamics. Oth er\nFIGURE 2 | Spin-orbit torque device undergoes oscillation due to appl ied\nexternal magnetic \ufb01eld, H, and charge current, Ic. Note that the directions of\nboth the magnetic \ufb01eld and magnetic anisotropy are in-plane.\nvariantsofoscillatorybehaviorcanbeachievedbymodi\ufb01eds pin\ndevicestructures( Matsumotoetal.,2019 ).\nIn order to achieve decoupled output oscillator readout\nand astrocyte injection induced phase coupling, we utilize\na three terminal device structure, as shown in Figure2, in\nwhich a nanomagnet with in-plane magnetic anisotropy lies\non top of a heavy metal (HM) layer with high spin-orbit\nTABLE 1 | MTJ device simulation parameters.\nParameters Value\nFerromagnet area, AFM 40\u00d7100 nm\nHM thickness, tHM 3 nm\nEnergy barrier, Eb 62.76 kT\nSaturation magnetization, Ms107\n4\u03c0A/m\nSpin-hall angle, \u03b8SH 0.3\nSpin-\ufb02ip length, \u03bbsf 1.4 nm\nGilbert damping factor, \u03b1 0.03\nExternal magnetic \ufb01eld, H 750 Oe\nTMR ratio, TMR 200%\nTemperature, T 300 K\ncoupling. Due to spin-Hall e\ufb00ect ( Hirsch, 1999 ), a transverse\nspin current is injected into the MTJ FL by charge current,\nIc, \ufb02owing through the HM between terminals T2 and T3.\nThe relation between spin current Isand charge current Ic\nis,\nIs=\u03b8SHAFM\nAHM/parenleftBigg\n1\u2212sech/parenleftBigg\ntHM\n\u03bbsf/parenrightBigg/parenrightBigg\nIc (2)\nwhere,AFMandAHMare the FM and HM cross-sectional\nareas respectively, \u03b8SHis the spin-Hall angle ( Hirsch, 1999 ),\ntHMis the HM thickness and \u03bbsfis the spin-\ufb02ip length.\nNote that an in-plane magnetic \ufb01eld, H, is also applied to\nachieve sustained oscillation. The MTJ state is read using th e\ncurrent sensed through terminal T1. The device simulation\nparameters are tabulated in Table1and are based on typical\nexperimental measurements reported in literature ( Fan et al.,\n2015). However, the conclusions presented in this study are\nnot speci\ufb01c to these parameters. Experimental demonstration\nof injection locked spin-torque oscillators have been achie ved\n(Rippard et al., 2005, 2013; Georges et al., 2008; Demidov\net al., 2014 ). It is worth mentioning here that we assume\nall the devices are magnetically isolated and su\ufb03ciently\nspaced such that dipolar coupling is negligible ( Yogendra\net al., 2017 ). We also consider that the generated charge\ncurrent in the HM layer due to FL magnetic precession\nvia the Inverse spin-Hall e\ufb00ect (ISHE) is not dominant\nenough to impact the phase coupling phenomena. While\nrecent studies have shown that the ISHE modulated current\nalone, without any ampli\ufb01cation, is not su\ufb03cient to impact\nphase locking ( Elyasi et al., 2015 ), such e\ufb00ects can be also\novercome by limiting the number of oscillators sharing a\ncommonHMsubstrate.\n3.2. Phase Synchronization of MTJ\nOscillator Neurons\nThe electrical analog of Figure1A is shown in Figure3,\nwhere the MTJs represent the oscillatory neurons present in\na particular network. The neurons share a HM layer which\nacts as the common substrate for the driving astrocyte signa l.The current \ufb02owing through the HM has two components\u2014\na DC current input which determines the free-running\nfrequency of the oscillator and a radio-frequency signal\nwhich represents the astrocyte input. Figure4A highlights the\noscillation characteristics of the MTJ. The DC current control s\nthe precession frequency in absence of other inputs. This DC\ninput is analogous to the external stimulus determining the\nfrequency of neuron oscillation in a particular network. In th e\nabsence of the RF signal, all the neurons oscillate at the same\nfrequency (dependent on stimulus magnitude or DC current)\nbut out-of-phase due to thermal noise. Upon the application\nof the external RF astrocyte signal, the device oscillation l ocks\nin phase and frequency to this input. Higher peak-to-peak\namplitude of the astrocyte locking signal increases the locki ng\nrange of the device. It is worth mentioning here that the lock ing\nfrequencyofneuronsinaparticularnetworkisdependentonth e\nstimulusandastrocytesonlyinducephaselocking.Therefor e,the\nalternating astrocyte signal \ufb02owing through the HM layer ca n\nbe generated from a separate astrocyte device that is driven b y\nthe corresponding DC input of the network, thereby ensuring\nindependent phase and frequency control. The astrocyte devic e\nis interfaced with a Reference MTJ and a voltage-to-current\nconverter to drive the alternating current signal through t he\ncommon HM layer. The Reference MTJ state is \ufb01xed to the AP\nstate (by ensuring that the read supply voltage, VDD=0.65V\nis not high enough to write the MTJ state) and forms a resistive\ndivider with the oscillating Astrocyte MTJ resistance. Theref ore,\nthe gate voltage of the interfaced PMOS transistor, VG=\nRA\nRA+RREFVDDwhereRAistheAstrocyteMTJresistanceand RREF\nistheReferenceMTJresistance,alsovariesaccordingly,whic hin\nturn, modulates the current \ufb02owing through the common HM\nlayerproportionally.\nIn order to evaluate the degree of phase synchronization in\npresence of thermal noise, we consider two MTJ devices lying\non top of a common HM layer at room temperature. Cross-\ncorrelationmetricisevaluatedforthetwoMTJoutputsignals to\nmeasurethesimilarityamongthemasafunctionofdisplacemen t\nof one relative to the other. Considering two time-domain\nfunctions x(t) andy(t), whose power spectrum density (PSD) is\ngivenbySxx(\u03c9)andSyy(\u03c9),respectively,theircross-correlationis\nde\ufb01nedby:\nRxy(\u03c4)=(x\u22c6y)(\u03c4)=/integraldisplay\u221e\n\u2212\u221ex(t\u2212\u03c4)y(t)dt (3)\nwhere,x(t) represents the complex conjugate of x(t) and \u03c4\ndenotes the lag parameter. Further, cross-power spectral densi ty\n(CPSD) is de\ufb01ned as the Fourier transformation of cross-\nspectrumin(3)andisgivenby:\nSxy(\u03c9)=/integraldisplay\u221e\n\u2212\u221eRxy(t)e\u2212j\u03c9tdt (4)\nSxycomprises of both magnitude and phase ( /negationslash) information\nat di\ufb00erent frequencies present in/bracketleftbig\u03c9/bracketrightbig\nvector. When\ntwo signals are phase synchronized, the cross-spectrum\nphase vector becomes zero, indicating high correlation.FIGURE 3 | Electrical emulation of astrocyte induced neural synchron y is shown where an astrocyte device drives an alternating cu rrent through a common HM\nsubstrate to phase-lock the MTJ oscillator neurons.\nFIGURE 4 | (A) Oscillator frequency plotted against the DC current input t o the device. Higher AC amplitudes lead to increased DC locki ng range at the injected RF\nsignal of 6.5 GHz frequency. (B)Cross-spectrum phase for 100 independent stochastic LLGS s imulations of two noisy MTJ neurons, under RF injection of 5 GHz.\nAverage CPSD phase indicates tight phase-coupling at the re quired frequency with un-correlated activity at other freq uencies. (C)Average cross-spectrum phase at\nthe injection frequency accounting for device dimension va riations.\nSuch a property is highlighted in Figure4B where 100\nindependent stochastic-LLGS simulations are performed for\ntwo neuronal devices placed on a common HM layer with\na 5 GHz injected RF current. Cross-spectrum phase at the\ninjection frequency, i.e., 5 GHz converges close to zero. Av erage\ncross-spectrum phase is also shown in the plot depicting\ntight phase-coupling between the neurons at the injection\nfrequency. Notably, a sharp reduction of average phase o\ufb00set\nto just 7.22\u25e6at 5 GHz is observed compared to 90\u25e6for\nother frequencies, thereby establishing the robustness of the\nsynchronization scheme. Additionally, the impact of non-\nidealitieslike device dimension variationsonthe phasecou pling\nphenomena is evaluated in Figure4C . The results are reported\nfor 50 independent Monte-Carlo simulations with variation in\nboth the length and width of the MTJ. Each Monte-Carlo\nsimulation consisted of 50 stochastic LLGS simulation for t he\naverage cross-spectrum phase calculation. The phase correlat ion\nbetween the device oscillations remains reasonably high ev en\nwith 7.5% variation in both length and width dimensions of th e\nMTJ. Related discussions on oscillator dynamics with respect to\nperturbative current and correspondence of the results with t he\nKuramotomodelforoscillatorsynchronizationisprovidedi nthe\nSupplementaryMaterial .4. BINDING PROBLEM\n4.1. Problem Formulation\nNext, we discuss a renowned problem which is envisioned\nto be solved by neural synchronous activity. Amongst the\nmost intriguing themes of neuro-psychological studies is the\n\u201cbinding problem\u201d (BP) ( Feldman, 2013; Fields et al., 2014 ). It\nconcernswithhowdi\ufb00erentattributesofsensoryinformation are\nencoded, processed, and perceived for decision-making by the\nhuman brain circuits. With a now widely accepted viewpoint of\ndistributive computing and segregated processing for di\ufb00eren t\nfeatures (especially visual) and later integration into a un i\ufb01ed\npercept via re-entrant connections ( Milner, 1974; Bartels and\nZeki, 2006 ), we have progressed further toward understanding\ncognition.Primatebrainshaveevolvedtocontinuouslyassi milate\nthe voluminous perceptive information available in their soc ial\nsetting and \ufb01nd a best \ufb01t for the primate\u2019s goals in the quickes t\nmanner.Thistrainingandgrowth,althoughverycrucialinm ost\nsituations\u2014sometimes also leads to \u201cmisbinding\u201d ( Whitney,\n2009).Inparticular,opticalillusions,suchasshownin Figure5A ,\nexploit the feature patterns ingrained in the human visual\npercept, causing misbinding. The \ufb01gure is a bistable portrait\nof an elephant, or an overlap of two (seemingly) possibleFIGURE 5 | (A) The optical illusion induces confusion in the viewer concer ning association among different apparent limbs with the bo dy and the background\n(CourtesyofRogerShepard\u2019s\u201cL\u2019egsistentialparadox\" ) (Shepard, 1990 ).(B)MTJ system architecture depicting hierarchical organizat ion of neurons. The illustrated\nbinding problem is mapped to this hardware with one possible interpretation shown. The connection between different ne uron layers is implemented by the\nmemristive cross-bar array with initially untuned synapti c weights. Unsupervised STDP learning rule causes the weigh ts to evolve, making the network to \ufb01nally elicit\nsynchronous responses post-training.\ninterpretations, obtained by associating di\ufb00erent body parts to\nother features of the image. For instance, the labels 1 and 2\ncan be viewed associated with the body (A), while 3 and 4 to\nthe background (B) to paint one such possible interpretation.\nThe other interpretation can be visualized if the roles A and B\nare reversed. For an in-depth discussion, interested reader s are\ndirected to Hasz and Miller (2013) andIgnatov et al. (2017).\nIn this work, we do not address the clustering mechanism of\nlabels 1\u20132 and 3\u20134. This labeling and identi\ufb01cation can be\npotentiallyattributedtotheagent\u2019svisualattention.Inpa rticular,\nattention captures the most relevant information present in a\nspace-time lapse by masking (\ufb01ltering) o\ufb00 the distractor area s,\nwhileperformingfeaturelabelingofthecroppedscene( Kosiorek\netal.,2017 ).Assumingthatattentionperformstheroleofspatio-\ntemporalintegrationamongsuchmultipleattributescaptured by\na visualscene, synchronous activityintheneurons is consi dered\nas the underlying mechanism in brain to create a coherent\nepisode of perception, and perhaps cognition. Indeed, it is now\nbecoming more evident that cognitive processes like attenti on\nand behavioral e\ufb03ciency elicit targeted synchronous activ ity in\ndi\ufb00erent brain regions tuned to responding toward di\ufb00erent\nspatial and featural attributes of the attended sensory input\n(Ward,2003;WomelsdorfandFries,2007 ).\n4.2. Hardware Mapping\nIn order to correlate our spin-orbit torque oscillator phase\nsynchronization due to astrocyte injection locking in the\ncontext of \u201ctemporal binding,\u201d we consider a network as shown\ninFigure5B . Adhering to the currently prominent view of\nhierarchical organization in the neural assemblies, spin-t orque\nneuronsN1,N2,N3,N4here are dedicated to processing simple\nattributes, while NaandNbafter receiving inputs from previous\nlayers perform complex feature processing corresponding to theassigned task. In reference to potential processing application s\nlike cognitive feature binding, each spin-orbit torque neur on\nin the network represents the corresponding feature in the\nelephant\u2019s bistable image, previously shown in Figure5A . All\nneuronal devices are mounted atop a HM with Idc=420\u00b5A\nDC drive ( ffree=7.05 GHz). The network utilizes two\ndi\ufb00erent injection signals with the same frequency of 7.05\nGHz with 180ophase di\ufb00erence (corresponding to the two\ndi\ufb00erent interpretations/con\ufb01gurations of the bistable ima ge).\nHere, we use two RF voltage sources, namely Vac1andVac2\nwith amplitude of 250 mV. The connection between the two\nneuron layers is achieved by means of a resistive synaptic cros s-\nbararray.Wecombinetheconceptsofbio-inspiredunsupervised\nSpike-Timing Dependent Plasticity (STDP) ( Bi and Poo, 1998 )\nand astrocyte induced neural phase synchrony to automatical ly\nenable the network to learn to elicit such behavioral pattern s,\non the \ufb02y. The developed system sets o\ufb00 from an unlearnt state\nwhere all neurons have an independent response and remain\nunsynchronizedinphase.However,uponsystemactivation(an d\nconsequently astrocyte RF injection), the architecture eve ntually\nlearns to bind the di\ufb00erent possible con\ufb01gurations for the\nvisual scene through phase correlation to either Vac1orVac2.\nIt is to be noted that neurons N1,N2,N3,N4comprise of\npre-neurons while NaandNbare post neurons, separated\nby the resistive cross-bar array. Ultimately, a tight phase an d\nfrequency locking is observed among a particular pair of pre-\nneurons ( N1,N2, andN3,N4) and post-neurons ( NaandNb).\nDuetorandomthermal\ufb02uctuations,thedevicescanconverge to\neither of the two possible con\ufb01gurations for the bistable imag e,\nthereby illustrating the concept of optical illusion. The work\ncan potentially pave the way for e\ufb03cient hardware realization of\ncoupledneuron-synapse-astrocytenetworksenabledbycompac t\nneuromimeticdevices.\n4.3. Learning Phase Correlation\nThepremisefortriggeringthesynchronousactivityviaastr ocyte\nis accredited to the sensory attention as discussed before, and\ncan be mapped in our proposed system to the amplitude of RF\ninjectionsignal.Similartobetterbindingobservedwithi ncreased\nattention, larger amplitudes lead to improved neural coupling .\nThestrengthofeachinputcurrentto NaandNbiscontrolledby\nthesynapticconductances G11\u2212G22ofthememristivecross-bar\narray as shown in Figure5B . Implementation of such cross-bar\narrays with in-situSTDP learning has been previously explored\nfor spintronic devices ( Sengupta et al., 2016; Sengupta and Roy,\n2017)andotherpost-CMOStechnologies( Joetal.,2010;Kuzum\net al., 2011; Saha et al., 2021 ). It is worth mentioning here\nthat each cross-connection also features a prior \ufb01ltering \u201cbi as\ntee\u201d to eliminate any possible DC current interactions among\ndi\ufb00erent devices. The DC paths of the bias tee are terminated\nto ground, while the AC signals get passed on to the cross-bar\nfor coupling. Elaborating, the input AC current to the jthpost-\nneuronal device (considering HM resistance to be considera bly\nlower in comparison to the synaptic resistances at each cross-\npoint)canbedescribedbyEquation(5)as:\nIac,Nj(t)=/summationdisplay\niGij.Vi(t) (5)\nWe now elucidate how our proposed architecture captures the\nessence of the optical illusion problem, shown in Figure5, in\nreferenceframeofanobserver.Speci\ufb01cally,thesystemshou ldbe\nable to adapt and converge to one of the possible interpretation\ndiscussedabove.Inparticular,biologicallyinspiredunsupe rvised\nSTDP principles are used to train the programmable synaptic\nconductances ( G11\u2212G22) in the cross-bar architecture for\nthis purpose. The STDP weight (conductance) update equations\nare given by: /Delta1w=\u03b7+wexp(\u2212/Delta1t\n\u03c4+) (for /Delta1t>0) and\n/Delta1w=\u03b7+wexp(/Delta1t\n\u03c4+) (for /Delta1t<0), where \u03b7+and\u03c4+are\nlearninghyperparameters, /Delta1wisthesynapticweightupdateand\n/Delta1tis the timing di\ufb00erence between the spikes corresponding\nto the selected post- and pre-neuron. The positive learning\nwindow ( /Delta1t>0) update occurs whenever a post-neuron\n\ufb01res while the negative learning window ( /Delta1t<0) update\noccurs at a pre-neuron \ufb01ring event. It is worth pointing out\nhere that we use a symmetric STDP learning rule in this\nwork, i.e., the synaptic weight is potentiated for both the\npositive and negative learning windows. This is in contrast t o\nthe more popular asymmetric STDP observed in glutamatergic\nsynapses ( Bi and Poo, 1998 ), typically used in neuromorphic\nalgorithms ( Diehl and Cook, 2015 ). While symmetric STDP\nhas also been observed in GABAergic synapses ( Woodin et al.,\n2003), further neuroscience insights are required to substanti ate\nthe exact underlying mechanisms and cause of this plasticity .\nAsymmetric STDP is useful in application domains requiring\ntemporal ordering of spikes, i.e., a pre-synaptic neuron spike\nwill trigger a post-neuron spike. However, for our scenario, a\ntemporalcorrelationiscrucialirrespectiveofthesequence ,which\nis enabled by the symmetric STDP behavior. Implementation of\nsymmetric STDP in memristive cross-bar arrays can be easily\nachieved by proper waveform engineering of the programmingTABLE 2 | Learning simulation parameters.\nParameters Value\nTime-step for LLG simulation 0.1 ps\nSTDP learning rate, \u03b7+ 0.25\nSTDP time constant, \u03c4+ 5\nInhibition learning rate, \u03b7\u2212 0.15\nInhibition time constant, \u03c4\u2212 5\nMaximum synapse resistance in cross-bar array 25 k/Omega1\nvoltage applied across the synapses ( Serrano-Gotarredona et al.,\n2013; Sengupta et al., 2016 ). The cross-bar resistances are\nconsidered to have an ON/OFF resistance ratio of 10. The\ndi\ufb00erent input spike trains are derived from each device\u2019s\nmagnetoresistance (MR) where a spike is triggered when the\nMR crosses its mean-value of 2 K/Omega1. Because N1(N3) and\nN2(N4) share a common HM, either of them can be used to\nextract the pre-neuron spikes during the weight update period.\nBesides STDP, a lateral inhibition e\ufb00ect ( Diehl and Cook, 2015 )\nis utilized. Whenever a spike occurs for any pre-neuron (post-\nneuron), the corresponding row (column) weights of the array\nare potentiated. However, the remaining rows (columns) are\ndepressed proportionately. The lateral inhibition weight upda te\nequations are given by: /Delta1w= \u2212\u03b7\u2212wexp(\u2212/Delta1t\n\u03c4\u2212) (for /Delta1t>0)\nand/Delta1w= \u2212\u03b7\u2212wexp(/Delta1t\n\u03c4\u2212) (for/Delta1t<0), where \u03b7\u2212and\u03c4\u2212are\nlearninghyperparameters, /Delta1wisthesynapticweightupdateand\n/Delta1tisthetimingdi\ufb00erencecorrespondingtothesymmetricSTDP\nweight update for the row or column which experiences weight\npotentiation. The lateral inhibition scheme is a simple exten sion\nof the synaptic programming voltage waveform engineering\nused in prior work ( Indiveri et al., 2011; Serrano-Gotarredona\net al., 2013; Sengupta et al., 2016 ). During the learning phase,\nthis lateral inhibition e\ufb00ect causes the neuron under study t o\nstartrespondingselectivelytowardaspeci\ufb01ccon\ufb01guration.T his,\nin turn, enables the network to later converge to one of the\ninterpretations for Figure5A , as mentioned previously. The\nnetwork simulation parameters are outlined in Table2. The\ntabulated time-constants are measured with respect to the ti me-\nstepforLLGsimulation.\n4.4. Simulation Results\nThe net currents for devices A and B, evolving through time, i s\nportrayedforoneofthesimulationsin Figures6A,B respectively.\nMeanwhile, the corresponding synaptic resistances for the\nnetworkareplottedin Figure6C toelucidatethelearningprocess\ndiscussed previously. The learning phase for the simulation\nis plotted as a function of timestep of the LLG simulation\nof the MTJ devices (0.1 ps). Observing the temporal pro\ufb01les,\nan interesting deduction can be formulated, con\ufb01rming that\nthe di\ufb00erent post-neurons get dominantly locked to di\ufb00erent\ninjection frequencies. The two sinusoids, being initially o ut of\nphase and adding up in comparable amounts for post-neurons,\nresult in very low net currents. But, as the learning progress es,\nit becomes clear that one of the frequency gets dominant for a\nparticular post-neuron, and thus the envelope tends to \ufb02atten i nFIGURE 6 | (A,B) The temporal evolution pro\ufb01les of the net currents (DC+AC)\n\ufb02owing through the heavy metal for devices A and B are shown. Th e\nincreasing AC amplitudes about the mean DC value can be seen. The relatively\n\ufb02attened envelopes post-learning suggest that the post-neu ron devices are\ndominantly locked to one of the frequencies. (C)Temporal evolution of the\ncross-bar resistances during the learning process is shown .\nthe end. It is worth mentioning here that the synaptic learnin g\nsimulation in this work was performed from an algorithmic\nstandpoint in a technology agnostic fashion. Depending on the\nunderlying synapse technology, prior proposals for peripheral\ndesign for STDP learning needs to be considered ( Serrano-\nGotarredona et al., 2013; Sengupta et al., 2016 ). Since the focus\nof this article is on the MTJ neural synchrony aspect, we did\nnot consider any speci\ufb01c synaptic device programming delay\nconstraint (which is re\ufb02ected in the instantaneous state ch anges\nof the synaptic connection strengths in Figure6C ). In reality,\nfrom a system design perspective, we need to have interleaved\nsynaptic device state update phases that do not interfere withtheneuronoscillationbehavior(forinstance,throughdeco upled\nwrite-read phases of three-terminal synaptic devices; Sengupta\netal.,2016 ).Theconvergencewasalsonota\ufb00ectedwithreduced\nprogramming resolution of the synaptic connections (4-bits),\ntherebyindicatingresiliencytoquantization( Huetal.,2021 ).\nCohesing to one of the percept should surmise of a\nrandom event to provide equal chance for any of the two\npossible con\ufb01gurations to develop. Indeed, it is observed in\nour network that the synchronization occurs for random \ufb01rst\nand second layer neurons, post-training. Such a phenomenon\ncan be accredited to the natural thermal \ufb02uctuations in our\nsystem, which tend to perturb the MTJ device\u2019s periodic nature.\nFigures7A,B , respectively, depict the FFTs and cross-spectrum\nphase for various devices in the network for one such possible\ncon\ufb01guration upon learning termination. Speci\ufb01cally, cross -\nspectrum phases for device-pairs 1 & A (blue curve), 1 & 3\n(yellowcurve),and1&B(greencurve)in Figure7B areplotted\nto highlight that device 1, 2, and A get locked in phase at the\ninjection frequency (7.05 GHz) while being completely out of\nphasewithdevices3,4,andBfortheconsideredcon\ufb01guration.\nFigure8 plots the temporal pro\ufb01le of device\nmagnetoresistance (MR) for N1,N2, andNadevices in the\ntop panel, along with MR of N3,N4, andNbdevices shown in\nthe bottom panel. Initially all neuronal devices, albeit opera ting\nat the same free-running frequency ( ffree=7.05 GHz), elicit\nun-correlated phases, and hence temporal spike response due to\ndevices\u2019 inherent thermal noise. After the astrocyte AC sign al\ninjection and STDP learning commences, it is observed that\nthe devices N1(N3) andN2(N4) achieve a gradual coherent\nphasealongwithdevice Na(Nb),gettinglockedtotherespective\ninjection signal, as can be clearly seen in the right panels. Th e\nsubsequent cross-correlation phase at the 7.05 GHz injection\nfrequency post-synchronization averages to 1.6232\u25e6for the\nthree-possible temporal pro\ufb01le pairs among N1,N2, andNa\n(N1\u22c6N2: 0.88\u25e6,N2\u22c6Na: 2.136\u25e6, andN1\u22c6Na: 1.856\u25e6). Likewise,\nN3,N4, andNbafter learning, achieve an average cross-phase\nof 1.848\u25e6. Bio-physically equivalent, this can be interpreted as a\ntightcorrelationamongtheattributes1, 2,and A,corresponding\nto one of the interpretations of the bistable image. Finally, an\nincreasing phase-mismatch is visible in neuronal outputs of a ll\ndevices if the synchronization is revoked by the astrocyte, and\nthe devices revert to their uncorrelated original free runn ing\nfrequency. This can be attributed to a diverted attention to ward\nthe sensory modal-input features leading to the impairment in\ncorrelatedactivity.\n5. DISCUSSION\nEven though this work proves to be a good preliminary\nframework for emulating such brain-like functions, more\ninvestigation is required for decoding the neural code in su ch\nprocesses along with integrating these insights in Arti\ufb01cia l\nIntelligence (AI) systems. For instance, selectivity bias t oward\nsome features among the myriad available sensory informatio n,\nand, reductionism (down-streaming) of such higher-level m odal\ninputs to local neuronal groups in the hierarchical structure ,FIGURE 7 | (A) FFT plots for all devices for one of the two possible con\ufb01gurat ions are shown post-learning. (B)Cross-spectrum phase for devices-pairs 1\u20133\n(178.53\u25e6), 1-A (3.35\u25e6), and 1-B (178.3\u25e6) are plotted to show the phase-locking nature of the network post-learning at the injection frequency of 7.05 GHz.\nFIGURE 8 | Temporal pro\ufb01le for the devices in the network (shown in Figure 5B ) before(left)and after synchronization (right)are depicted for one particular\ncon\ufb01guration. Astrocyte functionality activates the synch ronous regime causing learning to occur and subsequently co herent neural patterns are achieved for this\ncon\ufb01guration (a stochastic event). Devices N1,N2, andNa(top-right panel) lock to injection signal with \u03c6=0\u25e6, while devices N3,N4, andNbreveal concerted neural\npatterns in conjunction to \u03c6=180\u25e6injection signal (bottom-right panel).\nis poorly understood. There have been some e\ufb00orts to study\nsuch processes using a reverse approach, where robots like\nDarwin VIII, inspired by the re-entrant neuroanatomy and\nsynaptic plasticity, are developed and trained on visual mode\ndata (Seth et al., 2004 ). In agreement with our work, they show\nsynchronousactivitybindsdi\ufb00erentrepresentativefeature softhe\ndetected object. Incorporating such connections in our syst em\ncan be explored to further bridge the gap between real cortica l\nnetworksandtherespectiveinspiredmodels.Supportedbyboth\nneuroscience research and AI hardware developments, coupled\nastrocyte-neuron network architectures can potentially pav e the\nwayforanewgenerationofarti\ufb01cialcognitive-intelligenc e.\nDATA AVAILABILITY STATEMENT\nThe original contributions presented in the study are includ ed\nin the article/ SupplementaryMaterial , further inquiries can be\ndirectedtothecorrespondingauthor/s.AUTHOR CONTRIBUTIONS\nAll authors contributed equally to the writing of the paper,\ndevelopingtheconcepts,andperformingthesimulations.\nFUNDING\nThe work was supported in part by the National Science\nFoundation grant nos. BCS #2031632, ECCS #2028213, and\nCCF#1955815.\nSUPPLEMENTARY MATERIAL\nThe Supplementary Material for this article can be found\nonline at: https://www.frontiersin.org/articles/10.338 9/fnins.\n2021.699632/full#supplementary-material\nREFERENCES\nAllam, S. L., Ghaderi, V. S., Bouteiller, J.-M. C., Legendre, A., Nic olas, A.,\nGreget, R., et al. (2012). A computational model to investigate as trocytic\nglutamate uptake in\ufb02uence on synaptic transmission and neuronal spi king.\nFront.Comput.Neurosci .6:70.doi:10.3389/fncom.2012.00070\nBartels, A., and Zeki, S. (2006). The temporal order of binding visu al attributes.\nVis.Res.46,2280\u20132286.doi:10.1016/j.visres.2005.11.017\nBi, G.-Q., and Poo, M.-M. (1998). Synaptic modi\ufb01cations in cult ured\nhippocampal neurons: dependence on spike timing, synaptic\nstrength, and postsynaptic cell type. J. Neurosci . 18, 10464\u201310472.\ndoi:10.1523/JNEUROSCI.18-24-10464.1998\nDe Pitt\u00e1, M., Volman, V., Berry, H., Parpura, V., Volterra, A., and Ben-\nJacob, E. (2012). Computational quest for understanding the ro le of astrocyte\nsignalinginsynaptictransmissionandplasticity. Front.Comput.Neurosci .6:98.\ndoi:10.3389/fncom.2012.00098\nDemidov, V., Ulrichs, H., Gurevich, S., Demokritov, S., Tiberkevich, V.,\nSlavin, A., et al. (2014). Synchronization of spin hall nano-osci llators to\nexternal microwave signals. Nat. Commun . 5, 1\u20136. doi: 10.1038/ncomms\n4179\nDiehl, P. U., and Cook, M. (2015). Unsupervised learning of digit rec ognition\nusing spike-timing-dependent plasticity. Front. Comput. Neurosci . 9:99.\ndoi:10.3389/fncom.2015.00099\nElyasi, M., Bhatia, C. S., and Yang, H. (2015). Synchronization of spin-transfer\ntorque oscillators by spin pumping, inverse spin hall, and spin hall e\ufb00ect s.J.\nAppl.Phys .117:063907.doi:10.1063/1.4907914\nFan, D., Maji, S., Yogendra, K., Sharad, M., and Roy, K. (2015). Injection-\nlocked spin hall-induced coupled-oscillators for energy e\ufb03cient\nassociative computing. IEEE Trans. Nanotechnol . 14, 1083\u20131093.\ndoi:10.1109/TNANO.2015.2471092\nFaramarzi, F., Azad, F., Amiri, M., and Linares-Barranco, B. (2019).\nA neuromorphic digital circuit for neuronal information encoding\nusing astrocytic calcium oscillations. Front. Neurosci . 13:998.\ndoi:10.3389/fnins.2019.00998\nFeldman, J. (2013). The neural binding problem(s). Cogn. Neurodyn . 7, 1\u201311.\ndoi:10.1007/s11571-012-9219-8\nFell, J., and Axmacher, N. (2011). The role of phase synchronization\nin memory processes. Nat. Rev. Neurosci . 12, 105\u2013118. doi: 10.1038/\nnrn2979\nFellin, T., Pascual, O., Gobbo, S., Pozzan, T., Haydon, P. G., an d Carmignoto,\nG. (2004). Neuronal synchrony mediated by astrocytic glutamate\nthrough activation of extrasynaptic nmda receptors. Neuron43, 729\u2013743.\ndoi:10.1016/j.neuron.2004.08.011\nFields, R. D., Araque, A., Johansen-Berg, H., Lim, S.-S., Lynch, G., Nave, K.-A.,\netal.(2014).Glialbiologyinlearningandcognition. Neuroscientist 20,426\u2013431.\ndoi:10.1177/1073858413504465\nFries, P. (2005). A mechanism for cognitive dynamics: neuronal\ncommunication through neuronal coherence. Trends Cogn. Sci . 9, 474\u2013480.\ndoi:10.1016/j.tics.2005.08.011\nGarbo],A.D.,Barbi,M.,Chillemi,S.,Alloisio,S.,andNobile,M. (2007).Calcium\nsignallinginastrocytesandmodulationofneuralactivity. Biosystems 89,74\u201383.\ndoi:10.1016/j.biosystems.2006.05.013\nGeorges, B., Grollier, J., Darques, M., Cros, V., Deranlot, C., Marc ilhac, B.,\net al. (2008). Coupling e\ufb03ciency for phase locking of a spin transfer\nnano-oscillator to a microwave current. Phys. Rev. Lett . 101:017201.\ndoi:10.1103/PhysRevLett.101.017201\nHasz, B., and Miller, P. (2013). Storing autoassociative memories through gamma-\nfrequencybindingbetweencellassembliesofneuraloscilla tors(Thesis).Brandeis\nUniversity,Waltham,MA,UnitedStates\nHaydon, P. G., and Carmignoto, G. (2006). Astrocyte control of sy naptic\ntransmission and neurovascular coupling. Physiol. Rev . 86, 1009\u20131031.\ndoi:10.1152/physrev.00049.2005\nHirsch, J. (1999). Spin Hall e\ufb00ect. Phys. Rev. Lett . 83:1834.\ndoi:10.1103/PhysRevLett.83.1834\nHu, S., Qiao, G., Chen, T., Yu, Q., Liu, Y., and Rong, L. (2021). Quantized STDP-\nbased online-learning spiking neural network. Neural Comput. Appl . 1\u201316.\ndoi:10.1007/s00521-021-05832-yIgnatov, M., Ziegler, M., Hansen, M., and Kohlstedt, H. (2017). Memristive\nstochasticplasticityenablesmimickingofneuralsynchrony:memrist ivecircuit\nemulatesanopticalillusion. Sci.Adv.3:e1700849.doi:10.1126/sciadv.1700849\nIndiveri, G., Linares-Barranco, B., Hamilton, T. J., Van Schaik, A ., Etienne-\nCummings, R., Delbruck, T., et al. (2011). Neuromorphic silicon neuron\ncircuits.Front.Neurosci .5:73.doi:10.3389/fnins.2011.00073\nIrizarry-Valle, Y., and Parker, A. C. (2015). An astrocyte neuromorphic circuit\nthat in\ufb02uences neuronal phase synchrony. IEEE Trans. Biomed. Circ. Syst . 9,\n175\u2013187.doi:10.1109/TBCAS.2015.2417580\nIrizarry-Valle, Y., Parker, A. C., and Joshi, J. (2013). \u201cA CMOS neu romorphic\napproach to emulate neuro-astrocyte interactions,\u201d in The 2013 International\nJoint Conference on Neural Networks (IJCNN) , Dallas, TX, 1\u20137.\ndoi:10.1109/IJCNN.2013.6707076\nJackson,B.L.,Rajendran,B.,Corrado,G.S.,Breitwisch,M.,Bu rr,G.W.,Cheek,R.,\netal.(2013).Nanoscaleelectronicsynapsesusingphasechangede vices.ACMJ.\nEmerg.Technol.Comput.Syst .9:12.doi:10.1145/2463585.2463588\nJaeger, H., and Haas, H. (2004). Harnessing nonlinearity: predicti ng chaotic\nsystems and saving energy in wireless communication. Science304, 78\u201380.\ndoi:10.1126/science.1091277\nJo, S. H., Chang, T., Ebong, I., Bhadviya, B. B., Mazumder, P., a nd Lu, W. (2010).\nNanoscale memristor device as synapse in neuromorphic systems. Nano Lett .\n10,1297\u20131301.doi:10.1021/nl904092h\nJoshi, J., Parker, A. C., and Tseng, K. (2011). \u201cAn in-silicoglial microdomain to\ninvoke excitability in cortical neural networks,\u201d in 2011 IEEE International\nSymposium of Circuits and Systems (ISCAS) , Rio de Janeiro 681\u2013684.\ndoi:10.1109/ISCAS.2011.5937657\nJulliere, M. (1975). Tunneling between ferromagnetic \ufb01lms. Phys. Lett. A 54,\n225\u2013226.doi:10.1016/0375-9601(75)90174-7\nKarimi, G., Ranjbar, M., Amirian, M., and Shahim-aeen, A. (2018). A\nneuromorphic real-time VLSI design of Ca2+ dynamic in an astrocyte.\nNeurocomputing 272,197\u2013203.doi:10.1016/j.neucom.2017.06.071\nKosiorek, A., Bewley, A., and Posner, I. (2017). \u201cHierarchical a ttentive recurrent\ntracking,\u201d in Advances in Neural Information Processing Systems 30 , eds I.\nGuyon,U.V.Luxburg,S.Bengio,H.Wallach,R.Fergus,S.Vishwan athan,and\nR.Garnett(LongBeach,CA:CurranAssociates,Inc.),3053\u2013306 1.\nKuzum, D., Jeyasingh, R. G., Lee, B., and Wong, H.-S. P. (2011). Nanoelectronic\nprogrammable synapses based on phase change materials for brain-inspired\ncomputing. NanoLett .12,2179\u20132186.doi:10.1021/nl201040y\nLee, R. K., and Parker, A. C. (2016). \u201cA CMOS circuit implementatio n\nof retrograde signaling in astrocyte-neuron networks,\u201d in 2016 IEEE\nBiomedical Circuits and Systems Conference (BioCAS) , Shanghai 588\u2013591.\ndoi:10.1109/BioCAS.2016.7833863\nManninen, T., Havela, R., and Linne, M.-L. (2018). Computation al models\nfor calcium-mediated astrocyte functions. Front. Comput. Neurosci . 12:14.\ndoi:10.3389/fncom.2018.00014\nMatsumoto, R., Lequeux, S., Imamura, H., and Grollier, J. (2019).\nChaos and relaxation oscillations in spin-torque windmill spiking\noscillators. Phys. Rev. Appl . 11:044093. doi: 10.1103/PhysRevApplied.11.04\n4093\nMilner, P. M. (1974). A model for visual shape recognition. Psychol. Rev . 81,\n521\u2013535.doi:10.1037/h0037149\nM\u00f6ller, C., L\u00fccke, J., Zhu, J., Faustmann, P. M., and von der Malsb urg,\nC. (2007). Glial cells for information routing? Cogn. Syst. Res . 8, 28\u201335.\ndoi:10.1016/j.cogsys.2006.07.001\nNaeem, M., McDaid, L. J., Harkin, J., Wade, J. J., and Marsland, J . (2015). On the\nroleofastroglialsyncytiainself-repairingspikingneuralnetworks. IEEETrans.\nNeuralNetw.Learn.Syst .26,2370\u20132380.doi:10.1109/TNNLS.2014.2382334\nNazari,S.,Faez,K.,Amiri,M.,andKarami,E.(2015).Adigitalimple mentationof\nneuron-astrocyte interaction for neuromorphic applications. Neural Netw . 66,\n79\u201390.doi:10.1016/j.neunet.2015.01.005\nNewman, E. A. (2003). New roles for astrocytes: regulation\nof synaptic transmission. Trends Neurosci . 26, 536\u2013542.\ndoi:10.1016/S0166-2236(03)00237-6\nPolykretis, I., Tang, G., and Michmizos, K. P. (2020). \u201cAn astroc yte-modulated\nneuromorphic central pattern generator for hexapod robot locomotion on\nIntel\u2019s loihi,\u201d in International Conference on Neuromorphic Systems 2020 , Oak\nRidge,TN1\u20139.doi:10.1145/3407197.3407205\nRamakrishnan,S.,Hasler,P.E.,andGordon,C.(2011).Floatingg atesynapseswith\nspike-time-dependent plasticity. IEEE Trans. Biomed. Circ. Syst . 5, 244\u2013252.\ndoi:10.1109/TBCAS.2011.2109000\nRanjbar, M., and Amiri, M. (2016). Analog implementation of neuron-\nastrocyte interaction in tripartite synapse. J. Comput. Electron . 15, 311\u2013323.\ndoi:10.1007/s10825-015-0727-8\nRanjbar, M., and Amiri, M. (2017). On the role of astrocyte analog ci rcuit\nin neural frequency adaptation. Neural Comput. Appl . 28, 1109\u20131121.\ndoi:10.1007/s00521-015-2112-8\nRastogi, M., Lu, S., Islam, N., and Sengupta, A. (2020). On the se lf-repair role of\nastrocytes in STDP enabled unsupervised SNNs. Front. Neurosci . 14:603796.\ndoi:10.3389/fnins.2020.603796\nRiou, M., Torrejon, J., Garitaine, B., Abreu Araujo, F., Bortolotti , P., Cros, V.,\net al. (2019). Temporal pattern recognition with delayed-feedback s pin-torque\nnano-oscillators. Phys.Rev.Appl .12:024049.doi:10.1103/PhysRevApplied.12.0\n24049\nRippard, W., Pufall, M., and Kos, A. (2013). Time required to injectio n-\nlock spin torque nanoscale oscillators. Appl. Phys. Lett . 103:182403.\ndoi:10.1063/1.4821179\nRippard, W. H., Pufall, M. R., Kaka, S., Silva, T. J., Russek, S. E., an d\nKatine, J. A. (2005). Injection locking and phase control of spin transfer\nnano-oscillators. Phys. Rev. Lett . 95:067203. doi: 10.1103/PhysRevLett.95.06\n7203\nRomera, M., Talatchian, P., Tsunegi, S., Abreu Araujo, F., Cros, V. , Bortolotti, P.,\netal.(2018).Vowelrecognitionwithfourcoupledspin-torquenan o-oscillators.\nNature563,230\u2013234.doi:10.1038/s41586-018-0632-y\nRomera, M., Talatchian, P., Tsunegi, S., Yakushiji, K., Fukush ima, A., Kubota, H.,\netal.(2020).Bindingeventsthroughthemutualsynchronizatio nofspintronic\nnano-neurons. arXiv[Preprint]arXiv:2001.08044 .\nSaha, A., Islam, A., Zhao, Z., Deng, S., Ni, K., and Sengupta, A. ( 2021). Intrinsic\nsynaptic plasticity of ferroelectric \ufb01eld e\ufb00ect transistors for onlin e learning.\narXivpreprintarXiv:2107.13088 .\nScholz,W.,Schre\ufb02,T.,andFidler,J.(2001).Micromagneticsimula tionofthermally\nactivated switching in \ufb01ne particles. J. Magn. Magn. Mater . 233, 296\u2013304.\ndoi:10.1016/S0304-8853(01)00032-4\nSengupta, A., Banerjee, A., and Roy, K. (2016). Hybrid spintronic -cmos\nspiking neural network with on-chip learning: devices, circuits , and\nsystems. Phys. Rev. Appl . 6:064003. doi: 10.1103/PhysRevApplied.6.0\n64003\nSengupta, A., and Roy, K. (2017). Encoding neural and synaptic\nfunctionalities in electron spin: a pathway to e\ufb03cient neuromorphic\ncomputing. Appl. Phys. Rev . 4:041105. doi: 10.1063/1.50\n12763\nSerrano-Gotarredona, T., Masquelier, T., Prodromakis, T., Indiveri , G.,\nand Linares-Barranco, B. (2013). STDP and STDP variations with\nmemristors for spiking neuromorphic learning systems. Front. Neurosci .\n7:2.doi:10.3389/fnins.2013.00002\nSeth, A. K., McKinstry, J. L., Edelman, G. M., and Krichmar, J. L. (2 004).\nVisual Binding through reentrant connectivity and dynamic sync hronization\nin a brain-based device. Cereb. Cortex 14, 1185\u20131199. doi: 10.1093/cercor/\nbhh079Shepard, R. N. (1990). Mind Sights: Original Visual Illusions, Ambiguities, and\nOther Anomalies, With a Commentary on the Play of Mind in Perc eption and\nArt.NewYork,NY:WHFreeman;TimesBooks;HenryHolt&Co.\nTorrejon, J., Riou, M., Araujo, F. A., Tsunegi, S., Khalsa, G., Qu erlioz, D., et al.\n(2017).Neuromorphiccomputingwithnanoscalespintronicoscillators .Nature\n547:428.doi:10.1038/nature23011\nTsunegi, S., Taniguchi, T., Nakajima, K., Miwa, S., Yakushij i, K., Fukushima, A.,\netal.(2019).Physicalreservoircomputingbasedonspintorqueos cillatorwith\nforcedsynchronization. Appl.Phys.Lett .114:164101.doi:10.1063/1.5081797\nVolterra, A., and Meldolesi, J. (2005). Astrocytes, from brain glue to\ncommunication elements: the revolution continues. Nat. Rev. Neurosci . 6,\n626\u2013640.doi:10.1038/nrn1722\nWade, J., McDaid, L., Harkin, J., Crunelli, V., and Kelso, S. (2012 ). Self-repair in\na bidirectionally coupled astrocyte-neuron (an) system based on ret rograde\nsignaling. Front.Comput.Neurosci .6:76.doi:10.3389/fncom.2012.00076\nWade, J. J., McDaid, L. J., Harkin, J., Crunelli, V., and Kelso, J. A . S. (2011).\nBidirectional coupling between astrocytes and neurons mediates le arning and\ndynamic coordination in the brain: a multiple modeling approach. PLoS ONE\n6:e29445.doi:10.1371/journal.pone.0029445\nWard, L. M. (2003). Synchronous neural oscillations and cognitiv e processes.\nTrendsCogn.Sci .7,553\u2013559.doi:10.1016/j.tics.2003.10.012\nWhitney, D. (2009). Neuroscience: toward unbinding the bindi ng problem. Curr.\nBiol.19,R251-R253.doi:10.1016/j.cub.2009.01.047\nWomelsdorf, T., and Fries, P. (2007). The role of neuronal synchroni zation\nin selective attention. Curr. Opin. Neurobiol . 17, 154\u2013160.\ndoi:10.1016/j.conb.2007.02.002\nWoodin, M. A., Ganguly, K., and Poo, M.-m. (2003). Coincident\npre-and postsynaptic activity modi\ufb01es gabaergic synapses by\npostsynaptic changes in CL- transporter activity. Neuron39, 807\u2013820.\ndoi:10.1016/S0896-6273(03)00507-5\nYogendra, K., Liyanagedera, C., Fan, D., Shim, Y., and Roy, K. (2 017). Coupled\nspin-torque nano-oscillator-based computation: a simulation stud y.ACM J.\nEmerg.Technol.Comput.Syst .13,1\u201324.doi:10.1145/3064835\nCon\ufb02ict of Interest: The authors declare that the research was conducted in the\nabsence of any commercial or \ufb01nancial relationships that could be c onstrued as a\npotentialcon\ufb02ictofinterest.\nPublisher\u2019sNote: Allclaimsexpressedinthisarticlearesolelythoseoftheauthors\nand do not necessarily represent those oftheir a\ufb03liated organizat ions, or those of\nthepublisher,theeditorsandthereviewers.Anyproductthatmayb eevaluatedin\nthis article, or claim that may be made by its manufacturer, is not gua ranteed or\nendorsedbythepublisher.\nCopyright\u00a92021Garg,YangandSengupta.Thisisanopen-accessa rticledistributed\nunder the terms of the Creative Commons Attribution License (CC BY). The use,\ndistribution or reproduction in other forums is permitted, p rovided the original\nauthor(s) and the copyright owner(s) are credited and that th e original publication\nin this journal is cited, in accordance with accepted academ ic practice. No use,\ndistributionorreproductionispermittedwhichdoesnotco mplywiththeseterms.", "arxiv37": "Identi \ufb01cation of Biomarkers\nControlling Cell Fate In Blood Cell\nDevelopment\nMaryam Nazarieh1,2, Marc Hoeppner1and Volkhard Helms2*\n1Institute of Clinical Molecular Biology, Christian-Albrecht-University of Kiel, Kiel, Germany,2Center for Bioinformatics, Saarland\nUniversity, Saarbruecken, Germany\nA blood cell lineage consists of several consecutive developmental stages starting from the\npluri- or multipotent stem cell to a state of terminal differentiation. Despite their importancefor human biology, the regulatory pathways and gene networks that govern thesedifferentiation processes are not yet fully understood. This is in part due to challengesassociated with delineating the interactions between transcription factors (TFs) and theircorresponding target genes. A possible step forward in this case is provided by theincreasing amount of expression data, as a basis for linking differentiation stages and geneactivities. Here, we present a novel hierarchical approach to identify characteristicexpression peak patterns that global regulators excert along the differentiation path ofcell lineages. Based on such simple patterns, we identi \ufb01ed cell state-speci \ufb01c marker genes\nand extracted TFs that likely drive their differentiation. Integration of the mean expressionvalues of stage-speci \ufb01c\u201ckey player \u201dgenes yielded a distinct peaking pattern for each\nlineage that was used to identify further genes in the dataset which behave similarly.Incorporating the set of TFs that regulate these genes led to a set of stage-speci \ufb01c\nregulators that control the biological process of cell fate. As proof of concept, weconsidered two expression datasets covering key differentiation events in blood cellformation of mice.\nKeywords: developmental genes, transcription factor, gene ontology, gene expression, cell fate, master regulator,\ncell lineage\n1 INTRODUCTION\nCell fate describes a biological program, which determines how a less specialized cell type develops\ninto a more specialized one. For each transition out of a particular state, this involves a decisionbetween either self-renewal or differentiation into daughter cells ( Garcia-Ojalvo and Martinez Arias,\n2012 ). It is well accepted that such processes are tightly regulated by transcriptional networks,\ntypically centered around a discrete number of transcription factors ( Moignard and G\u00f6ttgens, 2014 ).\nKnowing the \u201ckey players \u201dinvolved in these events may thus not only serve as a predictive marker to\nhelp determining differentiation stages of cells, but furthermore could potentially be useful forclinical purposes, for example by aiding in the search for therapeutic targets across different diseasesinvolving aberrations in the composition of cell types or stages, respectively ( An et al., 2014 ). One of\nthe best-studied examples are blood cells, which are already widely used in diagnostics. Especially incomplex blood-related diseases such as leukemia, understanding the manifestation of the disease andmonitoring its progression and response to treatment could greatly bene \ufb01t from a deeperEdited by:\nAna\u00efs Baudot,\nINSERM U1251 Centre de G\u00e9n\u00e9tique\nM\u00e9dicale de Marseille (MMG), France\nReviewed by:\nDelphine Potier,\nINSERM U1104 Centre\nd\u2019immunologie de Marseille-Luminy\n(CIML), France\nEmmanuelle Becker,\nUniversity of Rennes 1, France\n*Correspondence:\nVolkhard Helms\nvolkhard.helms@bioinformatik.uni-\nsaarland.de\nSpecialty section:\nThis article was submitted to\nNetwork Bioinformatics,\na section of the journal\nFrontiers in Bioinformatics\nReceived: 13 January 2021\nAccepted: 01 July 2021\nPublished: 19 July 2021\nCitation:\nNazarieh M, Hoeppner M and Helms V\n(2021) Identi \ufb01cation of Biomarkers\nControlling Cell Fate In Blood\nCell Development.\nFront. Bioinform. 1:653054.\ndoi: 10.3389/fbinf.2021.653054understanding of the underlying regulatory processes and key\n\u201cactors \u201dthat govern blood cell differentiation. However,\ndelineating lineage-speci \ufb01c regulatory networks is a\nchallenging task, typically requiring the costly integration of\nmultiple data types; particularly from various \u201comics \u201d\ntechnologies. Previous work using a complex multi-omicsapproach identi \ufb01ed a set of 16 \u201cglobal regulators \u201dthat drive\nthe differentiation of blood cells across six discrete stages -Embryonic stem cells (ESCs), Mesoderm (MES),Hemangioblast (HB), Hemogenic endothelium (HE),Hematopoietic progenitor (HP) and Macrophages (MAC)(Goode et al., 2016 ). It is very plausible to assume that these\nglobal regulators stand at the top of the regulatory hierarchy andindirectly govern particular cellular identity. Interestingly,\nalthough the overall network is preserved across\ndevelopmental stages, analysis of the characteristic changes inexpression ( Figure 1 ) suggests that these \u201cglobal regulators \u201d\ncontribute differently at various stages. We have previouslydeveloped a method that reconstructs the core components ofa regulatory network from gene expression data and de \ufb01nes a so-\ncalled \u201cminimum dominating set \u201d(MDS), i.e. the minimum set of\nTFs that control the entire network by their interactions. Amodi \ufb01cation of this concept is the \u201cminimum connecteddominating set \u201d(MCDS), which searches for a minimum\nnumber of genes that are connected and control theunderlying co-network ( Nazarieh et al., 2016 ;Nazarieh, 2018 ;\nNazarieh and Helms, 2019 ). When applied to expression data,\none should expect that a key transcription factor being moststrongly associated with a certain differentiation stage exhibits apeak in expression at that stage compared to the other stages ofthat lineage. Genes directly regulated by such a key player can beexpected to somehow mimic its expression pro \ufb01le, thus allowing\ntheir assignment to a given regulator and cellular stage. In thepresent work, we introduce an approach to identify stage-speci \ufb01c\nkey regulators that are likely to control cell fate in adifferentiation/developmental or resistance pathway.PathDevFate is a method for identifying the set of connected\nin\ufb02uencers and connectors that play roles in cell differentiation\nand cell commitment. The method implements a work \ufb02ow to\ninitially identify in \ufb02uencers that follow a lineage-speci \ufb01c pattern\nde\ufb01ned by integrating cell-speci \ufb01c genes and TFs in a stage. Then,\nit identi \ufb01es the set of TFs that regulate these in \ufb02uencers. Finally, it\nintroduces a regulatory pathway of a connected set of in \ufb02uencers\nand connectors whereby the path length is determined by thenumber of in \ufb02uencers and connectors. We demonstrate the\nusefulness of this approach by the example of two expression\nFIGURE 1 | Expression of 16 global regulators driving hematopoietic speci \ufb01cation for six stages of blood development starting from ESCs (stage 1) up to terminally\ndifferentiated macrophages (stage 6) ( Goode et al., 2016 ).data sets that were used to investigate blood cell differentiation in\nmice ( Bock et al., 2012 ;Goode et al., 2016 ).\n2 METHODS\n2.1 Overview\nFigure 2 illustrates the work \ufb02ow of the entire approach. First, we\nderive diagnostic expression pro \ufb01les to identify genes that are\nlikely centrally involved in a cellular differentiation path(Figure 2A ). Next, we integrate the expression pattern of\nstage-speci \ufb01c developmental genes across full individual\nlineages ( Figure 2B ). From this, a set of correlated genes and\nassociated TFs is identi \ufb01ed ( Figure 2C ). This preliminary\nnetwork is further re \ufb01ned by incorporating experimentally\nvalidated data e.g. from a TF-gene interaction database such as\nTRRUST ( Han et al., 2017 )t od e \ufb01ne a sub-regulatory network\nwhose target genes follow the aforementioned lineage-speci \ufb01c\nexpression pattern and have a well-de \ufb01ned TF regulator\n(Figure 2D ). The regulatory relationships are modeled as a\ndirected graph as is commonly done in such analyses. Thesource nodes are TFs and target nodes can be genes and/orTFs. The edges correspond to the regulatory interactions betweenthem. Finally, we present an algorithm that \ufb01nds the shortest\nregulatory path that connects the target genes that are tightlyregulated by multiple TFs ( Figure 2E ). We suggest that the set of\ntarget genes and TFs that connect them forms an importantgroup of driver genes for the respective cell fate process. Afunctional enrichment analysis is then used to investigate thebiological processes these identi \ufb01ed TFs have previously shown to\nbe involved in. Details of the individual steps of this algorithm\nand the motivation behind the steps will be explained below insection 2.4 .\n2.2 Datasets\nThe\ufb01rst case study is based on genome-wide RNA-seq expression\npro\ufb01les (Goode et al., 2016 ) in form of FPKM values across six\nconsecutive differentiation stages, namely ESC, MES, HB, EH, HPand MAC (GEO accession GSE69080). The microarray data forthe second case study were published by Bock et al. (2012) .A s\nmentioned in that paper, the data were obtained as CEL \ufb01les and\nnormalized in the same order to reduce batch effects. The data\nincludes 13 cell populations sorted by FACS analysis across 6lineages.\n2.3 Regulatory Relationships\nData on the relationship between TFs and their target gene(s)were taken from the TRRUST database v2 ( Han et al., 2017 ) that\nwas compiled based on literature curation. This release of thedatabase includes 6552 TF-target interactions for 828 mouse TFs.\nFIGURE 2 | Overview of how biomarkers are identi \ufb01ed that control or drive a developmental cell fate process. (A)Fictitious expression pro \ufb01les (y-axis) of six selected\ntranscription factors (TFs) across six developmental stages ( x-axis). TFs are identi \ufb01ed having peak expression in the respective stage. This step yields the stage-speci \ufb01c\nkey regulators (TFs). (B)A lineage-speci \ufb01c pattern is constructed by integrating the stage-speci \ufb01c patterns across the lineage. (C)Further genes are identi \ufb01ed having\nhighly correlated expression pro \ufb01les to one of the stage-speci \ufb01c key regulators of (B)(here, one of the TFs peaking in the terminal stage MAC). (D)A gene-regulatory\n(GRN) network is constructed including all stage-speci \ufb01c key regulators and their correlated target genes. This GRN includes TFs and target genes from all stages. (E)A\nregulatory pathway is identi \ufb01ed (see methods) that connects (blue colored nodes) all \u201cin\ufb02uencer \u201dnodes (red colored nodes).2.4 Work \ufb02ow: Prioritization of the\nCandidates of the Cell Fate Process\n1) As input, we use existing knowledge about a small gold-\nstandard set of tissue-speci \ufb01c global regulators. All\ndifferentiation stages of the particular cell lineage underconsideration are arranged in a linear sequence (seeFigure 2A ). First, we identify which ones of the mentioned\nglobal regulators peak in the individual stages.\n2) Then, we aim at identifying an expression signature of each\nparticular stage. For this, we now identify further genes andTFs having a closely matching expression pro \ufb01le to the stage-\nspeci\ufb01c expression pattern of the global regulators peaking in\nthis stage just de \ufb01ned. The genes identi \ufb01ed in this manner are\ntermed \ufb01rst layer candidates. (see Figure 2A ).\n3) After having identi \ufb01ed sets of signature genes for\nparticular stages, we now combine the stage-speci \ufb01c\nexpression pattern across the entire lineage. The meanexpression value of all identi \ufb01ed stage-speci \ufb01c genes is\nconsidered as a representative for each stage. Thisaveraging is done to capture the typical behavior of allstage-speci \ufb01c genes by a single pro \ufb01le. This then yields a\nlineage-speci \ufb01c pattern. (see Figure 2B ). Alternatively, one\ncould have normalized the expression values of all stage-speci \ufb01c genes to a particular interval.\n4) In the next step, we \ufb01nd further genes and TFs having an\nexpression pattern that closely mimics the integrated lineage-\nspeci\ufb01c expression pattern. These are then termed second\nlayer candidates. (see Figure 2C ).\n5) Now, we determine TFs that regulate the candidates in the\nsecond layer identi \ufb01ed in step 4. These are then termed third\nlayer candidates.\n6) We now aggregate the regulators identi \ufb01ed in step 5 and the\ntarget genes identi \ufb01ed in step 4 into a regulatory subnetwork.\nBy way of design, this network includes those genes having aparticular lineage-speci \ufb01c expression pattern and their\nregulators. We consider this subnetwork of the full\nregulatory network of a cell as the essential part governing\nthe fate of a particular cell lineage. (see Figure 2D ).\n7) Now, we determine the high-indegree nodes in the regulatory\nsubnetwork identi \ufb01ed in step 6. The idea behind this is that\nthese hub genes contribute a major part of all regulatoryactivity in the constructed subnetwork. (see red color nodes intheFigure 2E ).\n8) Identify additional connector nodes that connect the nodes\nidenti \ufb01ed in step 7 (see blue color nodes in the Figure 2E ). The\nidea of this step is that this connected pathway forms anequivalent of a \u201cregulatory pathway \u201d. This step has an analogy\nto the concept of an MCDS of dominating nodes that we\nde\ufb01ned in our earlier work ( Nazarieh et al., 2016 ). The fourth\nlayer is a regulatory subnetwork including the set of\nin\ufb02uencers and connectors.\nThe implemented program code for the two afore-mentioned\ndatasets is available at: https://github.com/ikmb/KeyDevelopmentalFate in the code section: (KeyDevFate_Goode2016.R, KeydevFate_Bock2012.R)2.5 Randomization Algorithm\nInput: A set of correlated genes following an integrated pattern ofgene expression across the stages in one lineage. Output: Overlapsigni\ufb01cance of the correlated genes based either on the original\ndata or on the shuf \ufb02ed data.\n1) Shuf \ufb02e the data column-wise, whereby each column\ncorresponds to the expression value of the genes in acertain stage.\n2) Identify the set of correlated genes following the integrated\nexpression pattern based on shuf \ufb02ed data.\n3) Compute the overlap between the correlated genes in real data\nand the correlated genes in the shuf \ufb02ed data.\n4) To characterize the statistical signi \ufb01cance of the identi \ufb01ed\ngenes, we compared the obtained result to analogous results\nidenti \ufb01ed based on randomly shuf \ufb02ed data. If a considerable\npart of the originally correlated genes were also identi \ufb01ed\nfrom shuf \ufb02ed data, this would suggest that the \ufb01ndings are\ninsigni \ufb01cant. Precisely, we counted the number of times when\nthe overlap (Jaccard index) between the correlated genes in theoriginal data and the correlated genes in 1000 shuf \ufb02ed data\nsets is greater than 0.05. Here, the Jaccard index was computedas the ratio of the intersection between the set of correlatedgenes and the resampled data over the union of the two sets.\nThe implemented code for the \ufb01rst case study is available at:\nhttps://github.com/ikmb/KeyDevelopmentalFate in the code\nsection: RandomizationAlgorithm_Goode2016.R\n2.6 PathDevFate Algorithm: Find the\nRegulatory Path That Involves a Certain Setof Nodes\nInput: A network that is obtained from step 6 of the above-\nmentioned pipeline. Output: A set of genes and TFs with assignedroles of in \ufb02uencers and connectors.\n1) Identify the set of nodes that are regulated by at least one TF.\n2) Specify a threshold (here denoted by \u201cl\u201d) as a measure of in-\ndegree threshold.\n3) Select the nodes whose number of incoming edges exceeds \u201cl\u201d.\nThese are termed \u201cin\ufb02uencers \u201d.\n4) Find a path that connects the in \ufb02uencer nodes by adding a\nminimum number of further (Steiner) nodes ( \u201cconnectors \u201d).\nThe implemented code for the algorithm is available at:\nhttps://github.com/ikmb/KeyDevelopmentalFate in the codesection (PathDevFate) In step 2, a threshold is introduced thatprovides a balance between the number of in \ufb02uencers with\nrespect to the number of incoming edges and the number of\nTFs that are supposed to connect them (which depends on thedistance these in \ufb02uencers have from each other). This measure\nserves to capture the high-indegree nodes and imposes aminimum number of TFs to the regulatory pathway. The ideaof this algorithm has been taken from our MCDS algorithm(Nazarieh et al., 2016 ). In the MCDS algorithm, after \ufb01nding the\ndominator nodes, the next step is to \ufb01nd the connectors andminimise the number of dominators and connectors as long as\nconnectivity persists and the underlying connected network iscovered by the MCDS. In the new algorithm, after \ufb01nding the\nconnectors, we keep the set of in \ufb02uencer nodes (nodes with high\nin-degree) constant and then minimize the number of connector\nnodes. Based on the enrichment analysis, in \ufb02uencers take part\nmainly in the development and differentiation processes, whereasconnectors may in addition also contribute to cell fatecommitment.\n2.7 Functional Annotation\nThe biological function of the genes in each stage was evaluatedusing the enrichment analysis tool provided by the DAVID portalof NIH (version 6.8) based on the functional categories in GODirect ( Huang et al., 2008 ) and all Mus musculus genes as\nbackground. p-values below the threshold of 0.05 as obtained\nby the hypergeometric test were adjusted for multiple testingusing the Benjamini and Hochberg (BH) correction ( Benjamini\nand Hochberg, 1995 ).\n3 RESULTS\nThe main goal of this study was to derive an approach that\nidenti \ufb01es a connected set of cell-fate regulating genes. For this, we\nimplemented the hierarchical strategy illustrated in Figure 2 . The\n\ufb01rst layer includes the stage-speci \ufb01c TFs and genes that are\ninvolved in cellular differentiation. The second layer consistsof further genes and TFs following the same integrated stage-speci\ufb01c expression pattern. The third layer is formed by those TFs\nthat regulate the candidates in the second layer. A regulatorynetwork was constructed from the correlated genes following theintegrated expression pattern with a set of TFs that regulate themwhich forms the candidates in the fourth layer. Finally, we derived\na shortest regulatory path that connects the set of correlated genes\nthat are regulated by multiple TFs (PathDevFate, see Methods). Inshort, the target genes that are tightly regulated by multipletranscription factors are \ufb02agged as \u201cin\ufb02uencers \u201dand the nodes\nthat connect them as \u201cconnectors \u201d. As proof of concept, we\napplied the method to two datasets of murine blooddifferentiation. The \ufb01rst case study was a lineage of six stages\nstarting at ESC and leading to MAC ( Goode et al., 2016 ). We then\nextended the concept by setting rules de \ufb01ned for cellular\ndifferentiation in ( Artyomov et al., 2010 ) and applied it to\nexpression data from across 6 murine cell lineages in bloodformation ( Bock et al., 2012 ) starting at HSC and leading to\neither CD4 T-cells, CD8 T-cells, B cells, erythrocytes,\ngranulocytes or monocytes, respectively.\n3.1 Dataset 1: Differentiation of Murine\nBlood Stem Cells\nFrom published multi-omics data on murine blood stem cells\n(Goode et al., 2016 ), we retrieved the gene expression pro \ufb01le of 16\nglobal regulators that were identi \ufb01ed in the study of ( Goode et al.,\n2016 ). These were averaged to yield a stage-speci \ufb01c expression\npattern that is considered subsequently as signature pattern. Wethen identi \ufb01ed further genes (and further TFs) having strongly\ncorrelated expression pro \ufb01les with this stage-speci \ufb01c expression\npattern. Figure 3 shows the expression pattern of the TFs that\nwere among the identi \ufb01ed correlated genes. Obviously, multiple\nTFs show peaks in each of the individual differentiation stages.\nThis analysis, yielding our \u201c\ufb01rst\u201dgene layer, identi \ufb01ed between\n197 (HP) and 692 (HB) correlated gene expression pro \ufb01les\n(Supplementary Table S1 ). Included in this are between 10\n(MAC) and 57 (HB) TFs, such as SOX2 and ESRRB. For eachstage, we considered the identi \ufb01ed genes to reconstruct functional\npro\ufb01les of the correlated genes based on enriched gene ontology\nterms (GO) ( Supplementary Tables S2 \u2013S5). In order to\nunderstand the molecular mechanisms governing eachdifferentiation stage, we next performed a functionalenrichment analysis using both gene ontology (GO) terms and\nKEGG pathways for the key transcription factors\n(Supplementary Tables S6 \u2013S11) found in each differentiation\nstage, as well as for their (known) target genes ( Supplementary\nTables S12 \u2013S17), respectively. Supplementary Table S6 for ESC\nlists GO terms such as stem cell differentiation (GO:0048863),multicellular organism development (GO:0007275), endodermdevelopment (GO:0007492) and cell differentiation (GO:0030154), respectively. Moreover, the \ufb01ve genes Onecut1,\nEsrrb, Id1, Sox2, and Zic3 belong to the KEGG pathwaysignaling pathways regulating pluripotency of stem cells(mmu04550). Supplementary Tables S7 \u2013S11 list the enriched\nGO terms and KEGG pathways for the identi \ufb01ed TFs in MES,\nHB, HE, HP and MAC. The lists include further specialized GOterms in addition to some of the aforementioned terms such aspatterning of blood vessels (GO:0001569), cell fate commitment(GO:0045165), heart development (GO:0007507) andhemopoiesis (GO:0030097), respectively and also the KEGGpathway acute myeloid leukemia (mmu05221). Then, weinferred the set of target genes for the set of \u201ckey player \u201dTFs\nat each developmental stage from the TF-gene interactiondatabase TRRUST ( Han et al., 2017 ). Enrichment analysis for\nthe set of identi \ufb01ed target genes in the ESC stage yielded the\nenriched biological process GO terms listed in Supplementary\nTables S12 . The list includes GO terms such as proliferation (GO:\n0042127), multicellular organism development (GO:0007275),stem cell differentiation (GO:0048863), cell differentiation(GO:0030154), cell fate commitment (GO:0045165), celldevelopment (GO:0048468) and cell proliferation (GO:0008283), respectively. Supplementary Tables S13 \u2013S17list the\nenriched GO terms for the target genes in other developmental\nstages. In addition to common GO terms, distinct GO terms, suchas BMP signaling pathway involved in heart development (GO:0061312) and Wnt signalling pathway (GO:0016055) are added\nin the MES stage. More specialized GO terms appear in later\nstages HB, HE, and HP, such as liver development (GO:0001889),B cell lineage commitment (GO:0002326), ear development (GO:0043583) and eye development (GO:0001654), respectively.Although the TFs identi \ufb01ed in each particular developmental\nstage also follow the aforementioned expression pattern, theyexhibit different expression levels. The histograms in Figure 4\nshow the frequency of TFs based on their expression level. Ingeneral, there are many more TFs with low expression (e.g. 0 \u201310,0\u201320 etc.) than with high expression (above 50). There is an initial\nincrease in the absolute number of patterned TFs from 13 (ESC),\n14 (MES) to 34 (HB), followed by a corresponding decline over 22\n(HE), 15 (HP) to 6 (MAC). Genes that act in the same biologicalprocesses are expected to (partially) share activity pro \ufb01les\n(Huttenhower and Troyanskaya, 2008 ).Figure 5 shows the\nmean expression of the identi \ufb01ed stage-speci \ufb01c genes. To the\naim of identifying additional members of the candidate network,we extracted genes that mimic the same expression patternexhibited by the stage-speci \ufb01c genes ( Figure 5 ). For this, we\nrequired that their expression patterns across the six stages (fromESC to MAC) showed the same monotonic expression pattern\n(i.e. Spearman rank correlation larger than 0.9) as the stage-\nspeci\ufb01c genes. This led to the identi \ufb01cation of 243 genes\n(Supplementary Table S18 ) including 13 TFs. Figure 6 shows\nthe expression pattern of those genes having perfect Spearmancorrelation of 1.0. The 13 TFs are considered as candidates for thesecond layer. To verify the statistical signi \ufb01cance of the correlated\ngenes, we resampled the data 1000 times, identi \ufb01ed patterned\ngenes in each case, and measured the overlap between thecorrelated genes in the original data set and those determinedfrom the resampled data, see Supplementary Figure S1 . The\nFIGURE 3 | Expression pattern of identi \ufb01ed TFs in six stages of ESC, MES, HB, HE, HP and MAC that follow the global expression pattern.overlap was measured based on the Jaccard index as the ratio of\nintersection between the sets of correlated genes in real data and\nin resampled data over the union of the two sets. Only 3 out of\n1,000 cases had a similarity higher than 0.05 between thecorrelated genes in the original data and the correlated genesin the shuf \ufb02ed data ( p-value of 0.003). Thus, the stage-speci \ufb01c\ngenes identi \ufb01ed in the real data are rarely identi \ufb01ed based on\nrandomly shuf \ufb02ed data, which strengthens the biological\nmeaningfulness of this analysis. Next, we sought to identifyknown regulators of this initial set of co-expressed genes usingdata from the TRRUST database. This analysis resulted in 83 TFswhich then formed the third layer of our analysis(Supplementary Table S19 ). The intersection with cell-speci \ufb01c\nTFs of ESC, MES, HB, HE, HP and MAC identi \ufb01ed in the \ufb01rst\nlayer includes (Etv4, Hdac1, Prdm16, Sox2), (Foxo4), (Atf2, Etv2,Gata4, Msx2, Snail1), (Ebf1, Smad3), (Stat5a, Stat5b, Thra),(Arid3a, Stat5b), respectively. All these genes were previously\nreported to have speci \ufb01c roles in cell fate commitment ( Liu et al.,\n1996 ;Avilion et al., 2003 ;Dunn et al., 2004 ;Beuling et al., 2008 ;\nZandi et al., 2008 ;Ackermann et al., 2011 ;Rhee et al., 2014 ;\nBabajko et al., 2015 ;Horvay et al., 2015 ;Liu et al., 2015 ;Bourgeois\nand Madl, 2018 ;Garg et al., 2018 ).Supplementary Table S20\nshows the functional enrichment analysis (biological process) andKEGG pathways for the 83 TFs along with p-values, using a\nhypergeometric test and adjusted for multiple testing using theBenjamini and Hochberg (BH) correction ( Benjamini and\nHochberg, 1995 ) below a threshold of \u22640.05. Notable GO\nterms on this list include: GO:0008285 negative regulation ofcell proliferation, GO:0008284 positive regulation of cell\nproliferation GO:0043066 negative regulation of apoptotic\nprocess, GO:0043065 positive regulation of apoptotic process,GO:0002360 T cell lineage commitment, GO:1902262 apoptotic\nFIGURE 4 | Histograms of stage-speci \ufb01c TF expression levels (FPKM values) in the blood cell lineage show a quasi-exponential decay. Eg. for ESC, 13 TFs have\nexpression levels between 0 and 20, 6 TFs have expression levels between 20 \u201340.process involved in patterning of blood vessels, GO:0048863 stem\ncell differentiation, GO:0030154 cell differentiation, GO:0007507\nheart development, GO:0007275 multicellular organismdevelopment, GO:0033077 T cell differentiation in thymus,and GO:0030217 T cell differentiation. Finally, usinginformation from the TRRUST database, a regulatory networkwas reconstructed whose nodes are con \ufb01ned to the candidates of\nthe second and third layer. The network demonstrates theconnectivity between the candidates in the second and thirdlayer. The number of TFs in the network exceeds the number oftarget genes so that the network contains few genes with a highnumber of incoming edges. In the network having 90\ninteractions, the 83 regulators were taken from the third layer\nand 21 target genes taken from the second layer ( Supplementary\nTable S18 ). This network contains the three high-indegree nodes\nCcnd2, Pparg and Ihh in the largest connected component thatare connected through Msx2 and Foxo1, see Figure 7 . Indeed,\nprevious experimental work established that these genes and TFshave important functions in hematopoiesis: Ccnd2 as a target ofElf5 plays an important role in development and differentiation(Escamilla-Hern\u00e1ndez et al., 2010 ); Pparg is a regulator of\nhematopoietic stem cell homeostasis ( Sertorio et al., 2017 ); Ihh\nprograms developing mesoderm cells to become hematopoietic or\nvascular cells ( Sugiyama et al., 2011 ), and suppression of Foxo1\nexhibits myeloid lineage expansion and lymphoid developmentalabnormalities ( T\u00f3thov\u00e1 et al., 2007 ).\n3.2 Dataset 2: Blood Stem Cell\nDifferentiation Along Multiple Lineages\nThe previous section focused on a single example of cellular\ndifferentiation in blood formation, starting from previouslycharacterized \u201ckey\u201dtranscription factors. Therefore, we nextexpanded our initial approach and applied our concept of\n\u201ckey\u201dexpression pro \ufb01les to a more complex dataset, consisting\nof six differentiation lineages starting at mouse blood stem cells(Bock et al., 2012 ). Differentiation of these lineages was shown by\nthe authors to follow a gradual path of changing expressionpro\ufb01les through up to six steps into a fully differentiated cell\n(Figure 8 ). To derive the developmental genes and TFs we not\nonly relied on the cell-speci \ufb01c expression pattern as outlined\nabove, but also exploited the computational model and the rulessuggested by ( Artyomov et al., 2010 ). Within this model, each cell\nis de \ufb01ned by two network layers representing expression and\nepigenetic states. A set of master regulators de \ufb01ne the cellular\nidentity. On the event of cellular differentiation, the activatedgene module suppresses the activity of the competitor cells eitherin relationship of parent cell or daughter branch cells. Wemodi \ufb01ed the rules to the extent that developmental regulators\nspeci\ufb01c to each cell state have superiority in terms of gene\nexpression level over neighboring stages while following thecell-speci \ufb01c expression pattern from the top of the hierarchy\nuntil terminally differentiated cells. The afore-mentionedpatterns led to the identi \ufb01cation of between 4 and 128 cell-\nstage speci \ufb01c genes for the different cell types under consideration\n(Supplementary Table S21 ), including several well-known TFs.\nFigure 9 represents the changes of mean expression value of\nconstituent cells along the cell lineages starting from HSC until aterminally differentiated cell type (e.g. CD4 T-cell, CD8 T-cell,B cell, Erythrocyte (Eryth), Granulocyte (Granu) or Monocyte(Mono)). The stage-speci \ufb01c genes of erythrocytes and\ngranulocytes have particularly high expression levels in theterminally differentiated stage. For CD4 T-cells, CD8 T-cells,B cells, and monocytes, an inverse trend is observed.\nFIGURE 5 | Depiction of the mean expression of stage-speci \ufb01c genes\nacross six stages of blood cell differentiation (from ESC to MAC).\nFIGURE 6 | Depiction of the correlated genes. The red curve shows the\npattern of integrated mean expression of all six stages in the lineage. The blackcurves represent correlated genes that have perfectly positive correlation\nbased on the Spearman method (threshold /equals1).Supplementary Table S22 shows the number of lineage-speci \ufb01c\ncorrelated genes including the involved TFs. Additionally, it\ndepicts the number of TFs that regulate the correlated genes\ninferred from the TRRUST database and the number of identi \ufb01ed\ncorrelated genes that are targets of these TFs. Supplementary\nTables S23 \u2013S28contain the GO terms and KEGG pathways for\nthe set of TFs that regulate the correlated genes mentioned in thesecond layer. GO terms such as GO:0045165, GO: 0001709, GO:0001708 annotated to cell fate commitment, cell fatedetermination and cell fate speci \ufb01cation have been identi \ufb01ed\nin the downstream analysis of almost all the lineage-speci \ufb01c TFs.\nSupplementary Table S29 shows the network statistics for the six\nlineages. As mentioned before, these networks consist of the\nderived TFs in the third layer and the target genes of the second\nlayer. The network size lies between 81 and 272 nodes having 66up to 293 interactions. Figure 10 illustrates the CD8 network\nconstructed by the TFs and their target genes that overlap withthe correlated genes in the second layer. The PathDevFate\nprogram highlighted genes (in \ufb02uencers colored red and\nconnectors colored blue) that reside along the path to connect\nthe in \ufb02uencers. Supplementary Tables S30 \u2013S35list these nodes\nfor the six lineages including their roles and in-degree and out-degree. Supplementary Table S36 displays the enriched GO\nterms and KEGG pathways for the set of genes and TFsinvolved in the regulatory pathway of the CD8 T-cell lineage.Among many terms related to cell differentiation and cell fate,GO: 0030217, which is annotated to the three involved genesGata3, Ctnnb1 and Runx2, stands for T cell differentiation.Possible validation experiments of our predictions would beCRISPR-Cas knock out of these genes or siRNA silencing. Our\nexpectation is that this would impair differentiation. Jun, Gata3,\nNfatc1 and Runx2 are known to be key TFs for memoryCD8 T-cell development based on a genome-wide regulatorynetwork ( Hu and Chen, 2013 ). Fli1, Smad3, Sp1, Mycn, and Tal1\nFIGURE 7 | TF-target network for the set of correlated genes derived from the TRRUST database. In \ufb02uencers (red nodes) are the stage-speci \ufb01c target genes that\nare regulated by more than \ufb01ve TFs. Connectors are TFs (blue nodes).FIGURE 8 | Red colored nodes denote the gene modules whose expression pattern are the highest among the stages in the blood differentiation. Blue color nodes\nstand for the genes whose expression pattern are lower than the red color nodes. The parent nodes above the red colored node show a gradual increase in th e\nexpression pattern and the daughter blue nodes show a gradual decrease which reaches minimal expression at the terminally differentiated cells. Arr ows point in the\ndirection of decreasing expression level.White color nodes are the cells whose expression levels are not considered for this stage. The rules are lis ted in detail in the\nAppendix :play important roles in CD8 T-cell differentiation and\ndevelopment and in forging T-lymphocyte identity ( He et al.,\n2016 ;Rothenberg et al., 2016 ).Supplementary Tables S37 \u2013S40represent the enriched GO terms and KEGG pathways associated\nwith the set of genes and TFs involved in the regulatory pathwaysof CD4 T-cell, B cell, erythrocyte and granulocyte lineages ( Bock\net al., 2012 ).\n4 DISCUSSION\nIn this work, we devised a pipeline for inferring a set of genes\nand TFs that drive the blood differentiation processcontrolling the cell fate decisions across a lineage startingat the stem cell stage leading to a terminally differentiatedstage. We started by identifying a set of genes and TFs having aparticular stage-speci \ufb01c developmental expression pattern.\nPathDevFate is a new method based on the biologicalobservations of ( Bock et al., 2012 ). We \ufb01rst retrieve the\nexpression level of a given set of global regulators across adevelopmental lineage. By averaging these, we de \ufb01ne a \u201cstage-\nspeci \ufb01c pattern \u201d. Before arriving at our pattern de \ufb01nition, we\nalso experimented with a \u201cloosened \u201dcriterion where a stage-\nspeci \ufb01c gene could e.g. violate one out of six conditions. But\nthis led to a large increase in the number of identi \ufb01ed genes,\nwhich confused their downstream analysis. As cell fateregulators, we consider those genes that adhere exactly tothe given expression pattern of stage-speci \ufb01c genes across the\nlineage and are regulated and connected by a set of TFs. Othertechniques such as Spearman correlation or the methodintroduced by ( Pavlidis and Noble, 2001 ) may identify\ngenes where the expression does not peak in the speci \ufb01ed\nstage, but that have optimal matches for the other stages. Afterdetermining stage-speci \ufb01cp a t t e r n ,w ei d e n t i f yf u r t h e rg e n e s\nFIGURE 9 | Mean expression of stage-speci \ufb01c genes for the cells in each lineage for the six lineages CD4 T-cell, CD8 T-cell, B cell, erythrocyte, granulocyte and\nmonocyte.\nFIGURE 10 | The set of genes and TFs involved in the regulatory\npathway for CD8 T-cells. In \ufb02uencers (red nodes) are the target genes that are\nregulated by more than \ufb01ve TFs. Connectors are TFs (blue nodes).having highly correlated expression pro \ufb01l e sw i t ht h i sp a t t e r n\nand term them \u201cstage-speci \ufb01c\u201dgenes and TFs. The stage-\nspeci \ufb01c genes which follow the cell-speci \ufb01c pattern have\ndifferent expression levels. Therefore, we consider the mean\nexpression of all stage-speci \ufb01c genes as a representative value of\nall the genes with the same pattern. \u201cLineage-speci \ufb01cg e n e s \u201drefer to\nthe set of genes that follow the expression \ufb02uctuation of the stage-\nspeci\ufb01c genes in the respective lineage. As described before, a TF-\ngene regulatory network is reconstructed in layer 4 of the work \ufb02ow.\nThat comprises of TFs (connectors) and targets (in \ufb02uencers). Here,\nwe selected CD4 T-cell, CD8 T-cell, and B cell lineages to elucidatethe main biological roles of the in \ufb02uencers and connectors. The set\nof TFs is analyzed in Supplementary Tables S23 \u2013S25.T h e\nenrichment analysis of the set of target genes (in \ufb02uencers) is\npresented in Supplementary File S2 . Based on the analysis,\nin\ufb02uencers take part mainly in the developmental and\ndifferentiation processes, whereas connectors in additioncontribute to cell fate commitments. At the top level of thispipeline, we introduce a regulatory pathway in a gene-regulatorynetwork of TFs and target genes taking into account the identi \ufb01ed\ncorrelated genes and the TFs that regulate them. The regulatorypathway consists of a set of in \ufb02uencers that are regulated by\nmultiple TFs and a set of connector TFs that join them. Thequality of this pathway depends on several points: First of all, thecorrelation threshold is a variable unless only perfectly correlatedgenes are to be considered. After that, the number of TFs that\nregulate these genes relies on the database(s) and the type of\ninteraction which can be either experimentally con \ufb01rmed\n(though likely not in the particular case investigated here) orpredicted, or both. After all, the in-degree threshold forin\ufb02u e n c e r si sa l s oav a r i a b l e .At i g h t e rt h r e s h o l dl e a d st oa\nlower number of in \ufb02uencers but is not correlated to the size of\nthe regulatory pathway. As shown in Supplementary Figure S2 ,\nin the lineages of CD8 T-cells and granulocyte the number ofconnectors dramatically increases after a certain threshold. Thisobservation indicates that those high-indegree in \ufb02uencers are\nvery distant from each other an d the algorithm needs to inject\nmany connectors to join them. In principle, this work divides\nthe identi \ufb01e dg e n e sa n dT F si n t ot w og r o u p s .T h e \ufb01rst group\ndescribes the set of TFs that show the stage-speci \ufb01c\ndevelopmental patterns and have a tendency to reach theterminally differentiated state. The second group contains theset of TFs that regulate the set of genes and TFs which correlatewith the lineage-speci \ufb01c expression pattern. The regulatory\npathway demonstrates a path that encompasses thosecorrelated genes that are targeted by several TFs. Thissigni\ufb01es the necessity of the genes to be involved in the\nprocess. Moreover, this pathway introduces a set of TFs to\nsynchronize the activities of these in \ufb02uences in the lineage. At\nthis point, it is not very straigh t-forward to highlight the most\nimportant TFs as the number o f TFs that are induced for\nconnectivity highly depends on the number of in \ufb02uencers\nand the distance that these in \ufb02uencers have from each other\nin the network.5 CONCLUSION\nIn this work, we identi \ufb01ed a set of genes and, from within this\nset, TFs that can be considered as potential biomarkers for thecell fate process during blood formation. To infer thesecandidates, we took as starting point the expression patternof previously described global regulators in a blood lineage.Using this data, we identi \ufb01ed stage-speci \ufb01c genes that are\nlikely associated with the cellular differentiation based oncorrelated activity pro \ufb01les. By combining the cell-speci \ufb01c\nexpression pattern we obtained an integrated pattern\nspeci \ufb01c to each lineage. Inferring the set of correlated genes\nand TFs that follow the lineage-speci \ufb01c expression pattern and\nincorporating the TFs that regulate the genes that have highcorrelation with the integrated pattern led to the identi \ufb01cation\nof a regulatory subnetwork of TFs and their target genes.Nodes in these networks were \ufb01nally prioritized using a\nnewly developed \u201cregulatory pathway \u201dalgorithm to identify\nhigh-indegree genes and TFs by adding additional connectorTFs. All the nodes that reside along this path are suggested tobe of a high priority for network function. Here, the set of TFs\nis prioritized in four layers. In the \ufb01rst layer, there are TFs that\nare mainly involved in the cellular differentiation process. Thesecond layer consists of TFs that follow the integrated patternof stage-speci \ufb01c expression pattern. TFs that regulate the\ncorrelated genes and TFs in the second layer constitute thecandidate TFs in the third layer. Finally, the TFs thatcooperatively regulate targets genes and connect high-indegree nodes (in \ufb02uencers) in the network of TFs in the\nthird layer and the correlated genes and TFs in the second layermake up the candidates in the fourth layer. Enrichmentanalysis demonstrates that th ese biomarkers are not only\ninvolved in determining cell fate but also in other\ndevelopmental processes such as multicellular organismdevelopment etc. KEGG pathway analysis shows that thesebiomarkers can be potential targets for disease-relatedbiomarkers, such as leukaemia In addition to thecomputational approach to id entify a regulatory pathway\ndriving blood differentiation and also a set of genes andTFs that are introduced in four layers as potentialbiomarkers, the PathDevFate code can be used as a softwareto\ufb01nd the shortest path between a set of in \ufb02uencer nodes in\nthe largest connected component where a user can set a\nthreshold for the number of incoming edges. Also, users\nwho want to apply a different ranking scheme can easilymodify the provided R scripts and study the data sets oftheir choice.\nDATA AVAILABILITY STATEMENT\nOnly publicly available expression datasets were analyzed in this\nstudy. The source codes developed for this work are available\nhere: https://github.com/ikmb/KeyDevelopmentalFate.AUTHOR CONTRIBUTIONS\nMN initiated this study, designed and implemented the\nalgorithms, performed data analysis and wrote themanuscript. MH revised and edited the manuscript. VHproposed the biological motivation of the paper and helpedwith designing this study, data analysis and writing of themanuscript.\nFUNDING\nMN was supported by SFB 1027 through the DFG. Weacknowledge support by the DFG (DFG, German ResearchFoundation) and Saarland University within the funding\nprogramme Open Access Publishing.\nACKNOWLEDGMENTS\nWe thank Prof. Andre Franke for supporting this research.\nSUPPLEMENTARY MATERIAL\nThe Supplementary Material for this article can be found online at:https://www.frontiersin.org/arti cles/10.3389/fbinf.2021.653054/\nfull#supplementary-material\nREFERENCES\nAckermann, J., Ashton, G., Lyons, S., James, D., Hornung, J. P., Jones, N., et al.\n(2011). Loss of Atf2 Function Leads to Cranial Motoneuron Degenerationduring Embryonic Mouse Development. PLOS ONE 6, e19090-14. doi:10.1371/\njournal.pone.0019090\nAn, X., Schulz, V. P., Li, J., Wu, K., Liu, J., Xue, F., et al. (2014). Global\nTranscriptome Analyses of Human and Murine Terminal ErythroidDifferentiation. Blood 123 (22), 3466 \u20133477. doi:10.1182/blood-2014-01-548305\nArtyomov, M. N., Meissner, A., and Chakraborty, A. K. (2010). A Model for\nGenetic and Epigenetic Regulatory Networks Identi \ufb01es Rare Pathways for\nTranscription Factor Induced Pluripotency. Plos Comput. Biol. 6, e1000785-\n14. doi:10.1371/journal.pcbi.1000785\nAvilion, A. A., Nicolis, S. K., Pevny, L. H., P\u00e9rez, L., Vivian, N., and Lovell-Badge, R.\n(2003). Multipotent Cell Lineages in Early Mouse Development Depend onSox2 Function. Genes Dev. 17 (1), 126 \u2013140. doi:10.1101/gad.224503\nBabajko, S., de La Dure-Molla, M., Jedeon, K., and Berdal, A. (2015). Msx2 in\nAmeloblast Cell Fate and Activity. Front. Physiol. 5, 510. doi:10.3389/\nfphys.2014.00510\nBenjamini, Y., and Hochberg, Y. (1995). Controlling the False Discovery Rate: A\nPractical and Powerful Approach to Multiple Testing. J. R. Stat. Soc. Ser. B\n(Methodological) 57, 289 \u2013300. doi:10.1111/j.2517-6161.1995.tb02031.x\nBeuling, E., Bosse, T., aan de Kerk, D. J., Piaseckyj, C. M., Fujiwara, Y., Katz, S. G.,\net al. (2008). Gata4 Mediates Gene Repression in the Mature Mouse SmallIntestine through Interactions with Friend of Gata (Fog) Cofactors. Dev. Biol.\n322 (1), 179 \u2013189. doi:10.1016/j.ydbio.2008.07.022\nBock, C., Beerman, I., Lien, W. H., Smith, Z. D., Gu, H., Boyle, P., et al. (2012). Dna\nMethylation Dynamics during In Vivo Differentiation of Blood and Skin Stem\nCells. Mol. Cel 47, 633 \u2013647. doi:10.1016/j.molcel.2012.06.019\nBourgeois, B., and Madl, T. (2018). Regulation of Cellular Senescence via the\nFOXO4-P53 axis. FEBS Lett. 592, 2083 \u20132097. doi:10.1002/1873-3468.13057\nDunn, N. R., Vincent, S. D., Oxburgh, L., Robertson, E. J., and Bikoff, E. K. (2004).\nCombinatorial Activities of Smad2 and Smad3 Regulate Mesoderm Formationand Patterning in the Mouse Embryo. Development 131, 1717 \u20131728.\ndoi:10.1242/dev.01072\nEscamilla-Hern\u00e1ndez, R., Chakrabarti, R., Romano, R. A., Smalley, K., Zhu, Q., Lai,\nW., et al. (2010). Genome-wide Search Identi \ufb01es Ccnd2 as a Direct\nTranscriptional Target of Elf5 in Mouse Mammary Gland. BMC Mol. Biol.\n11, 68. doi:10.1186/1471-2199-11-68\nGarcia-Ojalvo, J., and Martinez Arias, A. (2012). Towards a Statistical Mechanics of\nCell Fate Decisions. Curr. Opin. Genet. Dev. 22, 619 \u2013626. doi:10.1016/\nj.gde.2012.10.004\nGarg, A., Hannan, A., Wang, Q., Collins, T., Teng, S., Bansal, M., et al. (2018). Fgf-\ninduced Pea3 Transcription Factors Program the Genetic Landscape for CellFate Determination. Plos Genet. 14, e1007660-20. doi:10.1371/\njournal.pgen.1007660\nGoode, D. K., Obier, N., Vijayabaskar, M. S., Lie-A-Ling, M., Lilly, A. J., Hannah,\nR., et al. (2016). Dynamic Gene Regulatory Networks Drive HematopoieticSpeci \ufb01cation and Differentiation. Dev. Cel. 36, 572 \u2013587. doi:10.1016/\nj.devcel.2016.01.024\nHan, H., Cho, J. W., Lee, S., Yun, A., Kim, H., Bae, D., et al. (2017). TRRUST V2: an\nExpanded Reference Database of Human and Mouse Transcriptional RegulatoryInteractions. Nucleic Acids Res. 46, D380 \u2013D386. doi:10.1093/nar/gkx1013\nHe, B., Xing, S., Chen, C., Gao, P., Teng, L., Shan, Q., et al. (2016). Cd8+ T Cells\nUtilize Highly Dynamic Enhancer Repertoires and Regulatory Circuitry inResponse to Infections. Immunity 45 (6), 1341 \u20131354. doi:10.1016/\nj.immuni.2016.11.009\nHorvay, K., Jard\u00e9, T., Casagranda, F., Perreau, V. M., Haigh, K., Nefzger, C. M.,\net al. (2015). Snai1 Regulates Cell Lineage Allocation and Stem Cell\nMaintenance in the Mouse Intestinal Epithelium. EMBO J. 34, 1319 \u20131335.\ndoi:10.15252/embj.201490881\nHu, G., and Chen, J. (2013). A Genome-wide Regulatory Network Identi \ufb01es Key\nTranscription Factors for Memory CD8 \u207aT-Cell Development. Nat. Commun.\n4, 2830. doi:10.1038/ncomms3830\nHuang, da. W., Sherman, B. T., and Lempicki, R. A. (2008). Systematic and\nIntegrative Analysis of Large Gene Lists Using David Bioinformatics Resources.Nat. Protoc. 4, 44 \u201357. doi:10.1038/nprot.2008.211\nHuttenhower, C., and Troyanskaya, O. G. (2008). Assessing the Functional\nStructure of Genomic Data. Bioinformatics 24, i330 \u2013i338. doi:10.1093/\nbioinformatics/btn160\nLiu, P., Dou, X., Liu, C., Wang, L., Xing, C., Peng, G., et al. (2015). Histone\nDeacetylation Promotes Mouse Neural Induction by Restricting Nodal-dependent Mesendoderm Fate. Nat. Commun. 6, 6830. doi:10.1038/\nncomms7830\nLiu, X., Robinson, G. W., and Hennighausen, L. (1996). Activation of Stat5a and\nStat5b by Tyrosine Phosphorylation Is Tightly Linked to Mammary Gland\nDifferentiation. Mol. Endocrinol. 10, 1496 \u20131506. doi:10.1210/\nmend.10.12.8961260\nMoignard, V., and G\u00f6ttgens, B. (2014). Transcriptional Mechanisms of Cell Fate\nDecisions Revealed by Single Cell Expression Pro \ufb01ling. Bioessays 36, 419 \u2013426.\ndoi:10.1002/bies.201300102\nNazarieh, M., and Helms, V. (2019). Topcontrol: A Tool to Prioritize Candidate\nDisease-Associated Genes Based on Topological Network Features. Sci. Rep. 9,\n19472. doi:10.1038/s41598-019-55954-6\nNazarieh, M., Wiese, A., Will, T., Hamed, M., and Helms, V. (2016). Identi \ufb01cation\nof Key Player Genes in Gene Regulatory Networks. BMC Syst. Biol. 10, 88.\ndoi:10.1186/s12918-016-0329-5\nNazarieh, M. (2018). Understanding Regulatory Mechanisms Underlying Stem Cells\nHelps to Identify Cancer Biomarkers . Dissertation. Saarbruecken, Germany:\nSaarland University. doi:10.22028/D291-27265\nPavlidis, P., and Noble, W. S. (2001). Analysis of Strain and Regional Variation in\nGene Expression in Mouse Brain. Genome Biol. 2, RESEARCH0042.\ndoi:10.1186/gb-2001-2-10-research0042\nRhee, C., Lee, B. K., Beck, S., Anjum, A., Cook, K. R., Popowski, M., et al. (2014).\nArid3a Is Essential to Execution of the First Cell Fate Decision via Direct\nEmbryonic and Extraembryonic Transcriptional Regulation. Genes Dev. 28,\n2219 \u20132232. doi:10.1101/gad.247163.114Rothenberg, E. V., Ungerb\u00e4ck, J., and Champhekar, A. (2016). Forging\nT-Lymphocyte Identity: Intersecting Networks of Transcriptional Control.Adv. Immunol. 129, 109 \u2013174. doi:10.1016/bs.ai.2015.09.002\nSertorio, M., Du, W., Amarachintha, S., Wilson, A., and Pang, Q. (2017). In Vivo\nRNAi Screen Unveils PPAR \u03b3as a Regulator of Hematopoietic Stem Cell\nHomeostasis. Stem Cel Rep. 8, 1242 \u20131255. doi:10.1016/j.stemcr.2017.03.008\nSugiyama, D., Inoue-Yokoo, T., Fraser, S. T., Kulkeaw, K., Mizuochi, C., and Horio,\nY. (2011). Embryonic Regulation of the Mouse Hematopoietic Niche.Scienti \ufb01cWorldJournal 11, 1770 \u20131780. doi:10.1100/2011/598097\nT\u00f3thov\u00e1, Z., Kollipara, R., Huntly, B. J., Lee, B. H., Castrillon, D. H., Cullen, D. E.,\net al. (2007). FoxOs Are Critical Mediators of Hematopoietic Stem Cell\nResistance to Physiologic Oxidative Stress. Cell 128, 325 \u2013339. doi:10.1016/\nj.cell.2007.01.003\nZ a n d i ,S . ,M \u00e5 n s s o n ,R . ,T s a p o g a s ,P . ,Z e t t e r b l a d ,J . ,B r y d e r ,D . ,a n d\nSigvardsson, M. (2008). EBF1 Is Essential for B-Lineage Priming andEstablishment of a Transcription Factor Network in Common\nLymphoid Progenitors. J. Immunol. 181, 3364 \u20133372. doi:10.4049/\njimmunol.181.5.3364\nCon\ufb02ict of Interest: The authors declare that the research was conducted in the\nabsence of any commercial or \ufb01nancial relationships that could be construed as a\npotential con \ufb02ict of interest.\nCopyright \u00a9 2021 Nazarieh, Hoeppner and Helms. This is an open-access article\ndistributed under the terms of the Creative Commons Attribution License (CC BY).The use, distribution or reproduction in other forums is permitted, provided the\noriginal author(s) and the copyright owner(s) are credited and that the original\npublication in this journal is cited, in accordance with accepted academic practice.No use, distribution or reproduction is permitted which does not comply withthese terms.APPENDIX\nHSC/equals(HSC >MPP1) & (MPP1 >MPP2) & (MPP2 >CLP) &\n(CLP >CD4) & (CLP >CD8) & (CLP >B cell) & (MPP2 >CMP)\n& (CMP >GMP) & (CMP >MEP) & (MEP >Eryth) & (GMP >\nGranu) & (GMP >Mono)\nMPP1 /equals(HSC <MPP1) & (MPP1 >MPP2) & (MPP2 >CLP) &\n(CLP >CD4) & (CLP >CD8) & (CLP >B cell) & (MPP2 >CMP)\n& (CMP >GMP) & (CMP >MEP) & (MEP >Eryth) & (GMP >\nGranu) & (GMP >Mono)\nMPP2 /equals(HSC <MPP1) & (MPP1 <MPP2) & (MPP2 >CLP) &\n(CLP >CD4) & (CLP >CD8) & (CLP >B cell) & (MPP2 >CMP)\n& (CMP >GMP) & (CMP >MEP) & (MEP >Eryth) & (GMP >\nGranu) & (GMP >Mono)\nCLP/equals(HSC <MPP1) & (MPP1 <MPP2) & (MPP2 <CLP) &\n(CLP >CD4) & (CLP >CD8) & (CLP >B cell) & (MPP2 >CMP)\n& (CMP >GMP) & (CMP >MEP) & (MEP >Eryth) & (GMP >\nGranu) & (GMP >Mono)\nCMP /equals(HSC <MPP1) & (MPP1 <MPP2) & (MPP2 >CLP) &\n(CLP >CD4) & (CLP >CD8) & (CLP >B cell) & (MPP2 <CMP)\n& (CMP >GMP) & (CMP >MEP) & (MEP >Eryth) & (GMP >\nGranu) & (GMP >Mono)MEP /equals(HSC <MPP1) & (MPP1 <MPP2) & (MPP2 >CLP) &\n(CLP >CD4) & (CLP >CD8) & (CLP >B cell) & (MPP2 <CMP)\n& (CMP >GMP) & (CMP <MEP) & (MEP >Eryth) & (GMP >\nGranu) & (GMP >Mono)\nGMP /equals(HSC <MPP1) & (MPP1 <MPP2) & (MPP2 >CLP) &\n(CLP >CD4) & (CLP >CD8) & (CLP >B cell) & (MPP2 <CMP)\n& (CMP <GMP) & (CMP >MEP) & (MEP >Eryth) & (GMP >\nGranu) & (GMP >Mono)\nCD4/equals(HSC <MPP1) & (MPP1 <MPP2) & (MPP2 <CLP) &\n(CLP <CD4) & (CLP >CD8) & (CLP >B cell) CD8 /equals(HSC <\nMPP1) & (MPP1 <MPP2) & (MPP2 <CLP) & (CLP >CD4) &\n(CLP <CD8) & (CLP >B cell)\nB cell /equals(HSC <MPP1) & (MPP1 <MPP2) & (MPP2 <CLP) &\n(CLP >CD4) & (CLP >CD8) & (CLP <B cell)\nEryth /equals(HSC <MPP1) & (MPP1 <MPP2) & (MPP2 <CMP) &\n(CMP >GMP) & (CMP <MEP) & (MEP <Eryth) & (GMP >\nGranu) & (GMP >Mono)Granu /equals(HSC <MPP1) & (MPP1 <\nMPP2) & (MPP2 <CMP) & (CMP <GMP) & (CMP >MEP) &\n(MEP >Eryth) & (GMP <Granu) & (GMP >Mono)Mono /equals\n(HSC <MPP1) & (MPP1 <MPP2) & (MPP2 <CMP) & (CMP <\nGMP) & (CMP >MEP) & (MEP >Eryth) & (GMP >Granu) &\n(GMP <Mono)", "arxiv38": "Identi \ufb01cation of Biomarkers\nControlling Cell Fate In Blood Cell\nDevelopment\nMaryam Nazarieh1,2, Marc Hoeppner1and Volkhard Helms2*\n1Institute of Clinical Molecular Biology, Christian-Albrecht-University of Kiel, Kiel, Germany,2Center for Bioinformatics, Saarland\nUniversity, Saarbruecken, Germany\nA blood cell lineage consists of several consecutive developmental stages starting from the\npluri- or multipotent stem cell to a state of terminal differentiation. Despite their importancefor human biology, the regulatory pathways and gene networks that govern thesedifferentiation processes are not yet fully understood. This is in part due to challengesassociated with delineating the interactions between transcription factors (TFs) and theircorresponding target genes. A possible step forward in this case is provided by theincreasing amount of expression data, as a basis for linking differentiation stages and geneactivities. Here, we present a novel hierarchical approach to identify characteristicexpression peak patterns that global regulators excert along the differentiation path ofcell lineages. Based on such simple patterns, we identi \ufb01ed cell state-speci \ufb01c marker genes\nand extracted TFs that likely drive their differentiation. Integration of the mean expressionvalues of stage-speci \ufb01c\u201ckey player \u201dgenes yielded a distinct peaking pattern for each\nlineage that was used to identify further genes in the dataset which behave similarly.Incorporating the set of TFs that regulate these genes led to a set of stage-speci \ufb01c\nregulators that control the biological process of cell fate. As proof of concept, weconsidered two expression datasets covering key differentiation events in blood cellformation of mice.\nKeywords: developmental genes, transcription factor, gene ontology, gene expression, cell fate, master regulator,\ncell lineage\n1 INTRODUCTION\nCell fate describes a biological program, which determines how a less specialized cell type develops\ninto a more specialized one. For each transition out of a particular state, this involves a decisionbetween either self-renewal or differentiation into daughter cells ( Garcia-Ojalvo and Martinez Arias,\n2012 ). It is well accepted that such processes are tightly regulated by transcriptional networks,\ntypically centered around a discrete number of transcription factors ( Moignard and G\u00f6ttgens, 2014 ).\nKnowing the \u201ckey players \u201dinvolved in these events may thus not only serve as a predictive marker to\nhelp determining differentiation stages of cells, but furthermore could potentially be useful forclinical purposes, for example by aiding in the search for therapeutic targets across different diseasesinvolving aberrations in the composition of cell types or stages, respectively ( An et al., 2014 ). One of\nthe best-studied examples are blood cells, which are already widely used in diagnostics. Especially incomplex blood-related diseases such as leukemia, understanding the manifestation of the disease andmonitoring its progression and response to treatment could greatly bene \ufb01t from a deeperEdited by:\nAna\u00efs Baudot,\nINSERM U1251 Centre de G\u00e9n\u00e9tique\nM\u00e9dicale de Marseille (MMG), France\nReviewed by:\nDelphine Potier,\nINSERM U1104 Centre\nd\u2019immunologie de Marseille-Luminy\n(CIML), France\nEmmanuelle Becker,\nUniversity of Rennes 1, France\n*Correspondence:\nVolkhard Helms\nvolkhard.helms@bioinformatik.uni-\nsaarland.de\nSpecialty section:\nThis article was submitted to\nNetwork Bioinformatics,\na section of the journal\nFrontiers in Bioinformatics\nReceived: 13 January 2021\nAccepted: 01 July 2021\nPublished: 19 July 2021\nCitation:\nNazarieh M, Hoeppner M and Helms V\n(2021) Identi \ufb01cation of Biomarkers\nControlling Cell Fate In Blood\nCell Development.\nFront. Bioinform. 1:653054.\ndoi: 10.3389/fbinf.2021.653054understanding of the underlying regulatory processes and key\n\u201cactors \u201dthat govern blood cell differentiation. However,\ndelineating lineage-speci \ufb01c regulatory networks is a\nchallenging task, typically requiring the costly integration of\nmultiple data types; particularly from various \u201comics \u201d\ntechnologies. Previous work using a complex multi-omicsapproach identi \ufb01ed a set of 16 \u201cglobal regulators \u201dthat drive\nthe differentiation of blood cells across six discrete stages -Embryonic stem cells (ESCs), Mesoderm (MES),Hemangioblast (HB), Hemogenic endothelium (HE),Hematopoietic progenitor (HP) and Macrophages (MAC)(Goode et al., 2016 ). It is very plausible to assume that these\nglobal regulators stand at the top of the regulatory hierarchy andindirectly govern particular cellular identity. Interestingly,\nalthough the overall network is preserved across\ndevelopmental stages, analysis of the characteristic changes inexpression ( Figure 1 ) suggests that these \u201cglobal regulators \u201d\ncontribute differently at various stages. We have previouslydeveloped a method that reconstructs the core components ofa regulatory network from gene expression data and de \ufb01nes a so-\ncalled \u201cminimum dominating set \u201d(MDS), i.e. the minimum set of\nTFs that control the entire network by their interactions. Amodi \ufb01cation of this concept is the \u201cminimum connecteddominating set \u201d(MCDS), which searches for a minimum\nnumber of genes that are connected and control theunderlying co-network ( Nazarieh et al., 2016 ;Nazarieh, 2018 ;\nNazarieh and Helms, 2019 ). When applied to expression data,\none should expect that a key transcription factor being moststrongly associated with a certain differentiation stage exhibits apeak in expression at that stage compared to the other stages ofthat lineage. Genes directly regulated by such a key player can beexpected to somehow mimic its expression pro \ufb01le, thus allowing\ntheir assignment to a given regulator and cellular stage. In thepresent work, we introduce an approach to identify stage-speci \ufb01c\nkey regulators that are likely to control cell fate in adifferentiation/developmental or resistance pathway.PathDevFate is a method for identifying the set of connected\nin\ufb02uencers and connectors that play roles in cell differentiation\nand cell commitment. The method implements a work \ufb02ow to\ninitially identify in \ufb02uencers that follow a lineage-speci \ufb01c pattern\nde\ufb01ned by integrating cell-speci \ufb01c genes and TFs in a stage. Then,\nit identi \ufb01es the set of TFs that regulate these in \ufb02uencers. Finally, it\nintroduces a regulatory pathway of a connected set of in \ufb02uencers\nand connectors whereby the path length is determined by thenumber of in \ufb02uencers and connectors. We demonstrate the\nusefulness of this approach by the example of two expression\nFIGURE 1 | Expression of 16 global regulators driving hematopoietic speci \ufb01cation for six stages of blood development starting from ESCs (stage 1) up to terminally\ndifferentiated macrophages (stage 6) ( Goode et al., 2016 ).data sets that were used to investigate blood cell differentiation in\nmice ( Bock et al., 2012 ;Goode et al., 2016 ).\n2 METHODS\n2.1 Overview\nFigure 2 illustrates the work \ufb02ow of the entire approach. First, we\nderive diagnostic expression pro \ufb01les to identify genes that are\nlikely centrally involved in a cellular differentiation path(Figure 2A ). Next, we integrate the expression pattern of\nstage-speci \ufb01c developmental genes across full individual\nlineages ( Figure 2B ). From this, a set of correlated genes and\nassociated TFs is identi \ufb01ed ( Figure 2C ). This preliminary\nnetwork is further re \ufb01ned by incorporating experimentally\nvalidated data e.g. from a TF-gene interaction database such as\nTRRUST ( Han et al., 2017 )t od e \ufb01ne a sub-regulatory network\nwhose target genes follow the aforementioned lineage-speci \ufb01c\nexpression pattern and have a well-de \ufb01ned TF regulator\n(Figure 2D ). The regulatory relationships are modeled as a\ndirected graph as is commonly done in such analyses. Thesource nodes are TFs and target nodes can be genes and/orTFs. The edges correspond to the regulatory interactions betweenthem. Finally, we present an algorithm that \ufb01nds the shortest\nregulatory path that connects the target genes that are tightlyregulated by multiple TFs ( Figure 2E ). We suggest that the set of\ntarget genes and TFs that connect them forms an importantgroup of driver genes for the respective cell fate process. Afunctional enrichment analysis is then used to investigate thebiological processes these identi \ufb01ed TFs have previously shown to\nbe involved in. Details of the individual steps of this algorithm\nand the motivation behind the steps will be explained below insection 2.4 .\n2.2 Datasets\nThe\ufb01rst case study is based on genome-wide RNA-seq expression\npro\ufb01les (Goode et al., 2016 ) in form of FPKM values across six\nconsecutive differentiation stages, namely ESC, MES, HB, EH, HPand MAC (GEO accession GSE69080). The microarray data forthe second case study were published by Bock et al. (2012) .A s\nmentioned in that paper, the data were obtained as CEL \ufb01les and\nnormalized in the same order to reduce batch effects. The data\nincludes 13 cell populations sorted by FACS analysis across 6lineages.\n2.3 Regulatory Relationships\nData on the relationship between TFs and their target gene(s)were taken from the TRRUST database v2 ( Han et al., 2017 ) that\nwas compiled based on literature curation. This release of thedatabase includes 6552 TF-target interactions for 828 mouse TFs.\nFIGURE 2 | Overview of how biomarkers are identi \ufb01ed that control or drive a developmental cell fate process. (A)Fictitious expression pro \ufb01les (y-axis) of six selected\ntranscription factors (TFs) across six developmental stages ( x-axis). TFs are identi \ufb01ed having peak expression in the respective stage. This step yields the stage-speci \ufb01c\nkey regulators (TFs). (B)A lineage-speci \ufb01c pattern is constructed by integrating the stage-speci \ufb01c patterns across the lineage. (C)Further genes are identi \ufb01ed having\nhighly correlated expression pro \ufb01les to one of the stage-speci \ufb01c key regulators of (B)(here, one of the TFs peaking in the terminal stage MAC). (D)A gene-regulatory\n(GRN) network is constructed including all stage-speci \ufb01c key regulators and their correlated target genes. This GRN includes TFs and target genes from all stages. (E)A\nregulatory pathway is identi \ufb01ed (see methods) that connects (blue colored nodes) all \u201cin\ufb02uencer \u201dnodes (red colored nodes).2.4 Work \ufb02ow: Prioritization of the\nCandidates of the Cell Fate Process\n1) As input, we use existing knowledge about a small gold-\nstandard set of tissue-speci \ufb01c global regulators. All\ndifferentiation stages of the particular cell lineage underconsideration are arranged in a linear sequence (seeFigure 2A ). First, we identify which ones of the mentioned\nglobal regulators peak in the individual stages.\n2) Then, we aim at identifying an expression signature of each\nparticular stage. For this, we now identify further genes andTFs having a closely matching expression pro \ufb01le to the stage-\nspeci\ufb01c expression pattern of the global regulators peaking in\nthis stage just de \ufb01ned. The genes identi \ufb01ed in this manner are\ntermed \ufb01rst layer candidates. (see Figure 2A ).\n3) After having identi \ufb01ed sets of signature genes for\nparticular stages, we now combine the stage-speci \ufb01c\nexpression pattern across the entire lineage. The meanexpression value of all identi \ufb01ed stage-speci \ufb01c genes is\nconsidered as a representative for each stage. Thisaveraging is done to capture the typical behavior of allstage-speci \ufb01c genes by a single pro \ufb01le. This then yields a\nlineage-speci \ufb01c pattern. (see Figure 2B ). Alternatively, one\ncould have normalized the expression values of all stage-speci \ufb01c genes to a particular interval.\n4) In the next step, we \ufb01nd further genes and TFs having an\nexpression pattern that closely mimics the integrated lineage-\nspeci\ufb01c expression pattern. These are then termed second\nlayer candidates. (see Figure 2C ).\n5) Now, we determine TFs that regulate the candidates in the\nsecond layer identi \ufb01ed in step 4. These are then termed third\nlayer candidates.\n6) We now aggregate the regulators identi \ufb01ed in step 5 and the\ntarget genes identi \ufb01ed in step 4 into a regulatory subnetwork.\nBy way of design, this network includes those genes having aparticular lineage-speci \ufb01c expression pattern and their\nregulators. We consider this subnetwork of the full\nregulatory network of a cell as the essential part governing\nthe fate of a particular cell lineage. (see Figure 2D ).\n7) Now, we determine the high-indegree nodes in the regulatory\nsubnetwork identi \ufb01ed in step 6. The idea behind this is that\nthese hub genes contribute a major part of all regulatoryactivity in the constructed subnetwork. (see red color nodes intheFigure 2E ).\n8) Identify additional connector nodes that connect the nodes\nidenti \ufb01ed in step 7 (see blue color nodes in the Figure 2E ). The\nidea of this step is that this connected pathway forms anequivalent of a \u201cregulatory pathway \u201d. This step has an analogy\nto the concept of an MCDS of dominating nodes that we\nde\ufb01ned in our earlier work ( Nazarieh et al., 2016 ). The fourth\nlayer is a regulatory subnetwork including the set of\nin\ufb02uencers and connectors.\nThe implemented program code for the two afore-mentioned\ndatasets is available at: https://github.com/ikmb/KeyDevelopmentalFate in the code section: (KeyDevFate_Goode2016.R, KeydevFate_Bock2012.R)2.5 Randomization Algorithm\nInput: A set of correlated genes following an integrated pattern ofgene expression across the stages in one lineage. Output: Overlapsigni\ufb01cance of the correlated genes based either on the original\ndata or on the shuf \ufb02ed data.\n1) Shuf \ufb02e the data column-wise, whereby each column\ncorresponds to the expression value of the genes in acertain stage.\n2) Identify the set of correlated genes following the integrated\nexpression pattern based on shuf \ufb02ed data.\n3) Compute the overlap between the correlated genes in real data\nand the correlated genes in the shuf \ufb02ed data.\n4) To characterize the statistical signi \ufb01cance of the identi \ufb01ed\ngenes, we compared the obtained result to analogous results\nidenti \ufb01ed based on randomly shuf \ufb02ed data. If a considerable\npart of the originally correlated genes were also identi \ufb01ed\nfrom shuf \ufb02ed data, this would suggest that the \ufb01ndings are\ninsigni \ufb01cant. Precisely, we counted the number of times when\nthe overlap (Jaccard index) between the correlated genes in theoriginal data and the correlated genes in 1000 shuf \ufb02ed data\nsets is greater than 0.05. Here, the Jaccard index was computedas the ratio of the intersection between the set of correlatedgenes and the resampled data over the union of the two sets.\nThe implemented code for the \ufb01rst case study is available at:\nhttps://github.com/ikmb/KeyDevelopmentalFate in the code\nsection: RandomizationAlgorithm_Goode2016.R\n2.6 PathDevFate Algorithm: Find the\nRegulatory Path That Involves a Certain Setof Nodes\nInput: A network that is obtained from step 6 of the above-\nmentioned pipeline. Output: A set of genes and TFs with assignedroles of in \ufb02uencers and connectors.\n1) Identify the set of nodes that are regulated by at least one TF.\n2) Specify a threshold (here denoted by \u201cl\u201d) as a measure of in-\ndegree threshold.\n3) Select the nodes whose number of incoming edges exceeds \u201cl\u201d.\nThese are termed \u201cin\ufb02uencers \u201d.\n4) Find a path that connects the in \ufb02uencer nodes by adding a\nminimum number of further (Steiner) nodes ( \u201cconnectors \u201d).\nThe implemented code for the algorithm is available at:\nhttps://github.com/ikmb/KeyDevelopmentalFate in the codesection (PathDevFate) In step 2, a threshold is introduced thatprovides a balance between the number of in \ufb02uencers with\nrespect to the number of incoming edges and the number of\nTFs that are supposed to connect them (which depends on thedistance these in \ufb02uencers have from each other). This measure\nserves to capture the high-indegree nodes and imposes aminimum number of TFs to the regulatory pathway. The ideaof this algorithm has been taken from our MCDS algorithm(Nazarieh et al., 2016 ). In the MCDS algorithm, after \ufb01nding the\ndominator nodes, the next step is to \ufb01nd the connectors andminimise the number of dominators and connectors as long as\nconnectivity persists and the underlying connected network iscovered by the MCDS. In the new algorithm, after \ufb01nding the\nconnectors, we keep the set of in \ufb02uencer nodes (nodes with high\nin-degree) constant and then minimize the number of connector\nnodes. Based on the enrichment analysis, in \ufb02uencers take part\nmainly in the development and differentiation processes, whereasconnectors may in addition also contribute to cell fatecommitment.\n2.7 Functional Annotation\nThe biological function of the genes in each stage was evaluatedusing the enrichment analysis tool provided by the DAVID portalof NIH (version 6.8) based on the functional categories in GODirect ( Huang et al., 2008 ) and all Mus musculus genes as\nbackground. p-values below the threshold of 0.05 as obtained\nby the hypergeometric test were adjusted for multiple testingusing the Benjamini and Hochberg (BH) correction ( Benjamini\nand Hochberg, 1995 ).\n3 RESULTS\nThe main goal of this study was to derive an approach that\nidenti \ufb01es a connected set of cell-fate regulating genes. For this, we\nimplemented the hierarchical strategy illustrated in Figure 2 . The\n\ufb01rst layer includes the stage-speci \ufb01c TFs and genes that are\ninvolved in cellular differentiation. The second layer consistsof further genes and TFs following the same integrated stage-speci\ufb01c expression pattern. The third layer is formed by those TFs\nthat regulate the candidates in the second layer. A regulatorynetwork was constructed from the correlated genes following theintegrated expression pattern with a set of TFs that regulate themwhich forms the candidates in the fourth layer. Finally, we derived\na shortest regulatory path that connects the set of correlated genes\nthat are regulated by multiple TFs (PathDevFate, see Methods). Inshort, the target genes that are tightly regulated by multipletranscription factors are \ufb02agged as \u201cin\ufb02uencers \u201dand the nodes\nthat connect them as \u201cconnectors \u201d. As proof of concept, we\napplied the method to two datasets of murine blooddifferentiation. The \ufb01rst case study was a lineage of six stages\nstarting at ESC and leading to MAC ( Goode et al., 2016 ). We then\nextended the concept by setting rules de \ufb01ned for cellular\ndifferentiation in ( Artyomov et al., 2010 ) and applied it to\nexpression data from across 6 murine cell lineages in bloodformation ( Bock et al., 2012 ) starting at HSC and leading to\neither CD4 T-cells, CD8 T-cells, B cells, erythrocytes,\ngranulocytes or monocytes, respectively.\n3.1 Dataset 1: Differentiation of Murine\nBlood Stem Cells\nFrom published multi-omics data on murine blood stem cells\n(Goode et al., 2016 ), we retrieved the gene expression pro \ufb01le of 16\nglobal regulators that were identi \ufb01ed in the study of ( Goode et al.,\n2016 ). These were averaged to yield a stage-speci \ufb01c expression\npattern that is considered subsequently as signature pattern. Wethen identi \ufb01ed further genes (and further TFs) having strongly\ncorrelated expression pro \ufb01les with this stage-speci \ufb01c expression\npattern. Figure 3 shows the expression pattern of the TFs that\nwere among the identi \ufb01ed correlated genes. Obviously, multiple\nTFs show peaks in each of the individual differentiation stages.\nThis analysis, yielding our \u201c\ufb01rst\u201dgene layer, identi \ufb01ed between\n197 (HP) and 692 (HB) correlated gene expression pro \ufb01les\n(Supplementary Table S1 ). Included in this are between 10\n(MAC) and 57 (HB) TFs, such as SOX2 and ESRRB. For eachstage, we considered the identi \ufb01ed genes to reconstruct functional\npro\ufb01les of the correlated genes based on enriched gene ontology\nterms (GO) ( Supplementary Tables S2 \u2013S5). In order to\nunderstand the molecular mechanisms governing eachdifferentiation stage, we next performed a functionalenrichment analysis using both gene ontology (GO) terms and\nKEGG pathways for the key transcription factors\n(Supplementary Tables S6 \u2013S11) found in each differentiation\nstage, as well as for their (known) target genes ( Supplementary\nTables S12 \u2013S17), respectively. Supplementary Table S6 for ESC\nlists GO terms such as stem cell differentiation (GO:0048863),multicellular organism development (GO:0007275), endodermdevelopment (GO:0007492) and cell differentiation (GO:0030154), respectively. Moreover, the \ufb01ve genes Onecut1,\nEsrrb, Id1, Sox2, and Zic3 belong to the KEGG pathwaysignaling pathways regulating pluripotency of stem cells(mmu04550). Supplementary Tables S7 \u2013S11 list the enriched\nGO terms and KEGG pathways for the identi \ufb01ed TFs in MES,\nHB, HE, HP and MAC. The lists include further specialized GOterms in addition to some of the aforementioned terms such aspatterning of blood vessels (GO:0001569), cell fate commitment(GO:0045165), heart development (GO:0007507) andhemopoiesis (GO:0030097), respectively and also the KEGGpathway acute myeloid leukemia (mmu05221). Then, weinferred the set of target genes for the set of \u201ckey player \u201dTFs\nat each developmental stage from the TF-gene interactiondatabase TRRUST ( Han et al., 2017 ). Enrichment analysis for\nthe set of identi \ufb01ed target genes in the ESC stage yielded the\nenriched biological process GO terms listed in Supplementary\nTables S12 . The list includes GO terms such as proliferation (GO:\n0042127), multicellular organism development (GO:0007275),stem cell differentiation (GO:0048863), cell differentiation(GO:0030154), cell fate commitment (GO:0045165), celldevelopment (GO:0048468) and cell proliferation (GO:0008283), respectively. Supplementary Tables S13 \u2013S17list the\nenriched GO terms for the target genes in other developmental\nstages. In addition to common GO terms, distinct GO terms, suchas BMP signaling pathway involved in heart development (GO:0061312) and Wnt signalling pathway (GO:0016055) are added\nin the MES stage. More specialized GO terms appear in later\nstages HB, HE, and HP, such as liver development (GO:0001889),B cell lineage commitment (GO:0002326), ear development (GO:0043583) and eye development (GO:0001654), respectively.Although the TFs identi \ufb01ed in each particular developmental\nstage also follow the aforementioned expression pattern, theyexhibit different expression levels. The histograms in Figure 4\nshow the frequency of TFs based on their expression level. Ingeneral, there are many more TFs with low expression (e.g. 0 \u201310,0\u201320 etc.) than with high expression (above 50). There is an initial\nincrease in the absolute number of patterned TFs from 13 (ESC),\n14 (MES) to 34 (HB), followed by a corresponding decline over 22\n(HE), 15 (HP) to 6 (MAC). Genes that act in the same biologicalprocesses are expected to (partially) share activity pro \ufb01les\n(Huttenhower and Troyanskaya, 2008 ).Figure 5 shows the\nmean expression of the identi \ufb01ed stage-speci \ufb01c genes. To the\naim of identifying additional members of the candidate network,we extracted genes that mimic the same expression patternexhibited by the stage-speci \ufb01c genes ( Figure 5 ). For this, we\nrequired that their expression patterns across the six stages (fromESC to MAC) showed the same monotonic expression pattern\n(i.e. Spearman rank correlation larger than 0.9) as the stage-\nspeci\ufb01c genes. This led to the identi \ufb01cation of 243 genes\n(Supplementary Table S18 ) including 13 TFs. Figure 6 shows\nthe expression pattern of those genes having perfect Spearmancorrelation of 1.0. The 13 TFs are considered as candidates for thesecond layer. To verify the statistical signi \ufb01cance of the correlated\ngenes, we resampled the data 1000 times, identi \ufb01ed patterned\ngenes in each case, and measured the overlap between thecorrelated genes in the original data set and those determinedfrom the resampled data, see Supplementary Figure S1 . The\nFIGURE 3 | Expression pattern of identi \ufb01ed TFs in six stages of ESC, MES, HB, HE, HP and MAC that follow the global expression pattern.overlap was measured based on the Jaccard index as the ratio of\nintersection between the sets of correlated genes in real data and\nin resampled data over the union of the two sets. Only 3 out of\n1,000 cases had a similarity higher than 0.05 between thecorrelated genes in the original data and the correlated genesin the shuf \ufb02ed data ( p-value of 0.003). Thus, the stage-speci \ufb01c\ngenes identi \ufb01ed in the real data are rarely identi \ufb01ed based on\nrandomly shuf \ufb02ed data, which strengthens the biological\nmeaningfulness of this analysis. Next, we sought to identifyknown regulators of this initial set of co-expressed genes usingdata from the TRRUST database. This analysis resulted in 83 TFswhich then formed the third layer of our analysis(Supplementary Table S19 ). The intersection with cell-speci \ufb01c\nTFs of ESC, MES, HB, HE, HP and MAC identi \ufb01ed in the \ufb01rst\nlayer includes (Etv4, Hdac1, Prdm16, Sox2), (Foxo4), (Atf2, Etv2,Gata4, Msx2, Snail1), (Ebf1, Smad3), (Stat5a, Stat5b, Thra),(Arid3a, Stat5b), respectively. All these genes were previously\nreported to have speci \ufb01c roles in cell fate commitment ( Liu et al.,\n1996 ;Avilion et al., 2003 ;Dunn et al., 2004 ;Beuling et al., 2008 ;\nZandi et al., 2008 ;Ackermann et al., 2011 ;Rhee et al., 2014 ;\nBabajko et al., 2015 ;Horvay et al., 2015 ;Liu et al., 2015 ;Bourgeois\nand Madl, 2018 ;Garg et al., 2018 ).Supplementary Table S20\nshows the functional enrichment analysis (biological process) andKEGG pathways for the 83 TFs along with p-values, using a\nhypergeometric test and adjusted for multiple testing using theBenjamini and Hochberg (BH) correction ( Benjamini and\nHochberg, 1995 ) below a threshold of \u22640.05. Notable GO\nterms on this list include: GO:0008285 negative regulation ofcell proliferation, GO:0008284 positive regulation of cell\nproliferation GO:0043066 negative regulation of apoptotic\nprocess, GO:0043065 positive regulation of apoptotic process,GO:0002360 T cell lineage commitment, GO:1902262 apoptotic\nFIGURE 4 | Histograms of stage-speci \ufb01c TF expression levels (FPKM values) in the blood cell lineage show a quasi-exponential decay. Eg. for ESC, 13 TFs have\nexpression levels between 0 and 20, 6 TFs have expression levels between 20 \u201340.process involved in patterning of blood vessels, GO:0048863 stem\ncell differentiation, GO:0030154 cell differentiation, GO:0007507\nheart development, GO:0007275 multicellular organismdevelopment, GO:0033077 T cell differentiation in thymus,and GO:0030217 T cell differentiation. Finally, usinginformation from the TRRUST database, a regulatory networkwas reconstructed whose nodes are con \ufb01ned to the candidates of\nthe second and third layer. The network demonstrates theconnectivity between the candidates in the second and thirdlayer. The number of TFs in the network exceeds the number oftarget genes so that the network contains few genes with a highnumber of incoming edges. In the network having 90\ninteractions, the 83 regulators were taken from the third layer\nand 21 target genes taken from the second layer ( Supplementary\nTable S18 ). This network contains the three high-indegree nodes\nCcnd2, Pparg and Ihh in the largest connected component thatare connected through Msx2 and Foxo1, see Figure 7 . Indeed,\nprevious experimental work established that these genes and TFshave important functions in hematopoiesis: Ccnd2 as a target ofElf5 plays an important role in development and differentiation(Escamilla-Hern\u00e1ndez et al., 2010 ); Pparg is a regulator of\nhematopoietic stem cell homeostasis ( Sertorio et al., 2017 ); Ihh\nprograms developing mesoderm cells to become hematopoietic or\nvascular cells ( Sugiyama et al., 2011 ), and suppression of Foxo1\nexhibits myeloid lineage expansion and lymphoid developmentalabnormalities ( T\u00f3thov\u00e1 et al., 2007 ).\n3.2 Dataset 2: Blood Stem Cell\nDifferentiation Along Multiple Lineages\nThe previous section focused on a single example of cellular\ndifferentiation in blood formation, starting from previouslycharacterized \u201ckey\u201dtranscription factors. Therefore, we nextexpanded our initial approach and applied our concept of\n\u201ckey\u201dexpression pro \ufb01les to a more complex dataset, consisting\nof six differentiation lineages starting at mouse blood stem cells(Bock et al., 2012 ). Differentiation of these lineages was shown by\nthe authors to follow a gradual path of changing expressionpro\ufb01les through up to six steps into a fully differentiated cell\n(Figure 8 ). To derive the developmental genes and TFs we not\nonly relied on the cell-speci \ufb01c expression pattern as outlined\nabove, but also exploited the computational model and the rulessuggested by ( Artyomov et al., 2010 ). Within this model, each cell\nis de \ufb01ned by two network layers representing expression and\nepigenetic states. A set of master regulators de \ufb01ne the cellular\nidentity. On the event of cellular differentiation, the activatedgene module suppresses the activity of the competitor cells eitherin relationship of parent cell or daughter branch cells. Wemodi \ufb01ed the rules to the extent that developmental regulators\nspeci\ufb01c to each cell state have superiority in terms of gene\nexpression level over neighboring stages while following thecell-speci \ufb01c expression pattern from the top of the hierarchy\nuntil terminally differentiated cells. The afore-mentionedpatterns led to the identi \ufb01cation of between 4 and 128 cell-\nstage speci \ufb01c genes for the different cell types under consideration\n(Supplementary Table S21 ), including several well-known TFs.\nFigure 9 represents the changes of mean expression value of\nconstituent cells along the cell lineages starting from HSC until aterminally differentiated cell type (e.g. CD4 T-cell, CD8 T-cell,B cell, Erythrocyte (Eryth), Granulocyte (Granu) or Monocyte(Mono)). The stage-speci \ufb01c genes of erythrocytes and\ngranulocytes have particularly high expression levels in theterminally differentiated stage. For CD4 T-cells, CD8 T-cells,B cells, and monocytes, an inverse trend is observed.\nFIGURE 5 | Depiction of the mean expression of stage-speci \ufb01c genes\nacross six stages of blood cell differentiation (from ESC to MAC).\nFIGURE 6 | Depiction of the correlated genes. The red curve shows the\npattern of integrated mean expression of all six stages in the lineage. The blackcurves represent correlated genes that have perfectly positive correlation\nbased on the Spearman method (threshold /equals1).Supplementary Table S22 shows the number of lineage-speci \ufb01c\ncorrelated genes including the involved TFs. Additionally, it\ndepicts the number of TFs that regulate the correlated genes\ninferred from the TRRUST database and the number of identi \ufb01ed\ncorrelated genes that are targets of these TFs. Supplementary\nTables S23 \u2013S28contain the GO terms and KEGG pathways for\nthe set of TFs that regulate the correlated genes mentioned in thesecond layer. GO terms such as GO:0045165, GO: 0001709, GO:0001708 annotated to cell fate commitment, cell fatedetermination and cell fate speci \ufb01cation have been identi \ufb01ed\nin the downstream analysis of almost all the lineage-speci \ufb01c TFs.\nSupplementary Table S29 shows the network statistics for the six\nlineages. As mentioned before, these networks consist of the\nderived TFs in the third layer and the target genes of the second\nlayer. The network size lies between 81 and 272 nodes having 66up to 293 interactions. Figure 10 illustrates the CD8 network\nconstructed by the TFs and their target genes that overlap withthe correlated genes in the second layer. The PathDevFate\nprogram highlighted genes (in \ufb02uencers colored red and\nconnectors colored blue) that reside along the path to connect\nthe in \ufb02uencers. Supplementary Tables S30 \u2013S35list these nodes\nfor the six lineages including their roles and in-degree and out-degree. Supplementary Table S36 displays the enriched GO\nterms and KEGG pathways for the set of genes and TFsinvolved in the regulatory pathway of the CD8 T-cell lineage.Among many terms related to cell differentiation and cell fate,GO: 0030217, which is annotated to the three involved genesGata3, Ctnnb1 and Runx2, stands for T cell differentiation.Possible validation experiments of our predictions would beCRISPR-Cas knock out of these genes or siRNA silencing. Our\nexpectation is that this would impair differentiation. Jun, Gata3,\nNfatc1 and Runx2 are known to be key TFs for memoryCD8 T-cell development based on a genome-wide regulatorynetwork ( Hu and Chen, 2013 ). Fli1, Smad3, Sp1, Mycn, and Tal1\nFIGURE 7 | TF-target network for the set of correlated genes derived from the TRRUST database. In \ufb02uencers (red nodes) are the stage-speci \ufb01c target genes that\nare regulated by more than \ufb01ve TFs. Connectors are TFs (blue nodes).FIGURE 8 | Red colored nodes denote the gene modules whose expression pattern are the highest among the stages in the blood differentiation. Blue color nodes\nstand for the genes whose expression pattern are lower than the red color nodes. The parent nodes above the red colored node show a gradual increase in th e\nexpression pattern and the daughter blue nodes show a gradual decrease which reaches minimal expression at the terminally differentiated cells. Arr ows point in the\ndirection of decreasing expression level.White color nodes are the cells whose expression levels are not considered for this stage. The rules are lis ted in detail in the\nAppendix :play important roles in CD8 T-cell differentiation and\ndevelopment and in forging T-lymphocyte identity ( He et al.,\n2016 ;Rothenberg et al., 2016 ).Supplementary Tables S37 \u2013S40represent the enriched GO terms and KEGG pathways associated\nwith the set of genes and TFs involved in the regulatory pathwaysof CD4 T-cell, B cell, erythrocyte and granulocyte lineages ( Bock\net al., 2012 ).\n4 DISCUSSION\nIn this work, we devised a pipeline for inferring a set of genes\nand TFs that drive the blood differentiation processcontrolling the cell fate decisions across a lineage startingat the stem cell stage leading to a terminally differentiatedstage. We started by identifying a set of genes and TFs having aparticular stage-speci \ufb01c developmental expression pattern.\nPathDevFate is a new method based on the biologicalobservations of ( Bock et al., 2012 ). We \ufb01rst retrieve the\nexpression level of a given set of global regulators across adevelopmental lineage. By averaging these, we de \ufb01ne a \u201cstage-\nspeci \ufb01c pattern \u201d. Before arriving at our pattern de \ufb01nition, we\nalso experimented with a \u201cloosened \u201dcriterion where a stage-\nspeci \ufb01c gene could e.g. violate one out of six conditions. But\nthis led to a large increase in the number of identi \ufb01ed genes,\nwhich confused their downstream analysis. As cell fateregulators, we consider those genes that adhere exactly tothe given expression pattern of stage-speci \ufb01c genes across the\nlineage and are regulated and connected by a set of TFs. Othertechniques such as Spearman correlation or the methodintroduced by ( Pavlidis and Noble, 2001 ) may identify\ngenes where the expression does not peak in the speci \ufb01ed\nstage, but that have optimal matches for the other stages. Afterdetermining stage-speci \ufb01cp a t t e r n ,w ei d e n t i f yf u r t h e rg e n e s\nFIGURE 9 | Mean expression of stage-speci \ufb01c genes for the cells in each lineage for the six lineages CD4 T-cell, CD8 T-cell, B cell, erythrocyte, granulocyte and\nmonocyte.\nFIGURE 10 | The set of genes and TFs involved in the regulatory\npathway for CD8 T-cells. In \ufb02uencers (red nodes) are the target genes that are\nregulated by more than \ufb01ve TFs. Connectors are TFs (blue nodes).having highly correlated expression pro \ufb01l e sw i t ht h i sp a t t e r n\nand term them \u201cstage-speci \ufb01c\u201dgenes and TFs. The stage-\nspeci \ufb01c genes which follow the cell-speci \ufb01c pattern have\ndifferent expression levels. Therefore, we consider the mean\nexpression of all stage-speci \ufb01c genes as a representative value of\nall the genes with the same pattern. \u201cLineage-speci \ufb01cg e n e s \u201drefer to\nthe set of genes that follow the expression \ufb02uctuation of the stage-\nspeci\ufb01c genes in the respective lineage. As described before, a TF-\ngene regulatory network is reconstructed in layer 4 of the work \ufb02ow.\nThat comprises of TFs (connectors) and targets (in \ufb02uencers). Here,\nwe selected CD4 T-cell, CD8 T-cell, and B cell lineages to elucidatethe main biological roles of the in \ufb02uencers and connectors. The set\nof TFs is analyzed in Supplementary Tables S23 \u2013S25.T h e\nenrichment analysis of the set of target genes (in \ufb02uencers) is\npresented in Supplementary File S2 . Based on the analysis,\nin\ufb02uencers take part mainly in the developmental and\ndifferentiation processes, whereas connectors in additioncontribute to cell fate commitments. At the top level of thispipeline, we introduce a regulatory pathway in a gene-regulatorynetwork of TFs and target genes taking into account the identi \ufb01ed\ncorrelated genes and the TFs that regulate them. The regulatorypathway consists of a set of in \ufb02uencers that are regulated by\nmultiple TFs and a set of connector TFs that join them. Thequality of this pathway depends on several points: First of all, thecorrelation threshold is a variable unless only perfectly correlatedgenes are to be considered. After that, the number of TFs that\nregulate these genes relies on the database(s) and the type of\ninteraction which can be either experimentally con \ufb01rmed\n(though likely not in the particular case investigated here) orpredicted, or both. After all, the in-degree threshold forin\ufb02u e n c e r si sa l s oav a r i a b l e .At i g h t e rt h r e s h o l dl e a d st oa\nlower number of in \ufb02uencers but is not correlated to the size of\nthe regulatory pathway. As shown in Supplementary Figure S2 ,\nin the lineages of CD8 T-cells and granulocyte the number ofconnectors dramatically increases after a certain threshold. Thisobservation indicates that those high-indegree in \ufb02uencers are\nvery distant from each other an d the algorithm needs to inject\nmany connectors to join them. In principle, this work divides\nthe identi \ufb01e dg e n e sa n dT F si n t ot w og r o u p s .T h e \ufb01rst group\ndescribes the set of TFs that show the stage-speci \ufb01c\ndevelopmental patterns and have a tendency to reach theterminally differentiated state. The second group contains theset of TFs that regulate the set of genes and TFs which correlatewith the lineage-speci \ufb01c expression pattern. The regulatory\npathway demonstrates a path that encompasses thosecorrelated genes that are targeted by several TFs. Thissigni\ufb01es the necessity of the genes to be involved in the\nprocess. Moreover, this pathway introduces a set of TFs to\nsynchronize the activities of these in \ufb02uences in the lineage. At\nthis point, it is not very straigh t-forward to highlight the most\nimportant TFs as the number o f TFs that are induced for\nconnectivity highly depends on the number of in \ufb02uencers\nand the distance that these in \ufb02uencers have from each other\nin the network.5 CONCLUSION\nIn this work, we identi \ufb01ed a set of genes and, from within this\nset, TFs that can be considered as potential biomarkers for thecell fate process during blood formation. To infer thesecandidates, we took as starting point the expression patternof previously described global regulators in a blood lineage.Using this data, we identi \ufb01ed stage-speci \ufb01c genes that are\nlikely associated with the cellular differentiation based oncorrelated activity pro \ufb01les. By combining the cell-speci \ufb01c\nexpression pattern we obtained an integrated pattern\nspeci \ufb01c to each lineage. Inferring the set of correlated genes\nand TFs that follow the lineage-speci \ufb01c expression pattern and\nincorporating the TFs that regulate the genes that have highcorrelation with the integrated pattern led to the identi \ufb01cation\nof a regulatory subnetwork of TFs and their target genes.Nodes in these networks were \ufb01nally prioritized using a\nnewly developed \u201cregulatory pathway \u201dalgorithm to identify\nhigh-indegree genes and TFs by adding additional connectorTFs. All the nodes that reside along this path are suggested tobe of a high priority for network function. Here, the set of TFs\nis prioritized in four layers. In the \ufb01rst layer, there are TFs that\nare mainly involved in the cellular differentiation process. Thesecond layer consists of TFs that follow the integrated patternof stage-speci \ufb01c expression pattern. TFs that regulate the\ncorrelated genes and TFs in the second layer constitute thecandidate TFs in the third layer. Finally, the TFs thatcooperatively regulate targets genes and connect high-indegree nodes (in \ufb02uencers) in the network of TFs in the\nthird layer and the correlated genes and TFs in the second layermake up the candidates in the fourth layer. Enrichmentanalysis demonstrates that th ese biomarkers are not only\ninvolved in determining cell fate but also in other\ndevelopmental processes such as multicellular organismdevelopment etc. KEGG pathway analysis shows that thesebiomarkers can be potential targets for disease-relatedbiomarkers, such as leukaemia In addition to thecomputational approach to id entify a regulatory pathway\ndriving blood differentiation and also a set of genes andTFs that are introduced in four layers as potentialbiomarkers, the PathDevFate code can be used as a softwareto\ufb01nd the shortest path between a set of in \ufb02uencer nodes in\nthe largest connected component where a user can set a\nthreshold for the number of incoming edges. Also, users\nwho want to apply a different ranking scheme can easilymodify the provided R scripts and study the data sets oftheir choice.\nDATA AVAILABILITY STATEMENT\nOnly publicly available expression datasets were analyzed in this\nstudy. The source codes developed for this work are available\nhere: https://github.com/ikmb/KeyDevelopmentalFate.AUTHOR CONTRIBUTIONS\nMN initiated this study, designed and implemented the\nalgorithms, performed data analysis and wrote themanuscript. MH revised and edited the manuscript. VHproposed the biological motivation of the paper and helpedwith designing this study, data analysis and writing of themanuscript.\nFUNDING\nMN was supported by SFB 1027 through the DFG. Weacknowledge support by the DFG (DFG, German ResearchFoundation) and Saarland University within the funding\nprogramme Open Access Publishing.\nACKNOWLEDGMENTS\nWe thank Prof. Andre Franke for supporting this research.\nSUPPLEMENTARY MATERIAL\nThe Supplementary Material for this article can be found online at:https://www.frontiersin.org/arti cles/10.3389/fbinf.2021.653054/\nfull#supplementary-material\nREFERENCES\nAckermann, J., Ashton, G., Lyons, S., James, D., Hornung, J. P., Jones, N., et al.\n(2011). Loss of Atf2 Function Leads to Cranial Motoneuron Degenerationduring Embryonic Mouse Development. PLOS ONE 6, e19090-14. doi:10.1371/\njournal.pone.0019090\nAn, X., Schulz, V. P., Li, J., Wu, K., Liu, J., Xue, F., et al. (2014). Global\nTranscriptome Analyses of Human and Murine Terminal ErythroidDifferentiation. Blood 123 (22), 3466 \u20133477. doi:10.1182/blood-2014-01-548305\nArtyomov, M. N., Meissner, A., and Chakraborty, A. K. (2010). A Model for\nGenetic and Epigenetic Regulatory Networks Identi \ufb01es Rare Pathways for\nTranscription Factor Induced Pluripotency. Plos Comput. Biol. 6, e1000785-\n14. doi:10.1371/journal.pcbi.1000785\nAvilion, A. A., Nicolis, S. K., Pevny, L. H., P\u00e9rez, L., Vivian, N., and Lovell-Badge, R.\n(2003). Multipotent Cell Lineages in Early Mouse Development Depend onSox2 Function. Genes Dev. 17 (1), 126 \u2013140. doi:10.1101/gad.224503\nBabajko, S., de La Dure-Molla, M., Jedeon, K., and Berdal, A. (2015). Msx2 in\nAmeloblast Cell Fate and Activity. Front. Physiol. 5, 510. doi:10.3389/\nfphys.2014.00510\nBenjamini, Y., and Hochberg, Y. (1995). Controlling the False Discovery Rate: A\nPractical and Powerful Approach to Multiple Testing. J. R. Stat. Soc. Ser. B\n(Methodological) 57, 289 \u2013300. doi:10.1111/j.2517-6161.1995.tb02031.x\nBeuling, E., Bosse, T., aan de Kerk, D. J., Piaseckyj, C. M., Fujiwara, Y., Katz, S. G.,\net al. (2008). Gata4 Mediates Gene Repression in the Mature Mouse SmallIntestine through Interactions with Friend of Gata (Fog) Cofactors. Dev. Biol.\n322 (1), 179 \u2013189. doi:10.1016/j.ydbio.2008.07.022\nBock, C., Beerman, I., Lien, W. H., Smith, Z. D., Gu, H., Boyle, P., et al. (2012). Dna\nMethylation Dynamics during In Vivo Differentiation of Blood and Skin Stem\nCells. Mol. Cel 47, 633 \u2013647. doi:10.1016/j.molcel.2012.06.019\nBourgeois, B., and Madl, T. (2018). Regulation of Cellular Senescence via the\nFOXO4-P53 axis. FEBS Lett. 592, 2083 \u20132097. doi:10.1002/1873-3468.13057\nDunn, N. R., Vincent, S. D., Oxburgh, L., Robertson, E. J., and Bikoff, E. K. (2004).\nCombinatorial Activities of Smad2 and Smad3 Regulate Mesoderm Formationand Patterning in the Mouse Embryo. Development 131, 1717 \u20131728.\ndoi:10.1242/dev.01072\nEscamilla-Hern\u00e1ndez, R., Chakrabarti, R., Romano, R. A., Smalley, K., Zhu, Q., Lai,\nW., et al. (2010). Genome-wide Search Identi \ufb01es Ccnd2 as a Direct\nTranscriptional Target of Elf5 in Mouse Mammary Gland. BMC Mol. Biol.\n11, 68. doi:10.1186/1471-2199-11-68\nGarcia-Ojalvo, J., and Martinez Arias, A. (2012). Towards a Statistical Mechanics of\nCell Fate Decisions. Curr. Opin. Genet. Dev. 22, 619 \u2013626. doi:10.1016/\nj.gde.2012.10.004\nGarg, A., Hannan, A., Wang, Q., Collins, T., Teng, S., Bansal, M., et al. (2018). Fgf-\ninduced Pea3 Transcription Factors Program the Genetic Landscape for CellFate Determination. Plos Genet. 14, e1007660-20. doi:10.1371/\njournal.pgen.1007660\nGoode, D. K., Obier, N., Vijayabaskar, M. S., Lie-A-Ling, M., Lilly, A. J., Hannah,\nR., et al. (2016). Dynamic Gene Regulatory Networks Drive HematopoieticSpeci \ufb01cation and Differentiation. Dev. Cel. 36, 572 \u2013587. doi:10.1016/\nj.devcel.2016.01.024\nHan, H., Cho, J. W., Lee, S., Yun, A., Kim, H., Bae, D., et al. (2017). TRRUST V2: an\nExpanded Reference Database of Human and Mouse Transcriptional RegulatoryInteractions. Nucleic Acids Res. 46, D380 \u2013D386. doi:10.1093/nar/gkx1013\nHe, B., Xing, S., Chen, C., Gao, P., Teng, L., Shan, Q., et al. (2016). Cd8+ T Cells\nUtilize Highly Dynamic Enhancer Repertoires and Regulatory Circuitry inResponse to Infections. Immunity 45 (6), 1341 \u20131354. doi:10.1016/\nj.immuni.2016.11.009\nHorvay, K., Jard\u00e9, T., Casagranda, F., Perreau, V. M., Haigh, K., Nefzger, C. M.,\net al. (2015). Snai1 Regulates Cell Lineage Allocation and Stem Cell\nMaintenance in the Mouse Intestinal Epithelium. EMBO J. 34, 1319 \u20131335.\ndoi:10.15252/embj.201490881\nHu, G., and Chen, J. (2013). A Genome-wide Regulatory Network Identi \ufb01es Key\nTranscription Factors for Memory CD8 \u207aT-Cell Development. Nat. Commun.\n4, 2830. doi:10.1038/ncomms3830\nHuang, da. W., Sherman, B. T., and Lempicki, R. A. (2008). Systematic and\nIntegrative Analysis of Large Gene Lists Using David Bioinformatics Resources.Nat. Protoc. 4, 44 \u201357. doi:10.1038/nprot.2008.211\nHuttenhower, C., and Troyanskaya, O. G. (2008). Assessing the Functional\nStructure of Genomic Data. Bioinformatics 24, i330 \u2013i338. doi:10.1093/\nbioinformatics/btn160\nLiu, P., Dou, X., Liu, C., Wang, L., Xing, C., Peng, G., et al. (2015). Histone\nDeacetylation Promotes Mouse Neural Induction by Restricting Nodal-dependent Mesendoderm Fate. Nat. Commun. 6, 6830. doi:10.1038/\nncomms7830\nLiu, X., Robinson, G. W., and Hennighausen, L. (1996). Activation of Stat5a and\nStat5b by Tyrosine Phosphorylation Is Tightly Linked to Mammary Gland\nDifferentiation. Mol. Endocrinol. 10, 1496 \u20131506. doi:10.1210/\nmend.10.12.8961260\nMoignard, V., and G\u00f6ttgens, B. (2014). Transcriptional Mechanisms of Cell Fate\nDecisions Revealed by Single Cell Expression Pro \ufb01ling. Bioessays 36, 419 \u2013426.\ndoi:10.1002/bies.201300102\nNazarieh, M., and Helms, V. (2019). Topcontrol: A Tool to Prioritize Candidate\nDisease-Associated Genes Based on Topological Network Features. Sci. Rep. 9,\n19472. doi:10.1038/s41598-019-55954-6\nNazarieh, M., Wiese, A., Will, T., Hamed, M., and Helms, V. (2016). Identi \ufb01cation\nof Key Player Genes in Gene Regulatory Networks. BMC Syst. Biol. 10, 88.\ndoi:10.1186/s12918-016-0329-5\nNazarieh, M. (2018). Understanding Regulatory Mechanisms Underlying Stem Cells\nHelps to Identify Cancer Biomarkers . Dissertation. Saarbruecken, Germany:\nSaarland University. doi:10.22028/D291-27265\nPavlidis, P., and Noble, W. S. (2001). Analysis of Strain and Regional Variation in\nGene Expression in Mouse Brain. Genome Biol. 2, RESEARCH0042.\ndoi:10.1186/gb-2001-2-10-research0042\nRhee, C., Lee, B. K., Beck, S., Anjum, A., Cook, K. R., Popowski, M., et al. (2014).\nArid3a Is Essential to Execution of the First Cell Fate Decision via Direct\nEmbryonic and Extraembryonic Transcriptional Regulation. Genes Dev. 28,\n2219 \u20132232. doi:10.1101/gad.247163.114Rothenberg, E. V., Ungerb\u00e4ck, J., and Champhekar, A. (2016). Forging\nT-Lymphocyte Identity: Intersecting Networks of Transcriptional Control.Adv. Immunol. 129, 109 \u2013174. doi:10.1016/bs.ai.2015.09.002\nSertorio, M., Du, W., Amarachintha, S., Wilson, A., and Pang, Q. (2017). In Vivo\nRNAi Screen Unveils PPAR \u03b3as a Regulator of Hematopoietic Stem Cell\nHomeostasis. Stem Cel Rep. 8, 1242 \u20131255. doi:10.1016/j.stemcr.2017.03.008\nSugiyama, D., Inoue-Yokoo, T., Fraser, S. T., Kulkeaw, K., Mizuochi, C., and Horio,\nY. (2011). Embryonic Regulation of the Mouse Hematopoietic Niche.Scienti \ufb01cWorldJournal 11, 1770 \u20131780. doi:10.1100/2011/598097\nT\u00f3thov\u00e1, Z., Kollipara, R., Huntly, B. J., Lee, B. H., Castrillon, D. H., Cullen, D. E.,\net al. (2007). FoxOs Are Critical Mediators of Hematopoietic Stem Cell\nResistance to Physiologic Oxidative Stress. Cell 128, 325 \u2013339. doi:10.1016/\nj.cell.2007.01.003\nZ a n d i ,S . ,M \u00e5 n s s o n ,R . ,T s a p o g a s ,P . ,Z e t t e r b l a d ,J . ,B r y d e r ,D . ,a n d\nSigvardsson, M. (2008). EBF1 Is Essential for B-Lineage Priming andEstablishment of a Transcription Factor Network in Common\nLymphoid Progenitors. J. Immunol. 181, 3364 \u20133372. doi:10.4049/\njimmunol.181.5.3364\nCon\ufb02ict of Interest: The authors declare that the research was conducted in the\nabsence of any commercial or \ufb01nancial relationships that could be construed as a\npotential con \ufb02ict of interest.\nCopyright \u00a9 2021 Nazarieh, Hoeppner and Helms. This is an open-access article\ndistributed under the terms of the Creative Commons Attribution License (CC BY).The use, distribution or reproduction in other forums is permitted, provided the\noriginal author(s) and the copyright owner(s) are credited and that the original\npublication in this journal is cited, in accordance with accepted academic practice.No use, distribution or reproduction is permitted which does not comply withthese terms.APPENDIX\nHSC/equals(HSC >MPP1) & (MPP1 >MPP2) & (MPP2 >CLP) &\n(CLP >CD4) & (CLP >CD8) & (CLP >B cell) & (MPP2 >CMP)\n& (CMP >GMP) & (CMP >MEP) & (MEP >Eryth) & (GMP >\nGranu) & (GMP >Mono)\nMPP1 /equals(HSC <MPP1) & (MPP1 >MPP2) & (MPP2 >CLP) &\n(CLP >CD4) & (CLP >CD8) & (CLP >B cell) & (MPP2 >CMP)\n& (CMP >GMP) & (CMP >MEP) & (MEP >Eryth) & (GMP >\nGranu) & (GMP >Mono)\nMPP2 /equals(HSC <MPP1) & (MPP1 <MPP2) & (MPP2 >CLP) &\n(CLP >CD4) & (CLP >CD8) & (CLP >B cell) & (MPP2 >CMP)\n& (CMP >GMP) & (CMP >MEP) & (MEP >Eryth) & (GMP >\nGranu) & (GMP >Mono)\nCLP/equals(HSC <MPP1) & (MPP1 <MPP2) & (MPP2 <CLP) &\n(CLP >CD4) & (CLP >CD8) & (CLP >B cell) & (MPP2 >CMP)\n& (CMP >GMP) & (CMP >MEP) & (MEP >Eryth) & (GMP >\nGranu) & (GMP >Mono)\nCMP /equals(HSC <MPP1) & (MPP1 <MPP2) & (MPP2 >CLP) &\n(CLP >CD4) & (CLP >CD8) & (CLP >B cell) & (MPP2 <CMP)\n& (CMP >GMP) & (CMP >MEP) & (MEP >Eryth) & (GMP >\nGranu) & (GMP >Mono)MEP /equals(HSC <MPP1) & (MPP1 <MPP2) & (MPP2 >CLP) &\n(CLP >CD4) & (CLP >CD8) & (CLP >B cell) & (MPP2 <CMP)\n& (CMP >GMP) & (CMP <MEP) & (MEP >Eryth) & (GMP >\nGranu) & (GMP >Mono)\nGMP /equals(HSC <MPP1) & (MPP1 <MPP2) & (MPP2 >CLP) &\n(CLP >CD4) & (CLP >CD8) & (CLP >B cell) & (MPP2 <CMP)\n& (CMP <GMP) & (CMP >MEP) & (MEP >Eryth) & (GMP >\nGranu) & (GMP >Mono)\nCD4/equals(HSC <MPP1) & (MPP1 <MPP2) & (MPP2 <CLP) &\n(CLP <CD4) & (CLP >CD8) & (CLP >B cell) CD8 /equals(HSC <\nMPP1) & (MPP1 <MPP2) & (MPP2 <CLP) & (CLP >CD4) &\n(CLP <CD8) & (CLP >B cell)\nB cell /equals(HSC <MPP1) & (MPP1 <MPP2) & (MPP2 <CLP) &\n(CLP >CD4) & (CLP >CD8) & (CLP <B cell)\nEryth /equals(HSC <MPP1) & (MPP1 <MPP2) & (MPP2 <CMP) &\n(CMP >GMP) & (CMP <MEP) & (MEP <Eryth) & (GMP >\nGranu) & (GMP >Mono)Granu /equals(HSC <MPP1) & (MPP1 <\nMPP2) & (MPP2 <CMP) & (CMP <GMP) & (CMP >MEP) &\n(MEP >Eryth) & (GMP <Granu) & (GMP >Mono)Mono /equals\n(HSC <MPP1) & (MPP1 <MPP2) & (MPP2 <CMP) & (CMP <\nGMP) & (CMP >MEP) & (MEP >Eryth) & (GMP >Granu) &\n(GMP <Mono)", "arxiv61": "Personalized Stress Monitoring using Wearable Sensors in Everyday Settings\nAli Tazarvk, Sina Labbaf\u0003, Stephanie M. Reichy, Nikil Dutt\u0003;x, Amir M. Rahmaniz;\u0003;x, Marco Levorato\u0003\nkDept. of Electrical Engineering and Computer Science, \u0003Dept. of Computer Science,\nySchool of Education, zSchool of Nursing, xInstitute for Future Health (IFH)\nUniversity of California, Irvine\nAbstract \u2014 Since stress contributes to a broad range of mental\nand physical health problems, the objective assessment of stress\nis essential for behavioral and physiological studies. Although\nseveral studies have evaluated stress levels in controlled settings,\nobjective stress assessment in everyday settings is still largely\nunder-explored due to challenges arising from confounding\ncontextual factors and limited adherence for self-reports. In\nthis paper, we explore the objective prediction of stress levels\nin everyday settings based on heart rate (HR) and heart\nrate variability (HRV) captured via low-cost and easy-to-wear\nphotoplethysmography (PPG) sensors that are widely available\non newer smart wearable devices. We present a layered system\narchitecture for personalized stress monitoring that supports\na tunable collection of data samples for labeling, and present\na method for selecting informative samples from the stream\nof real-time data for labeling. We captured the stress levels of\nfourteen volunteers through self-reported questionnaires over\nperiods of between 1-3 months, and explored binary stress\ndetection based on HR and HRV using Machine Learning\nmethods. We observe promising preliminary results given that\nthe dataset is collected in the challenging environments of\neveryday settings. The binary stress detector is fairly accurate\nand can detect stressful vs non-stressful samples with a macro-\nF1 score of up to %76. Our study lays the groundwork for more\nsophisticated labeling strategies that generate context-aware,\npersonalized models that will empower health professionals to\nprovide personalized interventions.\nI. I NTRODUCTION\nStress can contribute to illness through its direct phys-\niological effects or indirectly through maladaptive health\nbehaviors ( e.g., smoking, poor eating or sleeping habits) [1].\nIt is therefore critical to motivate people to adjust their\nbehavior and lifestyle and introduce appropriate strategies\nto achieve a better stress balance before an increased level\nof stress results in serious health conditions [2].\nThe increasing availability of wearables, interconnected\ndevices capable of acquiring high-quality biosignals, opens\nimportant opportunities for advanced machine learning-\nenabled health monitoring and intervention applications [3],\n[4]. Recent literature [5] demonstrates that it is indeed\npossible to objectively detect stress by analyzing biological\nsignals. However, existing objective stress detection frame-\nworks are designed for controlled settings, where data is\nrecorded while users are in a set of prede\ufb01ned physical\nstates or performing certain activities ( e.g. sitting, lying\ndown, running). On the other hand, stress detection needs\nThis work was partially supported by NSF Smart and Connected Com-\nmunities (S&CC) grant CNS-1831918.to be performed in everyday settings , where subjects are\nengaged in their normal daily activities and routines. Every-\nday settings pose inherent challenges for stress monitoring,\nincluding: real-time collection and analysis of data; the lower\nquality of signals due to motion and noise artifacts (MNAs);\nand dif\ufb01culties in collecting self-reports due to limited user\nadherence [5], [6]. Furthermore, personalization of stress\nmonitoring in everyday settings raises additional challenges:\nfeatures may emerge that are speci\ufb01c to the user\u2019s character-\nistics, behavioral patterns, physiology and context, as well\nas sensor setup/con\ufb01guration, thus presenting a much higher\ndegree of variations from one person to another compared to\ncontrolled settings. These differences can result in degrading\nthe performance of general classi\ufb01ers in everyday settings.\nSince effective everyday stress monitoring and interven-\ntion must be personalized and context-aware, the underlying\nML (Machine Learning) core needs to be adapted to match\nthe stream of data generated by the user. It is important\nto note that personalized classi\ufb01ers often outperform those\ntrained using data from the general population even in\nidealized settings [5]. These classi\ufb01ers depend on labels\ngenerated from subjects in-the-moment to accurately record\ninstances of stress. However, users may not respond in a\ntimely or interactive manner, resulting in a trade-off between\nthe number of labels provided by the subjects versus the\naccuracy of the predictive model. This trade-off creates the\nneed for a smart label query strategy that we use to explore\nreal-time stress detection based on wearable data in every\nday settings.\nThe key contributions of this paper are:\n\u000fWe architect a three-tier system for the collection and\nreal-time analysis of biosignals labeled using self-reports.\nThe system is composed of wearable sensors, a smartphone\nserving as a gateway, and a cloud server. We discuss system-\nlevel challenges in\ufb02uencing data acquisition capabilities.\n\u000fWe develop a smart strategy to obtain labels for an adequate\nnumber of samples to proportionally represent the entire data\nfrom each user while capturing less overlapping regions of\nthe feature space.\n\u000fWe develop a machine learning based stress predictor. We\nmap the stress labels into binary stressed (1) andnot stressed\n(0), and then train classi\ufb01cation methods using these labels.\n\u000fWe capture the stress levels of fourteen volunteers through\nself-reported questionnaires over periods of between 1-3\nmonths, and evaluate our binary stress detection based on\nHR and HRV . Our classi\ufb01ers are able to identify the binaryWearable SensorGatewayUser Side Remote\nCloud Server\nInformation and \nnotification panelWiFi\nMetaHealth :\n-PPG\n-3D Accelerometer\n-Gyroscope\n-Gravity\nForeground App-Pushup \nNotifications\n-EMAs (Stress, \nActivity, etc.)\n-Daily and \nWeekly Surveys-Stress detection\n-Daily activity pattern\n-Data analytics\n-Triggering EMA\n-Machine LearningData Collection and \nTransfer ServicesFig. 1. Overview of the system architecture.\nclasses with an F1 score up to 76%. We also analyze the\neffect of personalization, and show how the stress detection\nperformance improves over time, as we collect more labels\nfrom a subject and use those in the training process.\nThe rest of the paper is organized as follows. Section II\ndescribes the system architecture we used for data collection,\nand the proposed strategy for label collection in everyday\nsettings. Section III describes the classi\ufb01cation methods we\nused for detecting stress. Section IV presents our analysis\nand results on stress detection. Section V concludes the paper\nwith a summary and directions for future work.\nII. S YSTEM MODEL AND DATA COLLECTION\nThe ultimate goal of data collection is to train a personal-\nized classi\ufb01er for stress detection based on biosignals (PPG).\nOne of the key challenges in collecting such datasets in\neveryday settings is the interaction with the users, as sending\nqueries for labeling too often may overwhelm the users and\nmay also lead to unnecessary data collection.\nTo enable real-time interaction with the user while min-\nimizing resource usage, a layered design is necessary. The\nsensor layer should collect the raw signals, while the cloud\nlayer processes the data, determines the quality of the signals,\nperforms feature extraction and other computationally inten-\nsive and power consuming tasks. We also have to provide\nusers with an interface to input their labels and build a\ncommunication path between these layers. In this section,\nwe present our proposed solution for these requirements.\nThe experimental procedures involving human subjects\ndescribed in this paper were approved by the Institutional\nReview Board (IRB) at UC Irvine.\nA. System Architecture\nFigure 1 outlines the system we developed to acquire the\nreal-time dataset associating self-reported stress ratings from\nusers to biosignals from wearable devices. We use a 3-tier\narchitecture composed of a wearable device (sensor layer),\na smartphone (edge layer), and a remote cloud server (cloud\nlayer) working to collect and process the data, as described\nbelow.The wearable platforms acquire and\ntransmit raw physiological (PPG) and Movements (Ac-\ncelerometer, Gyroscope and Gravity) signals. We used Sam-\nsung Gear Sport smartwatches and developed a service\nrunning on Tizen operating system to collect raw PPG and\nmovement signals. The sampling frequency of all the above\nmentioned signals is 20Hz. The watch can send the data\ndirectly to the cloud layer (if connected to a local Wi-Fi), or\nto the smartphone via Bluetooth. The raw signal acquisition\napplication includes two services and a user interface (UI).\nThe \ufb01rst service collects the sensor data at a constant rate\n(once every 15 minutes) and duration (2-minutes intervals)\nand sends it to the cloud. If the service fails to send the\ndata to the cloud immediately, the data will be stored on the\nwatch and transferred to the server at a later time. The UI is\na simple app installed on the watch for restarting these two\nservices.\n2)Cloud Layer :A cloud web-server receives the data\nsamples from the watch and processes them. Based on the\nobserved features of each incoming sample, an internal logic\n(described later) determines whether it needs to ask users for\na label or not. The responses from users are transferred to\nthe cloud and stored in the database.\n3)Edge Layer :We developed a smartphone app that asks\nthe participants for labels through an Ecological Momentary\nAssessment (EMA). The EMA is triggered by the cloud for\na portion of samples and when triggered, a push noti\ufb01cation\nis displayed on the phone that asks the participant about their\nstress levels and recent physical activity or state (e.g., sitting,\nstanding, etc.). The stress levels in the EMA are not at all ,\na little bit ,some ,a lot , and extremely .\nThe edge-cloud connection is established through the In-\nternet on the smartphone. In addition, the watch is connected\nto the smartphone using Bluetooth Low Energy (BLE). In\norder to send the collected data to the cloud, the watch\nproxies the connected phone\u2019s Internet connection through\nBLE. This setting is energy ef\ufb01cient, and thus suitable for\neveryday setting applications. This is a back up connection\nand takes effect when the watch is not directly connected to\nthe Wi-Fi.\nB. Data Labeling\nThe system needs to parsimoniously trigger the EMA to\ncollect labels to build a meaningful dataset as quickly as\npossible without imposing excessive burden on the user.\nTherefore, we devised a selection method to select infor-\nmative samples to be labeled by the user. However, before\napplying the selection method, the raw signals need to be\npre-processed for extracting the corresponding features.\n1) Data Cleaning and Feature Extraction: When a raw\nPPG sample is received at the cloud, we \ufb01rst \ufb01lter the raw\nsignal to clean up the high and low frequency noises. We\napply a Butterworth band-pass \ufb01lter of order 3, with cut off\nfrequencies set at (0:7Hz,3:5Hz), corresponding to 42bpm\nand 210bpm )respectively. Then, we pass the signal through\na moving average \ufb01lter and at the end apply a peak detector\non it. Using the peak points of the \ufb01ltered signal, we extract\nSubject # samples total labels used labels\nS01 4,580 228 217\nS02 2,164 101 92\nS03 1,764 67 42\nS04 2,580 56 53\nS05 2,267 68 59\nS06 17,552 376 370\nS07 10,087 105 101\nS08 2,752 96 93\nS09 1,236 53 50\nS10 7,910 119 104\nS11 2,555 73 60\nS12 1,2296 956 942\nS13 3,738 47 45\nS14 1,332 61 55\nthirteen features from each sample (2 minutes of data). These\nfeatures are: BPM, IBI, SDNN, SDSD, RMSSD, pNN20,\npNN50, MAD, SD1, SD2, S, SD1/SD2, and BR1. We use\nthese features for further processing and decision making.\n2) Strategy for Labelling Selected Data: Data collection\nconsists of two phases:\nInitial Phase: In order to get an initial estimate of the\ndistribution of samples in the sample space, we start the\nprocedure by observation. For the \ufb01rst Nsamples (100\nsamples in our setup; \u001825 hours of wearing the watch), we\ndo not trigger any EMAs. At the end of this phase, we get an\nestimate of the distribution of samples in the samples space.\nQuery Phase: For samples after the initial phase ( N+1 and\nabove), we trigger the EMA (ask for labels) for a portion\nof samples. The probability of selecting each sample to be\nlabeled is proportional to the number of previous samples\n(unlabeled) in its neighborhood. This way, if a sample falls in\na region in which there has been a large number of unlabeled\nsamples, it is more likely that we ask the user for the label.\nFor each region after we collect suf\ufb01cient number of labeled\nsamples, we stop collecting labels. However, the minimum\nprobability of triggering the EMA for a sample is P= 0.1.\nThis means if a sample falls in a region where there is little\nor no previous samples, the probability of query is still non-\nzero. This results in exploring unseen regions, as well as\nregions with higher densities.\nWe capture the stress levels of fourteen volunteers through\nself-reported questionnaires over periods of between 1-3\nmonths. The total number of samples, along with the number\nof labeled samples for each user is presented in Table I.\n1BPM: Beats per Minute, Heart Rate. IBI: Inter-Beat Interval, average\ntime interval between two successive heart beats (called NN intervals).\nSDNN: Standard Deviation of NN intervals. SDSD: Standard Deviation\nof Successive Differences between adjacent NNs. RMSD: Root Mean\nSquare of Successive Differences between the adjacent NNs. pNN20: The\nproportion of successive NNs greater than 20ms (or 50ms for pNN50).\nMAD: Median Absolute Deviation of NN intervals. SD1 and SD2: Standard\nDeviations of the corresponding Poincar \u00b4e plot. S:Area of ellipse described\nby SD1 and SD2. BR: Breathing Rate.\nIn this section, we explore the possibility of predicting\nstressful vs non-stressful moments based on the collected\nsignals. We train our stress detection models on both personal\nand general datasets to evaluate the performance. For stress\ndetection, we use several machine learning classi\ufb01cation\nalgorithms such as Multi Layer Perceptron (MLP), Random\nForest (RF), k-Nearest Neighbors (kNN), Support Vector\nMachine (SVM), and XGBoost. MLP is a class of feed-\nforward neural networks that can be trained to do nonlinear\nclassi\ufb01cation and regression tasks. RF is an ensemble learn-\ning method for classi\ufb01cation that operates by constructing\na number of decision trees at training time and outputting\nthe class that is the mode of the classes of the individual\ntrees. kNN uses the knearest points and takes a majority\nvote to predict the class of the sample. SVM \ufb01nds hyper\nplanes and partitions the sample space into different classes.\nXGBoost is an implementation of Gradient Boosted Decision\nTrees that is fast and performs well in classi\ufb01cation tasks.\nWe train each of these classi\ufb01ers on our dataset and analyse\ntheir performance using machine learning methods and F1\nscore as the evaluation metric.\nIV. R ESULTS AND ANALYSIS\nDetecting stress by only using PPG signals in everyday\nsettings is a challenging task [5]. To evaluate the validity of\nour models, we perform K-Fold cross validation ( K= 5). In\nK-Fold Cross Validation, we split the data into K equally\nsized segments (folds) and in each iteration use 1 fold for\nevaluation, and the other K-1 folds for training. The data is\nstrati\ufb01ed prior to be split in K folds, to ensure each fold is\na proper representative of the whole. The ML methods we\nused are introduced and explained in Section III. To evaluate\nthe performance of each method on our collected dataset,\nwe used Macro-F1 score2. The mean and standard deviation\n(\u0016\u0006\u001b) of the F1 scores over the K folds are presented in\nTable II. Based on these experiments, RF outperforms other\nmethods for most cases (except for the \ufb01rst row).\nA. Personalization\nThe bias in the physiological data (both the signals and the\nlabels) can be different for personal or general datasets [5].\nTherefore, we show the effect of personalization and how it\nimproves the prediction accuracy on our collected dataset.\nTo this end, we consider 3 participants from which more\ndata is available (subjects S06, S10, S12). In the \ufb01rst step,\nwe exclude the data from one subject (e.g. S06), train on\nthe data from all other subjects, then test on half of the data\nfrom S06 (picked randomly). In the next step, in order to\npersonalize the model, we use the other half of data from\nS06 and use it for training (along with the data from other\nusers), and then test it on the \ufb01rst half of the data from\nS06. The results are reported in Table III. As can been seen\nfrom these results, personalization improves the prediction\nperformance (macro-F1 score).\n2F1 score is de\ufb01ned on each class separately. macro-F1 score is the\naverage of F1 scores on all the classes (two here).FOR STRESS DETECTION\nBASED ON PPG FEATURES ,BASELINE IS ALWAYS \u201dNOT AT ALL \u201dCLASS\n5 fold Cross Validation, F1 Score\nBinary Classes Number of Samples MLP SVM kNN RF XGBoost\na little bit (1) VS. baseline (0): (605, 143) 0.73 \u00b1 0.06 0.66 \u00b1 0.03 0.72 \u00b1 0.03 0.67 \u00b1 0.04 0.72 \u00b1 0.04\nsome (1) VS. baseline (0): (299, 143) 0.70 \u00b1 0.03 0.69 \u00b1 0.04 0.66 \u00b1 0.06 0.71 \u00b1 0.05 0.70 \u00b1 0.04\na lot orextremely (1) VS. baseline (0): (72, 143) 0.68 \u00b1 0.06 0.69 \u00b1 0.13 0.69 \u00b1 0.04 0.76 \u00b1 0.05 0.73 \u00b1 0.09\nsome, a lot orextremely (1) VS.\na little bit ornot at all (0): (748, 371) 0.62 \u00b1 0.04 0.60 \u00b1 0.04 0.59 \u00b1 0.03 0.63 \u00b1 0.02 0.63 \u00b1 0.04\nTABLE III\nEFFECT OF PERSONALIZATION ON STRESS PREDICTION PERFORMANCE .\nBEFORE AND AFTER ROWS ARE F1SCORES BEFORE AND AFTER\nPERSONALIZATION FOR EACH USER .\nF1 Score on 50% of data from one user\nUser Personalization MLP SVM KNN RF XGB\nS06:before 0.43 0.37 0.44 0.40 0.38\nafter 0.53 0.54 0.50 0.54 0.52\nS10:before 0.58 0.63 0.60 0.612 0.60\nafter 0.62 0.62 0.63 0.616 0.61\nS12:before 0.58 0.59 0.61 0.59 0.55\nafter 0.63 0.62 0.64 0.63 0.61\nB. Improvement Over Size of Training Data\nAs we collect more labels from a user, the stress prediction\ncan be performed more accurately. In order to show this\nprocess, we only use data from one user having for him a\nlarge number of labels is available (Subject S12). We also\nuse random forest classi\ufb01er for this experiment. We randomly\nseparate 100 samples and use those for testing. We use the\nrest of the data in an incremental manner; \ufb01rst we train the\nmodel on 100 samples only, and then increase the training\nsize. In each step, we test the trained model on the test data\n(all from S12). The improvement of prediction performance\nis presented in Figure 2. The model improves as we increase\nthe subject\u2019s data size up to about 300 samples. For each\nstep, we repeat the process (selection of test data and training\ndata) 100 times, and the values in the \ufb01gure show the mean\nand the standard deviation of the F1 score over all these 100\nexperiments.\nV. C ONCLUSIONS AND FUTURE WORK\nCollecting photoplethysmogram (PPG) signals with\nenough labels collected from users in everyday settings is\na challenging task. Our study used a Samsung Gear Sport\nsmartwatch as a wearable device for data collection and\nutilized a method to improve the labeling procedure. The data\nwere collected from fourteen active volunteers. We explored\nthe possibility of detecting stressful vs non stressful moments\n(samples) using leave-samples-out validation based on PPG\nsignals, in everyday settings. We analyzed the improvement\nof the trained classi\ufb01er, as we personalize the classi\ufb01er with\nFig. 2. Stress Prediction over size of training data\nsamples from a certain subject. The results are promising: we\nachieved macro-F1 scores up to 76% for binary classi\ufb01cation\nof stressful vs non stressful samples. This motivates our\nfuture work to utilize more advanced methods, possibly\nvariants of active learning, in the labeling procedure. More\ninformative labels will allow us to design classi\ufb01ers that\ncan possibly detect mental health conditions of users based\non HRV from their biosignals and the type of user activity\n\u2013 promising to provide valuable tools for mental health\nprofessionals to better diagnose and treat stress and anxiety\nin a personalized way.\nREFERENCES\n[1] K. Glanz and M. D. Schwartz, \u201cStress, coping, and health behavior.,\u201d\n2008.\n[2] J. Bakker, M. Pechenizkiy, and N. Sidorova, \u201cWhat\u2019s your current stress\nlevel? detection of stress patterns from gsr sensor data,\u201d in 2011 IEEE\n11th international conference on data mining workshops , pp. 573\u2013580,\nIEEE, 2011.\n[3] F. Firouzi et al. , \u201cInternet-of-things and big data for smarter health-\ncare: From device to architecture, applications and analytics,\u201d Future\nGeneration Computer Systems , vol. 78, pp. 583 \u2013 586, 2018.\n[4] R. Mieronkoski et al. , \u201cThe internet of things for basic nursing care\u2014a\nscoping review,\u201d International Journal of Nursing Studies , vol. 69,\npp. 78 \u2013 90, 2017.\n[5] H. J. Han et al. , \u201cObjective stress monitoring based on wearable sensors\nin everyday settings,\u201d Journal of Medical Engineering & Technology ,\nvol. 44, no. 4, pp. 177\u2013189, 2020.\n[6] E. K. Naeini et al. , \u201cA real-time ppg quality assessment approach for\nhealthcare internet-of-things,\u201d Procedia Computer Science , vol. 151,\npp. 551 \u2013 558, 2019.", "arxiv7": "Received June 28, 2020, accepted July 12, 2020, date of publication July 22, 2020, date of current version August 5, 2020.\nDigital Object Identifier 10.1 109/ACCESS.2020.301 1099\nSecondary Use of Electronic Health Record:\nOpportunities and Challenges\nSHAHID MUNIR SHAH AND RIZWAN AHMED KHAN\nFaculty of Information Technology, Barrett Hodgson University, Karachi 74900, Pakistan\nCorresponding author: Rizwan Ahmed Khan (rizwan.khan@bhu.edu.pk)\nABSTRACT In the present technological era, healthcare providers generate huge amounts of clinical data\non a daily basis. Generated clinical data is stored digitally in the form of Electronic Health Record (EHR) as\na central data repository of hospitals. Data contained in EHR is not only used for the patients' primary\ncare but also for various secondary purposes such as clinical research, automated disease surveillance\nand clinical audits for quality enhancement. Using EHR data for secondary purposes without consent or\nin some cases even with consent creates privacy issues. Secondly, EHR data is also made accessible to\nvarious stakeholders including different government agencies at various geographical sites through wired or\nwireless networks. Sharing of EHR across multiple agencies makes it vulnerable to cyber attacks and also\nmakes it dif\u001ccult to implement strict privacy laws as in some cases data is shared with organization that\nis governed by speci\u001cc regional law. Privacy of individuals could be severely affected when their sensitive\nprivate information contained in EHR is leaked or exposed to the public. Data leaks can cause \u001cnancial losses\nor an individual may encounter social boycott if his / her medical condition is exposed in public. To protect\npatients personal data from such threats, there exists different privacy regulations such as General Data\nProtection Regulation (GDPR), Health Insurance Portability and Accountability Act (HIPAA) and My Health\nRecord (MHR). However, continually evolving state-of-the-art techniques in Machine Learning (ML), Data\nAnalytics (DA) and hacking are making it even more dif\u001ccult to completely protect an individual's/patient's\nprivacy. In this article, we have systematically examined various secondary uses of EHR with the aim to\nhighlight how these secondary uses affect patients' privacy. Secondly, we have critically analyzed GDPR &\nHIPAA regulations and highlighted their possible areas of improvement, considering escalating use of\ntechnology and different secondary uses of EHR.\nINDEX TERMS Electronic health records (EHR), ethical concerns, general data protection regula-\ntion (GDPR), privacy, secondary uses of EHR.\nI. INTRODUCTION\nClinical data is generated in the form of ongoing patient\ndiagnostic services. These services usually take place in hos-\npitals, clinics or laboratories through different clinical trials\n(via medical imaging or doctors' prescriptions) or through\nwireless body area network using wearable sensors [1]. All of\nthese sources produce a huge amount of clinical data world\nwide and its volume is experiencing an exponential growth.\nIt is estimated that clinical data will swell up to 2314 Exabytes\nby 2020 from a \u001cgure of 153 Exabytes in 2013 with an annual\ngrowth rate of 48% [2].\nThe associate editor coordinating the review of this manuscript and\napproving it for publication was Yu-Huei Cheng\n .In most of the countries (especially developing countries),\ndata generated during routine clinical practices is stored\nmanually in the form of paper based medical records. This\nprocedure is adopted by the medical practitioners because of\nease of handling, lack of understanding or for the purpose\nof treating more patients in less time. However, this method\nof storing patient's medical information is not useful for the\npatients and does not guarantee accurate and timely deliver-\nance of healthcare services. Some other problems associated\nwith manual recording of clinical/medical data are:\n1) Paper based medical records can easily be altered or\ncan be lost and may cause severe consequences.\n2) Physicians/clinicians can prescribe wrong medica-\ntions (due to alteration of paper based medical\nrecords) or cannot advise right medications during\nfollow up visits without properly knowing past medical\nrecords of patients.\n3) It is not practical for a person to carry a huge bunch\nof paper based past medical records during follow up\nvisits or to describe complete medical history to a\nphysician/clinician in case of change of physician or\nhospital.\n4) Reviewing and analyzing paper based records poses\ncumbersome task for new physicians or medical staff\nwhen patients change their physicians or hospital.\nTo avoid all of the above described dif\u001cculties, an auto-\nmated/electronic online patient information system through\nwhich patients' complete medical record is made available\nto healthcare professionals is required. Such electronic sys-\ntem also serves the purpose of storing patients data for\nlonger time without any alterations and makes it accessible\nthrough different locations to support quick decision making\nprocesses [3].\nHealthcare organizations are now adopting techniques to\ndigitize medical records to overcome challenges (described\nabove) faced by them or by patients while using paper\nbased medical records [4]. With the new technique, patients'\nclinical data is now stored as Electronic Health Records\n(EHR). EHR are the patients' computerized health records\nthat contain patients' complete information along with their\nmedical history in a format (refer Figure 1) that can be\neasily shared among different health care providers or can\nbe accessed by them through different linked locations when\nrequired [5].\nFIGURE 1. EHR as a clinical data repository.\nAdoption of EHR provide range of bene\u001cts over the tradi-\ntional paper based medical record systems. For Example:\n1) EHR are capable of storing structured, coded and elec-\ntronic patient data all together to form a complete his-\ntory of patient's health [6].\n2) Electronic data saved as EHR makes a Decision Sup-\nport System (DSS) for monitoring health outputs toimprove health care quality [7], where DSS is a tool,\nusually software based tool, that supports decision\nmaking by providing automated analysis of data [8].\n3) EHR system acts as a central database of informa-\ntion for patient documentation and billing, maintain-\ning quality, and supporting patient related sensitive\ndecisions [9].\n4) Data saved in EHRs can be accessed through multi-\nple locations simultaneously and also can be shared\nwith different partner organizations conveniently. Thus,\nmaking data accessible to the concerned physicians\nacross multiple sites to better provide healthcare\nservices.\n5) EHR reduces the probability of errors related to medi-\ncal data analysis as it stores complete medical records\nand thus lowers overall healthcare cost [10].\nWith all the above mentioned bene\u001cts of using EHR, cer-\ntain risk factors are also associated with it. The most impor-\ntant issue is the data security and patient's privacy. In case,\nif EHR data is leaked/theft or stolen from the database it can\nbe misused (by altering dosage of drugs or treatment proce-\ndure etc.) and may cause severe complications or even lead\nto the patient's death [11]. It is therefore utmost important\nto protect patient's information in the central database from\nunauthorized wrong hands. Patient's information may also be\nstolen while it is in transmission to the other linked services\nover the network or when it is stored on distributed servers of\ncloud.\nInformation contained in EHR is also used for different\nsecondary purposes (other than patient personal care) such\nas clinical research, health promotions, clinical audit and\nclinical governance, national screening and preventive cam-\npaigns, audits against national standards, national statistics,\nplanning future services, and resource allocations etc., [12]\n(refer Section V for discussion on secondary uses of EHR).\nFor all such uses, patients may not be willing to share their\ninformation as often patients share their private health data\nfor their personal care and not for the other/secondary uses.\nUsing patient sensitive information for different secondary\npurposes without their consent can seriously affect their\nprivacy.\nTo safeguard patient privacy or personal data, there exist\nprivacy standards in different regions of the world such\nas General Data Protection Regulation (GDPR) in Europe\n[13], [14], Health Insurance Portability and Accountabil-\nity Act (HIPAA) in the United States (US) [15] and My\nHealth Record (MHR) in Australia [16], [17]. These stan-\ndards provide legislation to protect personal data but with\nfast paced advancement in Data Analytics (DA) and Arti\u001ccial\nIntelligence (AI) [18], [19] poses new challenges for such\nstandards.\nOur contributions in this article are following:\n1) In this study we have described various secondary uses\nof EHR with the aim to highlight how these secondary\nuses affect patients' privacy, refer Section V for discus-\nsion on secondary uses of EHR.FIGURE 2. Conceptual overview of EHR system.\n2) In this article we have discussed various issues asso-\nciated with secondary use of EHR (refer Section VI).\nReferred section also elaborates on security and privacy\nissues of using EHR data (Section VI-D).\n3) This article has systematically analyzed GDPR and\nHIPAA regulation and enlisted their challenges for\nensuring data privacy in this era where usage of EHR\ndata (that contains sensitive personal information) has\ngrown exponentially, refer Section VII for discussion\non this issue.\nOur contributions in this article are oriented toward under-\nstanding ethical concerns when dealing with personal data\nin the era of AI. Research domain of our contributions\n(described above) needs more collaborative efforts by the\nresearch community working in the domain of medicine,\ncomputing and law to achieve better insight. Ethical issues\narising due to fast proliferation of AI-assisted technolo-\ngies [20] will raise various serious concerns, specially related\nto privacy of individuals. Due to the complex nature of this\ninterdisciplinary research domain, it is hard to \u001cnd literature\non the topic and thus, our article is novel as it systematically\nanalyzes uses of sensitive EHR data which, if violated, creates\nmany privacy and ethical concerns.\nThe rest of the paper is structured as follows: Section II\ndescribes EHR along with their different standards.\nSection III describes information sources of EHR. Section IV\npresents an overview of various Deep Learning (DL)\napproaches for EHR data analysis. Section V describes use\nof EHR in various secondary purposes. Section VI presents\nchallenges of using EHR for secondary purposes. Section VII\ndescribes systematic analysis of popular data protection reg-\nulations i.e. GDPR and HIPAA in the context of patients\nprivacy and data security with respect to secondary uses of\nEHR. Finally, in the Section VIII conclusions are presented.\nII. ELECTRONIC HEALTH RECORDS (EHR):\nDATA SHARING\nEHR is a clinical data repository containing basic patient\ninformation such as a patient's personal pro\u001cle, theircomplete family history, laboratory reports, physicians and\nother medical staff notes etc. Along with this primary infor-\nmation, EHR also contains data form the other hospital\ninformation systems such as Imaging data from Radiology\ndepartment, patients genomics data from Genetic department\nor Endoscopic and Colonoscopic data from Gastroenterology\ndepartment etc. Figure 1 illustrates the most important data\nelements included in the EHR.\nEHR also provides functionality of generating reminders\nfor routine screenings and disease reporting, generating\ngraphical trends against various parameters such as blood\npressure monitoring, heart beat monitoring, blood glucose\nlevel monitoring etc. The same is also shown in Figure 1.\nSuch reporting is highly bene\u001ccial for patients health and\nsafety especially when patients are in critical condition and\ntheir strict monitoring is required.\nConceptually EHR system can be divided into two basic\nparts [21]. Creation part and the access part (refer Figure 2).\nCreation part is based on the interaction of patients with the\nhealthcare providers. This part explains, how the data from\nthe patient is captured, how it is formatted according to the\npolicies and standard and \u001cnally, how the formatted data\nis stored in an interoperable database. Access part is based\non the access of the data stored in EHR by the different\nauthorized users or organization. This part explains how con-\n\u001cdential information from EHR can be securely accessed by\nthe authorized users via user friendly interfaces.\nA. EHR STANDARDS\nFor the effective use of data contained in EHR, it must be\nshared through different linked locations such as clinics, hos-\npitals, radiology departments, pharmacies, laboratories and\npatient homes [22] (refer Figure 3).\nShared data at multiple locations ensures patients solitary\ncare by identifying their basic needs in terms of care, safety,\ntimeliness, and effective monitoring. It also helps medical\nstaff (physician, nurses etc.) to take the right actions based\non patient conditions. The data usefulness can further be\nincreased if the data contained in EHR is linked with differentFIGURE 3. EHR data sharing.\nclinical decision support systems (CDSS). CDSS refers to\nan automated medical data analysis tool that suggests next\nsteps for treatment and generates alerts by predicting future\nconditions/trends by analyzing provided data [23]. By this\nway, the physicians can take sensitive decisions quickly and\neffectively [24].\nHowever, without any industry standard for information\nexchange, it is usually dif\u001ccult to share and exchange EHR\ndata across multiple sites. The same dif\u001cculty was faced\nby the healthcare organizations to communicate EHR data\nwith each other and with different DSSs when there was no\nindustry standard available for health information exchange.\nIt was the main reason behind the slow adoption of the EHR\nsystem in healthcare organizations even if their adoption was\nhighly bene\u001ccial for them [25].\n1) HEALTH LEVEL SEVEN (HL7) STANDARD\nThe Health Level Seven (HL7) organization was estab-\nlished in the US in March 1987 to develop consistent com-\nmon standards for Hospital Information System (HIS) [26].\nAfterwards this organization de\u001cned HL7-Clinical Docu-\nment Architecture (HL7 CDA) as EHR messaging standard\nfor easy integration, interchange, sharing and retrieval of\ninformation across different clinical information systems.\nThe HL7 standard allows different healthcare organizations\nto share and exchange patient information via encoded data\nexchange. It provides a common syntax of information for\ndifferent clinical information systems to share information\n(contained in EHR) conveniently [9].\nThe HL7 CDA Framework 1.0 release, became an Ameri-\ncan National Standards Institute (ANSI) approved HL7 stan-\ndard in November 2000 [27]. After the release of the \u001crst\nversion, version 2 and version 3 releases were also made\navailable with some new standards and modi\u001ccations [28].\nHL7 CDA is a markup for specifying composition and\nsemantics of data ingredients of EHR such as a discharge\nreport, admission summary, progress and procedure reportsand to exchange them with various stakeholders. It is an\nabsolute object document that may hold clinical data in var-\nious formats such as text, image, sound, or other multime-\ndia content. Extensible Markup Language (XML) is used to\nencode the HL7 CDA clinical documents, which then can be\nexchanged in form of HL7 messages or using other transport\nsolutions.\nAn HL7 CDA message consists of a header and a\nbody. Header contains information regarding patient, source\n(provider) and the authentication of the message. On the\nother hand, the body of the message includes organized clin-\nical reports i.e. lab, radiology, Magnetic Resonance Imaging\n(MRI), Computed Tomography (CT) scan, ultrasound etc.\n2) FAST HEALTHCARE INTEROPERABILITY\nRESOURCES (FHIR)\nIn order to improve inter interoperability and exchange of\ninformation, HL7 released different versions from time to\ntime. In 1988, HL7 version 2 was released to enhance and\nstreamline information exchange mechanisms/procedures,\nthat can be used by different departments across hospi-\ntals [29]. However, different limitations were exposed in this\nversion such as a dif\u001ccult implementation process, having a\nnumber of optional segments and above all lack of proper\nrepresentation that is capable enough to identify techniques\nfor exchanging messages and interfaces [30]. To overcome\nthe shortcomings of version 2, version 3 was developed\nin the year 1995. Although HL7 version 3 resolved much\nof the problems of previous versions, it could not resolve\nthe incompatibility issue raised because of a variety of sub\nversions [31]. In order to further improve HL7 standards,\nanother novel interoperability standard i.e. Fast Healthcare\nInteroperability Resources (FHIR) was initiated in the year\n2011 [32] by HL7 organization. FHIR standards are very\nsimple to adapt, possess scalability and are robust in nature.\nThese standards have potential capabilities of supporting\nwork \u001dows in small devices like mobile phones [33].\nIII. ELECTRONIC HEALTH RECORD\nINFORMATION SOURCES\nAdoption of EHR is bene\u001ccial both for patients, physi-\ncians and healthcare providers. It improves overall health-\ncare quality, omits paperwork, reduces medical errors and\nincreases work ef\u001cciency as well as reduces overall health-\ncare cost [34].\nBeside patients personal care, EHR data is also used for\ndifferent secondary purposes (refer sectionV for secondary\nuses of EHR). However, EHR data has not been utilized to\nits full potential for secondary uses and one of the reasons\nfor under utilization of EHR data is non uniformity in its\ndata components. Non uniformity in data elements exists\nbecause of the fact that during daily clinical practices, EHR\ndata is often recorded in free text and unstructured format.\nTherefore, EHR contains structured and unstructured sets\nof information. Figure 4 elaborates more on the structured\nand unstructured data components of EHR. As shown inFIGURE 4. Unstructured and structured data elements of EHR.\nFigure 4, structured data includes laboratory results, vital\nsigns, prescriptions, medications and International Classi\u001c-\ncation of Diseases (ICD) codes whereas, unstructured data\nincludes narrative information (free text) such as images and\ngraphics, radiology reports, visit notes, discharge summary,\nchief complaint etc.\nFigure 4 depicts that the major portion of EHR data con-\nsisted of unstructured elements. Such data elements are not\nrepresented in any standard coding scheme such as ICD\ncodes, therefore, their retrieval, reporting and aggregation\nis not easy like structured data using commonly available\ndatabase tools [34]. It is therefore required to convert unstruc-\ntured data elements into structured data in order to make it\nequally useful for secondary uses.\nOne of the methods to convert unstructured data into struc-\ntured data is manually reviewing EHR by the experts using\ntext charts or data abstraction methods [35]. However, these\nmethods are time consuming and not reliable to capture all\nthe structured information. Furthermore, it is beyond the\ncapacity of human to review clinical data of EHR in large\nvolume. Natural language processing (NLP) methods have\nshown their usefulness for extraction of structured clinical\ndata from unstructured data elements [36], [37].\nMostly, NLP uses statistical (probabilistic) Machine\nLearning (ML) models to derive language data from large\nvolumes of free text data. These models use text data to iden-\ntify common patterns and associations in the data. NLP based\nML models give meanings to words and phrases in text and\nconvert unstructured data elements of EHR into structured\ncodes. In short, NLP captures unstructured data elements\nof EHR, analyzes the data elements with respect to their\ngrammatical structures, obtains meanings from grammatical\nstructures, and \u001cnally summarizes information to make it\nuseful for further analysis.IV. DEEP LEARNING FOR EHR DATA ANALYSIS\nAs discussed above, techniques under the umbrella of NLP\nare used to extract information from unstructured clinical\nnotes. Such techniques utilize different sequence labeling\nalgorithms such as Conditional Random Fields (CRFs), Hid-\nden Markov Models (HMMs), Arti\u001ccial Neural Networks\n(ANN) etc., [38] to label relevant information to be extracted.\nSequence labeling is a robust technique that has been used\nfor automatic recognition of various tasks e.g. speech recog-\nnition [39], network intrusion detection [40], mental illness\ndetection using social media content [41]. Data contained in\nEHR (in the form of clinical notes) is often noisy, incomplete\nand inconsistent as well as it contains grammatical errors,\nmisspelled words etc. (refer Section VI for more detail),\nthus effectiveness of sequence labeling is limited for extrac-\ntion of relevant information from EHR data [42]. To sum\nup, It is usually a dif\u001ccult task for the traditional sequence\nlabeling algorithms to extract relevant information from EHR\ndata [43] and traditional algorithms also face challenges in\nanalyzing EHR data due as such algorithms are not suitable\nfor dealing with huge columns of data [44].\nTo overcome challenges faced by traditional NLP\napproaches in extracting information from EHR, recently,\nDeep Learning (DL approaches have gained popularity [45].\nPopularity of DL models is due to:\n1) their capability of analyzing multiple data types,\n2) their ability to extract optimal features and learn repre-\nsentation from data automatically [46].\n3) their robustness against high complex functions, and\n4) their performance gets better on large datasets and it\nfurther improves as data grows in size [47].\nVarious DL architectures and frameworks have been\nused for EHR analysis. For example, deep patient [48] a\nunsupervised deep feature learning architecture, deepr [49]\na convolution Neural Network (CNN) based architecture,\nMed2Vec [50] a Multi Layer Perceptron (MLP) based archi-\ntecture, Doctor AI [51] a Recurrent Neural Networks (RNN)\nbased architecture etc. are few of the popular Deep Neural\nNetworks (DNN) architectures employed for EHR data anal-\nysis and processing. Even though, various DL architectures\nhave been used, the most popular DNN architecture used for\nEHR data analysis is RNN [52], [53]. This is due to the fact\nthat RNN are capable of dealing with the temporal nature\nof EHR data in an effective manner [54]. In short, with the\ntechnology advancements, at one side EHR have become\nmore informative sources than ever before but on the other\nhand, DL approaches have opened new avenues to extract\nand use information contained in EHR for different real world\napplications.\nDL models have shown promising results in EHR data\nanalysis and its processing [55], [56] but with new advance-\nments in medical testing, nature of EHR data (its unstructured\nelements) is getting complex. With time EHR will contain\nsuch pieces of data/information that was never used before.\nTherefore, for the effective management of advanced and\nvast data contained in EHR, more ef\u001ccient tools are required.\nResearchers need to develop such tools that can ef\u001cciently\nmanage EHR data and can convert it into knowledge that\nbene\u001cts society.\nV. SECONDARY USES OF EHR\nOne of the contributions of this study, as described above,\nis systematic analysis of various secondary uses of EHR data\nwith the aim to highlight how these secondary uses affect\npatient's privacy. This section discusses different popular\nsecondary uses of EHR data. Section VI elaborates on chal-\nlenges associated with the secondary use of EHR data while\nSection VI-D focuses on privacy and security challenges of\nEHR data.\nA. CLINICAL RESEARCH\nThe basic purpose of clinical research is to use EHR for\ndesign and execution of clinical trials for new medicines [57].\nHealth related issues are directly proportional to the pop-\nulation. Since the population of the world (especially third\nworld countries) has increased at a fast pace in the past few\nyears. This abrupt increase in the population of the world\nhas posed many challenges for healthcare professionals. For\nexample, healthcare organizations, hospitals, laboratories are\nfacing shortage of trained medical staff to tackle healthcare\nneeds of large population and because of insuf\u001ccient health-\ncare facilities, new types of diseases are grown in people or\nexisting diseases exhibit more complicated behaviors. There-\nfore, there exists a need to discover new drugs with better\nresults as well as new techniques and robust strategies to \u001cght\nagainst new grown diseases or existing complicated diseases\nstructures i.e. Covid-19 [58]. All such activities require clin-\nical research to be conducted. Thus, clinical research holds\na pivotal role in tackling some of the hard pressed medical\nissues.Some of the other areas where clinical research is\nrequired are:\n1) Prediction of diseases based on patients present\ndata [59].\n2) Study of drug behaviors with different diseases or dif-\nferent patients i.e. study on antibiotics [60].\n3) Developing vaccines for the prevention of diseases\nbefore their attack [61].\nOther than the areas mentioned above, there exists multiple\ndomains (refer Table 1) where clinical research is essential\nto overcome the existing problems of the medical world\nand to ensure high quality of healthcare delivery to the\npatients.\nTABLE 1. Different domains of clinical research.\nIn the domain of clinical research, EHR is an essential\npart because it is a basic information source and a possi-\nble way of exchanging clinical information with different\nstakeholders. Based on this exchange of information, vari-\nous health statistics are developed and decisions are made.\nFor example, based on data collected word wide, the World\nHealth Organization (WHO) publishes various reports time to\ntime for public awareness and for the authorities knowledge\nto understand the current trends and future needs related to\nparticular diseases [62], [63].\nTable 2 lists possible information sources available in EHR\nthat can help in successfully carrying out clinical research in\ndifferent domains.\nTable 2 shows that EHR contains enough information to\ncarry out clinical research in different domains. Successful\nutilization of this information for research purposes requires\ndevelopment of new and emerging research infrastructures\ncapable of exchanging information based on latest pub-\nlished standards. However, when data is shared across\ndifferent healthcare organizations, it raises different secu-\nrity and privacy concerns. These concerns are discussed\nin Section VI-D.TABLE 2. Different information sources available in EHR that can help in\ncarrying out clinical Research.\nB. PUBLIC HEALTH SURVEILLANCE\nAnother secondary use of EHR is Public Health Surveillance\n(PHS). PHS is a process of collecting, analyzing and inter-\npreting data related to a speci\u001cc disease for administering and\nassessing public health on the whole [64]. PHS particularly\ninvestigates those diseases, which harm or may tend to harm\na large population and grow in communities like epidemic or\npandemic diseases. Its main functions include collection of\nfacts about a particular disease, risk factors of its spread and\ninterpretation and analysis of the collected facts for control-\nling the disease to prevent the public from its severe effects.\nOne of the examples of PHS is the surveillance of the\nDengue outbreak in Pakistan that has been reported in [65].\nDengue is a viral disease which causes high fever in patients\nand spreads in people because of the bite of a particularAedes aegypti mosquito. Recently, it has affected around 40%\nof world's population. Pakistan is one of the most affected\ncountry from it. There are several other examples of PHS\nworld wide like reported in [66], [67].\nAs discussed above, PHS is a common practice world wide\nbut mostly in third world countries it is performed using\nmanual procedures [68], [69]. In these methods, data about\ndisease for surveillance purposes is collected using traditional\nmethods. For example, physicians prescription records are\ngathered either from patients or from hospitals and clinics\nor through public surveys [70], similarly data from other\ndepartments of the hospitals (laboratories, radiology depart-\nments, emergency departments etc) is also collected manually\nby visiting the logs of these departments' databases. The\ncollected data is then cross communicated between public\nhealth staff and health protecting agencies via telephonic and\nfax communication networks. Collected data is stored on\npapers manually and manual procedures are used to analyze\nthe stored data [71]. This method of PHS is time consuming,\nrequires large manpower and needs huge efforts to record,\nstore and analyze the data. It is also not a reliable method as\nthere are chances of errors due to manual handling of data.\nInaccurate and uncertain outcomes are possible based on the\ncollection and inspection of manually collected and stored\ndata [72]. Such traditional methods are not suitable for the\ncon\u001crmation of certain diseases, understanding its severity,\nits transmission risks, and the spread of other linked diseases.\nWith more effective ways, surveillance of diseases can be\nperformed by actively monitoring patients' EHR. As EHR is\nrich in variety of data, the summary generated by analyzed\ndata is provided to public health agencies for prevention and\ncontrol of diseases. Health surveillance by EHR provides the\nglance of the health status of the community, which promotes\nthe quality of healthcare. It tracks the key diseases, with more\neffective ways than manual procedures. Use of EHR provides\nthe opportunity to automate the PHS. It is an effective way\nof preventing outbreaks by discovering utmost danger cases\nirrespective of merely reacting to outbreaks [73]. Figure 5\nelaborates the effectiveness of EHR based automated surveil-\nlance against the traditional manual surveillance systems.\nFIGURE 5. Traditional v/s automated surveillance.\nDuring traditional surveillance, most of the time is utilized\non manual screenings and reviewing charts and less time is\nsaved for the actual intervention. On the other hand auto-\nmated PHS assisted by EHR data is time ef\u001ccient in analyzing\ndata. The same is shown in Figure 5.\nUse of EHR for public health surveillance has proved to be\neffective in developed countries such as the United Kingdom\n(UK), United States (US), France, Norway, Canada and Aus-\ntralia [74]. In these countries, local health departments have\ndiverted their manual surveillance system towards EHR based\nelectronic surveillance system. This practice has advanced\nthe functionality of PHS [75]. Developing nations have also\ninitiated adoption of EHRs for PHS to robustly analyze data\nand take actions, if required [76]. Thus, it is an important need\nof the present day automated surveillance systems to use data\nfrom EHR. For example, Integrated Disease Surveillance and\nResponse System (IDSRS) requires data to be obtained from\npatient medical records [77], [78].\nDuring the ongoing COVID-19 outbreak, the importance\nof digital data recording systems (like EHR) has been clearly\nrevealed and demonstrated to the whole world [79]. EHR has\nbeen proved to be an ef\u001ccient tool for detecting, monitoring\nand managing needs of a health systems [80]. Leveraging on\narti\u001ccial intelligence based tracking systems different coun-\ntries were able to track movement of Corona positive individ-\nuals, thus tracking down any further local transmissions of the\nvirus [80], [81]. It would not be possible, without extensive\nutilization of EHR, to place in practice a system of effective\npublic health surveillance specially to predict, monitor and\nmanage pandemic like COVID-19 [58], [82].\nFIGURE 6. Clinical audit as a cyclic process.\nC. CLINICAL AUDIT AND QUALITY ASSURANCE\nThe aim of clinical audit is to enhance patient care via\nrigorous analysis of care provided against benchmark stan-\ndards [83]. Clinical audit is a systematic way of settling stan-\ndards, analyzing data based on standards, performing actions\nto meet settled standards and executing proper monitoring to\nsustain the standards. Clinical audit is a cyclic process (refer\nFigure 6) that contains different stages to be followed for the\nachievement of best practices in clinical practices.Standards settled for the clinical audits require not only\nto be obeyed by the medical staff (doctors, nurses, mid-\nwives, therapists etc.) but also by the healthcare organizations\nlike hospitals, clinics, nursing homes, ambulatory surgical\ncenters, autonomous laboratories, radiology units, collec-\ntion units etc. Clinical audit focuses on broadly accepted\nmethods to improve overall healthcare quality. For exam-\nple, organizational development, information management\nand statistics evaluation are the key functions of clinical\naudits.\nThe role of EHR is important in clinical audits as it pro-\nvides detailed and accurate information to the auditors. Using\nEHR for clinical audits give convenience to the auditors to\nperform the clinical audits as compared to use of traditional\nclinical data for audit [84]. Figure 6 shows that the data col-\nlection and data analysis are the important parts of the clinical\naudit. In order to perform quality clinical audits, the clinical\ndata must be easily available as well as the available data\nmust be reliable to perform clinical audit. EHR conveniently\nprovides data to the auditors from multiple access points to\nperform clinical audits to better provide the quality of the care\nto the patients.\nVI. CHALLENGES ASSOCIATED WITH\nSECONDARY USES OF EHR\nPrimarily, EHR data is collected for patient's individual care\nand administrative billing purposes. Using this data for differ-\nent secondary purposes (as elaborated in Section V) is always\nchallenging [6], [85]. It is because priorities and settings of\nprimary and secondary uses are different. The quality of data\ncollected for the primary purpose cannot be the same as the\nquality of data collected for secondary uses. For example,\ndata collected for clinical research needs much more care\nand attention during collection than the data gathered during\nroutine clinical practices in the form of EHR. The quality of\ncollected clinical data is a serious concern of the researchers.\nDue to this reason, with respect to reuse of clinical data,\nthe authors of [86] suggested that the data must be used for\nits primary purpose only.\nFollowing are different factors of concern that affect the\nquality of clinical data collected through EHR.\nA. CORRECTNESS\nCorrectness refers to the accuracy of the collected data that\nis directly linked with its initial documentation (how the data\nwas collected, recorded and stored). EHR data is collected\nthrough routine clinical practices during which the clinicians\npriority is to collect the patients data according to their own\npoint of interest and according to different administrative\nneeds but not according to their various secondary uses (refer\nSection V). The chances of errors are obvious in this case.\nAccording to the study presented in [87], data accuracy col-\nlected through EHR ranges between 44% to 100%.\nErrors in EHR may lead to different outcomes, if their data\nis used for various secondary purposes. Errors include:1) Inaccurate predictions by clinical researchers\n2) Degradation in health standards and statistics as data\nanalyzed was error prone.\n3) False health surveillance results that may lead to\nunforeseen medical emergency.\nImprovement in accuracy of EHR is essential to make it\nequally bene\u001ccial for primary as well as secondary uses.\nB. INCOMPLETENESS\nAnother factor that affects quality of clinical data is related to\nthe completeness of the EHR. Usually, EHR do not contain\ncomplete patient history. It is because patients do not always\ntrust a single healthcare organization and may visit several\nsuch organizations to get a sense of satisfaction. Study con-\nducted in [88] showed that out of 1.1 million adult patients,\n31% visited two or more hospitals, whereas, one percent\npatients visited \u001cve or more hospitals for acute care during\na \u001cve year period of their study.\nPatients also miss follow up visits suggested by the physi-\ncians or sometimes due to the perfunctory of the concerned\nmedical staff (who records patient related data), incom-\nplete records are stored in EHR. A Study was conducted at\nColumbia University on 3068 pancreatic cancer patients out\nof which only 48% patients had complete pathology records,\nwhile the rest had incomplete records about the disease [89].\nEHR data is also considered incomplete for secondary\nuses because of the data ``locked-up'' condition. Locked-up\ncondition means records have details regarding patients but it\nis not present in the coded portion of the record or in other\nwords data present in EHR is structured and unstructured\n(already described in Section III). Structured data is in the\nformat that can be easily processed by the computers. On the\nother hand unstructured data mostly requires NLP (for hand\nwritten prescriptions) technique to be applied to make it\nstructured (detail is provided in Section III) and processable\nby computers [90], [91].\nC. INCONSISTENCY\nEHR data is handled by various individuals and at different\nlocations. Multiple persons are involved in entering, stor-\ning and processing the data, therefore, data contains several\nde\u001cnitions. Most of the data is present without mentioning\nproper units as units are often remembered by the medical\nstaff and they can understand language written by each other.\nOn the other hand for the non concerned person (who wants\nto use the data for secondary purposes), it may be highly\ndif\u001ccult to interpret the data without speci\u001ced units. Involve-\nment of different individuals in preparation and processing\nof EHR leads to an inconsistent form of data. It means,\ndata present in EHR is not uniform. In such non uniform\ndata, it is often dif\u001ccult to relate assessments of different\npractitioners (because the assessment of different clinicians\nis often different). Secondly, data inconsistency also arises\ndue to the fact that the data is collected with different tools at\ndifferent locations, which may be time varying (data codingregulations and system abilities may change with time) [85].\nInconsistent data may lead to erroneous data analysis and\nwrong results. Therefore, such inconsistent data is not useful\nfor secondary use.\nD. SECURITY AND PRIVACY CHALLENGES\nEHR based clinical data provides many advantages over\nmanual paper based medical records. It is cost effective,\nimproves overall healthcare quality and above all can be\neasily accessed through different linked locations. All such\nadvantages motivate health providing agencies and medi-\ncal practitioners to adopt an EHR based system. However,\nadoption of EHR and its data processing introduces several\nprivacy and security issues. Especially, when this data is used\nfor secondary purposes (refer Section V for discussion on\nsecondary uses of EHR). In the next subsections, security and\nprivacy challenges related to secondary uses of EHR have\nbeen separately discussed.\n1) SECURITY CHALLENGES\nEHR data is the most vulnerable data to the Cyber Threats.\nThe prime reason for criminals to target healthcare data is\nto get \u001cnancial gain. Criminals sell valuable data taken from\nEHR to the ``darkweb'' [92] (darkweb refers to the content on\nthe web that is not indexed by search engines and thus remains\nhidden from the general public) and achieve high \u001cnancial\ngain. For the criminals, EHR data is more informative than\ncredit cards because it contains various \u001cxed identi\u001cers and\nimportant \u001cnancial information that is extremely valuable in\nblack markets. Fixed identi\u001cers of EHR data can not be reset\nlike the ones in credit cards. Such identi\u001cers in EHR are the\nbest information sources for the criminals to get easy access\nto the patient's bank accounts for getting loans or to cap-\nture their passports and other important documents (property,\ninsurance etc.) [93]. There are several cases, which shows\nthat highly sensitive information of patients was easily stolen\nby simply stealing EHR data. For example, a recent article\npublished a story about theft of EHR data (20,000 records)\nfrom North Carolina-based Catawba Valley Medical Center.\nStolen data contained patients' names, dates of birth, med-\nical data, health insurance information and social security\nnumbers [94].\nSince, the data in EHR contains more detailed infor-\nmation than the other sources, therefore, in case of cyber\nattacks (Ransomware, Distributed Denial of Service (DDoS)\netc.), a big population can be affected at once that can lead\nmuch beyond the \u001cnancial losses [95]. For example, in the\nUnited States (US), 4.5 millions patients' affected by losing\ntheir data form a popular group of hospitals through hack-\ners attack [96]. Similarly, 80 millions people were affected\nbecause their healthcare data was lost from a health insurance\ncompany in US [97].\nOther than personal and \u001cnancial information, EHR data\nalso contains patient's highly con\u001cdential data in the form\nof physicians' personal notes, neuroimaging data [98], [99],\nX-rays, ultrasounds as well as lab reports. This data may\ninclude lab results of HIV and other sexually transmitted\ndiseases [100], mental disorders [101], personality disor-\nders [102], contagious diseases as well as doctors sensitive\ncomments about patient mental illness or personality dis-\norders etc. All such data is stored in the hospital's local\ndatabase (each hospital may have its own local electronic\ndatabase), which is connected across other hospitals' or\nhealth providers' databases via wired or wireless connections\nfor sharing purposes. Transfer of such con\u001cdential data over\nthe internet creates several security risks. It provides a chance\nto hackers and other harmful attackers to access the data and\nuse it for their own purpose [103]. In case of patients mon-\nitored at home, the data from patients is collected through a\ndistributed network of sensors. Securing such data is another\nbig challenge because there are greater chances of spying and\nskimming [104].\nWith the passage of time healthcare technologies are\nextending and new technologies are being introduced to pro-\nvide instant help to the patients and to enhance healthcare\nquality. For example, different smart devices monitor health\n(with the general purpose devices or wearable sensors) and\nprescribe medications as well as provide telemedicine tech-\nnology for delivering remote care [105]. Patients now can\neasily access healthcare facilities by integrating their mobile\nphones with telemedicine and telehealth services using sim-\nple mobile applications [106]. As the technology in health-\ncare is continually evolving, its inter connectivity is also\nevolving. With the help of interconnected networks, patients'\ninformation is made broadly available to the relevant organi-\nzations and staff to provide quality healthcare. Exchange of\npatient information over the large inter connected network is\nbene\u001ccial in many ways but has increased existing security\nrisks.\nWith the increased used of smart healthcare services,\ne health solutions [107], [108], and digital record systems,\nEHR data generates sheer volume of data (Alone in US 48%\ngrowing annually [109]), therefore, most of the data of EHR\ndatabase is stored on cloud services [110].\nCloud storage of EHR is bene\u001ccial in many ways like it\nprovides cost effective storage, easy access as well as process-\ning and updating of information is achieved with improved\neffectiveness and ef\u001cciency but on the other hand opens new\ndoors for the threats and breaches [111]. It is because highly\nsensitive and con\u001cdential patients' information contained in\nEHR is stored on a third party server where the owner does\nnot have any direct access [112]. Vulnerabilities also increase\nbecause of the fact that during cloud services, a large amount\nof EHR data runs on a wide network of integrated remote\nservers and is accessed by multiple authorized users as a\nsingle echo system from different distributed locations [113].\nCyber security is a technology that safeguards computer\nnetworks and information contained in them from different\ncyber attacks [114]. In case of healthcare data, cyber security\ntechnology needs to be robust and strong as the healthcare\nsector presents a lucrative avenue to cyber criminals to attackand get hold of very sensitive data to gain large \u001cnancial\nbene\u001cts.\nThere have been many efforts reported in literature to\nprotect information contained in EHR while it is acces-\nsible to different stakeholders through network. Different\ncryptographic, non cryptographic and hybrid access control\nmodels have been developed to securely access EHR data\n[115], [116], but with the advancements in technology, secur-\ning data in EHR is more challenging as it was ever before.\nTherefore, there is a high need of securing data in EHR over\nthe network and on cloud servers [117].\nEspecially securing EHR data on the cloud needs more\nattention. According to the recently published research in\nliterature [111] the existing privacy and security-protecting\nmechanisms are not enough to ensure foolproof security in\nthe e-health cloud. Even though, researchers have introduced\na few very advanced encryption methods such as Attribute\nBased Encryption (ABE) [118], Key Policy Attribute Based\nEncryption (KP-ABE) [119] and Cipher text policy Attribute\nBased Encryption (CP-ABE) [120] but these are not of much\nhelp because the data hosted on clouds is not only vulnerable\nto external hackers' attacks but also to the internal attacks\nfrom the authorized people (database administrators and key\nmanagers). The above mentioned advanced access control\nmethod cannot provide support when the key managers are\nattackers.\nIn order to overcome such de\u001cciencies of cloud based\nstorage, recently blockchain chain technology has been\nintroduced in the healthcare sector [121], [122]. Although\nblockchain technology provides a range of bene\u001cts over\nthe cloud computing technology, it does not provide \u001cne-\ngrained control of access over EHR. In blockchain technol-\nogy, only the patient's private key can decrypt the encrypted\nEHR [123].\nIt is worth mentioning here to explain that the security\nof healthcare data is not only today's concern rather it was\nthe concern before the emergence of the EHR [104]. Data\nsecurity was well studied before the EHR came into existence\n(paper based patients records were needed to be safeguarded\nwithin the premises of hospitals and not on large scales)\nbut with the adoption of EHR multiple gateways opened\nfor accessing patients' information remotely. Furthermore,\nThe patient's EHR contains more detailed information all\ntogether in a single source as compared to the previous paper\nbased medical records, which were distributed among differ-\nent departments of hospitals. With the adoption of EHR it is\nnow easy for the criminals to attack millions of people at a\ntime and to steal their valuable information (because EHR are\ninterconnected with numerous networks. In the case of paper\nbased records it was not possible to steal millions of patients\nrecords at a time).\nIn short, adoption of EHR has not only provided the range\nof bene\u001cts but also introduced potential risks of cyber attacks.\nHealthcare organizations spend more on increasing their inte-\ngration but do not spend much on their system protection.In order to gain patients' trust and to give them satisfaction\nregarding their data safety, the healthcare providers have to\nthink about developing robust practical standards and solu-\ntions with particular healthcare/ EHR needs.\n2) PRIVACY CHALLENGES\nPrivacy is de\u001cned as ``right to be left alone'' or to keep\naway from public domain [124]. The United Nations Gen-\neral Assembly (UNGA) declared privacy as a fundamental\nhuman right in its universal declaration of human rights.\nHowever, in this digital era the term privacy has become\nsubjective and is interpreted and implemented differently by\neach state or country [125]. Such ambiguities are sometimes\nexploited for different reasons, for example EHR data is used\nto gain \u001cnancial bene\u001cts [126] or for different secondary\npurposes, refer Section V for discussion on secondary uses\nof EHR.\nAs mentioned above, EHR data contains several security\nrisks especially when the information contained in them is\nshared with different stakeholders over the interconnected\nnetworks. Other than security issues, there are certain privacy\nconcerns linked with exchange and sharing of EHR data.\nThese privacy concerns are usually raised due to the fact that\nwhen the patients data (which was recorded for the purpose of\npatient individual care) is being shared or linked without con-\nsent or knowledge of a particular individual. Usually consent\nof an individual is necessary for sharing of data but ambiguity\narises when different healthcare organizations have different\nperspectives on the question of ``who owns the data?''. Does\ndata belong to the patient, his/her physician, health insurance\norganization, healthcare organization, social security agency\nor is it jointly owned by all [104], [127]?\nBreach of data can happen due to various reasons, refer\nSection VI-D1, which has many ethical repercussions. For\nexample, disclosing a patient's sensitive private information\nsuch as sexually transmitted diseases or mental illness in the\npublic domain can negatively impact an individual's reputa-\ntion. In extreme cases such individuals can face social boy-\ncott as people start avoiding an individual if they know that\nhe/she has sexually transmitted diseases like HIV, chlamy-\ndia etc., [128]. Secondly, a person's status in the society is\nseriously affected if his/her mental illness is disclosed to the\npublic [129]. Another dimension to this issue is \u001cnancial\nimpact on an individual's life as medical insurance companies\nusually calculate premium/cost of insurance based on medi-\ncal history and life events. In such cases insurance companies\ncan increase their premium [130], [131].\nThe privacy of clinical data has been subject to a lot of\nresearch and it has been dif\u001ccult to determine how much of\nthe data belongs to the patient and how much of it may belong\nto healthcare organizations and whether the consent of the\nowner of data is needed, in case the data is to be used for the\nresearch purpose [127], [132], [133]. Privacy of patients can\nbe affected when his/her data is used for clinical research or\nsecondary use, refer Section V for discussion on secondaryuses of EHR. For example, a blood sample given by a patient\nis stored in a laboratory and after carrying out requested\nanalysis the same sample is analyzed again for the purpose\nof clinical research. Even though the sample is returned back\nto the laboratory without any damage, still it violated data\nprivacy because by this way the patient's control over his/her\ndata was lost [127], [132].\nIn research conducted by Bovenberg and Almeida [134]\nreferred to a case of patients versus Myriad Genetics, a molec-\nular diagnostic company. The case was about four US cancer\npatients who wanted to have full access to their genomic\ndata. Myriad claimed that patients were provided with all\nthe information that was necessary to be included in their\nreports and additional data was not part of the medical record\nset. Patients, however, claimed that the additional data was\nacquired from their lab samples, hence they have the right\nover data and only they should decide what happens to their\ndata.\nIn order to protect sensitive data many patients try to\nconceal their sensitive information. It is because of the lack\nof con\u001cdence in the system's security retaining their data.\nIt also shows mistrust of patients' on medical staff (doctors,\nnurses and the others) because patients think that they might\ndisclose their con\u001cdential information to the public that may\ncreate embarrassment for them in society [135]. Some events\nhave happened in the past because of which patients have\nbecome more sensitive in disclosing their private information.\nFor example, in 2013, one of the medical technicians of\na US hospital was found guilty in selling patients medical\ninformation [136]. Similarly, a hospital in the US informed\nits 34000 patients that their medical information has been\nlost from their agent [137]. Due to all such incidents, patients\ndon't feel con\u001cdent in disclosing their information even to the\nphysicians. Hiding facts and information from the physicians\nand the medical staff can lead to treatment failure. Thus,\nsuch challenges may have severe consequences for patients,\nhealthcare providers and even for the governments.\nIt is highly recommended from policy makers, leaders and\nrelated authorities to discuss privacy and security concerns\nof EHR data (database storage policies or its sharing poli-\ncies and paradigms) and formulate policies to address these\nconcerns. There are some existing policies, which need to\nbe revised or reformulated according to the present day era,\nan era of data analytics, big data and arti\u001ccial intelligence.\nVII. POPULAR DATA PROTECTION REGULATIONS\nAND THEIR CHALLENGES\nA. GENERAL DATA PROTECTION REGULATION (GDPR)\nIn order to protect patients' personal sensitive data from\ndifferent security threats and privacy violations, in some\nregions of the world, data protection regulations have been\nenforced by the authorities. The most popular data pro-\ntection regulations are General Data Protection Regulation\n(GDPR) [13], Health Insurance Portability and Account-\nability Act (HIPAA) [138] In this study we have critically\nanalyzed these regulations in terms of how these protect\npatient privacy and enforce data security.\nAfter years of discussions, drafting, negotiations and\nefforts, in April 2016 GDPR was passed by European Union.\nOn 25 May 2018, the European Parliament and Council of the\nEuropean Union both with their combined efforts enforced\nthe GDPR 2016/679 [139]. Since then, professionals, citizens\nand authorities across Europe and beyond are strictly bound\nto the legal regimes imposed by GDPR. It is an exhaustive\ndocument of legislation that addresses challenges of data pro-\ntection of personal data. The aim of GDPR is to control and\nimprove handling and processing of personal data particularly\nof European citizens. It oversees every aspect of citizens per-\nsonal data handling and has recommended to impose heavy\npenalties for non compliance that may include prosecution of\nany organization in the world that is found guilty of privacy\nbreach or misusing European citizens data [140].\nGDPR is not only bene\u001ccial for the citizens but also for\nthe organizations as it gives citizens con\u001cdence to share their\ndata with the organizations when required. It also boosts\norganizations business and helps them in their smooth run-\nning without any hurdle of acquiring citizens data (without\ntrust citizens usually do not share their data when required\nby the organizations, refer Section VI-D2 for discussion on\nmistrust between data provider and data handler). Even with\nall these obvious advantages, organizations in the past were\nrigid to adapt (at present they are forced to adapt) privacy\nregulations imposed by GDPR [141]. This is due to the fact\nthat enterprises and organizations were facing challenges\nin implementing these regulations [142]. The organizations\nwere already complying with the regulations imposed by the\nEuropean Data Protection Directive (EDPD) of 1995 [143]\nand were not prepared for the new changes or possibly there\nwas a lack of awareness of the new requirements raised by\nthe GDPR. Another issue with the implementation of GDPR\nwas \u001cnancial needs, human resource requirements as well as\nproper training of the employees to understand the GDPR\nregulations [144].\nGDPR de\u001cnes six main data protection principles (other\ndata protection principles further clarify them or further\nenhance them) that organizations (healthcare organizations)\nhave to comply with when processing European citizens\npersonal data [145].\nEach of these principles is brie\u001dy explained below with\nimplications on EHR data.\n1)Lawfulness, fairness and transparency\n(Article 5(1)(a)): This article states that citizens per-\nsonal data must be processed lawfully, fairly and trans-\nparently. Lawful processing of data is further de\u001cned\nin Article 6, which states that in order to process\npersonal data lawfully, it is necessary for the data con-\ntrollers to set out/obey one of the following conditions\n(In this section the term ``data controller'' is used\nmultiple times and in the context of this study this term\nrefers to healthcare organizations which records and\nstores/hold personal data):\u000f``The data subject must be given consent\n(Article 6(1)(a))''.\n\u000f``Processing is necessary for the performance of\na contract to which the data subject is party\n(Article 6(1)(b))''.\n\u000f``Processing is necessary for compliance with the\nlaw (Article 6(1)(c))''.\n\u000f``Processing is necessary to protect vital interest of\nthe data subject (Article 6(1)(d))''.\n\u000f``Processing is necessary for the performance\nof a task carried out in the public interest\n(Article 6(1)(e)''.\n\u000f``Processing is necessary for a legitimate interest\nof the controller or third party (Article 6(1)(f)''.\nIn order to process personal data lawfully, all the\nclauses of the Article 6 (mentioned above) are impor-\ntant to be followed by the data controllers but the\nmost pertinent clause of the article 6 in the context\nof EHR data is 6(1)(a) that relates to the processing\nof personal data with the consent of the person whose\ndata is being used. However, based on the employer-\nemployee or physician-patient relationships, where one\nparty (physician in our case) is in power and processes\nother party's personal data, consent is not a proper legal\nbasis to be relayed upon [146]. This is due to the fact\nthat data protection regulation requires consent should\nbe genuinely free without any pressure/intimidation.\nIt can only be possible if the patients have freedom\nin giving their consent or not and have a choice to\nwithdraw their consent at any point of time without any\ndetriment as easy as they gave it.\n2)Purpose limitations (Article 5(1)(b)) : Purpose limita-\ntions bounds organizations (healthcare organizations)\nand individuals to collect personal data only for a\nspeci\u001cc, explicit and legitimate purpose and the data\nmust be used for achieving that purpose only. Data\npurpose must be clearly de\u001cned before its collection\nand it should not be further processed in a way that is\nincompatible with the original de\u001cned purpose(s).\n3)Data minimization (Article 5(1)(c)) : In order to use\npersonal data, it must be limited to its primary purpose\nonly. It must not be collected more than its need.\n4)Accuracy(Article 5(1)(d)) : In dealing with the citizens\npersonal data it must be responsibly dealt for example,\nif the data needs updation and inaccurate or incomplete\ndata elements need to be removed, all must be done\nwith high accuracy.\n5)Storage limitations (Article 5(1)(e)) : Storage limita-\ntions refer to the fact that personal data must be deleted\nafter it has been used and no longer further needed.\nIt means data should be collected with a proper prede-\n\u001cned time-line and it must be removed after the time-\nline is reached.\n6)Integrity and Con\u001cdentiality (Article 5(1)(f)) : It is\nthe entire responsibility of the individuals or organiza-\ntions (who want to process citizens personal data) toensure the safe processing of data and to protect it from\nunauthorized use. During processing, data must be safe\nfrom any accidental loss, damage or demolition and it\nmust be protected against any unlawful use.\nIf analyzed critically, clauses (b-f) of Article 5 have con-\ntradictory nature in the context of EHR data concepts. The\nregulations mentioned in these clauses (such as data mini-\nmization, purpose limitation) limits the quantity of data col-\nlection and enforces its deletion soon after the purpose has\nbeen achieved. On the other hand, healthcare organizations\nencourage collecting more and more data and to save it for\nlonger periods of time for the purpose of detailed analysis,\nmining and predictions [147], as discussed in Section V.\nArticle 25 further enhances the ideas presented in Article 5\nby de\u001cning privacy by design i.e. ``The controller must\nimplement appropriate technical and organizational measures\nfor ensuring that, by default, only personal data which are\nnecessary for each speci\u001cc purpose of the processing are\nprocessed''. Although, this Article enhances protection of\npersonal data by demanding privacy by design form the\ncontrollers but it is dif\u001ccult to implement because of its\nbroader de\u001cnition and due to the requirement of additional\nimplementation cost and resources. Furthermore, privacy by\ndesign can show rigid behavior with time (like the other\nembedded technical solutions) because of not updating its\nmeasures frequently [148].\nIt has already been described in this study (refer\nSection VI) that the healthcare data is one of the most vul-\nnerable data in terms of security threats, therefore needs\nspecial attention for protection during processing. Article 9\nof GDPR de\u001cnes the processing of such special categories\nof data, which requires additional protections in processing\nsuch as genetic data, biometric data, healthcare data etc.\nArticle 9 imposes additional obligations and provides more\nrestrictive legal basis for processing health related sensitive\ndata. The recommendation of this article is to obtain explicit\nconsent of collecting and processing sensitive personal data.\nAlthough, explicit consent of data processing is required in\nprocessing any type of personal data (Refer article 6(1)(a)\nmentioned above) but in case of processing healthcare data,\nobtaining consent is usually dif\u001ccult, specially for secondary\npurpose, refer Section V for secondary uses of EHR data.\nObtaining explicit consent for every secondary use is a time\nconsuming, costly as well as an exhausting process [149].\nThere has been a great debate on obtaining speci\u001cc consent\nin literature. The conclusive outcome of all such debates\nis to shift speci\u001cc consent into a broader consent of data\nprocessing that covers the range of its future uses (such as\nsecondary uses of EHR) [150].\nAt present, most of the patients are not aware (or do not\nwant to be aware) about what happens to their data once it\nhas been taken from them and also they do not know about\nthe data processing procedures undertaken by the healthcare\nproviders. According to Spiekermann et al. [151], if indi-\nviduals knew about today's healthcare business model andhow third parties use personal private data, they would be\nsurprised and feel betrayed. Obviously, under such circum-\nstances, obtaining broad consent is not logical.\nArticle 32 of GDPR de\u001cnes security of processing of per-\nsonal data. According to it, to process and maintain security\nof personal data pseudonymisation should be performed [13].\nPseudonymisation is a technique to ensure that an indi-\nvidual won't be identi\u001ced through personal data (personal\ndata includes direct and indirect identi\u001cers that can identify\na person for example, name, ID number, location, contact\ninformation (Article 4)) [13]. The process is to replace the\nmain characteristic of an individual with randomly generated\nindicators. The information regarding identi\u001ccation must be\nstored separately [152]. Even if pseudonymisation technique\nis applied, it is possible to re-identify individuals by combin-\ning different data sets [153]. Re-identi\u001ccation pulls down the\nillusion of privacy policies, which are promised by technol-\nogists. Lawmakers should re-evaluate law and consider the\nweakness of pseudonymisation [154].\nOther than the regulations described above, one of the\nmost controversial regulation is the ``Right to be Forgot-\nten'' (Article 17). This article imposes an obligation of era-\nsure of one's personal data on the controllers. It gives the\nright to the users to erase their data any time from all the\navailable places from where they want as per their request.\nAccording to concept of healthcare data where decision sup-\nport and predictive systems are being made by archiving\nthe patients' personal data (consider case of public health\nsurveillance or clinical research, refer Section V), this arti-\ncle creates huge controversy because logically no more\nbackups or archives of data would be applicable by the\norganizations.\nB. HEALTH INSURANCE PORTABILITY AND\nACCOUNTABILITY ACT (HIPAA)\nIn the year 1996 US congress made and passed HIPAA\nact to protect the patients' con\u001cdential health information\ncontained in their medical records. HIPAA act brought forth\nmultiple standards for addressing the privacy and security\nrelated issues with the patients Protected Health Informa-\ntion (PHI) [155]. In terms of HIPAA, PHI refers to the\n``Individually Identi\u001cable Information'' that is transmitted\nthrough electronic or any other media with the exception of\neducational or employment records [156]. The basic purpose\nof HIPAA was to secure healthcare information that is sub-\njected to the health transactions. The HIPAA regulations were\nslowly implemented and its additional rules and regulations\nwere released from time to time. During the period from\n2002 to 2007, the following six additional regulations were\nreleased [157].\n\u000fIn October 2002, standards for electronic claims and\ntransactions were established.\n\u000fIn April 2003, guidelines for the disclosure of patient\nhealth information were established.\n\u000fIn June 2004, National Employer Identi\u001cer Rule (NERI)\nwas established according to which the federal tax iden-\nti\u001ccation number was considered as the employer's\nnational identi\u001cer.\n\u000fIn April 2005, some technical as well as administrative\nprotocols were established for the security and integrity\nof the patient's health information.\n\u000fIn February 2006, HIPAA enforcement rule was estab-\nlished to guide how the government will enforce the\norganizations to implement HIPAA regulations.\n\u000fIn May 2007, National Provider Identi\u001cer (NPI) rule was\nestablished based on which a national identi\u001cer for each\nprovider was made and the procedures for spreading,\nstoring, and updating the identi\u001cer was set up.\nIn 2009, Health Information Technology for Economic\nand Clinical Health (HITECH) Act was passed. The prime\nobjective of this act was to promote across the USA, imple-\nmentation of EHR by providing different incentive programs\nfor adoption of EHR and penalties for not implementing\nit [158], [159]. Alongside the EHRs implementation, HITEC\nalso expanded the existing HIPAA privacy and security reg-\nulations and enhanced the monetary penalties of HIPAA\nviolations [160].\nIn 2013, HIPAA was further enhanced by adding new rules\nknown as Omnibus rules 2013 [158]. After the Omnibus\nrules, HIPAA's coverage was expanded from healthcare\nproviders (physicians, hospitals, insurance companies etc.)\nto third party administrators (pharmacy bene\u001ct managers,\nhospitals consultants etc.) who after the implementation\nof these rules, get punishments in case of any privacy\nbreach [161].\nIn the year 2016, 21st Century Cures Act was passed [162],\nwhich further enhanced existing HIPAA regulations by solv-\ning several interoperability issues. The Cures Act de\u001cnes\nspeci\u001cc policies to promote patient access to their data.\nParticularly, its purpose was to establish strong linkage\nand partnership between healthcare organizations and health\ninformation exchange organizations to ease patient access to\ntheir information contained in EHR, in a format that is easy\nto understand & handle, secure while accessing, and can be\nupdated automatically [163].\nHIPAA provides comprehensive guidelines to understand\nthe use of technology for the collecting, storing and trans-\nmitting PHI. It focuses on streamlining procedures for imple-\nmentation of different security measures but on the other\nhand it does not elaborate on how to practically implement\nsuch measures. After its legislation in 1966, HIPAA has\nnot undergone any major iteration, therefore, its rules have\nbeen outdated and cannot provide much help in safeguarding\nagainst the vague threats of the present digital age [164].\nDue to this reason, alternative frameworks are being adopted\nby the healthcare providers in order to give their systems\nfull support against threats. For example, in complement\nto HIPAA, National Institute of Standards and Technol-\nogy (NIST) provided a framework (published in 2014 andaugmented in 2018) that speci\u001ccally focuses the areas where\nHIPAA lacks (like, helping organizations by educating and\ntraining their employees) [165].\nAnother major issue with HIPAA regulations is that its\nprotection applies only on covered entities i.e. health care\nproviders, clinicians, pharmacies, health care facilities and\nhealthcare clearinghouses but not on the non covered enti-\nties i.e. different types of information sharing platforms like\nsocial media posts [166]. Therefore, it can cause personal\ninformation leak [167]. In case of releasing patient informa-\ntion from uncovered entities like online e-commerce plat-\nforms, social media posts, \u001ctness trackers data on the internet\netc. HIPAA does not provide any protection.\nIn short, HIPAA with HITEC and Cure regulations have\nnot advanced itself with fast growing technology. It does not\ncompletely ful\u001cll patients' expectations of immediate avail-\nability of their health data electronically when needed [168]\nand robustly securing personal data. Therefore, HIPAA rules\nneed further re\u001cnement [169] keeping in view of fast pace\nproliferation of technology and AI assisted gadgets.\nIn light of above discussion, HIPAA rules need major\namendments in order to robustly protect patients personal\nand sensitive data and to make it accessible instantly where\nand when needed. There is also a need to de\u001cne and include\ndifferent non covered entities into HIPAA's scope to extend\nits protection to different information sources critically asso-\nciated with the EHR data in the present digital era.\nVIII. CONCLUSION\nThe objective of this research article is to provide overview\nof EHR and its various secondary uses, how such uses affect\nindividuals privacy and whether the existing important pri-\nvacy regulations i.e. GDPR and HIPPA overcome these pri-\nvacy challenges. Article began with an overview of EHR,\nits data sources that contribute to making EHR. Then, dif-\nferent standards for sharing EHR data i.e. HL7 and FHIR\nare discussed. Subsequently, thorough analysis of various\nsecondary uses of EHR with the aim to highlight how these\nsecondary uses affect patients' privacy is presented. In the\nlast, the article critically examined GDPR and HIPAA reg-\nulations and highlighted possible areas of improvement in\nthese regulations, considering escalating use of technology\nand different secondary uses of EHR.\nPresented article outlined various secondary uses of EHR\nto give readers an idea that how effectively EHR data can be\nused in different domains such as clinical research, public\nhealth surveillance and clinical audits to provide effective,\ntimely and quality healthcare facilities to the patients, refer\nSection V. In order to use EHR data for secondary purposes\nmore effectively, challenges associated with the secondary\nuses of EHR have also been described to make readers well\naware of the EHR data challenges when using it for secondary\npurposes.\nIn the present technological era, adoption of EHR has posi-\ntively impacted healthcare services. With the help of seamlessdata sharing an individual can avail instant healthcare\nservices at their location of preference. However, with evolv-\ning technology, risks of data security and compromise of\nprivacy have also been signi\u001ccantly increased. EHR data con-\ntains highly personal and sensitive information i.e. ID/social\nsecurity number, bank details, family information and med-\nical history. Unauthorized access to EHR information can\nhave devastating \u001cnancial and social impact on individuals\nif such sensitive information is leaked in the public sphere.\nIn this article different ethical and privacy issues arising\nfrom EHR data leak are discussed in detail in Section VI-D.\nIn the referred section, data security and patients' privacy\nrisks related to the secondary uses of EHR especially when\nEHR data is stored on cloud, transmitted through network and\nshared & exchanged with multiple stakeholders are critically\nstudied.\nThere exists different privacy regulations to protect patients\nprivacy and data security when EHR data is used for sec-\nondary purposes and transferred & exchanged with multiple\nconcerned stakeholders through different linked locations.\nHowever, there is a need to critically examine such regu-\nlations to analyze them for calculating their effectiveness\nin terms of safeguarding personal data as per present era\nneeds. There is also a need to highlight the challenges of\nsuch regulations to further improve their effectiveness in\nsafeguarding personal data from the potential cyber attacks\nand to cope with the technological advancements of cyber\nattacks. In this study, important privacy regulations i.e. GDPR\nand HIPPA are studied in perspective of secondary use of\nEHR, refer Section VII. Our purpose is to highlight possible\nimprovements areas in these regulations to make them more\neffective in protecting privacy and data security and to make\nthem robust against escalating AI-assisted techniques in data\nanalytics and cyber attacks.\nREFERENCES\n[1] S. Al-Janabi, I. Al-Shourbaji, M. Shojafar, and S. Shamshirband, ``Survey\nof main challenges (security and privacy) in wireless body area net-\nworks for healthcare applications,'' Egyptian Inform. J. , vol. 18, no. 2,\npp. 113\u0015122, Jul. 2017.\n[2] P. K. D. Pramanik, S. Pal, and M. Mukhopadhyay, ``Healthcare big data:\nA comprehensive overview,'' in Intelligent Systems for Healthcare Man-\nagement and Delivery . Hershey, PA, USA: IGI Global, 2019, pp. 72\u0015100.\n[3] M. Maghazil, ``A comparative analysis of data security in computer-based\nand paper-based patient record systems from the perceptions of healthcare\nproviders in major hospitals in Saudi Arabia,'' Ph.D. dissertation, School\nEng. Appl. Sci., George Washington Univ., Washington, DC, USA, 2004.\n[4] O. Ben-Assuli, ``Electronic health records, adoption, quality of care, legal\nand privacy issues and their implementation in emergency departments,''\nHealth Policy , vol. 119, no. 3, pp. 287\u0015297, Mar. 2015.\n[5] C. Spiranovic, A. Matthews, J. Scanlan, and K. C. Kirkby, ``Increas-\ning knowledge of mental illness through secondary research of elec-\ntronic health records: Opportunities and challenges,'' Adv. Mental Health ,\nvol. 14, no. 1, pp. 14\u001525, Jan. 2016.\n[6] D. F. Lobach and D. E. Detmer, ``Research challenges for electronic\nhealth records,'' Amer. J. Preventive Med. , vol. 32, pp. S104\u0015S111,\nMay 2007.\n[7] P. J. O'Connor, J. M. Sperl-Hillen, W. A. Rush, P. E. Johnson,\nG. H. Amundson, S. E. Asche, H. L. Ekstrom, and T. P. Gilmer, ``Impact\nof electronic health record clinical decision support on diabetes care:\nA randomized trial,'' Ann. Family Med. , vol. 9, no. 1, pp. 12\u001521,\nJan. 2011.[8] A. Temko, W. Marnane, G. Boylan, and G. Lightbody, ``Clinical imple-\nmentation of a neonatal seizure detection algorithm,'' Decis. Support\nSyst., vol. 70, pp. 86\u001596, Feb. 2015.\n[9] T. Seymour, D. Frantsvog, and T. Graeber, ``Electronic health records\n(EHR),'' Amer. J. Health Sci. , vol. 3, no. 3, pp. 201\u0015210, Jul. 2012.\n[10] N. Menachemi and T. C. Collum, ``Bene\u001cts and drawbacks of electronic\nhealth record systems,'' Risk Manage. Healthcare Policy , vol. 4, p. 47,\nMay 2011.\n[11] J. Wang, Z. Zhang, K. Xu, Y. Yin, and P. Guo, ``A research on security and\nprivacy issues for patient related data in medical organization system,''\nInt. J. Secur. Appl. , vol. 7, no. 4, pp. 287\u0015298, 2013.\n[12] S. Teasdale, D. Bates, K. Kmetik, J. Suzewits, and M. Bainbridge, ``Sec-\nondary uses of clinical data in primary care,'' J. Innov. Health Inform. ,\nvol. 15, no. 3, pp. 157\u0015166, Sep. 2007.\n[13] Regulation (EU) 2016/679 of the European Parliament and of the Council\nof 27 April 2016 on the Protection of Natural Persons With Regard to the\nProcessing of Personal Data and on the Free Movement of Such Data, and\nRepealing Directive 95/46 , General Data Protection Regulation, 2016.\n[14] J. P. Albrecht, ``How the GDPR will change the world,'' Eur. Data\nProtection Law Rev. , vol. 2, no. 3, pp. 287\u0015289, 2016.\n[15] Health Insurance Portability and Accountability Act of 1996 , Account-\nability Act, 1996.\n[16] B. Hemsley, S. McCarthy, N. Adams, A. Georgiou, S. Hill, and\nA. S. Balandin, ``Legal, ethical, and rights issues in the adoption and use\nof the `my health record' by people with communication disability in\nAustralia,'' J. Intellectual Develop. Disab. , vol. 43, no. 4, pp. 506\u0015514,\n2018.\n[17] P. C.-I. Pang and S. Chang, ``The Twitter adventure of #MyHealthRecord:\nAn analysis of different user groups during the opt-out period,'' Stud.\nHealth Technol. Inform. , vol. 266, pp. 142\u0015148, Aug. 2019.\n[18] R. Munir and R. A. Khan, ``An extensive review on spectral imaging in\nbiometric systems: Challenges & advancements,'' J. Vis. Commun. Image\nRepresent. , vol. 65, Dec. 2019, Art. no. 102660.\n[19] R. A. Khan, A. Crenn, A. Meyer, and S. Bouakaz, ``A novel database\nof children's spontaneous facial expressions (LIRIS-CSE),'' Image Vis.\nComput. , vols. 83\u001584, pp. 61\u001569, Mar./Apr. 2019.\n[20] M. S. Jaliaawala and R. A. Khan, ``Can autism be catered with arti\u001ccial\nintelligence-assisted intervention technology? A comprehensive survey,''\nArtif. Intell. Rev. , vol. 53, no. 2, pp. 1039\u00151069, Feb. 2020.\n[21] N. A. Latha, B. R. Murthy, and U. Sunitha, ``Electronic health record,''\nInt. J. Eng. , vol. 1, no. 10, pp. 25\u001527, 2012.\n[22] K. H\u00e4yrinen, K. Saranto, and P. Nyk\u00e4snen, ``De\u001cnition, structure, con-\ntent, use and impacts of electronic health records: A review of the\nresearch literature,'' Int. J. Med. Inform. , vol. 77, no. 5, pp. 291\u0015304,\nMay 2008.\n[23] K. Kawamoto, C. A. Houlihan, E. A. Balas, and D. F. Lobach, ``Improving\nclinical practice using clinical decision support systems: A systematic\nreview of trials to identify features critical to success,'' BMJ, vol. 330,\nno. 7494, p. 765, Apr. 2005.\n[24] C. Castaneda, K. Nalley, C. Mannion, P. Bhattacharyya, P. Blake,\nA. Pecora, A. Goy, and K. S. Suh, ``Clinical decision support systems\nfor improving diagnostic accuracy and achieving precision medicine,''\nJ. Clin. Bioinf. , vol. 5, no. 1, p. 4, Dec. 2015.\n[25] A. Boonstra and M. Broekhuis, ``Barriers to the acceptance of elec-\ntronic medical records by physicians from systematic review to taxonomy\nand interventions,'' BMC Health Services Res. , vol. 10, no. 1, p. 231,\nDec. 2010.\n[26] D. Kalra and D. Ingram, ``Electronic health records,'' in Information\nTechnology Solutions for Healthcare . London, U.K.: Springer, 2006,\npp. 135\u0015181.\n[27] R. H. Dolin, L. Alschuler, C. Beebe, P. V. Biron, S. L. Boyer, D. Essin,\nE. Kimber, T. Lincoln, and J. E. Mattison, ``The HL7 clinical document\narchitecture,'' J. Amer. Med. Inform. Assoc. , vol. 8, no. 6, pp. 552\u0015569,\nNov. 2001.\n[28] R. H. Dolin, L. Alschuler, S. Boyer, C. Beebe, F. M. Behlen, P. V. Biron,\nand A. Shabo, ``HL7 clinical document architecture, release 2,'' J. Amer.\nMed. Inform. Assoc. , vol. 13, no. 1, pp. 30\u001539, Jan. 2006.\n[29] T. Benson and G. Grieve, ``HL7 version 2,'' in Principles of Health\nInteroperability . Cham, Switzerland: Springer, 2016, pp. 223\u0015242.\n[30] G. W. Beeler, ``HL7 version 3\u0016An object-oriented methodology for\ncollaborative standards development,'' Int. J. Med. Inform. , vol. 48,\npp. 151\u0015161, Feb. 1998.\n[31] T. Al-Enazi and S. El-Masri, ``HL7 engine module for healthcare infor-\nmation systems,'' J. Med. Syst. , vol. 37, no. 6, p. 9986, Dec. 2013.\n[32] D. Bender and K. Sartipi, ``HL7 FHIR: An agile and RESTful approach\nto healthcare information exchange,'' in Proc. 26th IEEE Int. Symp.\nComput.-Based Med. Syst. , Jun. 2013, pp. 326\u0015331.\n[33] M. Sharma and H. Aggarwal, ``HL-7 based middleware standard for\nhealthcare information system: FHIR,'' in Proc. 2nd Int. Conf. Commun.,\nComput. Netw. Singapore: Springer, 2019, pp. 889\u0015899.\n[34] A. Atreja, J.-P. Achkar, A. K. Jain, C. M. Harris, and B. A. Lashner,\n``Using technology to promote gastrointestinal outcomes research: A case\nfor electronic health records,'' Amer. J. Gastroenterol. , vol. 103, no. 9,\npp. 2171\u00152178, Sep. 2008.\n[35] J. Lin, T. Jiao, J. E. Biskupiak, and C. McAdam-Marx, ``Application of\nelectronic medical record data for health outcomes research: A review\nof recent literature,'' Expert Rev. Pharmacoeconomics Outcomes Res. ,\nvol. 13, no. 2, pp. 191\u0015200, Apr. 2013.\n[36] K. P. Liao, T. Cai, G. K. Savova, S. N. Murphy, E. W. Karlson,\nA. N. Ananthakrishnan, V. S. Gainer, S. Y. Shaw, Z. Xia, P. Szolovits,\nS. Churchill, and I. Kohane, ``Development of phenotype algorithms\nusing electronic medical records and incorporating natural language pro-\ncessing,'' BMJ, vol. 350, no. 11, p. h1885, Apr. 2015.\n[37] K. Kreimeyer, M. Foster, A. Pandey, N. Arya, G. Halford, S. F. Jones,\nR. Forshee, M. Walderhaug, and T. Botsis, ``Natural language process-\ning systems for capturing and standardizing unstructured clinical infor-\nmation: A systematic review,'' J. Biomed. Inform. , vol. 73, pp. 14\u001529,\nSep. 2017.\n[38] F. Liu, C. Weng, and H. Yu, ``Advancing clinical research through natural\nlanguage processing on electronic health records: Traditional machine\nlearning meets deep learning,'' in Clinical Research Informatics . Cham,\nSwitzerland: Springer, 2019, pp. 357\u0015378.\n[39] D. Palaz, M. Magimai-Doss, and R. Collobert, ``End-to-end acoustic\nmodeling using convolutional neural networks for HMM-based automatic\nspeech recognition,'' Speech Commun. , vol. 108, pp. 15\u001532, Apr. 2019.\n[40] A. Mahendiran and R. Appusamy, ``An intrusion detection system for\nnetwork security situational awareness using conditional random \u001celds,''\nInt. J. Intell. Eng. Syst. , vol. 11, no. 3, pp. 196\u0015204, Jun. 2018.\n[41] A. Choudhury and C. M Greene, ``Prognosticating autism spectrum dis-\norder using arti\u001ccial neural network: Levenb erg-marquardt algorithm,''\nArch. Clin. Biomed. Res. , vol. 2, no. 6, pp. 188\u0015197, 2018.\n[42] B. Shickel, P. J. Tighe, A. Bihorac, and P. Rashidi, ``Deep EHR: A survey\nof recent advances in deep learning techniques for electronic health record\n(EHR) analysis,'' IEEE J. Biomed. Health Informat. , vol. 22, no. 5,\npp. 1589\u00151604, Sep. 2018.\n[43] P. Yadav, M. Steinbach, V. Kumar, and G. Simon, ``Mining electronic\nhealth records (EHRs): A survey,'' ACM Comput. Surv. , vol. 50, no. 6,\npp. 1\u001540, Jan. 2018.\n[44] O. Sofrygin, Z. Zhu, J. A. Schmittdiel, A. S. Adams, R. W. Grant,\nM. J. Laan, and R. Neugebauer, ``Targeted learning with daily EHR data,''\nStatist. Med. , vol. 38, no. 16, pp. 3073\u00153090, Jul. 2019.\n[45] V. Osmani, L. Li, M. Danieletto, B. Glicksberg, J. Dudley, and\nO. Mayora, ``Processing of electronic health records using deep\nlearning: A review,'' 2018, arXiv:1804.01758 . [Online]. Available:\nhttp://arxiv.org/abs/1804.01758\n[46] C. Xiao, E. Choi, and J. Sun, ``Opportunities and challenges in developing\ndeep learning models using electronic health records data: A systematic\nreview,'' J. Amer. Med. Inform. Assoc. , vol. 25, no. 10, pp. 1419\u00151428,\nOct. 2018.\n[47] A. Esteva, A. Robicquet, B. Ramsundar, V. Kuleshov, M. DePristo,\nK. Chou, C. Cui, G. Corrado, S. Thrun, and J. Dean, ``A guide to deep\nlearning in healthcare,'' Nature Med. , vol. 25, no. 1, pp. 24\u001529, Jan. 2019.\n[48] R. Miotto, L. Li, and J. T. Dudley, ``Deep learning to predict patient future\ndiseases from the electronic health records,'' in Proc. Eur. Conf. Inf. Retr.\nCham, Switzerland: Springer, 2016, pp. 768\u0015774.\n[49] N. Wickramasinghe, ``Deepr: A convolutional net for medical records,''\nTech. Rep., 2017.\n[50] E. Choi, M. T. Bahadori, E. Searles, C. Coffey, M. Thompson, J. Bost,\nJ. Tejedor-Sojo, and J. Sun, ``Multi-layer representation learning for med-\nical concepts,'' in Proc. 22nd ACM SIGKDD Int. Conf. Knowl. Discovery\nData Mining , Aug. 2016, pp. 1495\u00151504.\n[51] E. Choi, M. T. Bahadori, A. Schuetz, W. F. Stewart, and J. Sun, ``Doctor\nAI: Predicting clinical events via recurrent neural networks,'' in Proc.\nMach. Learn. Healthcare Conf. , 2016, pp. 301\u0015318.[52] A. N. Jagannatha and H. Yu, ``Bidirectional RNN for medical event detec-\ntion in electronic health records,'' in Proc. Conf. North Amer. Chapter\nAssoc. Comput. Linguistics, Hum. Lang. Technol. , 2016, p. 473.\n[53] A. Jagannatha and H. Yu, ``Structured prediction models for RNN based\nsequence labeling in clinical text,'' in Proc. Conf. Empirical Methods\nNatural Lang. Process. , 2016, p. 856.\n[54] J. R. A. Solares, F. E. D. Raimondi, Y. Zhu, F. Rahimian, D. Canoy,\nJ. Tran, A. C. P. Gomes, A. H. Payberah, M. Zottoli, M. Nazarzadeh,\nN. Conrad, K. Rahimi, and G. Salimi-Khorshidi, ``Deep learning for\nelectronic health records: A comparative review of multiple deep neural\narchitectures,'' J. Biomed. Inform. , vol. 101, Jan. 2020, Art. no. 103337.\n[55] V. Yadav and S. Bethard, ``A survey on recent advances in named\nentity recognition from deep learning models,'' 2019, arXiv:1910.11470 .\n[Online]. Available: http://arxiv.org/abs/1910.11470\n[56] S. Silvestri, A. Esposito, F. Gargiulo, M. Sicuranza, M. Ciampi, and\nG. De Pietro, ``A big data architecture for the extraction and analysis of\nEHR data,'' in Proc. IEEE World Congr. Services (SERVICES) , vol. 2642,\nJul. 2019, pp. 283\u0015288.\n[57] P. Coorevits, M. Sundgren, G. O. Klein, A. Bahr, B. Claerhout, C. Daniel,\nM. Dugas, D. Dupont, A. Schmidt, and P. Singleton, ``Electronic health\nrecords: New opportunities for clinical research,'' J. Internal Med. ,\nvol. 274, no. 6, pp. 547\u0015560, 2013.\n[58] S. Mahmood, K. Hasan, M. C. Carras, and A. Labrique, ``Global pre-\nparedness against COVID-19: We must leverage the power of digital\nhealth (preprint),'' JMIR Public Health Surveill. , vol. 6, no. 2, Mar. 2020,\nArt. no. e18980.\n[59] Y. Xiao, J. Wu, Z. Lin, and X. Zhao, ``A deep learning-based multi-model\nensemble method for cancer prediction,'' Comput. Methods Programs\nBiomed. , vol. 153, pp. 1\u00159, Jan. 2018.\n[60] C. Willyard, ``The drug-resistant bacteria that pose the greatest health\nthreats,'' Nature , vol. 543, no. 7643, p. 15, Mar. 2017.\n[61] I. H. Spicknall, K. J. Looker, S. L. Gottlieb, H. W. Chesson, J. T. Schiffer,\nJ. Elmes, and M.-C. Boily, ``Review of mathematical models of HSV-\n2 vaccination: Implications for vaccine development,'' Vaccine , vol. 37,\nno. 50, pp. 7396\u00157407, Nov. 2019.\n[62] Global Status Report on Alcohol and Health 2018 , World Health Org.,\nGeneva, Switzerland, 2019.\n[63] Global Hepatitis Report 2017 , World Health Org., Geneva, Switzerland,\n2017.\n[64] S. M. Teutsch and R. E. Churchill, Principles and Practice of Pub-\nlic Health Surveillance . New York, NY, USA: Oxford Univ. Press,\n2000.\n[65] S. Ahmad, M. Asif, R. Talib, M. Adeel, M. Yasir, and M. H. Chaudary,\n``Surveillance of intensity level and geographical spreading of dengue\noutbreak among males and females in Punjab, Pakistan: A case study\nof 2011,'' J. Infection Public Health , vol. 11, no. 4, pp. 472\u0015485,\nJul. 2018.\n[66] A. M. Schwartz, A. F. Hinckley, P. S. Mead, S. A. Hook, and\nK. J. Kugeler, ``Surveillance for lyme disease\u0016United States,\n2008\u00152015,'' MMWR Surveill. Summaries , vol. 66, no. 22, pp. 1\u001512,\nNov. 2017.\n[67] K. E. Mace, P. M. Arguin, and K. R. Tan, ``Malaria surveillance\u0016United\nStates, 2015,'' MMWR Surveill. Summaries , vol. 67, no. 7, pp. 1\u001528,\n2018.\n[68] E. Khan, J. Siddiqui, S. Shakoor, V. Mehraj, B. Jamil, and R. Hasan,\n``Dengue outbreak in Karachi, Pakistan, 2006: Experience at a tertiary\ncare center,'' Trans. Roy. Soc. Tropical Med. Hygiene , vol. 101, no. 11,\npp. 1114\u00151119, Nov. 2007.\n[69] A. R. Anvikar, N. Shah, A. C. Dhariwal, G. S. Sonal, M. M. Pradhan,\nS. K. Ghosh, and N. Valecha, ``Epidemiology of Plasmodium vivax\nmalaria in India,'' Amer. J. Tropical Med. Hygiene , vol. 95, pp. 108\u0015120,\nDec. 2016.\n[70] B. Shah and P. Mathur, ``Surveillance of cardiovascular disease risk\nfactors in India: The need & scope,'' Indian J. Med. Res. , vol. 132, no. 5,\npp. 634\u0015642, 2010.\n[71] H. Siswoyo, M. Permana, R. P. Larasati, J. Farid, A. Suryadi, and\nE. R. Sedyaningsih, ``EWORS: Using a syndromic-based surveillance\ntool for disease outbreak detection in Indonesia,'' BMC , vol. 2, no. S3,\npp. 1\u00155, Dec. 2008.\n[72] M. E. Sips, M. J. M. Bonten, and M. S. M. van Mourik, ``Automated\nsurveillance of healthcare-associated infections: State of the art,'' Current\nOpinion Infectious Diseases , vol. 30, no. 4, pp. 425\u0015431, Aug. 2017.[73] A. Atreja, S. M. Gordon, D. A. Pollock, R. N. Olmsted, and P. J. Brennan,\n``Opportunities and challenges in utilizing electronic health records for\ninfection surveillance, prevention, and control,'' Amer. J. Infection Con-\ntrol, vol. 36, no. 3, pp. S37\u0015S46, Apr. 2008.\n[74] J. W. Keck, J. T. Redd, J. E. Cheek, L. J. Layne, A. V. Groom, S. Kitka,\nM. G. Bruce, A. Suryaprasad, N. L. Amerson, T. Cullen, R. T. Bryan, and\nT. W. Hennessy, ``In\u001duenza surveillance using electronic health records\nin the American Indian and Alaska native population,'' J. Amer. Med.\nInform. Assoc. , vol. 21, no. 1, pp. 132\u0015138, Jan. 2014.\n[75] G. S. Birkhead, M. Klompas, and N. R. Shah, ``Uses of electronic health\nrecords for public health surveillance to advance public health,'' Annu.\nRev. Public Health , vol. 36, no. 1, pp. 345\u0015359, Mar. 2015.\n[76] W. Odero, J. Rotich, C. T. Yiannoutsos, T. Ouna, and W. M. Tierney,\n``Innovative approaches to application of information technology in dis-\nease surveillance and prevention in western kenya,'' J. Biomed. Inform. ,\nvol. 40, no. 4, pp. 390\u0015397, Aug. 2007.\n[77] S. A. Ali, M. Salman, M. Din, K. Khan, M. Ahmad, F. H. Khan, and\nM. Arif, ``Dengue outbreaks in Khyber Pakhtunkhwa (KPK), Pakistan in\n2017: An integrated disease surveillance and response system (IDSRS)-\nbased report,'' Polish J. Microbiol. , vol. 68, no. 1, pp. 115\u0015119, 2019.\n[78] P. C. Onyebujoh, A. K. Thirumala, and J.-B. Ndihokubwayo, ``Integrating\nlaboratory networks, surveillance systems and public health institutes in\nafrica,'' Afr. J. Lab. Med. , vol. 5, no. 3, pp. 1\u00154, Oct. 2016.\n[79] A. Kapoor, S. Guha, M. K. Das, K. C. Goswami, and R. Yadav, ``Digital\nhealthcare: The only solution for better healthcare during COVID-19\npandemic?'' Indian Heart J. , vol. 72, no. 2, pp. 61\u001564, 2020.\n[80] J. J. Reeves, H. M. Hollandsworth, F. J. Torriani, R. Taplitz, S. Abeles,\nM. Tai-Seale, M. Millen, B. J. Clay, and C. A. Longhurst, ``Rapid\nresponse to COVID-19: Health informatics support for outbreak man-\nagement in an academic health system,'' J. Amer. Med. Inform. Assoc. ,\nvol. 27, no. 6, pp. 853\u0015859, Jun. 2020.\n[81] N. L. Bragazzi, H. Dai, G. Damiani, M. Behzadifar, M. Martini, and\nJ. Wu, ``How big data and arti\u001ccial intelligence can help better manage\nthe COVID-19 pandemic,'' Int. J. Environ. Res. Public Health , vol. 17,\nno. 9, p. 3176, May 2020.\n[82] C. N. Shappell and C. Rhee, ``Leveraging electronic health record data to\nimprove sepsis surveillance,'' Tech. Rep., 2020.\n[83] R. Burgess and J. Moorhead, New Principles of Best Practice in Clinical\nAudit . Abingdon, U.K.: Radcliffe Publishing, 2011.\n[84] P. Esposito, ``Clinical audit, a valuable tool to improve quality of care:\nGeneral methodology and applications in nephrology,'' World J. Nephrol. ,\nvol. 3, no. 4, p. 249, 2014.\n[85] K. B. Bayley, T. Belnap, L. Savitz, A. L. Masica, N. Shah, and\nN. S. Fleming, ``Challenges in using electronic health record data for\nCER: Experience of 4 learning organizations and solutions applied,''\nMed. Care , vol. 51, pp. S80\u0015S86, Aug. 2013.\n[86] J. van der Lei, ``Use and abuse of computer-stored medical records,''\nMethods Inf. Med. , vol. 30, no. 2, pp. 79\u001580, 1991.\n[87] W. R. Hogan and M. M. Wagner, ``Accuracy of data in computer-based\npatient records,'' J. Amer. Med. Inform. Assoc. , vol. 4, no. 5, pp. 342\u0015355,\nSep. 1997.\n[88] F. C. Bourgeois, K. L. Olson, and K. D. Mandl, ``Patients treated at multi-\nple acute health care facilities: Quantifying information fragmentation,''\nArch. Internal Med. , vol. 170, no. 22, pp. 1989\u00151995, 2010.\n[89] T. Botsis, G. Hartvigsen, F. Chen, and C. Weng, ``Secondary use of\nEHR: Data quality issues and informatics opportunities,'' Summit Transl.\nBioinf. , vol. 2010, pp. 1\u00155, Mar. 2010.\n[90] A. N. Kho, L. V. Rasmussen, J. J. Connolly, P. L. Peissig, J. Starren,\nH. Hakonarson, and M. G. Hayes, ``Practical challenges in integrating\ngenomic data into the electronic health record,'' Genet. Med. , vol. 15,\nno. 10, pp. 772\u0015778, Oct. 2013.\n[91] N. Ramakrishnan, D. Hanauer, and B. Keller, ``Mining electronic health\nrecords,'' Computer , vol. 43, no. 10, pp. 77\u001581, Oct. 2010.\n[92] G. Weimann, ``Going dark: Terrorism on the dark Web,'' Stud. Con\u001dict\nTerrorism , vol. 39, no. 3, pp. 195\u0015206, Mar. 2016.\n[93] C. S. Kruse, B. Frederick, T. Jacobson, and D. K. Monticone, ``Cyberse-\ncurity in healthcare: A systematic review of modern threats and trends,''\nTechnol. Health Care , vol. 25, no. 1, pp. 1\u001510, Feb. 2017.\n[94] J. Davis. (Oct. 2018). 3 Phishing Hacks Breach 20,000 Catawba Valley\nPatient Records . [Online]. Available: https://www.healthcareitnews.\ncom/news/3-phishing-hacks-breach-20000-catawba-valley-patient-\nrecords[95] M. Ahmed and A. S. S. M. B. Ullah, ``False data injection attacks in\nhealthcare,'' in Proc. Australas. Conf. Data Mining . Singapore: Springer,\n2017, pp. 192\u0015202.\n[96] M. R. Fuentes, ``Cybercrime and other threats faced by the healthcare\nindustry,'' Trend Micro, Tokyo, Japan, Tech. Rep., 2017.\n[97] B. Edwards, S. Hofmeyr, and S. Forrest, ``Hype and heavy tails: A closer\nlook at data breaches,'' J. Cybersecur. , vol. 2, no. 1, pp. 3\u001514, Dec. 2016.\n[98] H. Sharif and R. A. Khan, ``A novel machine learning based\nframework for detection of autism spectrum disorder (ASD),'' 2019,\narXiv:1903.11323 . [Online]. Available: http://arxiv.org/abs/1903.11323\n[99] J. N. Giedd, ``Structural magnetic resonance imaging of the adolescent\nbrain,'' Ann. New York Acad. Sci. , vol. 1021, no. 1, pp. 77\u001585, Jun. 2004.\n[100] H. Julien and I. Fourie, ``Re\u001dections of affect in studies of information\nbehavior in HIV/AIDS contexts: An exploratory quantitative content\nanalysis,'' Library Inf. Sci. Res. , vol. 37, no. 1, pp. 3\u00159, Jan. 2015.\n[101] L. Bellak, ``The schizophrenic syndrome and attention de\u001ccit disor-\nder: Thesis, antithesis, and synthesis?'' Amer. Psychol. , vol. 49, no. 1,\npp. 25\u001529, 1994.\n[102] A. W. Bateman, J. Gunderson, and R. Mulder, ``Treatment of personality\ndisorder,'' Lancet , vol. 385, pp. 735\u0015743, Feb. 2015.\n[103] J. G. Ronquillo, J. E. Winterholler, K. Cwikla, R. Szymanski, and A. Levy,\n``Health IT, hacking, and cybersecurity: National trends in data breaches\nof protected health information,'' JAMIA Open , vol. 1, no. 1, pp. 15\u001519,\n2018.\n[104] M. Meingast, T. Roosta, and S. Sastry, ``Security and privacy issues with\nhealth care information technology,'' in Proc. Int. Conf. IEEE Eng. Med.\nBiol. Soc. , Aug. 2006, pp. 5453\u00155458.\n[105] D. V. Dimitrov, ``Medical Internet of Things and big data in healthcare,''\nHealthcare Inform. Res. , vol. 22, no. 3, pp. 156\u0015163, 2016.\n[106] R. S. Weinstein, A. M. Lopez, B. A. Joseph, K. A. Erps, M. Holcomb,\nG. P. Barker, and E. A. Krupinski, ``Telemedicine, telehealth, and mobile\nhealth applications that work: Opportunities and barriers,'' Amer. J. Med. ,\nvol. 127, no. 3, pp. 183\u0015187, Mar. 2014.\n[107] F. Leu, C. Ko, I. You, K.-K.-R. Choo, and C.-L. Ho, ``A smartphone-based\nwearable sensors for monitoring real-time physiological data,'' Comput.\nElectr. Eng. , vol. 65, pp. 376\u0015392, Jan. 2018.\n[108] C. D. Grood, A. Raissi, Y. Kwon, and M. J. Santana, ``Adoption of e-\nHealth technology by physicians: A scoping review,'' J. Multidisciplinary\nHealthcare , vol. 9, p. 335, Aug. 2016.\n[109] L. Minor, ``Harnessing the power of data in health,'' Stanford Med. Heal.\nTrends Rep., 2017.\n[110] C. Esposito, A. De Santis, G. Tortora, H. Chang, and K.-K.-R. Choo,\n``Blockchain: A panacea for healthcare cloud-based data security and\nprivacy?'' IEEE Cloud Comput. , vol. 5, no. 1, pp. 31\u001537, Jan. 2018.\n[111] S. Chenthara, K. Ahmed, H. Wang, and F. Whittaker, ``Security and\nprivacy-preserving challenges of e-Health solutions in cloud computing,''\nIEEE Access , vol. 7, pp. 74361\u001574382, 2019.\n[112] A. Abbas and S. U. Khan, ``A review on the state-of-the-art privacy-\npreserving approaches in the e-Health clouds,'' IEEE J. Biomed. Health\nInformat. , vol. 18, no. 4, pp. 1431\u00151441, Jul. 2014.\n[113] R. Zhang and L. Liu, ``Security models and requirements for health-\ncare application clouds,'' in Proc. IEEE 3rd Int. Conf. Cloud Comput. ,\nJul. 2010, pp. 268\u0015275.\n[114] A. Nazir and R. A. Khan, ``Combinatorial optimization based fea-\nture selection method: A study on network intrusion detection,'' 2019,\narXiv:1906.04494 . [Online]. Available: http://arxiv.org/abs/1906.04494\n[115] P. Vimalachandran, H. Wang, Y. Zhang, G. Zhuo, and H. Kuang,\n``Cryptographic access control in electronic health record systems:\nA security implication,'' in Proc. Int. Conf. Web Inf. Syst. Eng. Cham,\nSwitzerland: Springer, 2017, pp. 540\u0015549.\n[116] U. Premarathne, A. Abuadbba, A. Alabdulatif, I. Khalil, Z. Tari,\nA. Zomaya, and R. Buyya, ``Hybrid cryptographic access control for\ncloud-based EHR systems,'' IEEE Cloud Comput. , vol. 3, no. 4,\npp. 58\u001564, Jul. 2016.\n[117] S. Chenthara, H. Wang, and K. Ahmed, ``Security and privacy in big data\nenvironment,'' Tech. Rep., 2018.\n[118] C. Guo, R. Zhuang, Y. Jie, Y. Ren, T. Wu, and K.-K.-R. Choo, ``Fine-\ngrained database \u001celd search using attribute-based encryption for E-\nhealthcare clouds,'' J. Med. Syst. , vol. 40, no. 11, p. 235, Nov. 2016.\n[119] K. Liu, ``Secure electronic health record system based on online/of\u001dine\nKP-ABE in the cloud,'' in Proc. 2nd Int. Conf. Internet Things, Big Data\nSecur. , 2017, pp. 110\u0015116.\n[120] H. Cui, R. H. Deng, G. Wu, and J. Lai, ``An ef\u001ccient and expres-\nsive ciphertext-policy attribute-based encryption scheme with partially\nhidden access structures,'' in Proc. Int. Conf. Provable Secur. Cham,\nSwitzerland: Springer, 2016, pp. 19\u001538.\n[121] W. J. Gordon and C. Catalini, ``Blockchain technology for healthcare:\nFacilitating the transition to patient-driven interoperability,'' Comput.\nStruct. Biotechnol. J. , vol. 16, pp. 224\u0015230, Jan. 2018.\n[122] L. Chen, W.-K. Lee, C.-C. Chang, K.-K.-R. Choo, and N. Zhang,\n``Blockchain based searchable encryption for electronic health record\nsharing,'' Future Gener. Comput. Syst. , vol. 95, pp. 420\u0015429, Jun. 2019.\n[123] C. E. Exceline and J. Norman, ``Existing enabling technologies and solu-\ntions to maintain privacy and security in healthcare records,'' in Security\nand Privacy of Electronic Healthcare Records: Concepts, Paradigms and\nSolutions . 2019, p. 155.\n[124] Health Data in the Information Age: Use, Disclosure, and Privacy , Com-\nmittee Regional Health Data Netw. Inst. Med., Nat. Academies Press,\nWashington, DC, USA, 1994.\n[125] M. Kayaalp, ``Patient privacy in the era of big data,'' Balkan Med. J. ,\nvol. 35, no. 1, pp. 8\u001517, 2018.\n[126] L. J. Camp and M. E. Johnson, The Economics of Financial and Medical\nIdentity Theft . Springer, 2012.\n[127] N. R. Council, Networking Health: Prescriptions for the Internet .\nWashington, DC, USA: National Academies Press, 2000.\n[128] SNS. (2015). HIV Positive Couple Face Social Boycott . [Online].\nAvailable: https://www.thestatesman.com/world/hiv-positive-couple-\nface-social-boycott-83187.html\n[129] W. P. Corrigan, C. A. Watson, P. Byrne, and K. E. Davis, ``Mental illness\nstigma: Problem of public health or social justice?'' Social Work , vol. 50,\nno. 4, pp. 363\u0015368, 2005.\n[130] D. J. Knutson, ``Risk adjustment of insurance premiums in the United\nStates and implication for people with disabilities,'' in The Future of\nDisability in America . Washington, DC, USA: The National Academies\nPress, 2007.\n[131] A. Abbas, K. Bilal, L. Zhang, and S. U. Khan, ``A cloud based health\ninsurance plan recommendation system: A user centered approach,''\nFuture Gener. Comput. Syst. , vol. 43\u001544, pp. 99\u0015109, Feb. 2015.\n[132] G. Richter, C. Borzikowsky, W. Lieb, S. Schreiber, M. Krawczak, and\nA. Buyx, ``Patient views on research use of clinical data without consent:\nLegal, but also acceptable?'' Eur. J. Hum. Genet. , vol. 27, pp. 841\u0015847,\nJan. 2019.\n[133] D. I. Shalowitz and F. G. Miller, ``Disclosing individual results of clinical\nresearch: Implications of respect for participants,'' J. Amer. Med. Assoc. ,\nvol. 294, no. 6, pp. 737\u0015740, 2005.\n[134] J. A. Bovenberg and M. Almeida, ``Patients v. Myriad or the GDPR access\nright v. The EU database right,'' Eur. J. Hum. Genet. , vol. 27, no. 2,\npp. 211\u0015215, Feb. 2019.\n[135] B. Sadan, ``Patient data con\u001cdentiality and patient rights,'' Int. J. Med.\nInform. , vol. 62, no. 1, pp. 41\u001549, Jun. 2001.\n[136] District of Columbia U.S. Attorney's Of\u001cce. (2012). Former\nHoward University Hospital Employee Pleads Guilty to Selling\nPersonal Information About Patients . [Online]. Available: https://\narchives.fbi.gov/archives/washingtondc/press-releases/2012/former-\nhoward-university-hospital-employee-pleads-guilty-to-selling-personal-\ninformation-about-patients\n[137] N. Jamshed, F. Ozair, A. Sharma, and P. Aggarwal, ``Ethical issues in\nelectronic health records: A general overview,'' Perspect. Clin. Res. ,\nvol. 6, no. 2, p. 73, 2015.\n[138] Health Insurance Portability and Accountability Act of 1996 (HIPAA) ,\n1996.\n[139] E. Politou, A. Michota, E. Alepis, M. Pocs, and C. Patsakis, ``Backups and\nthe right to be forgotten in the GDPR: An uneasy relationship,'' Comput.\nLaw Secur. Rev. , vol. 34, no. 6, pp. 1247\u00151257, Dec. 2018.\n[140] S. Sirur, J. R. C. Nurse, and H. Webb, ``Are we there yet?: Understanding\nthe challenges faced in complying with the general data protection regu-\nlation (GDPR),'' in Proc. 2nd Int. Workshop Multimedia Privacy Secur.\n(MPS) , 2018, pp. 88\u001595.\n[141] N. Gruschka, V. Mavroeidis, K. Vishi, and M. Jensen, ``Privacy issues and\ndata protection in big data: A case study analysis under GDPR,'' in Proc.\nIEEE Int. Conf. Big Data (Big Data) , Dec. 2018, pp. 5027\u00155033.\n[142] C. Tankard, ``What the GDPR means for businesses,'' Netw. Secur. ,\nvol. 2016, no. 6, pp. 5\u00158, Jun. 2016.[143] Directive 95/46/EC on the Protection of Individuals With Regard to the\nProcessing of Personal Data and on the Free Movement of Such Data ,\nDirective, 1995.\n[144] C. Tikkinen-Piri, A. Rohunen, and J. Markkula, ``EU general data pro-\ntection regulation: Changes and implications for personal data collect-\ning companies,'' Comput. Law Secur. Rev. , vol. 34, no. 1, pp. 134\u0015153,\nFeb. 2018.\n[145] M. Goddard, ``The EU general data protection regulation (GDPR): Euro-\npean regulation that has a global impact,'' Int. J. Market Res. , vol. 59,\nno. 6, pp. 703\u0015705, Nov. 2017.\n[146] M. J. Taylor and M. Prictor, ``Insight or intrusion? Correlating routinely\ncollected employee data with health risk,'' Social Sci. , vol. 8, no. 10,\np. 291, Oct. 2019.\n[147] O. Tene and J. Polonetsky, ``Big data for all: Privacy and user control\nin the age of analytics,'' Northwestern J. Technol. Intellectual Property ,\nvol. 11, no. 5, pp. 1\u001538, 2012.\n[148] G. Bincoletto, ``A data protection by design model for privacy manage-\nment in electronic health records,'' in Annual Privacy Forum . 2019.\n[149] M. Mostert, A. L. Bredenoord, M. C. I. H. Biesaart, and\nJ. J. M. van Delden, ``Big data in medical research and EU data\nprotection law: Challenges to the consent or anonymise approach,'' Eur.\nJ. Hum. Genet. , vol. 24, no. 7, pp. 956\u0015960, Jul. 2016.\n[150] C. A. Harle, E. H. Golembiewski, K. P. Rahmanian, B. Brumback,\nJ. L. Krieger, K. W. Goodman, A. G. Mainous, and R. E. Moseley, ``Does\nan interactive trust-enhanced electronic consent improve patient experi-\nences when asked to share their health records for research? A randomized\ntrial,'' J. Amer. Med. Inform. Assoc. , vol. 26, no. 7, pp. 620\u0015629, Jul. 2019.\n[151] S. Spiekermann, A. Acquisti, R. B\u00f6hme, and K.-L. Hui, ``The challenges\nof personal data markets and privacy,'' Electron. Markets , vol. 25, no. 2,\npp. 161\u0015167, Jun. 2015.\n[152] P. Voigt and A. von dem Bussche, ``Scope of application of the\nGDPR,'' in The EU General Data Protection Regulation . Cham,\nSwitzerland: Springer, 2017, pp. 9\u001530.\n[153] T. Z. Zarsky, ``Incompatible: The GDPR in the age of big data,'' Seton\nHall Law Rev. , vol. 47, no. 4, p. 26, 2016.\n[154] P. Ohm, ``Broken promises of privacy: Responding to the surprising\nfailure of anonymization,'' UCLA Law Rev. , vol. 57, p. 1701, Aug. 2009.\n[155] A. M. Wheeler and B. Bertram, The Counselor and the Law: A Guide to\nLegal and Ethical Practice . Hoboken, NJ, USA: Wiley, 2019.\n[156] T. Wilkinson and R. Reinhardt, ``Technology in counselor education:\nHIPAA and HITECH as best practice,'' Prof. Counselor , vol. 5, no. 3,\npp. 407\u0015418, Jun. 2015.\n[157] J. M. Kiel, F. A. Ciamacco, and B. T. Steines, ``Privacy and data security:\nHIPAA and HITECH,'' in Healthcare Information Management Systems .\nCham, Switzerland: Springer, 2016, pp. 437\u0015449.\n[158] N. Yaraghi and R. D. Gopal, ``The role of HIPAA omnibus rules in reduc-\ning the frequency of medical data breaches: Insights from an empirical\nstudy,'' Milbank Quart. , vol. 96, no. 1, pp. 144\u0015166, Mar. 2018.\n[159] J. Pipersburgh, ``The push to increase the use of EHR technology by\nhospitals and physicians in the United States through the HITECH Act\nand the Medicare incentive program,'' J. Health Care Finance , vol. 38,\nno. 2, pp. 54\u001578, 2011.\n[160] W. Moore and S. A. Frye, ``Review of HIPAA, part 1: History, protected\nhealth information, and privacy and security rules,'' J. Nucl. Med. Tech-\nnol., vol. 47, no. 4, pp. 269\u0015272, 2019.\n[161] C. J. Wang and D. J. Huang, ``The HIPAA conundrum in the era of mobile\nhealth and communications,'' J. Amer. Med. Assoc. , vol. 310, no. 11,\npp. 1121\u00151122, 2013.\n[162] A. S. Kesselheim and J. Avorn, ``New `21st century cures' legislation:\nSpeed and ease vs science,'' J. Amer. Med. Assoc. , vol. 317, no. 6,\npp. 581\u0015582, 2017.\n[163] C. T. Lye, H. P. Forman, J. G. Daniel, and H. M. Krumholz, ``The 21st\ncentury cures act and electronic health records one year later: Will\npatients see the bene\u001cts?'' J. Amer. Med. Inform. Assoc. , vol. 25, no. 9,\npp. 1218\u00151220, 2018.\n[164] D. Mohammed, ``US healthcare industry: Cybersecurity regulatory\nand compliance issues,'' J. Res. Bus., Econ. Manage. , vol. 9, no. 5,\npp. 1771\u00151776, 2017.\n[165] S. M. Ahmed and A. Rajput, ``Threats to patients' privacy in smart health-\ncare environment,'' in Innovation in Health Informatics . Amsterdam,\nThe Netherlands: Elsevier, 2020, pp. 375\u0015393.[166] I. G. Cohen and M. M. Mello, ``HIPAA and protecting health information\nin the 21st Century,'' J. Amer. Med. Assoc. , vol. 320, no. 3, pp. 231\u0015232,\n2018.\n[167] W. Moore and S. Frye, ``Review of HIPAA, part 2: Limitations, rights,\nviolations, and role for the imaging technologist,'' J. Nucl. Med. Technol. ,\nvol. 48, no. 1, pp. 17\u001523, Mar. 2020.\n[168] B. S. Lee, J. Walker, T. Delbanco, and J. G. Elmore, ``Transparent\nelectronic health records and lagging laws,'' Ann. Internal Med. , vol. 165,\nno. 3, pp. 219\u0015220, 2016.\n[169] S. T. Rosenbloom, J. R. L. Smith, R. Bowen, J. Burns, L. Riplinger, and\nT. H. Payne, ``Updating HIPAA for the electronic medical record era,''\nJ. Amer. Med. Inform. Assoc. , vol. 26, no. 10, pp. 1115\u00151119, Oct. 2019.\nSHAHID MUNIR SHAH received the M.Sc.\ndegree in electronics and M.S. degree in tele-\ncom. He received the Ph.D. degree in informa-\ntion technology (IT) from the University of Sindh,\nJamshoro. He has vast teaching experience in\nmathematical and applied sciences background in\nnational and international organizations of repute.\nHe is currently working as an Assistant Profes-\nsor with Barrett Hodgson University, Karachi,\nPakistan. His research interests include machine\nlearning, signal processing, natural language processing, and pattern\nrecognition.\nRIZWAN AHMED KHAN received the Ph.D.\ndegree in computer vision from Universit\u00e9 Claude\nBernard Lyon 1, France, in 2013. He has worked\nas Postdoctoral Research Associate with Lab-\noratoire d'InfoRmatique en Image et Systemes\nd'information (LIRIS), Lyon, France. He is cur-\nrently working as a Professor with Barrett Hodg-\nson University, Karachi, Pakistan. His research\ninterests include machine learning, computer\nvision, image processing, pattern recognition, and\nhuman perception.\n", "arxiv73": "\nA Survey of Human Activity Recognition in Smart Homes\nBased on IoT Sensors Algorithms: Taxonomies, Challenges,\nand Opportunities with Deep Learning\nDamien Bouchabou1,2,*\n, Sao Mai Nguyen1,*\n, Christophe Lohr1\n, Benoit LeDuc2and Ioannis Kanellos1\n/gid00030/gid00035/gid00032/gid00030/gid00038/gid00001/gid00033/gid00042/gid00045 /gid00001\n/gid00048/gid00043/gid00031/gid00028/gid00047/gid00032/gid00046/gid00030/gid00035/gid00032/gid00030/gid00038/gid00001/gid00033/gid00042/gid00045 /gid00001\n/gid00048/gid00043/gid00031/gid00028/gid00047/gid00032/gid00046\nCitation: Bouchabou, D.; Nguyen,\nS.M.; Lohr, C.; LeDuc, B.; Kanellos, I.\nA Survey of Human Activity\nRecognition in Smart Homes Based\non IoT Sensors Algorithms:\nTaxonomies, Challenges, and\nOpportunities with Deep Learning.\nSensors 2021 ,21, 6037. https://\ndoi.org/10.3390/s21186037\nAcademic Editor: Antonio Pulia\ufb01to\nReceived: 31 July 2021\nAccepted: 4 September 2021\nPublished: 9 September 2021\nPublisher\u2019s Note: MDPI stays neutral\nwith regard to jurisdictional claims in\npublished maps and institutional af\ufb01l-\niations.\nCopyright: \u00a9 2021 by the authors.\nLicensee MDPI, Basel, Switzerland.\nThis article is an open access article\ndistributed under the terms and\nconditions of the Creative Commons\nAttribution (CC BY) license (https://\ncreativecommons.org/licenses/by/\n4.0/).1IMT Atlantique Engineer School, 29238 Brest, France; christophe.lohr@imt-atlantique.fr (C.L.);\nioannis.kanellos@imt-atlantique.fr (I.K.)\n2Delta Dore Company, 35270 Bonnemain, France; bleduc@deltadore.com\n*Correspondence: damien.bouchabou@imt-atlantique.fr (D.B); nguyensmai@gmail.com (S.M.N.)\nAbstract: Recent advances in Internet of Things (IoT) technologies and the reduction in the cost\nof sensors have encouraged the development of smart environments, such as smart homes. Smart\nhomes can offer home assistance services to improve the quality of life, autonomy, and health of\ntheir residents, especially for the elderly and dependent. To provide such services, a smart home\nmust be able to understand the daily activities of its residents. Techniques for recognizing human\nactivity in smart homes are advancing daily. However, new challenges are emerging every day. In\nthis paper, we present recent algorithms, works, challenges, and taxonomy of the \ufb01eld of human\nactivity recognition in a smart home through ambient sensors. Moreover, since activity recognition in\nsmart homes is a young \ufb01eld, we raise speci\ufb01c problems, as well as missing and needed contributions.\nHowever, we also propose directions, research opportunities, and solutions to accelerate advances in\nthis \ufb01eld.\nKeywords: survey; human activity recognition; deep learning; smart home; ambient assisting living;\ntaxonomies; challenges; opportunities\n1. Introduction\nWith an aging population, providing automated services to enable people to live as\nindependently and healthily as possible in their own homes has opened up a new \ufb01eld of\neconomics [ 1]. Thanks to advances in the Internet of Things (IoT), the smart home is the\nsolution being explored today to provide home services, such as health care monitoring, as-\nsistance in daily tasks, energy management, or security. A smart home is a house equipped\nwith many sensors and actuators that can detect the opening of doors, the luminosity of\nthe rooms, their temperature and humidity, etc. However, also to control some equipment\nof our daily life, such as heating, shutters, lights, or our household appliances. More and\nmore of these devices are now connected and controllable at a distance. It is now possible\nto \ufb01nd in the houses, televisions, refrigerators, and washing machines known as intelligent,\nwhich contain sensors and are controllable remotely. All these devices, sensors, actuators,\nand objects can be interconnected through communication protocols.\nIn order to provide all of these services, a smart home must understand and recognize\nthe activities of residents. To do so, the researchers are developing the techniques of Human\nActivity Recognition (HAR), which consists of monitoring and analyzing the behavior of\none or more people to deduce the activity that is carried out. The various systems for\nHAR [2] can be divided into two categories [ 3]: video-based systems and sensor-based\nsystems (see Figure 1).Figure 1. Human Activity Recognition approaches.\n1.1. Vision-Based\nThe vision-based HAR uses cameras to track human behavior and changes in the\nenvironment. This approach uses computer vision techniques, e.g., marker extraction,\nstructure model, motion segmentation, action extraction, and motion tracking. Researchers\nuse a wide variety of cameras, from simple RGB cameras to more complex systems by\nfusion of several cameras for stereo vision or depth cameras able to detect the depth of a\nscene with infrared lights. Several survey papers about vision-based activity recognition\nhave been published [ 3,4]. Beddiar et al. [ 4] aims to provide an up-to-date analysis of\nvision-based HAR-related literature and recent progress.\nHowever, these systems pose the question of acceptability. A recent study [ 5] shows\nthat the acceptability of these systems depends on users\u2019 perception of the bene\ufb01ts that\nsuch a smart home can provide. It also conditions their concerns about the monitoring and\nsharing the data collected. This study shows that older adults (ages 36 to 70) are more open\nto tracking and sharing data, especially if it is useful to their doctors and caregivers, while\nyounger adults (up to age 35) are rather reluctant to share information. This observation\nargues for less intrusive systems, such as smart homes based on IoT sensors.\n1.2. Sensor-Based\nHAR from sensors consists of using a network of sensors and connected devices,\nto track a person\u2019s activity. They produce data in the form of a time series of state changes\nor parameter values. The wide range of sensors\u2014contact detectors, RFID, accelerometers,\nmotion sensors, noise sensors, radar, etc.\u2014can be placed directly on a person, on objects or\nin the environment. Thus, the sensor-based solutions can be divided into three categories,\nrespectively: Wearable [6], Sensor on Objects [7], and Ambient Sensor [8].\nConsidering the privacy issues of installing cameras in our personal space, to be less\nintrusive and more accepted, sensor-based systems have dominated the applications of\nmonitoring our daily activities [ 2,9]. Owing to the development of smart devices and\nInternet of Things, and the reduction of their prices, ambient sensor-based smart homes\nhave become a viable technical solution which now needs to \ufb01nd human activity algorithms\nto uncover their potential.\n1.3. Key Contributions\nWhile existing surveys [ 2,10\u201313] report past works in sensor-based HAR in general, we\nwill focus in this survey on algorithms for human activity recognition in smart homes and\nits particular taxonomies and challenges for the ambient sensors, which we will develop in\nthe next sections. Indeed, HAR in smart homes is a challenging problem because the human\nactivity is something complex and variable from a resident to another. Every resident\nhas different lifestyles, habits, or abilities. The wide range of daily activities, as well asis scalable and must be adaptive.\nMany methods have been used for the recognition of human activity. However, this\n\ufb01eld still faces many technical challenges. Some of these challenges are common to other\nareas of pattern recognition (Section 2) and, more recently, on automatic features extraction\nalgorithms (Section 3), such as computer vision and natural language processing, while\nsome are speci\ufb01c to sensor-based activity recognition, and some are even more speci\ufb01c\nto the smart home domain. This \ufb01eld requires speci\ufb01c methods for real-life applications.\nThe data have a speci\ufb01c temporal structure (Section 4) that needs to be tackled, as well\nas poses challenges in terms of data variability (Section 5) and availability of datasets\n(Section 6) but also speci\ufb01c evaluation methods (Section 7). The challenges are summarized\nin Figure 2.\nTo carry out our review of the state of the art, we searched the literature for the\nlatest advances in the \ufb01eld. We took the time to reproduce some works to con\ufb01rm the\nresults of works proposing high classi\ufb01cation scores. In this study, we were able to\nstudy and reproduce the work of References [ 14\u201316], which allowed us to obtain a better\nunderstanding of the dif\ufb01culties, challenges, and opportunities in the \ufb01eld of HAR in\nsmart homes.\nCompared with existing surveys, the key contributions of this work can be summa-\nrized as follows:\n\u2022 We conduct a comprehensive survey of recent methods and approaches for human\nactivity recognition in smart homes.\n\u2022 We propose a new taxonomy of human activity recognition in smart homes in the\nview of challenges.\n\u2022 We summarize recent works that apply deep learning techniques for human activity\nrecognition in smart homes.\n\u2022 We discuss some open issues in this \ufb01eld and point out potential future research\ndirections.\nFigure 2. Challenges for Human Activity Recognition in smart homes.Algorithms for Human Activity Recognition (HAR) in smart homes are \ufb01rst pattern\nrecognition algorithms. The methods found in the literature can be divided into two broad\ncategories: Data-Driven Approaches (DDA) and Knowledge-Driven Approaches (KDA).\nThese two approaches are opposite. DDA uses user-generated data to model and recognize\nthe activity. They are based on data mining and machine learning techniques. KDA uses\nexpert knowledge and rule design. They use prior knowledge of the domain, its modeling,\nand logical reasoning.\n2.1. Knowledge-Driven Approaches (KDA)\nIn KDA methods, an activity model is built through the incorporation of rich prior\nknowledge gleaned from the application domain, using knowledge engineering and knowl-\nedge management techniques.\nKDA are motivated by real-world observations that involve activities of daily living\nand lists of objects required for performing such activities. In real life situations, even\nif the activity is performed in different ways, the number and objects type involved do\nnot vary signi\ufb01cantly. For example, the activity \u201cbrush teeth\u201d contain actions involving\na toothbrush, toothpaste, water tap, cup, and towel. On the other hand, as humans have\ndifferent lifestyles, habits, and abilities, they can perform various activities in different\nways. For instance, the activity \u201cmake coffee\u201d could be very different form one person\nto another.\nKDA are founded upon the observations that most activities, specifically , routine activi-\nties of daily living and working, take place in a relatively circumstance of time, location, and\nspace. For example, brushing teeth is normally undertaken twice a day in a bathroom in the\nmorning and before going to bed and involves the use of toothpaste and toothbrush. Thin\nimplicit relationships between activities, related temporal and spatial context and the entities\ninvolved, provide a diversity of hints and heuristics for inferring activities.\nThe knowledge structure is modeled and represented through forms, such as schemas,\nrules, or networks. KDA modeling and recognition intends to make use of rich do-\nmain knowledge and heuristics for activity modeling and pattern recognition. Three\nsub-approaches exist to use KDA: mining-based approach [ 17], logic-based approach [ 18],\nand ontology-based approach.\nOntology-based approaches are the most commonly used, as ontological activity\nmodels do not depend on algorithmic choices. They have been utilized to construct reliable\nactivity models. Chen et al., in Reference [ 19], proposed an overview. Yamada et al. [ 20]\nuse ontologies to represent objects in an activity space. Their work exploits the semantic\nrelationship between objects and activities. A teapot is used in an activity of tea preparation,\nfor example. This approach can automatically detect possible activities related to an object.\nIt can also link an object to several representations or variability of an activity.\nChen et al. [ 21\u201323] constructed context and activity ontologies for explicit domain modeling.\nKDA have the advantages to formalize activities and propose semantic and logical\napproaches. Moreover, these representations try to be the most complete as possible to\novercome the activity diversity. However, the limitations of these approaches are the\ncomplete domain knowledge requirements to build activities models and the weakness in\nhandling uncertainty and adaptability to changes and new settings. They need domain\nexperts to design knowledge and rules. New rules can break or bypass the previous rules.\nThese limitations are partially solved in the DDA approaches.\n2.2. Data-Driven Approaches (DDA)\nThe DDA for HAR include both supervised and unsupervised learning methods,\nwhich primarily use probabilistic and statistical reasoning. Supervised learning requires\nlabeled data on which an algorithm is trained. After training, the algorithm is then able to\nclassify the unknown data.handling noisy, uncertain, and incomplete sensor data. They can capture domain heuristics,\ne.g., some activities are more likely than others. They do not require a prede\ufb01ned domain\nknowledge. However, DDA require much data and, in the case of supervised learning,\nclean and correctly labeled data.\nWe observe that decision trees [ 24], conditional random fields [ 25], or support vector\nmachines [ 26] have been used for HAR. Probabilistic classifiers, such as the Naive Bayes\nclassifier [ 27\u201329], also showed good performance in learning and classifying offline activities\nwhen a large amount of training data is available. Sedkly et al. [ 30] evaluated several classi-\nfication algorithms, such as AdaBoost, Cortical Learning Algorithm (CLA), Decision Trees,\nHidden Markov Model (HMM), Multi-layer Perceptron (MLP), Structured Perceptron, and\nSupport Vector Machines (SVM). They reported superior performance of DT, LSTM, SVM\nand stochastic gradient descent of linear SVM, logistic regression, or regression functions.\n2.3. Outlines\nTo summarize, KDA propose to model activities following expert engineering knowl-\nedge, which is time consuming and dif\ufb01cult to maintain in case of evolution. DDA seems\nto yield good recognition levels and promises to be more adaptive to evolution and new\nsituations. However, the DDA only yield good performance when given well-designed\nfeatures as inputs. DDA needs more data and computation time than KDA, but the increas-\ning number of datasets and the increasing computation power minimizes these dif\ufb01culties\nand allows, today, even more complex models to be trained, such as Deep Learning(DL)\nmodels, which can overcome the dependency on input features.\n3. Features Extraction\nWhile the most promising algorithms for Human Activity Recognition in smart homes\nseem to be machine learning techniques, we describe how their performance depends on\nthe features used as input. We describe how more recent machine learning has tackled this\nissue to generate automatically these features, as well as to propose end-to-end learning.\nWe then highlight an opportunity to generate these features, while taking advantage of the\nsemantic of human activity.\n3.1. Handcrafted Features\nIn order to recognize the activities of daily life in smart homes, researchers \ufb01rst used\nmanual methods. These handcrafted features are made after segmentation of the dataset\ninto explicit activity sequences or windows. In order to provide ef\ufb01cient activity recognition\nsystems, researchers have studied different features [31].\nInitially, Krishann et al. [ 32] and Yala et al. [ 33] proposed several feature vector\nextraction methods described below: baseline, time dependency, sensor dependency, and\nsensor dependency extension. These features are then used by classi\ufb01cation algorithms,\nsuch as SVM or Random Forest, to perform the \ufb01nal classi\ufb01cation.\nInspired by previous work, more recently, Aminikhanghahi et al. [ 34] evaluate dif-\nferent types of sensor \ufb02ow segmentations. However, they also listed different handmade\nfeatures. Temporal features, such as day of the week, time of day, number of seconds since\nmidnight, or time between sensor transitions, have been studied. Spatial features were also\nevaluated, such as location. However, metrics, such as the number of events in the window\nor the identi\ufb01er of the sensor, also appear most frequently in the previous segments.\n3.1.1. The Baseline Method\nThis consists of extracting a feature vector from each window. It contains the time of\nthe \ufb01rst and last sensor events in the window, the duration of the window, and a simple\ncount of the different sensor events within the window. The size of the feature vector\ndepends on the number of sensors in the datasets. For instance, if the dataset containsmethod to overcome different problems or challenges.\n3.1.2. The Time Dependence Method\nThis tries to overcome the problem of the sampling rate of sensor events. In most\ndataset, sensor events are not sampled regularly, and the temporal distance of an event\nfrom the last event in the segment has to be taken into account. To do this, the sensors\nare weighted according to their temporal distance. The more distant the sensor is in time,\nthe less important it is.\n3.1.3. The Sensor Dependency Method\nThis has been proposed to address the problem of the relationship between the events\nin the segment. The idea is to weight the sensor events in relation to the last sensor event\nin the segment. The weights are based on a matrix of mutual information between sensors,\ncalculated of\ufb02ine. If the sensor appears in pair with the last sensor of the segment in other\nparts of the sensor \ufb02ow, then the weight is high, and respectably low otherwise.\n3.1.4. The Sensor Dependency Extension Method\nThis proposes to add the frequency of the sensor pair in the mutual information\nmatrix. The more frequently a pair of sensors appears together in the dataset, the greater\ntheir weight.\n3.1.5. The Past Contextual Information Method\nThis is an extension of the previous approaches to take into account information\nfrom past sessions. The classi\ufb01er does not know the activity of the previous segment.\nFor example, the activity \u201center home\u201d can only appear after the activity \u201cleave home\u201d.\nNaively the previous activity cannot be added to the feature vector. The algorithm might\nnot be able to generalize enough. Therefore, Krishnan et al. [ 32] propose a two-part learning\nprocess. First, the model is trained without knowing the previous activity. Then, each\nprediction of activity in the previous segment is given to the classi\ufb01er when classifying the\ncurrent segment.\n3.1.6. The Latent Knowledge Method\nThis was recently proposed by Surong et al. [ 16]. They improved these features by\nadding probability features. These additional features are learned from explicit activity\nsequences, in an unsupervised manner by a HMM and a Bayesian network. In their work,\nSurong et al. compared these new features with features extracted by deep learning algo-\nrithms, such as LSTM and CNN. The results obtained with these unsupervised augmented\nfeatures are comparable to deep learning algorithms. They conclude that unsupervised\nlearning signi\ufb01cantly improves the performance of handcrafted features.\n3.2. Automatic Features\nIn the aforementioned works, machine learning methods for the recognition of human\nactivity make use of handcrafted features. However, these extracted features are carefully\ndesigned and heuristic. There is no universal or systematic approach for feature extraction\nto effectively capture the distinctive features of human activities.\nCook et al. [ 32] introduced, few years ago, an unsupervised method of discovering\nactivities from sensor data based on a traditional machine learning algorithm. The algo-\nrithm searches for a sequence pattern that best compresses the input dataset. After many\niterations, it reports the best patterns. These patterns are then clustered and given to a\nclassi\ufb01er to perform the \ufb01nal classi\ufb01cation.\nIn recent years, deep learning has \ufb02ourished remarkably by modeling high-level\nabstractions from complex data [ 35] in many \ufb01elds, such as computer vision, natural\nlanguage processing, and speech processing [ 6]. Deep learning models have the end-without the guidance of human experts, which facilitates their wide applications. Thus,\nresearchers used Multi-layer Perceptron (MLP) in order to carry out the classi\ufb01cation of\ntheactivities [36,37] . However, the key point of deep learning algorithms is their ability\nto learn features directly from the raw data in a hierarchical manner, eliminating the\nproblem of crafty approximations of features. They can also perform the classi\ufb01cation task\ndirectly from their own features. Wang et al. [ 12] presented a large study on deep learning\ntechniques applied to HAR with the sensor-based approach. Here, only the methods\napplied to smart homes are discussed.\n3.2.1. Convolutional Neural Networks (CNN)\nWorks using Convolutional Neural Networks (CNN) have been carried out by the\nresearchers. The CNN have demonstrated their strong capacity to extract characteristics\nin the \ufb01eld of image processing and time series. The CNN have two advantages for the\nHAR. First, they can capture local dependency, i.e., the importance of nearby observations\ncorrelated with the current event. In addition, they are scale invariant in terms of step\ndifference or event frequency. Moreover, they are able to learn a hierarchical representation\nof the data. There are two types of CNN: 2D CNN for image processing and 1D CNN for\nsequence processing.\nGochoo et al. [ 15] have transformed activity sequences into binary images in order\nto use 2D CNN-based structures. Their work showed that this type of structure could\nbe applied to the HAR. In an extension, Gochoo et al. [ 38] propose to use colored pixels\nin the image to encode new sensor information about the activity in the image. Their\nextension proposes a method to encode sensors, such as temperature sensors, which are\nnot binary, as well as the link between the different segments. Mohmed et al. [ 39] adopt\nthe same strategy but convert activities into grayscale images. The gray value is correlated\nto the duration of sensor activation. The AlexNet structure [ 40] is then used for the feature\nextraction part of the images. Then, these features are used with classi\ufb01ers to recognize the\n\ufb01nal activity.\nSingh et al. [ 41] use a CNN 1D-based structure on raw data sequences for their\nhigh feature extraction capability. Their experiments show that the CNN 1D architecture\nachieves similar height results.\n3.2.2. Autoencoder Method\nAutoencoder is an unsupervised arti\ufb01cial neural network that learns how to ef\ufb01ciently\ncompress and encode data then learns how to reconstruct the data back from the reduced\nencoded representation to a representation that is as close to the original input as possible.\nAutoencoder, by design, reduces data dimensions by learning how to ignore the noise\nin the data. Researchers have explored this possibility because of the strong capacity of\nAutoencoders to generate the most discriminating features. The reduced encoded represen-\ntation created by the Autoencoder contains the features that allow for discrimination of\nthe activities.\nWang et al., in Reference [ 42], apply a two-layer Stacked Denoising Autoencoder\n(SDAE) to automatically extract unsupervised meaningfully features. The input of the\nSDAE are feature vectors extracted from 6-s time windows without overlap. The feature\nvector size is the number of sensors in the dataset. They compared two features forms:\nbinary representation and numerical representation. The numerical representation method\nrecords the number of \ufb01ring of a sensor during the time window, while the binary represen-\ntation method sets to one the sensor value if this one \ufb01red in the time window. Wang et al.\nthen use a dense layer on top of the SDAE to \ufb01ne-tune this layer with the labeled data to\nperform the classi\ufb01cation. Their method outperforms machine learning algorithms on the\nVan Kasteren Dataset [43] with the two features representations.\nGhods et al. [ 44] proposed a method, Activity2Vec to learn an activity Embedding from\nsensor data. They used a Sequence-to-Sequence model (Seq2Seq) [ 45] to encode and extractthe initial input sequence in output. Ghods et al. validate the method with two datasets\nfrom HAR domain; one was composed of accelerometer and gyroscope signals from a\nsmartphone, and the other one contained smart sensor events. Their experiment shows that\nthe Activity2Vec method generates good automatic features. They measured the intra-class\nsimilarities with handcrafted and Activity2Vec features. It appears that, for the \ufb01rst dataset\n(smartphone HAR), intra-class similarities are smallest with the Activity2Vec encoding.\nConversely, for the second dataset (smart sensors events), the intra-class similarities are\nsmallest with handcrafted features.\n3.3. Semantics\nPrevious work has shown that deep learning algorithms, such as Autoencoder or\nCNN, are capable of extracting features but also of performing classi\ufb01cation. Thus, they\nallow the creation of so-called end-to-end models. However, these models do not translate\nsemantics representing the relationship between activities, as ontologies could represent\nthese relationships [ 20]. However, in recent years, researchers in the \ufb01eld of Natural Lan-\nguage Processing (NLP) have developed techniques of word embedding and the language\nmodel for deep learning algorithms to understand not only the meaning of words but also\nthe structure of phases and texts. A \ufb01rst attempt to add NLP word embedding to deep\nlearning has shown a better performance in daily activity recognition in smart homes [ 46].\nMoreover, the use of the semantics of the HAR domain may allow the development of new\nlearning techniques for quick adaptation, such as zero-shot learning, which is developed in\nSection 5.\n3.4. Outlines\nAll handcrafted methods for extracting features have produced remarkable results in\nmany HAR applications. These approaches assume that each dataset has a set of features\nthat are representative, allowing a learning model to achieve the best performance. How-\never, handcrafted features require extensive pre-processing. This is time consuming and\ninef\ufb01cient because the dataset is manually selected and validated by experts. This reduces\nadaptability to various environments. This is why HAR algorithms must automatically\nextract the relevant representations.\nMethods based on deep learning allow better and higher quality features to be ob-\ntained from raw data. Moreover, these features can be learned for any dataset. They can\nbe processed in a supervised or unsupervised manner, for example, windows labeled or\nnot with the name of the activity. In addition, deep learning methods can be end-to-end,\ni.e., they extract features and perform classi\ufb01cation. Thanks to deep learning, great ad-\nvances have been made in the \ufb01eld of NLP . It allows for representing words, sentences,\nor texts, thanks to models, structures, and learning methods. These models are able to\ninterpret the semantics of words, to contextualize them, to make prior or posterior correla-\ntions between words, and, thus, to increase their performance in terms of sentence or text\nclassi\ufb01cation. Moreover, these models are able to automatically extract the right features to\naccomplish their task. The NLP and HAR domains in smart homes both process data in\nthe form of sequences. In smart homes, sensors generate a stream of events. This stream of\nevents is sequential and ordered, such as words in a text. Some events are correlated to\nearlier or later events in the stream. This stream of events can be segmented into sequences\nof activities. These sequences can be similar to sequences of words or sentences. Moreover,\nsemantic links between sensors or types of sensors or activities may exist [ 20]. We suggest\nthat some of these learning methods or models can be transposed to deal with sequences\nof sensor events. We think particularly of methods using attention or embedding models.\nHowever, these methods developed for pattern recognition might not be suf\ufb01cient to\nanalyze these data which are, in fact, temporal series.In a smart home, sensors record the actions and interactions with the residents\u2019 envi-\nronment over time. These recordings are the logs of events that capture the actions and\nactivities of daily life. Most sensors only send their status when there is a change in status,\nto save battery power and also to not overload wireless communications. In addition,\nsensors may have different triggering times. This results in scattered sampling of the time\nseries and irregular sampling. Therefore, recognizing human activity in a smart home is\na pattern recognition problem in time series with irregular sampling, unlike recognizing\nhuman activity in videos or wearables.\nIn this section, we describe literature methods for segmentation of the sensor data\nstream in a smart home. These segmentation methods provide a representation of sensor\ndata for human activity recognition algorithms. We highlight the challenges of dealing\nwith the temporal complexity of human activity data in real use cases.\n4.1. Data Segmentation\nAs in many \ufb01elds of activity recognition, a common approach consists of segmenting\nthe data \ufb02ow. Then, using algorithms to identify the activity in each of these segments.\nSome methods are more suitable for real-time activity recognition than others. Real time is\na necessity to propose reactive systems. In some situations, it is not suitable to recognize\nactivities several minutes or hours after they occur, for example, in case of emergencies,\nsuch as fall detection. Quigley et al. [ 47] have studied and compared different window-\ning approaches.\n4.1.1. Explicit Windowing (EW)\nThis consists of parsing the data \ufb02ow per activity [ 32,33]. Each of these segments\ncorresponds to one window that contain a succession of sensor events belonging to the\nsame activity. This window segmentation depends on the labeling of the data. In the case\nof absence of labels, it is necessary to \ufb01nd the points of change of activities. The algorithms\nwill then classify these windows by assigning the right activity label. This approach has\nsome drawbacks. First of all, it is necessary to \ufb01nd the segments corresponding to each\nactivity in case of unlabeled data. In addition, the algorithm must use the whole segment\nto predict the activity. It is, therefore, not possible to use this method in real time.\n4.1.2. Time Windows (TW)\nThe use of TW consists of dividing the data stream into time segments with a regular\ntime interval. This approach is intuitive but rather favorable to the time series of sensors\nwith regular or continuous sampling over time. This is a common technique with wearable\nsensors, such as accelerometers and gyroscopes. One of the problems is the selection of\nthe optimal duration of the time interval. If the window is too small, it may not contain\nany relevant information. If it is too large, then the information may be related to several\nactivities, and the dominant activity in the window will have a greater in\ufb02uence on the\nchoice of the label. Van Kasteren et al. [ 48] determined that a window of 60 s is a time step\nthat allows a good classi\ufb01cation rate. This value is used as a references in many recent\nworks [ 49\u201352]. Quigley et al. [ 47] show that TW achieves a high accuracy but does not\nallow for \ufb01nding all classes.\n4.1.3. Sensor Event Windows (SEW)\nA SEW divides the stream via a sliding window into segments containing an equal\nnumber of sensor events. Each window is labeled with the label of the last event in the\nwindow. The sensor events that precede the last event in the window de\ufb01ne the context\nof the last event. This method is simple but has some drawbacks. This type of window\nvaries in terms of duration. It is, therefore, impossible to interpret the time between events.\nHowever, the relevance of the sensor events in the window can be different, depending on\nthe time interval between the events [ 53]. Furthermore, because it is a sliding window, it isIn addition, The size of the window in number of events, as for any type of window, is also\na dif\ufb01cult parameter to determine. This parameter de\ufb01nes the size of the context of the last\nevent. If the context is too small, there will be a lack of information to characterize the last\nevent. However, if it is too large, it will be dif\ufb01cult to interpret. A window of 20\u201330 events\nis usually selected in the literature [34].\n4.1.4. Dynamic Windows (DW)\nDW uses a non-\ufb01xed window size unlike the previous methods. It is a two-stage\napproach that uses an of\ufb02ine phase and an online phase [ 54]. In the of\ufb02ine phase, the data\nstream is split into EW. From the EW, the \u201cbest-\ufb01t sensor group\u201d is extracted based on rules\nand thresholds. Then, for the online phase, the dataset is streamed to the classi\ufb01cation\nalgorithm. When it identi\ufb01es the \u201cbest-\ufb01t sensor group\u201d in the stream, the classi\ufb01er\nassociates the corresponding label with the given input segment. Problems can arise if\nthe source dataset is not properly annotated. Quigley et al. [ 47] have shown that this\napproach is inef\ufb01cient for modeling complex activities. Furthermore, rules and thresholds\nare designed by experts, manually, which is time consuming.\n4.1.5. Fuzzy Time Windows (FTW)\nFTW were introduced in the work of Medina et al. [ 49]. This type of window was\ncreated to encode multi-varied binary sensor sequences, i.e., one series per sensor. The ob-\njective is to generate features for each sensor series according to its short, medium, and\nlong term evolution for a given time interval. As for the TW, the FTW segments the signal\ntemporarily. However, unlike other types of window segmentation, FTW use a trapezoidal\nshape to segment the signal of each sensor. The values de\ufb01ning the trapezoidal shape\nfollow the Fibonacci sequence, which resulted in good performance during classi\ufb01cation.\nThe construction of a FTW is done in two steps. First, the sensor stream is resampled by the\nminute, forming a binary matrix. Each column of this matrix represents a sensor, and each\nrow contains the activation value of the sensor during the minute, i.e., 1 if the sensor is\nactivated in the minute, or 0 otherwise. For each sensor and each minute, a number of FTW\nis de\ufb01ned and calculated. Thus, each sensor for each minute is represented by a vector\ntranslating its activation in the current minute but also its past evolution. The size of this\nvector is related to the number of FTW. This approach allowed to obtain excellent results\nfor binary sensors. Hamand et al. [ 50] proposed an extension of FTW by adding FTW using\nthe future data of the sensor in addition to the past information. The purpose of this com-\nplement is to introduce a delay in the decision-making of the classi\ufb01er. The intuition is that\nrelying only on the past is not enough to predict the right label of activity and that, in some\ncases, delaying the recognition time allows for making a better decision. To illustrate with\nan example, if a binary sensor deployed on the front door generates an opening activation,\nthe chosen activity could be \u201cthe inhabitant has left the house\u201d. However, it may happen\nthat the inhabitant opens the front door only to talk to another person at the entrance of the\nhouse and comes back home without leaving. Therefore, the accuracy could be improved\nby using the activation of the following sensors. It is, therefore, useful to introduce a time\ndelay in decision-making. The longer the delay, the greater the accuracy. However, a\nproblem can appear if this delay is too long, and, indeed, the delay prevents real time.\nWhile a long delay may be acceptable for some types of activity, others require a really\nshort decision time in case of an emergency, e.g., the fall of a resident. Furthermore, FTW\nare only applicable to binary sensors data and do not allow the use of non-binary sensors.\nHowever, in a smart home, the sensors are not necessarily binary, e.g., humidity sensors.\n4.1.6. Outlines\nThe Table 1 below summarizes and categorizes the different segmentation techniques\ndetailed above.\nSegmentation TypeUsable forRequire Resamplig Time RepresentationUsable on Capture Long Capture Dependence# StepsReal Time Raw Data Term Dependencies between Sensors\nEW No No No Yes only inside the sequence Yes 1\nSEW Yes No No Yes depends of the size Yes 1\nTW Yes Yes Yes Yes depends of the size No 1\nDW Yes No No Yes only inside the pre-segmented sequence Yes 2\nFTW Yes Yes Yes Yes Yes No 2\n4.2. Time Series Classi\ufb01cation\nThe recognition of human activity in a smart home is a problem of pattern recognition\nin time series with irregular sampling. Therefore, more speci\ufb01c machine learning for\nsequential data analysis has also proven ef\ufb01cient for HAR in smart homes.\nIndeed, statistical Markov models, such as Hidden Markov Models [ 29,55] and their\ngeneralization, Probabilistic graphical models, such as Dynamic Bayesian Networks [ 56],\ncan model spatiotemporal information. In the deep learning framework, they have been\nimplemented as Recurrent Neural Networks (RNN). RNN show, today, a stronger capacity\nto learn features and represent time series or sequential multi-dimensional data.\nRNN are designed to take a series of inputs with no predetermined limit on size.\nRNN remembers the past, and its decisions are in\ufb02uenced by what it has learnt from\nthe past. RNN can take one or more input vectors and produce one or more output\nvectors, and the output(s) are in\ufb02uenced not just by weights applied on inputs, such\nas a regular neural network, but also by a hidden state vector representing the context\nbased on prior input(s)/output(s). So, the same input could produce a different output,\ndepending on previous inputs in the series. However, RNN suffers from the long-term\ndependency problem [57] . To avoid this problem, two RNN variations have been proposed,\nthe Long Short Term Memory (LSTM) [ 58] and Gated Recurrent Unit (GRU) [ 59], which is\na simpli\ufb01cation of the LSTM.\nLiciotti et al., in Reference [ 14], studied different LSTM structures on activity recogni-\ntion. They showed that the LSTM approach outperforms traditional HAR approaches in\nterms of classi\ufb01cation score without using handcrafted features, as LSTM can generate fea-\ntures that encode the temporal pattern. The higher performance of LSTM was also reported\nin Reference [ 60] in comparison traditional machine learning techniques (Naive Bayes,\nHMM, HSMM, and Conditional Random Fields). Likewise, Sedkly et al. [ 30] reported that\nLSTM perform better than AdaBoost, Cortical Learning Algorithm (CLA), Hidden Markov\nModel, or Multi-layer Perceptron or Structured Perceptron. Nevertheless, the LSTM still\nhave limitations, and their performance is not signi\ufb01cantly higher than decision Trees, SVM\nand stochastic gradient descent of linear SVM, logistic regression, or regression functions.\nIndeed, LSTM still have dif\ufb01culties in \ufb01nding the suitable time scale to balance between\nlong-term temporal dependencies and short term temporal dependencies. A few works\nhave attempted to tackle this issue. Park et al. [ 61] used a structure using multiple LSTM\nlayers with residual connections and an attention module. Residual connections reduce the\ngradient vanishing problem, while the attention module marks important events in the\ntime series. To deal with variable time scales, Medina-Quero et al. [ 49] combined the LSTM\nwith a fuzzy window to process the HAR in real time, as fuzzy windows can automatically\nadapt the length of its time scale. With accuracies lower than 96%, these re\ufb01nements still\nneed to be consolidated and improved.\n4.3. Complex Human Activity Recognition\nBesides, these sequential data analysis algorithms can only process simple, primitive\nactivities, and they cannot yet deal with complex activities. A simple activity is an activity\nthat consists of a single action or movement, such as walking, running, turning on the\nlight, or opening a drawer. A complex activity is an activity that involves a sequence\nof actions, potentially involving different interactions with objects, equipment, or other\npeople, for example, cooking. , such as gestures that are carried\nout the same way by all individuals. Activities of daily living that our smart homes want\nto recognize can be on the contrary seen as sequences of micro actions, which we can call\ncompound actions. These sequences of micro actions generally follow a certain pattern,\nbut there are no strict constraints on their compositions or the order of micro actions. This\nidea of compositionality was implemented by an ontology hierarchy of context-aware\nactivities: a tree hierarchy of activities link each activity to its sub-activities [ 62]. Another\nwork proposed a method to learn this hierarchy: as the Hidden Markov Model approach\nis not well suited to process long sequences, an extension of HMM called Hierarchical\nHidden Markov Model was proposed in Reference [ 63] to encode multi-level dependencies\nin terms of time and follow a hierarchical structure in their context. To our knowledge, there\nhave been no extensions of such hierarchical systems using deep learning, but hierarchical\nLTSM using two-layers of LSTM to tackle the varying composition of actions for HAR\nbased on videos proposing [ 64] or using tow hidden layers in the LSTM for HAR using\nwearables [ 65] can constitute inspirations for HAR in smart home applications. Other works\nin video-based HAR proposed to automatically learn a stochastic grammar describing\nthe hierarchical structure of complex activities from annotations acquired from multiple\nannotators [66].\nThe idea of these HAR algorithms is to use the context of a sensor activation, either by\nintroducing multi-timescale representation to take into account longer term dependencies\nor by introducing context-sensitive information to channel the attention in the stream of\nsensor activations.\nThe latter idea can be developed much further by taking advantage of the methods\ndeveloped by the \ufb01eld of natural language processing, where texts also have a multi-\nlevel hierarchical structure, where the order of words can vary and where the context of\na word is very important. Embedding techniques, such as ELMo [ 67], based on LSTM,\nor, more recently, BERT [ 68], based on Transformers [ 69], have been developed to han-\ndle sequential data while handling long-range dependencies through context-sensitive\nembeddings. These methods model the context of words to help the processing of long\nsequences. Applied to HAR, they could model the context of the sensors and their order of\nappearance. Taking inspiration from References [ 46,66], we can draw a parallel between\nNLP and HAR: a word is apparent to a sensor event, a micro activity composed of sensor\nevents is apparent to a sentence, and a compound activity composed of sub-activities is\na paragraph. The parallel between word and sensor events has led to the combination of\nword encodings with deep learning to improve the performance of HAR in smart homes in\nReference [46].\n4.3.2. Interleave and Concurrent Activities\nHuman activities are often carried out in a complex manner. Activities can be carried\nout in an interleave or concurrent manner. An individual may alternately cook and wash\ndishes, or cook and listen to music simultaneously, but could just as easily cook and wash\ndishes, alternately, while listening to music. The possibilities are in\ufb01nite in terms of activity\nscheduling. However, some activities seem impossible to see appearing in the dataset and\ncould be anomalous, such as cooking while the individual sleeps in his room.\nResearchers are working on this issue. Modeling this type of activity is becoming\ncomplex. However, it could be modeled as a multi-label classi\ufb01cation problem. Safyan\net al. [ 70] have explored this problem using ontology. Their approach uses a semantic\nsegmentation of sensors and activities. This allows the model to relate the possibility that\ncertain activities may or may not occur at the same time for the same resident. Li et al. [ 71]\nexploit a CNN-LSTM structure to recognize concurrent activity with multi-modal sensors.Moreover, monitoring the activities of daily living performed by a single resident\nis already a complex task. The complexity increases with several residents. The same\nactivities become more dif\ufb01cult to recognize. On the one hand, in a group, a resident\nmay interact to perform common activities. In this case, the activation of the sensors\nre\ufb02ects the same activity for each resident in the group. On the other hand, everyone can\nperform different activities simultaneously. This produces a simultaneous activation of\nthe sensors for different activities. These activations are then merged and mixed in the\nactivity sequences. An activity performed by one resident is a noise for the activities of\nanother resident.\nSome researchers are interested in this problem. As with the problem of recogniz-\ning competing activities, the multi-resident activity recognition problem is a multi-label\nclassi\ufb01cation problem [ 72]. Tran et al. [ 73] tackled the problem using a multi-label RNN.\nNatani et al. [ 74] studied different neural network architectures, such as MLP , CNN, LSTM,\nGRU, or hybrid structures, to evaluate which structure is the most ef\ufb01cient. The hybrid\nstructure that combines a CNN 1D and a LSTM is the best performing one.\n4.4. Outlines\nA number of algorithms have been studied for HAR in smart homes. Table 2 show a\nsummary and comparison of recent HAR methods in smart homes.\nTable 2. Summary and comparison of activity recognition methods in smart homes.\nRef Segmentation Data Representation Encoding Feature Type Classi\ufb01er Dataset Real-Time\n[14] EW SequenceInteger sequence (one integer\nAutomaticUni LSTM, Bi LSTM, Cascade CASAS [75]:\nNo for each possible LSTM, Ensemble LSTM, Milan, Cairo, Kyoto2,\nsensors activations) Cascade Ensemble LSTM Kyoto3, Kyoto4\n[60] TW Multi-channel Binary matrix Automatic Uni LSTM Kasteren [43] Yes\n[61] EW SequenceInteger sequence (one Automatic Residual LSTM,MIT [76] Nointeger for each sensor Id) Residual GRU\n[49] FTW Multi-channelReal values matrix (computedManual LSTMOrdonez [77], CASAS A &Yesvalues inside each FTW) CASAS B [75]\n[15] EW + SEW Multi-channel Binary picture Automatic 2D CNN CASAS [75]: Aruba No\n[51] FTW Multi-channelReal values matrix (computedManual Joint LSTM + 1D CNNOrdonez [77],Yesvalues inside each FTW) Kasteren [43]\n[41] TW Multi-channel Binary matrix Automatic 1D CNN Kasteren [43] Yes\n[78] TW Multi-channel/SequenceBinary matrix, Binary vector, Automatic/Manual Autoencoder, 1D CNN,Ordonez [77] YesNumerical vector, Probability vector Automatic/Manual 2D CNN, LSTM, DBN\n[34] SEW Sequence Categorical values Manual Random Forest CASAS [75]: HH101-HH125 Yes\nLSTM shows excellent performance on the classi\ufb01cation of irregular time series in the\ncontext of a single resident and simple activities. However, human activity is more complex\nthan this. In addition, challenges related to the recognition of concurrent, interleaved or idle\nactivities offer more dif\ufb01culties. Previous cited works did not take into account these type\nof activities. Moreover, people rarely live alone in a house. This is why even more complex\nchallenges are introduced, including the recognition of activity in homes with multiple\nresidents. These challenges are multi-class classi\ufb01cation problems and still unsolved.\nIn order to address these challenges, activity recognition algorithms should be able to\nsegment the stream for each resident. Techniques in the \ufb01eld of image processing based\non Fully Convolutional Networks [ 79], such as U-Net [ 80], allow for segmentation of the\nimages. These same approaches can be adapted to time series [ 81] and can constitute\ninspirations for HAR in smart home applications.\n5. Data Variability\nNot only are real human activities complex, the application of human activity recog-\nnition in smart homes for real-use cases also faces issues causing a discrepancy between\ntraining and test data. The next subsections detail the issues inherent to smart homes: the\ntemporal drift of the data and the variability of settings.Smart homes through their sensors and interactions with residents collect data on\nthe behavior of residents. Initial training data is the portrait of the activities performed\nat the time of registration. A model is generated and trained using this data. Over time,\nthe behavior and habits of the residents may change. The data that is now captured is\nno longer the same as the training data. It corresponds to a time drift as introduced in\nReference [ 82]. This concept means that the statistical properties of the target variable,\nwhich the model is trying to predict, evolve over time in an unexpected way. A shift in the\ndistribution between the training data and the test data.\nTo accommodate this drift, algorithms for HAR in smart homes should incorporate\nlife-long learning to continuously learn and adapt to changes in human activities from new\ndata as proposed in Reference [ 83]. Recent works in life-long learning incorporating deep\nlearning as reviewed in Reference [ 84] could help tackle this issue of temporal drift. In par-\nticular, one can imagine that an interactive system can from time to time request labeled\ndata to users to continue to learn and adapt. Such algorithms have been developed under\nthe names of interactive reinforcement learning or active imitation learning in robotics.\nIn Reference [ 85], they allowed the system to learn micro and compound actions, while\nminimizing the number of requests for labeled data by choosing when, what information\nto ask, and to whom to ask for help. Such principles could inspire a smart home system\nto continue to adapt its model, while minimizing user intervention and optimizing his\nintervention, by pointing out the missing key information.\n5.2. Variability of Settings\nBesides these long-term evolutions, the data from one house to another are also very\ndifferent, and the model learned in one house is hardly applicable in another because of\nthe change in house con\ufb01guration, sensors equipment, and families\u2019 compositions and\nhabits. Indeed, the location, the number and the sensors type of smart homes can in\ufb02uence\nactivity recognition systems performances. Each smart homes can be equipped in different\nways and have different architecture in terms of sensors, room con\ufb01guration, appliance,\netc. Some can have a lot of sensors, multiple bathrooms, or bedrooms and contain multiple\nappliances, while others can be smaller, such as a single apartment, where sensors can\nbe fewer and have more overlaps and noisy sequences. Due to this difference in house\ncon\ufb01gurations, a model that optimized in the \ufb01rst smart homes could perform poorly in\nanother. This issue could be solved by collecting a new dataset for each new household to\ntrain the models anew; however, this is costly, as explained in Section 6.\nAnother solution is to adapt the models learned in a household to another. Transfer\nlearning methods have recently been developed to allow pre-trained deep learning models\nto be used with different data distributions, as reviewed in Reference [ 86]. Transfer learning\nusing deep learning has been successfully applied to time series classi\ufb01cation, as reviewed\nin Reference [ 87]. For activity recognition, Cook et al. [ 88] reviewed the different types of\nknowledge that could be transferred in traditional machine learning. These methods can be\nupdated with deep learning algorithms and by bene\ufb01ting from recent advances in transfer\nlearning for deep learning. Furthermore, adaptation to new settings have recently been\nimproved by the development of meta-learning algorithms. Their goal is to train a model\non a variety of learning tasks, so it can solve new learning tasks using only a small number\nof training samples. This \ufb01eld has seen recent breakthroughs, as reviewed in Reference [ 89],\nwhich has never been applied yet to HAR. Yet, the peculiar variability of data of HAR in\nsmart homes can only bene\ufb01t from such algorithms.\n6. Datasets\nDatasets are key to train, test, and validate activity recognition systems. Datasets\nwere \ufb01rst generated in laboratories. However, these records do not allow enough variety\nand complexity of activities and were not real enough. To overcome these issues, public\ndatasets were created from recordings in real homes with volunteer residents. In parallelwere created, such as Evaluating AAL Systems Through Competitive Benchmarking-AR\n(EvAAL-AR) [90] or UCAmI Cup [91].\nHowever, the production of datasets is a tedious task and recording campaigns are\ndif\ufb01cult to manage. They require volunteer actors and apartments or houses equipped\nwith sensors. In addition, data annotation and post-processing take a lot of time. Intelligent\nhome simulators have been developed as a solution to generate datasets.\nThis section presents and analyzes some real and synthetic datasets in order to under-\nstand the advantages and disadvantages of these two approaches.\n6.1. Real Smart Home Dataset\nA variety of public real homes datasets exist [ 43,75,76,92,93]. De-la-Hoz et al. [ 94]\nprovides an overview of sensor-based datasets used in HAR for smart homes. They\ncompiled documentation and analysis of a wide range of datasets with a list of results and\napplied algorithms. However, such dataset production implies some problems as: sensors\ntype and placement, variability in terms of user pro\ufb01le or typology of dwelling, and the\nannotation strategy.\n6.1.1. Sensor Type and Positioning Problem\nWhen acquiring data in a house, it is dif\ufb01cult to choose the sensors and their numbers\nand locations. It is important to select sensors that are as minimally invasive as possible in\norder to respect the privacy of the volunteers [ 92]. No cameras nor video recordings were\nused. The majority of sensor-oriented smart home datasets use so-called low-level sensors.\nThese include infrared motion sensors (PIR), magnetic sensors for openings and closures,\npressure sensors placed in sofas or beds, sensors for temperature, brightness, monitoring\nof electricity or water consumption, etc.\nThe location of these sensors is critical to properly capture activity. Strategic position-\ning allows for accurate capture of certain activities, e.g., a water level sensor in the toilet\nto capture toilet usage or a pressure sensor under a mattress to know if a person is in bed.\nThere is no precise method or strategy for positioning and installing sensors in homes.\nCASAS [ 75] researchers have proposed and recommended a number of strategic positions.\nHowever, some of these strategic placements can be problematic in terms of evolution. It\nis possible to imagine that, during the life of a house, the organization or use of its rooms\nchanges, e.g., if a motion sensor is placed above the bed to capture its use. However, if\nthe bed is moved to a different place in the room, then the sensor will no longer be able to\ncapture this information. In the context of a dataset and the use of the dataset to validate\nthe algorithms, this constraint is not important. However, it becomes important in the\ncontext of real applications to evaluate the resilience of algorithms, which must continue to\nfunction in case of loss of information.\nIn addition to positioning, it is important to choose enough sensors to cover a maxi-\nmum of possible activities. The number of sensors can be very different from one dataset\nto another. For example, the MIT dataset [ 76] uses 77 and 84 sensors for each of these\napartments. The Kasteren dataset [ 43] uses between 14 and 21 sensors. ARAS [ 92] has\napartments with 20 sensors. Orange4Home [ 93] is based on an apartment equipped with\n236 sensors. This difference can be explained by the different types of dwellings but also\nby the number and granularity of the activities that we want to recognize. Moreover, some\ndataset are voluntarily over-equipped. There is still no method nor strategy to de\ufb01ne the\nnumber of sensors installed according to an activity list.\n6.1.2. Pro\ufb01le and Typology Problem\nIt is important to take into account that there are different typologies of houses:\napartment, house, with garden, with \ufb02oors, without \ufb02oor, one or more bathrooms, one or\nmore bedrooms, etc. These different types and variabilities of houses lead to dif\ufb01culties,\nsuch as: the possibility that the same activity takes place in different rooms, that thenetwork coverage of the sensors can be problematic. For example, Alerndar et al. [ 92] faced\na problem of data synchronization. One of their houses required two sensor networks to\ncover the whole house. They must synchronize the data for dataset needs. It is, therefore,\nnecessary that the datasets can propose different house configurations in order to evaluate the\nalgorithms in multiple configurations. Several datasets with several houses exist [ 43,43,76,92].\nCASAS [ 75] is one of them, with about 30 several houses configurations. These datasets are\nvery often used in the literature [ 94]. However, the volunteers are mainly elderly people,\nand coverage of several age groups is important. A young resident does not have the\nsame behavior as an older one. The Orange4Home dataset [ 93] covers the activity of a\nyoung resident. The number of residents is also important. The activity recognition is more\ncomplex in the case of multiple residents. This is why several datasets also cover this field of\nresearch [43,75,92].\n6.1.3. Annotation Problem\nDataset annotation is something essential for supervised algorithm training. When\ncreating, these datasets, it is necessary to deploy strategies to enable this annotation, such as\njournal [ 43], smartphone applications [ 93], personal digital assistant (PDA) [ 76], Graphical\nUser Interface (GUI) [92], or voice records, to annotate the dataset [43].\nAs these recordings are made directly by volunteers, they are asked to annotate their\nown activities. For the MIT dataset [ 76], residents used a PDA to annotate their activities.\nEvery 15 min, the PDA beeped to prompt residents to answer a series of questions to\nannotate their activities; however, several problems were encountered with this method of\nuser self-annotation. However, several problems were encountered with this method of\nself-annotation by the user, such as some short activities not being entered, errors in label\nselection, or omissions. A post-annotation based on the study of a posteriori activations was\nnecessary to overcome these problems, thus potentially introducing new errors. In addition,\nthis annotation strategy is cumbersome and stressful because of the frequency of inquiries.\nIt requires great rigor from the volunteer and, at the same time, interrupts activity execution\nby pausing it when the information is given. These interruptions reduce the \ufb02uidity and\nnatural \ufb02ow of activities.\nVan Kasteren et al. [ 43] proposed another way of annotating their data. The annotation\nwas also done by the volunteers themselves, although using voice through a Bluetooth\nheadset and a journal. This strategy allowed the volunteers to be free to move around\nand not need to create breaks in the activities. This allowed for more \ufb02uid and natural\nsequences of activities. The Diary allowed the volunteers to complete some additional\ninformation when wearing a helmet was not possible. However, wearing a helmet all day\nlong remains a constraint.\nThe volunteers of the ARAS dataset [ 92] used a simple Graphical User Interface\n(GUI) to annotate their activities. Several instances were placed in homes to minimize\ninterruptions in activities and avoid wearing an object, such as a helmet, all day long.\nVolunteers were asked to indicate only the beginning of each activity. It is assumed that\nresidents will perform the same activity until the next start of the activity. This assumption\nre\ufb02ects a bias that sees human activity as a continuous stream of known activity.\n6.2. Synthetic Smart Home Dataset\nThe cost to build real smart homes and the collection of datasets for such scenarios is\nexpensive and sometimes infeasible for many projects. Measurements campaigns should\ninclude a wide variety of activities and actors. It should be done with suf\ufb01cient rigor\nto obtain qualitative data. Moreover, \ufb01nding the optimal placement of the sensors [ 95],\n\ufb01nding appropriate participants [ 96,97], and the lack of \ufb02exibility [ 98,99] makes the dataset\ncollection dif\ufb01cult. For these reasons, researchers imagined smart homes simulation\ntools [100].and interactive [ 102], according to Synnott et al. [ 103]. The model-based approach uses\nprede\ufb01ned models of activities to generate synthetic data. In contrast, the interactive ap-\nproach relies on having an avatar that can be controlled by a researcher, human participant,\nor simulated participant. Some hybrid simulators, such as OpenSH [ 100], can combine\nadvantages from both interactive and model-based approaches. In addition, a smart homes\nsimulation tool can focus on the dataset generation or data visualization. Some simulation\ntools provide multi-resident or fast forwarding to accelerate the time during execution.\nThese tools allow you to quickly generate data and visualize it. However, the capture\nof activities can be unnatural and not noisy. Some uncertainty may be missing.\n6.3. Outlines\nAll these public datasets, synthetic or real, are useful and allow evaluating processes.\nBoth, show advantages and drawbacks. Table 3 details some datasets from the literature,\nresulting from the hard work of the community.\nTable 3. Example of real datasets of the literature.\nRef Multi-Resident Resident Type Duration Sensor Type # of Sensors # of Activity # of Houses Year\n[43] No Elderly 12\u201322 days Binary 14\u201321 8 3 2011\n[92] Yes Young 2 months Binary 20 27 3 2013\n[93] No Young 2 weeks Binary, Scalar 236 20 1 2017\n[75] Yes Elderly 2\u20138 months Binary, Scalar 14\u201330 10\u201315 >30 2012\n[77] No Elderly 14\u201321 days Binary 12 11 2 2013\n[76] No Elderly 2 weeks Binary, Scalar 77\u201384 9\u201313 2 2004\nReal datasets, such as Orange4Home [ 93], provide a large sensor set. That can help\nto determine which sensors can be useful for which activity. CASAS [ 75] proposes many\nhouses or apartment con\ufb01gurations and topologies with elderly people, which allows\nevaluating the adaptability to house topologies. ARAS [ 92] proposes younger people and\nmulti-residents\u2019 living environments, which is useful to validate the noisy resilience and\nsegmentation ability of the activity recognition system. The strength of real datasets is\ntheir variability, as well as their representativeness in number and execution of activities.\nHowever, sensors can be placed too strategically and wisely chosen to cover some speci\ufb01c\nkinds of activities. In some datasets, PIR sensors are used as a grid or installed as a\ncheckpoint to track residents trajectory. Strategic placement, a large number of sensors, or\nthe choice of a particular sensor is great to help algorithms to infer knowledge, but they\nare not the real ground truth.\nSynthetic datasets allow for quick evaluation of different con\ufb01guration sensors and\ntopologies. In addition, they can produce large amounts of data without real setup or\nvolunteer subjects. The annotation is more precise compared to real dataset methods (diary,\nsmartphone apps, voice records).\nHowever, activities provided by synthetic datasets are less realistic in terms of exe-\ncution rhythm and variability. Every individual has its own rhythm in terms of action\nduration, interval or order. The design of the virtual smart homes can be a tedious task for\na non-expert designer. Moreover, no synthetic datasets are publicly available. Only some\ndataset generation tools, such as OpenSH [100], are available.\nToday, even if smart sensors become cheaper and cheaper, real houses are not equipped\nwith a wide range of sensors as can be found in datasets. It is not realistic to \ufb01nd an\nopening sensor on a kitchen cabinet. Real homes contains PIR to monitor wide areas with\nthe security system. Temperature sensors to control the heat. More and more air qualitative\nor luminosity sensors can be found. Some houses are now equipped with smart lights\nor smart plugs. Magnetic sensors can be found on external openings. In addition, now,\nsome houses provide general electrical and water consumption. These datasets are not\nrepresentative of the actual home sensor equipment.tative labels to learn correct features and classify activities. Residents\u2019 self-annotation can\nproduce errors and lack of precision. Post-processing to add annotations adds uncertainty,\nas they are always based on hypothesis, such as every activity being performed sequentially.\nHowever, the human activity \ufb02ow is not always sequential. Very few datasets provide\nconcurrent or interleaved activities. Moreover, every dataset proposes its own taxonomy\nfor annotations, even if synthetic datasets try to overcome annotation issues.\nThis section demonstrates the dif\ufb01culty of providing a correct evaluation system or\ndataset. In addition, the work already provided by all the scienti\ufb01c community is excellent.\nThanks to this amount of work, it is possible to, in certain conditions, evaluate activity\nrecognition systems.\nHowever, there are several areas of research that can be explored to help the \ufb01eld\nprogress more quickly. A \ufb01rst possible research axis for data generation is the generation\nof data from video games. Video games constitute a multi-billion dollar industry, where\ndevelopers put great effort into build highly realistic worlds. Recent works in the \ufb01eld of\nsemantic video segmentation consider and use video games to generate datasets in order\nto train algorithms [ 104,105]. Recently, Roitberg et al. [ 106] studied a \ufb01rst possibility using\na commercial game by Electronic Arts (EA), \u201c The Sims 4\u201d, a daily life simulator game,\nto reproduce the video Toyota Smarthome dataset [ 107]. The objective was to evaluate and\ntrain HAR algorithms from video produced by a video game and compare them to the\noriginal dataset. This work showed promising results. An extension of this work could be\nenvisaged in order to generate datasets of sensor activity traces. Moreover, every dataset\nproposes its own taxonomy. Some are inspired by medical works, such as, Katz et al.\u2019s\nwork [ 108], to de\ufb01ne a list of basic and necessary activities. However, there is no proposal\nfor a hierarchical taxonomy, e.g., cook lunch and cook dinner are children activities of\ncook, or taxonomy taking into account concurrent or parallel activities. The suggestion of a\ncommon taxonomy for datasets is a research axis to be studied in order to homogenize and\ncompare algorithms more ef\ufb01ciently.\n7. Evaluation Methods\nIn order to validate the performance of the algorithms, the researchers use datasets.\nHowever, learning the parameters of a prediction function and testing it on the same data\nis a methodological error: a model that simply repeats the labels of the samples it has\njust seen would have a perfect score but could not predict anything useful on data that is\nstill invisible. This situation is called over\ufb01tting. To avoid it, it is common practice in a\nsupervised machine learning experiment to retain some of the available data as a dataset for\ntesting. Several methods exist in the \ufb01eld of machine learning and deep learning. For the\nproblem of HAR in smart houses, some of them have been used by researchers.\nThe evaluation of these algorithms is not only related to the use of these methods. It\ndepends on the methodology but also on the datasets on which the evaluation is based. It is not\nuncommon that pre-processing is necessary . However, this pre-processing can influence the\nfinal results. This section highlights some of the biases that can be induced by pre-processing\nthe datasets, as well as the application and choice of certain evaluation methods.\n7.1. Datasets Pre-Processing\n7.1.1. Unbalanced Datasets Problem\nUnbalanced datasets pose a challenge because most of the machine learning algorithms\nused for classi\ufb01cation have been designed assuming an equal number of examples for each\nclass. This results in models with poor predictive performance, especially for the minority\nclass. This is a problem because, in general, the minority class is larger; therefore, the\nproblem is more sensitive to classi\ufb01cation errors for the minority class than for the majority\nclass. To get around this problem, some researchers will rebalance the dataset by removing\nclasses that are too little represented and by randomly removing examples for the mostalgorithms but do not allow them to represent the reality.\nWithin the context of the activities of daily life, certain activities are performed more\nor less often during the course of the days. A more realistic approach is to group activities\nunder a new, more general label; for example, \u201cpreparing breakfast\u201d, \u201cpreparing lunch\u201d,\n\u201cpreparing dinner\u201d, and \u201cpreparing a snack\u201d can be grouped under the label \u201cpreparing a\nmeal\u201d. Therefore, activities that are less represented but semantically close can be used as\nparts of example. This can allow fairer comparisons between datasets if the label names\nare shared. Liciotti et al. [14] adopted this approach to compare several datasets between\nthem. One of the drawbacks is the loss of granularity of activities.\n7.1.2. The Other Class Issue\nIn the \ufb01eld of HAR in smart houses, it is very frequent that a part of the dataset is not\nlabeled. Usually, the label \u201cOther\u201d is assigned to these unlabeled events. The class \u201cOther\u201d\ngenerally represents 50% of the dataset [ 14,16]. This makes it the most represented class\nin the dataset and unbalances the dataset. Furthermore, the \u201cOther\u201d class may represent\nseveral different activity classes or simply something meaningless. Some researchers\nchoose to suppress this class, as it is judged to be over-represented and containing too\nmany random sequences. Others prefer to remove it from the training phase and, therefore,\nfrom the training set. However, they keep it in the test set in order to evaluate the system in\na more real-life environment [ 33]. Yala et al. [ 33] evaluated performance with and without\nthe \u201cOther\u201d class and showed that this choice has a strong impact on the \ufb01nal results.\nHowever, being able to dissociate this class opens perspectives. Algorithms able to\nisolate these sequences could propose to the user to annotate them in the future in order to\ndiscover new activities.\n7.1.3. Labeling Issue\nAs noted above, the datasets for the actual houses are labeled by the residents them-\nselves, via a logbook or graphical user interface. They are then post-processed by the\nresponsible researchers. However, it is not impossible that some labels may be missing, as\nin the CASAS Milan dataset [ 75]. Table 4 presents an extract from the Milan dataset where\nlabels are missing. However, events or days are duplicated, i.e., same timestamp, same\nsensor, same value, and same activity label. A cleaning of the dataset must be considered\nbefore the algorithms are formed. Obviously, depending on the quality of the labels and\ndata, the results will be different. Indeed, some occurrence of classes could be arti\ufb01cially\nincreased or decreased. Some events could be labeled \u201cOther\u201d, even though they actually\nbelong to a de\ufb01ned activity. In this case, the recognition algorithm could label this event\ncorrectly, but it would appear to be confused with another class in the confusion matrix.\n7.1.4. Evaluation Metrics\nSince HAR is a multi-class classi\ufb01cation problem, researchers use metrics [109], such\nas Accuracy, Precision, Recall, and F-Score, to evaluate their algorithms [ 41,49,61]. These\nmetrics are de\ufb01ned by means of four features, such as true Positive, true Negative , false\nPositive, and false Negative, of class Ci. The F-score, also called the F1-score, is a measure\nof a model\u2019s accuracy on a dataset. The F-score is a way of combining the Precision and\nRecall of the model, and it is de\ufb01ned as the harmonic mean of the model\u2019s Precision and\nRecall. It should not be forgotten that real house datasets are mostly imbalanced in terms\nof class. In other words, some activities have more examples than others and are in the\nminority. In an imbalanced dataset, a minority class is harder to predict because there are\nfew examples of this class, by de\ufb01nition. This means it is more challenging for a model to\nlearn the characteristics of examples from this class, as well as to differentiate examples\nfrom this class from the majority class. Therefore, it would be more appropriate to use\nmetrics weighted by the class support of the dataset, such as balanced Accuracy, weighted\nPrecision, weighted Recall, or weighted F-score [110,111].\nDate Time Sensor ID Value Label\n2010-01-05 08:25:37.000026 M003 OFF\n2010-01-05 08:25:45.000001 M004 ON Read begin\n. . . . . . . . . . . . . . .\n2010-01-05 08:35:09.000069 M004 ON\n2010-01-05 08:35:12.000054 M027 ON\n2010-01-05 08:35:13.000032 M004 OFF (Read should end)\n2010-01-05 08:35:18.000020 M027 OFF\n2010-01-05 08:35:18.000064 M027 ON\n2010-01-05 08:35:24.000088 M003 ON\n2010-01-05 08:35:26.000002 M012 ON (Kitchen Activity should begin)\n2010-01-05 08:35:27.000020 M023 ON\n. . . . . . . . . . . . . . .\n2010-01-05 08:45:22.000014 M015 OFF\n2010-01-05 08:45:24.000037 M012 ON Kitchen Activity end\n2010-01-05 08:45:26.000056 M023 OFF\n7.2. Evaluation Process\n7.2.1. Train/Test\nA \ufb01rst way to evaluate the algorithms is to divide the datasets into two distinct\nparts: one for training and the other for testing. It is generally chosen to use 70% for\ntraining and 30% for testing. Several researchers have chosen to adopt this method.\nSurong et al. [16] adopted this evaluation method in the application of real time activation\nrecognition. In order to show the generalization of their approach, they chose to divide the\ndatasets temporally into two equal parts. Then, they chose to re-divide each of these parts\ntemporally into training and test datasets. Thus, they propose two sub-sets of training and\ntest. The advantage of this method is that it is usually preferable to the residual method\nand takes no longer to compute. Moreover, it does not allow for taking into account the\ndrift [34] of the activities. In addition, it is always possible that the algorithm over\ufb01tted on\nthe test sets because the parameters were adapted to optimal values. This approach does\nnot guarantee a generalization of the algorithms.\n7.2.2. K-Fold Cross Validation\nThis is a wide approach used for model evaluation. It consists of dividing the dataset\ninto K sub-dataset; the value of K is often between 3 and 10. K-1dataset is selected for\ntraining, and the remaining dataset for testing. The algorithm iterates until all the sub-\ndataset is used for testing. The average of the training K scores is used to evaluate the\ngeneralization of the algorithm. It is usually customary that the data is mixed before\nbeing divided into K sub-datasets in order to increase the generalization capability of the\nalgorithms. However, it is possible that some classes are not represented in the training\nor test sets. That is why some implementations propose that all classes are represented in\ntests as not training.\nIn the context of HAR in smart homes, this method is a good approach for classi\ufb01cation\nof EW [ 14,61]. Indeed, EW can be considered as independent and not temporally correlated.\nHowever, it seems not relevant for sliding windows, especially if they have a strong overlap,\nand the windows are distributed equally according to their class between the test and\ntraining set. The training and test sets would look too similar, which would increase the\nperformance of the algorithms and would not allow it to generalize enough.\n7.2.3. Leave-One-Out Cross-Validation\nThis is a special case of cross-validation where the number of folds equals the number\nof instances in the dataset. Thus, the learning algorithm is applied once for each instance,\nusing all other instances as a training set and using the selected instance as a single-item\ntest set.of real-time HAR. In their experiments, the dataset is divided into days. One day is used\nfor testing, while the other days are used for training. Each day becomes a test day, in turn.\nThis approach allows a large part of the dataset to be used for training, as well as allowing\nthe algorithms to train on a wide variety of data. However, the size of the test is not very\nsigni\ufb01cant and does not allow for demonstrating the generalization of the algorithm in the\ncase of HAR in smart homes.\n7.2.4. Multi-Day Segment\nAminikhanghahi et al. [ 34] propose a validation method called Multi-Day Segment.\nThis approach proposes to take into account the sequential nature of segmentation in\na context of real-time HAR. Indeed, in this real-time context, each segment or window\nis temporally correlated. According to Aminikhanghahi et al., and as expressed above,\ncross-validation would bias the results in this context. A possible solution would be to use\nthe 2/3 training and 1/3 test partitioning, as described above. However, this introduces the\nconcept of drift into the data. Drift in terms of change in resident behavior would induce a\nbig difference between the training and test set.\nTo overcome these problems, the proposed method consists of dividing the dataset\ninto 6 consecutive days. The \ufb01rst 4 days are used for training, and the last 2 days are used\nfor testing. This division into 6-day segments creates a rotation that allows for representing\nevery day of the week in the training and test set. In order to make several folds, the begin-\nning of the 6-day sequence is shifted 1 day forward at each fold. This approach allows for\nmaintaining the order of the data, while avoiding the drift of the dataset.\n7.3. Outlines\nDifferent validation methods for HAR in smart homes were reviewed in this section,\nas shown in Table 5. Depending on the problem being addressed, not all methods can be\nused to evaluate an algorithm.\nTable 5. Summary of methods for evaluating activity recognition algorithms.\nRef Train/Test SpiltK-Fold Leave-One-Out Multi-Day Respect Time Sensitive to Data Real TimeOf\ufb02ine RecognitionUsable on\nCross-Validation Cross-Validation Segment Order of Activities Drift Problem Recognition Small Datasets\n[16] ! Yes Yes Yes Yes No\n[14,15,61] ! No No No Yes No\n[41,49,51,60,78] ! Not necessarily No Yes Yes Yes\n[34] ! Yes No Yes Yes No\nIn the case of of\ufb02ine HAR, i.e., with EW or pre-segmented activity sequences, the K-\nfold cross-validation seems to be the most suitable, provided that the time dependency\nbetween segments is not taken into account. Otherwise, it is preferable to use another\nmethod. The Leave-One-Out Cross-Validation approach is an alternative. It allows for pro-\ncessing of datasets containing little data. However, the days are considered as independent.\nIt is not possible to make a link between two different days, e.g., a weekday or a weekend\nday. Aminikhanghahi et al. [34] proposed a method to preserve the temporal dependence\nof the segments and avoid the problem of data drift induced by changes in the habits of\nthe resident(s) over time.\nIn addition, the pre-processing of dataset data, the rebalancing, the removal of the\n\u201cOther\u201d class, and the annotation of events affect the algorithms\u2019 performance. It is, there-\nfore, important to take into account the evaluation method and the pre-processing per-\nformed, in order to judge the performance of the algorithm. Moreover, classic metrics,\nsuch as accuracy or F score, may not be suf\ufb01cient. It may be more judicious to use met-\nrics weighted by the number of representations if dataset classes, such as dataset, are\nunbalanced. Balanced accuracy, or F1 weighted score, should be a better metric in this\ncase [110,111].Establishing a uniform protocol according to the type of problem to be solved (real-time,\nof\ufb02ine) would speed up research in this \ufb01eld and allow a fairer comparison between the\nproposed algorithms and approaches.\n8. General Conclusion and Discussions\nIn this article, we have highlighted the challenges of Human Activity Recognition in\nsmart homes, some of which have particularities compared to other \ufb01elds of HAR. We have\nproposed a taxonomy of the main components of a human activity recognition algorithm\nand reviewed the most promising solutions. To overcome the current issues, we point out\nthe opportunities provided by new advances from other \ufb01elds.\n8.1. Comparison with Other HAR\nWhile human activity recognition algorithms have seen tremendous improvements for\nvision-based data owing to the rapid development of deep learning for image processing,\nhuman activity recognition using wearables and sensors on objects are also seeing signi\ufb01-\ncant improvements. However, vision-based systems are seen by users as too intrusive as\nthese systems could unveil too much private information, whereas wearables and sensors\non objects require the daily instrumentation of the sensors on the body of subjects or their\npersonal objects, and ambient sensors could provide a solution to tackle this issue.\nHAR in smart homes have seen recent advances owing to the development of recent\ndeep learning algorithms for end-to-end classi\ufb01cation, such as convolutional neural net-\nworks. It also bene\ufb01ts from recent algorithms for sequence learning, such as long-short term\nmemory, but, as with video processing, sequence learning still needs to be improved to both\nbe able to deal with the vanishing gradient problem and to take into account the context\nof the sensor readings. The temporal dimension is incidentally a particularity of ambient\nsensor systems, as the data for a sparse and irregular time series. The irregular sampling\nin time has also been tackled with adapted windowing methods for data segmentation.\nIn addition to the time windows used in other HAR \ufb01elds, sensor event windows are\nalso commonly used. The sparsity of the data of ambient sensors does not allow machine\nlearning algorithms to take advantage of the redundancy of data over time, as in the case\nof videos where successive video frames are mostly similar. Moreover, whereas HAR in\nvideos, the context of the human action can be seen in the images by the detection of his\nenvironment or objects of attention, the sparsity of the HAR in ambient sensors results in a\nhigh reliance in the past information to infer the context information.\nWhile HAR in ambient sensors have to face the problems of complex activities, such\nas sequences of activities, concurrent activities, or multi-occupant activities, or data drift,\nit also has to tackle speci\ufb01c unsolved problems, such as the variability of data. Indeed,\nthe data collected by sensors are even more sensitive to the house con\ufb01guration, the choice\nof sensors, and their localization.\n8.2. Taxonomy and Challenges\nTo face its speci\ufb01c challenges and the challenges common to other systems, in our\nreview, we introduced a taxonomy of the main components of a human activity recognition\nalgorithm for real-use. The three components we have pointed out are: classi\ufb01cation,\nautomatic feature extraction, and time series analysis. It needs to carry out a pattern\nrecognition from raw data, thus requiring feature extraction. Moreover, the algorithm must\nintegrate a time series analysis.\nWhile pattern recognition analysis and the feature extraction challenges seem to be\nwell tackled by deep learning algorithms, such as CNN, the sequence analysis parts have\nimproved recently with the application of LSTM. Both approaches based on CNN and LSTM\nare reported to give equivalent performance levels, and state-of-the-art developments are\nmostly based on either LSTM or convolutional deep learning. However, the sequence analysis\nchallenges still remain largely unsolved because of the impact of the sparsity and irregularitychallenges of composite activities (sequences of activities), concurrent activities, multi-user\nactivities recognition, and data drift more difficult. The sparsity of the data also makes it more\ndifficult to cope with the variability of the smart home data in its various settings.\nAccording to our analysis, the state-of-the-art options in HAR for ambient sensors are\nstill far from ready to be deployed in real-use cases. To achieve this, the field must address\nthe shortcomings of datasets, as well as needs to also standardize the evaluation metrics\nso as to reflect the requirements for a real-use deployment and to enable fair comparison\nbetween algorithms.\n8.3. Opportunities\nMoreover, we believe that recent advances in machine learning from other \ufb01elds also\noffer opportunities for signi\ufb01cant advances in HAR in smart homes.\nWe advocate that the application of recent NLP techniques can bring advances in\nsolving some of these challenges. Indeed, NLP also deploys methods of sequence analysis\nand has also seen tremendous advances in the recent years. For instance, sparsity of the\ndata can be alleviated by a better domain knowledge in the form of an emerging semantic.\nThus, taking inspiration from word encoding and language models, we can automatically\nintroduce semantic knowledge between activities, as shown in the preliminary study of\nReference [ 46]. Furthermore, a semantic encoding of the data will also help the system be\nmore robust to unknown data as in the challenges of data drift or adaptation to changes,\nas it could be able to relate new data semantically to known data. Besides, the recent\ntechniques for analyzing long texts by inferring long-term context, but also analyzing the\nsequences of words and sentences, can serve as an inspiration to analyze sequences of\nactivities or composite activities.\nLastly, we think that the unsolved problem of adaptation to changes of habits, users,\nor sensor sets could soon \ufb01nd its solution in the current research on meta learning and\ninteractive learning.\n8.4. Discussion\nIn this review, we have pointed out the key elements for an efficient algorithm of human\nactivity recognition in smart homes. We have also pointed out the most efficient methods, in\naddition to the remaining challenges and present opportunities. However, the full deployment\nof smart home services, beyond the HAR algorithms, depends also on the development of the\nhardware systems and the acceptability and usability of these systems by final users.\nFor the hardware systems, the development of IoT devices with the improvement in\nthe accuracy and autonomy, along with the decrease in their cost, will make them accessible\nto normal households. Despite cheaper sensors and actuators, it will not be realistic to\nprovide all homes with a large set of sensors as in the current datasets, but real homes are\nnot as lavishly equipped. Thus, a smart home system needs to optimize their hardware\nunder constraints of budget, house con\ufb01guration, number of inhabitants, etc. Smart home\nbuilder companies need to provide an adequate HAR hardware kit. To determine the\nminimal set of sensors, recently, Bolleddula et al. [ 112] used PCA to determine the most\nimportant sensors in a lavishly equipped smart home. This study is a \ufb01rst work to imagine\na minimal sensors setup.\nFinally , while IoT devices seem to be better accepted by users than cameras, there are still\nsocial barriers to the adoption of smart homes that need to be overcome [ 113]. These require a\ntrustworthy privacy-preserving data management, as well as reliable cyber-secure systems.\nAuthor Contributions: D.B. performed the literature reading, algorithm coding and measurements.\nS.M.N. provided guidance, structuring and proofreading of the article. C.L., I.K. and B.L. pro-\nvided guidance and proofreading. All authors have read and agreed to the published version of\nthe manuscript.\nFunding: This research received no external funding.Metropole, the region of Brittany and the European Regional Development Fund (ERDF). This work\nwas carried out within the context of a CIFRE agreement with the company Delta Dore in Bonemain\n35270 France, managed by the National Association of Technical Research (ANRT) in France.\nCon\ufb02icts of Interest: The authors declare no con\ufb02ict of interest.\nReferences\n1. Chan, M.; Est\u00e8ve, D.; Escriba, C.; Campo, E. A review of smart homes\u2014Present state and future challenges. Comput. Methods\nPrograms Biomed. 2008 ,91, 55\u201381. [CrossRef]\n2. Hussain, Z.; Sheng, M.; Zhang, W.E. Different Approaches for Human Activity Recognition: A Survey. arXiv 2019 ,\narXiv:1906.05074.\n3. Dang, L.M.; Min, K.; Wang, H.; Piran, M.J.; Lee, C.H.; Moon, H. Sensor-based and vision-based human activity recognition: A\ncomprehensive survey. Pattern Recognit. 2020 ,108, 107561. [CrossRef]\n4. Beddiar, D.R.; Nini, B.; Sabokrou, M.; Hadid, A. Vision-based human activity recognition: A survey. Multimed. Tools Appl. 2020 ,\n79, 30509\u201330555. [CrossRef]\n5. Singh, D.; Psychoula, I.; Kropf, J.; Hanke, S.; Holzinger, A. Users\u2019 perceptions and attitudes towards smart home technologies. In\nInternational Conference on Smart Homes and Health Telematics ; Springer: Berlin/Heidelberg, Germany, 2018; pp. 203\u2013214.\n6. Ord\u00f3\u00f1ez, F.J.; Roggen, D. Deep convolutional and lstm recurrent neural networks for multimodal wearable activity recognition.\nSensors 2016 ,16, 115. [CrossRef] [PubMed]\n7. Li, X.; Zhang, Y.; Marsic, I.; Sarcevic, A.; Burd, R.S. Deep learning for r\ufb01d-based activity recognition. In Proceedings of the 14th\nACM Conference on Embedded Network Sensor Systems CD-ROM, Stanford, CA, USA, 14\u201316 November 2016; pp. 164\u2013175.\n8. Gomes, L.; Sousa, F.; Vale, Z. An intelligent smart plug with shared knowledge capabilities. Sensors 2018 ,18, 3961. [CrossRef]\n[PubMed]\n9. Chen, L.; Hoey, J.; Nugent, C.D.; Cook, D.J.; Yu, Z. Sensor-based activity recognition. IEEE Trans. Syst. Man Cybern. Part C (Appl.\nRev.) 2012 ,42, 790\u2013808. [CrossRef]\n10. Aggarwal, J.; Xi, L. Human activity recognition from 3d data: A review. Pattern Recognit. Lett. 2014 ,48, 70\u201380. [CrossRef]\n11. Vrigkas, M.; Nikou, C.; Kakadiaris, I.A. A review of human activity recognition methods. Front. Robot. AI 2015 ,2, 28. [CrossRef]\n12. Wang, J.; Chen, Y.; Hao, S.; Peng, X.; Hu, L. Deep learning for sensor-based activity recognition: A survey. Pattern Recognit. Lett.\n2019 ,119, 3\u201311. [CrossRef]\n13. Chen, K.; Zhang, D.; Yao, L.; Guo, B.; Yu, Z.; Liu, Y. Deep learning for sensor-based human activity recognition: Overview,\nchallenges and opportunities. arXiv 2020 , arXiv:2001.07416.\n14. Liciotti, D.; Bernardini, M.; Romeo, L.; Frontoni, E. A Sequential Deep Learning Application for Recognising Human Activities in\nSmart Homes. Neurocomputing 2020 ,396, 501\u2013513. [CrossRef]\n15. Gochoo, M.; Tan, T.H.; Liu, S.H.; Jean, F.R.; Alnajjar, F.S.; Huang, S.C. Unobtrusive activity recognition of elderly people living\nalone using anonymous binary sensors and DCNN. IEEE J. Biomed. Health Inform. 2018 ,23, 693\u2013702. [CrossRef] [PubMed]\n16. Yan, S.; Lin, K.J.; Zheng, X.; Zhang, W. Using latent knowledge to improve real-time activity recognition for smart IoT. IEEE\nTrans. Knowl. Data Eng. 2020 ,32, 574\u2013587. [CrossRef]\n17. Perkowitz, M.; Philipose, M.; Fishkin, K.; Patterson, D.J. Mining models of human activities from the web. In Proceedings of the\n13th International Conference on World Wide Web, New York, NY, USA, 17\u201320 May 2004; pp. 573\u2013582.\n18. Chen, L.; Nugent, C.D.; Mulvenna, M.; Finlay, D.; Hong, X.; Poland, M. A logical framework for behaviour reasoning and\nassistance in a smart home. Int. J. Assist. Robot. Mechatron. 2008 ,9, 20\u201334.\n19. Chen, L.; Nugent, C.D. Human Activity Recognition and Behaviour Analysis ; Springer: Berlin/Heidelberg, Germany, 2019.\n20. Yamada, N.; Sakamoto, K.; Kunito, G.; Isoda, Y.; Yamazaki, K.; Tanaka, S. Applying ontology and probabilistic model to human\nactivity recognition from surrounding things. IPSJ Digit. Cour. 2007 ,3, 506\u2013517. [CrossRef]\n21. Chen, L.; Nugent, C.; Mulvenna, M.; Finlay, D.; Hong, X. Semantic smart homes: Towards knowledge rich assisted living\nenvironments. In Intelligent Patient Management ; Springer: Berlin/Heidelberg, Germany, 2009; pp. 279\u2013296.\n22. Chen, L.; Nugent, C. Ontology-based activity recognition in intelligent pervasive environments. Int. J. Web Inf. Syst. 2009 ,5, 410\u2013430.\n[CrossRef]\n23. Chen, L.; Nugent, C.D.; Wang, H. A knowledge-driven approach to activity recognition in smart homes. IEEE Trans. Knowl. Data\nEng. 2011 ,24, 961\u2013974. [CrossRef]\n24. Logan, B.; Healey, J.; Philipose, M.; Tapia, E.M.; Intille, S. A long-term evaluation of sensing modalities for activity recognition. In\nProceedings of the International Conference on Ubiquitous Computing, Innsbruck, Austria, 16\u201319 September 2007; Springer:\nBerlin/Heidelberg, Germany, 2007; pp. 483\u2013500.\n25. Vail, D.L.; Veloso, M.M.; Lafferty, J.D. Conditional random \ufb01elds for activity recognition. In Proceedings of the 6th International\nJoint Conference on Autonomous Agents and Multiagent Systems, Honolulu, HI, USA, 14\u201318 May 2007; pp. 1\u20138.\n26. Fleury, A.; Vacher, M.; Noury, N. SVM-based multimodal classi\ufb01cation of activities of daily living in health smart homes: Sensors,\nalgorithms, and \ufb01rst experimental results. IEEE Trans. Inf. Technol. Biomed. 2009 ,14, 274\u2013283. [CrossRef]\n27. Brdiczka, O.; Crowley, J.L.; Reignier, P . Learning situation models in a smart home. IEEE Trans. Syst. Man Cybern. Part B (Cybern.)\n2008 ,39, 56\u201363. [CrossRef]Conference on Intelligent Environments, Ulm, Germany, 24\u201325 September 2007; pp. 209\u2013212.\n29. Cook, D.J. Learning setting-generalized activity models for smart spaces. IEEE Intell. Syst. 2010 ,2010 , 1. [CrossRef]\n30. Sedky, M.; Howard, C.; Alshammari, T.; Alshammari, N. Evaluating machine learning techniques for activity classi\ufb01cation in\nsmart home environments. Int. J. Inf. Syst. Comput. Sci. 2018 ,12, 48\u201354.\n31. Chinellato, E.; Hogg, D.C.; Cohn, A.G. Feature space analysis for human activity recognition in smart environments. In Proceedings\nof the 2016 12th International Conference on Intelligent Environments (IE), London, UK, 14\u201316 September 2016; pp. 194\u2013197.\n32. Cook, D.J.; Krishnan, N.C.; Rashidi, P . Activity discovery and activity recognition: A new partnership. IEEE Trans. Cybern. 2013 ,\n43, 820\u2013828. [CrossRef] [PubMed]\n33. Yala, N.; Fergani, B.; Fleury, A. Feature extraction for human activity recognition on streaming data. In Proceedings of the 2015\nInternational Symposium on Innovations in Intelligent SysTems and Applications (INISTA), Madrid, Spain, 2\u20134 September 2015;\npp. 1\u20136.\n34. Aminikhanghahi, S.; Cook, D.J. Enhancing activity recognition using CPD-based activity segmentation. Pervasive Mob. Comput.\n2019 ,53, 75\u201389. [CrossRef]\n35. Pouyanfar, S.; Sadiq, S.; Yan, Y.; Tian, H.; Tao, Y.; Reyes, M.P .; Shyu, M.L.; Chen, S.C.; Iyengar, S. A survey on deep learning:\nAlgorithms, techniques, and applications. ACM Comput. Surv. (CSUR) 2018 ,51, 1\u201336. [CrossRef]\n36. Fang, H.; He, L.; Si, H.; Liu, P .; Xie, X. Human activity recognition based on feature selection in smart home using back-propagation\nalgorithm. ISA Trans. 2014 ,53, 1629\u20131638. [CrossRef] [PubMed]\n37. Irvine, N.; Nugent, C.; Zhang, S.; Wang, H.; Ng, W.W. Neural network ensembles for sensor-based human activity recognition\nwithin smart environments. Sensors 2020 ,20, 216. [CrossRef]\n38. Tan, T.H.; Gochoo, M.; Huang, S.C.; Liu, Y.H.; Liu, S.H.; Huang, Y.F. Multi-resident activity recognition in a smart home using\nRGB activity image and DCNN. IEEE Sens. J. 2018 ,18, 9718\u20139727. [CrossRef]\n39. Mohmed, G.; Lot\ufb01, A.; Pourabdollah, A. Employing a deep convolutional neural network for human activity recognition based\non binary ambient sensor data. In Proceedings of the 13th ACM International Conference on PErvasive Technologies Related to\nAssistive Environments, Corfu, Greece, 30 June\u20133 July 2020; pp. 1\u20137.\n40. Krizhevsky, A.; Sutskever, I.; Hinton, G.E. Imagenet classi\ufb01cation with deep convolutional neural networks. Adv. Neural Inf.\nProcess. Syst. 2012 ,25, 1097\u20131105. [CrossRef]\n41. Singh, D.; Merdivan, E.; Hanke, S.; Kropf, J.; Geist, M.; Holzinger, A. Convolutional and recurrent neural networks for activity\nrecognition in smart environment. In Towards Integrative Machine Learning and Knowledge Extraction ; Springer: Berlin/Heidelberg,\nGermany, 2017; pp. 194\u2013205.\n42. Wang, A.; Chen, G.; Shang, C.; Zhang, M.; Liu, L. Human activity recognition in a smart home environment with stacked\ndenoising autoencoders. In Proceedings of the International Conference on Web-Age Information Management, Nanchang,\nChina, 3\u20135 June 2016; Springer: Berlin/Heidelberg, Germany, 2016; pp. 29\u201340.\n43. van Kasteren, T.L.; Englebienne, G.; Kr\u00f6se, B.J. Human activity recognition from wireless sensor network data: Benchmark and\nsoftware. In Activity Recognition in Pervasive Intelligent Environments ; Springer: Berlin/Heidelberg, Germany, 2011; pp. 165\u2013186.\n44. Ghods, A.; Cook, D.J. Activity2vec: Learning adl embeddings from sensor data with a sequence-to-sequence model. arXiv 2019 ,\narXiv:1907.05597.\n45. Sutskever, I.; Vinyals, O.; Le, Q.V . Sequence to sequence learning with neural networks. In Advances in Neural Information\nProcessing Systems ; MIT Press: Cambridge, MA, USA, 2014 ; pp. 3104\u20133112.\n46. Bouchabou, D.; Nguyen, S.M.; Lohr, C.; Kanellos, I.; Leduc, B. Fully Convolutional Network Bootstrapped by Word Encoding\nand Embedding for Activity Recognition in Smart Homes. In Proceedings of the IJCAI 2020 Workshop on Deep Learning for\nHuman Activity Recognition, Yokohama, Japan, 8 January 2021.\n47. Quigley, B.; Donnelly, M.; Moore, G.; Galway, L. A Comparative Analysis of Windowing Approaches in Dense Sensing\nEnvironments. Proceedings 2018 ,2, 1245. [CrossRef]\n48. van Kasteren, T.L.M. Activity Recognition for Health Monitoring Elderly Using Temporal Probabilistic Models. Ph.D. Thesis,\nUniversiteit van Amsterdam, Amsterdam, The Netherlands, 2011.\n49. Medina-Quero, J.; Zhang, S.; Nugent, C.; Espinilla, M. Ensemble classi\ufb01er of long short-term memory with fuzzy temporal\nwindows on binary sensors for activity recognition. Expert Syst. Appl. 2018 ,114, 441\u2013453. [CrossRef]\n50. Hamad, R.A.; Hidalgo, A.S.; Bouguelia, M.R.; Estevez, M.E.; Quero, J.M. Ef\ufb01cient activity recognition in smart homes using\ndelayed fuzzy temporal windows on binary sensors. IEEE J. Biomed. Health Inform. 2019 ,24, 387\u2013395. [CrossRef] [PubMed]\n51. Hamad, R.A.; Yang, L.; Woo, W.L.; Wei, B. Joint learning of temporal models to handle imbalanced data for human activity\nrecognition. Appl. Sci. 2020 ,10, 5293. [CrossRef]\n52. Hamad, R.A.; Kimura, M.; Yang, L.; Woo, W.L.; Wei, B. Dilated causal convolution with multi-head self attention for sensor\nhuman activity recognition. Neural Comput. Appl. 2021 , 1\u201318.\n53. Krishnan, N.C.; Cook, D.J. Activity recognition on streaming sensor data. Pervasive Mob. Comput. 2014 ,10, 138\u2013154. [CrossRef]\n[PubMed]\n54. Al Machot, F.; Mayr, H.C.; Ranasinghe, S. A windowing approach for activity recognition in sensor data streams. In Proceedings\nof the 2016 Eighth International Conference on Ubiquitous and Future Networks (ICUFN), Vienna, Austria, 5\u20138 July 2016;\npp. 951\u2013953.56. Philipose, M.; Fishkin, K.P .; Perkowitz, M.; Patterson, D.J.; Fox, D.; Kautz, H.; Hahnel, D. Inferring activities from interactions\nwith objects. IEEE Pervasive Comput. 2004 ,3, 50\u201357. [CrossRef]\n57. Bengio, Y.; Simard, P .; Frasconi, P . Learning long-term dependencies with gradient descent is dif\ufb01cult. IEEE Trans. Neural Netw.\n1994 ,5, 157\u2013166. [CrossRef]\n58. Hochreiter, S.; Schmidhuber, J. Long short-term memory. Neural Comput. 1997 ,9, 1735\u20131780. [CrossRef]\n59. Cho, K.; Van Merri\u00ebnboer, B.; Gulcehre, C.; Bahdanau, D.; Bougares, F.; Schwenk, H.; Bengio, Y. Learning phrase representations\nusing RNN encoder-decoder for statistical machine translation. arXiv 2014 , arXiv:1406.1078.\n60. Singh, D.; Merdivan, E.; Psychoula, I.; Kropf, J.; Hanke, S.; Geist, M.; Holzinger, A. Human activity recognition using recurrent\nneural networks. In Proceedings of the International Cross-Domain Conference for Machine Learning and Knowledge Extraction,\nReggio, Italy, 29 August\u20131 September 2017; Springer: Berlin/Heidelberg, Germany, 2017; pp. 267\u2013274.\n61. Park, J.; Jang, K.; Yang, S.B. Deep neural networks for activity recognition with multi-sensor data in a smart home. In Proceedings\nof the 2018 IEEE 4th World Forum on Internet of Things (WF-IoT), Singapore, 5\u20138 February 2018; pp. 155\u2013160.\n62. Hong, X.; Nugent, C.; Mulvenna, M.; McClean, S.; Scotney, B.; Devlin, S. Evidential fusion of sensor data for activity recognition\nin smart homes. Pervasive Mob. Comput. 2009 ,5, 236\u2013252. doi: 10.1016/j.pmcj.2008.05.002. [CrossRef]\n63. Asghari, P .; Soelimani, E.; Nazerfard, E. Online Human Activity Recognition Employing Hierarchical Hidden Markov Models.\narXiv 2019 , arXiv:1903.04820.\n64. Devanne, M.; Papadakis, P .; Nguyen, S.M. Recognition of Activities of Daily Living via Hierarchical Long-Short Term Memory\nNetworks. In Proceedings of the International Conference on Systems Man and Cybernetics, Bari, Italy, 6\u20139 October 2019;\npp. 3318\u20133324. [CrossRef]\n65. Wang, L.; Liu, R. Human Activity Recognition Based on Wearable Sensor Using Hierarchical Deep LSTM Networks. Circuits Syst.\nSignal Process. 2020 ,39, 837\u2013856. [CrossRef]\n66. Tayyub, J.; Hawasly, M.; Hogg, D.C.; Cohn, A.G. Learning Hierarchical Models of Complex Daily Activities from Annotated\nVideos. In Proceedings of the IEEE Winter Conference on Applications of Computer Vision, Lake Tahoe, NV , USA, 12\u201315 March\n2018; pp. 1633\u20131641.\n67. Peters, M.E.; Neumann, M.; Iyyer, M.; Gardner, M.; Clark, C.; Lee, K.; Zettlemoyer, L. Deep contextualized word representations.\narXiv 2018 , arXiv:1802.05365.\n68. Devlin, J.; Chang, M.W.; Lee, K.; Toutanova, K. Bert: Pre-training of deep bidirectional transformers for language understanding.\narXiv 2018 , arXiv:1810.04805.\n69. Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones, L.; Gomez, A.N.; Kaiser, L.; Polosukhin, I. Attention is all you need.\narXiv 2017 , arXiv:1706.03762.\n70. Safyan, M.; Qayyum, Z.U.; Sarwar, S.; Garc\u00eda-Castro, R.; Ahmed, M. Ontology-driven semantic uni\ufb01ed modelling for concurrent\nactivity recognition (OSCAR). Multimed. Tools Appl. 2019 ,78, 2073\u20132104. [CrossRef]\n71. Li, X.; Zhang, Y.; Zhang, J.; Chen, S.; Marsic, I.; Farneth, R.A.; Burd, R.S. Concurrent activity recognition with multimodal\nCNN-LSTM structure. arXiv 2017 , arXiv:1702.01638.\n72. Alhamoud, A.; Muradi, V .; B\u00f6hnstedt, D.; Steinmetz, R. Activity recognition in multi-user environments using techniques of\nmulti-label classi\ufb01cation. In Proceedings of the 6th International Conference on the Internet of Things, Stuttgart, Germany,\n7\u20139 November 2016; pp. 15\u201323.\n73. Tran, S.N.; Zhang, Q.; Smallbon, V .; Karunanithi, M. Multi-resident activity monitoring in smart homes: A case study. In\nProceedings of the 2018 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom\nWorkshops), Athens, Greece, 19\u201323 March 2018; pp. 698\u2013703.\n74. Natani, A.; Sharma, A.; Perumal, T. Sequential neural networks for multi-resident activity recognition in ambient sensing smart\nhomes. Appl. Intell. 2021 ,51, 6014\u20136028. [CrossRef]\n75. Cook, D.J.; Crandall, A.S.; Thomas, B.L.; Krishnan, N.C. CASAS: A smart home in a box. Computer 2012 ,46, 62\u201369. [CrossRef]\n[PubMed]\n76. Tapia, E.M.; Intille, S.S.; Larson, K. Activity recognition in the home using simple and ubiquitous sensors. In Proceedings of the\nInternational Conference on Pervasive Computing, Linz and Vienna, Austria, 21\u201323 April 2004; Springer: Berlin/Heidelberg,\nGermany, 2004; pp. 158\u2013175.\n77. Ord\u00f3\u00f1ez, F.; De Toledo, P .; Sanchis, A. Activity recognition using hybrid generative/discriminative models on home environments\nusing binary sensors. Sensors 2013 ,13, 5460\u20135477. [CrossRef] [PubMed]\n78. Wang, A.; Zhao, S.; Zheng, C.; Yang, J.; Chen, G.; Chang, C.Y. Activities of Daily Living Recognition With Binary Environment\nSensors Using Deep Learning: A Comparative Study. IEEE Sens. J. 2020 ,21, 5423\u20135433. [CrossRef]\n79. Long, J.; Shelhamer, E.; Darrell, T. Fully convolutional networks for semantic segmentation. In Proceedings of the IEEE\nConference on Computer Vision and Pattern Recognition, Boston, MA, USA, 7\u201312 June 2015; pp. 3431\u20133440.\n80. Ronneberger, O.; Fischer, P .; Brox, T. U-net: Convolutional networks for biomedical image segmentation. In Proceedings of the\nInternational Conference on Medical Image Computing and Computer-Assisted Intervention, Munich, Germany, 5\u20139 October\n2015; Springer: Berlin/Heidelberg, Germany, 2015; pp. 234\u2013241.\n81. Perslev, M.; Jensen, M.H.; Darkner, S.; Jennum, P .J.; Igel, C. U-time: A fully convolutional network for time series segmentation\napplied to sleep staging. arXiv 2019 , arXiv:1910.11162. ; Springer US: Boston, MA, USA, 1998.\n84. Parisi, G.I.; Kemker, R.; Part, J.L.; Kanan, C.; Wermter, S. Continual lifelong learning with neural networks: A review. Neural\nNetw. 2019 ,113, 54\u201371. [CrossRef]\n85. Duminy, N.; Nguyen, S.M.; Zhu, J.; Duhaut, D.; Kerdreux, J. Intrinsically Motivated Open-Ended Multi-Task Learning Using\nTransfer Learning to Discover Task Hierarchy. Appl. Sci. 2021 ,11, 975. [CrossRef]\n86. Weiss, K.; Khoshgoftaar, T.M.; Wang, D. A survey of transfer learning. J. Big Data 2016 ,3, 9. [CrossRef]\n87. Fawaz, H.I.; Forestier, G.; Weber, J.; Idoumghar, L.; Muller, P .A. Transfer learning for time series classi\ufb01cation. In Proceedings of\nthe 2018 IEEE International Conference on Big Data (Big Data), Seattle, WA, USA, 10\u201313 December 2018; pp. 1367\u20131376.\n88. Cook, D.; Feuz, K.; Krishnan, N. Transfer Learning for Activity Recognition: A Survey. Knowl. Inf. Syst. 2013 ,36, 537\u2013556.\n[CrossRef] [PubMed]\n89. Hospedales, T.; Antoniou, A.; Micaelli, P .; Storkey, A. Meta-Learning in Neural Networks: A Survey. arXiv 2020 , arXiv:2004.05439.\n90. Gjoreski, H.; Kozina, S.; Gams, M.; Lustrek, M.; \u00c1lvarez-Garc\u00eda, J.A.; Hong, J.H.; Ramos, J.; Dey, A.K.; Bocca, M.; Patwari, N.\nCompetitive live evaluations of activity-recognition systems. IEEE Pervasive Comput. 2015 ,14, 70\u201377. [CrossRef]\n91. Espinilla, M.; Medina, J.; Nugent, C. UCAmI Cup. Analyzing the UJA Human Activity Recognition Dataset of Activities of Daily\nLiving. Proceedings 2018 ,2, 1267. [CrossRef]\n92. Alemdar, H.; Ertan, H.; Incel, O.D.; Ersoy, C. ARAS human activity datasets in multiple homes with multiple residents. In\nProceedings of the 2013 7th International Conference on Pervasive Computing Technologies for Healthcare and Workshops,\nVenice, Italy, 5\u20138 May 2013; pp. 232\u2013235.\n93. Cumin, J.; Lefebvre, G.; Ramparany, F.; Crowley, J.L. A dataset of routine daily activities in an instrumented home. In Proceedings\nof the International Conference on Ubiquitous Computing and Ambient Intelligence, Philadelphia, PA, USA, 7\u201310 November\n2017; Springer: Berlin/Heidelberg, Germany, 2017; pp. 413\u2013425.\n94. De-La-Hoz-Franco, E.; Ariza-Colpas, P .; Quero, J.M.; Espinilla, M. Sensor-based datasets for human activity recognition\u2014A\nsystematic review of literature. IEEE Access 2018 ,6, 59192\u201359210. [CrossRef]\n95. Helal, S.; Kim, E.; Hossain, S. Scalable approaches to activity recognition research. In Proceedings of the 8th International\nConference Pervasive Workshop, Mannheim, Germany, 29 March\u20132 April 2010; pp. 450\u2013453.\n96. Helal, S.; Lee, J.W.; Hossain, S.; Kim, E.; Hagras, H.; Cook, D. Persim-Simulator for human activities in pervasive spaces.\nIn Proceedings of the 2011 Seventh International Conference on Intelligent Environments, Nottingham, UK, 25\u201328 July 2011;\npp. 192\u2013199.\n97. Mendez-Vazquez, A.; Helal, A.; Cook, D. Simulating events to generate synthetic data for pervasive spaces. In Workshop\non Developing Shared Home Behavior Datasets to Advance HCI and Ubiquitous Computing Research . 2009. Available online: https:\n//dl.acm.org/doi/abs/10.1145/1520340.1520735 (accessed on 2 July 2021).\n98. Armac, I.; Retkowitz, D. Simulation of smart environments. In Proceedings of the IEEE International Conference on Pervasive\nServices, Istanbul, Turkey, 15\u201320 July 2007; pp. 257\u2013266.\n99. Fu, Q.; Li, P .; Chen, C.; Qi, L.; Lu, Y.; Yu, C. A con\ufb01gurable context-aware simulator for smart home systems. In Proceedings of\nthe 2011 6th International Conference on Pervasive Computing and Applications, Port Elizabeth, South Africa, 26\u201328 October\n2011; pp. 39\u201344.\n100. Alshammari, N.; Alshammari, T.; Sedky, M.; Champion, J.; Bauer, C. Openshs: Open smart home simulator. Sensors 2017 ,17, 1003.\n[CrossRef] [PubMed]\n101. Lee, J.W.; Cho, S.; Liu, S.; Cho, K.; Helal, S. Persim 3d: Context-driven simulation and modeling of human activities in smart\nspaces. IEEE Trans. Autom. Sci. Eng. 2015 ,12, 1243\u20131256. [CrossRef]\n102. Synnott, J.; Chen, L.; Nugent, C.D.; Moore, G. The creation of simulated activity datasets using a graphical intelligent environment\nsimulation tool. In Proceedings of the 2014 36th Annual International Conference of the IEEE Engineering in Medicine and\nBiology Society, Chicago, IL, USA, 26\u201330 August 2014; pp. 4143\u20134146.\n103. Synnott, J.; Nugent, C.; Jeffers, P . Simulation of smart home activity datasets. Sensors 2015 ,15, 14162\u201314179. [CrossRef]\n104. Richter, S.R.; Vineet, V .; Roth, S.; Koltun, V . Playing for data: Ground truth from computer games. In Proceedings of the European\nConference on Computer Vision, Amsterdam, The Netherlands, 8\u201316 October 2016; Springer: Berlin/Heidelberg, Germany, 2016;\npp. 102\u2013118.\n105. Richter, S.R.; Hayder, Z.; Koltun, V . Playing for benchmarks. In Proceedings of the IEEE International Conference on Computer\nVision, Venice, Italy, 22\u201329 October 2017; pp. 2213\u20132222.\n106. Roitberg, A.; Schneider, D.; Djamal, A.; Seibold, C.; Rei\u00df, S.; Stiefelhagen, R. Let\u2019s Play for Action: Recognizing Activities of Daily\nLiving by Learning from Life Simulation Video Games. arXiv 2021 , arXiv:2107.05617.\n107. Das, S.; Dai, R.; Koperski, M.; Minciullo, L.; Garattoni, L.; Bremond, F.; Francesca, G. Toyota smarthome: Real-world activities\nof daily living. In Proceedings of the IEEE/CVF International Conference on Computer Vision, Seoul, Korea, 27 October\u2013\n2 November 2019; pp. 833\u2013842.\n108. Katz, S. Assessing self-maintenance: Activities of daily living, mobility, and instrumental activities of daily living. J. Am. Geriatr.\nSoc. 1983 ,31, 721\u2013727. [CrossRef] [PubMed]\n109. Sokolova, M.; Lapalme, G. A systematic analysis of performance measures for classi\ufb01cation tasks. Inf. Process. Manag. 2009 ,\n45, 427\u2013437. [CrossRef]Berlin/Heidelberg, Germany, 2018; Volume 10.\n111. He, H.; Ma, Y. Imbalanced Learning: Foundations, Algorithms, and Applications ; University of Rhode Island: Kingston, RI, USA, 2013.\n112. Bolleddula, N.; Hung, G.Y.C.; Ma, D.; Noorian, H.; Woodbridge, D.M.k. Sensor Selection for Activity Classi\ufb01cation at Smart\nHome Environments. In Proceedings of the 2020 42nd Annual International Conference of the IEEE Engineering in Medicine &\nBiology Society (EMBC), Montreal, QC, Canada, 20\u201324 July 2020; pp. 3927\u20133930.\n113. Balta-Ozkan, N.; Davidson, R.; Bicket, M.; Whitmarsh, L. Social barriers to the adoption of smart homes. Energy Policy 2013 ,\n63, 363\u2013374. [CrossRef]", "arxiv75": "\nAdaptive R-Peak Detection on Wearable ECG\nSensors for High-Intensity Exercise\nElisabetta De Giovanni\n , Tomas Teijeiro\n , Gr\u00b4egoire P . Millet\n , and David Atienza\n ,Fellow, IEEE\nAbstract \u2014Objective: Continuous monitoring of biosig-\nnals via wearable sensors has quickly expanded in the\nmedical and wellness \ufb01elds. At rest, automatic detection of\nvital parameters is generally accurate. However, in condi-\ntions such as high-intensity exercise, sudden physiological\nchanges occur to the signals, compromising the robust-\nness of standard algorithms. Methods: Our method, called\nBayeSlope, is based on unsupervised learning, Bayesian\n\ufb01ltering, and non-linear normalization to enhance and cor-\nrectly detect the R peaks according to their expected po-\nsitions in the ECG. Furthermore, as BayeSlope is compu-\ntationally heavy and can drain the device battery quickly,\nwe propose an online design that adapts its robustness to\nsudden physiological changes, and its complexity to the\nheterogeneous resources of modern embedded platforms.\nThis method combines BayeSlope with a lightweight al-\ngorithm, executed in cores with different capabilities, to\nreduce the energy consumption while preserving the accu-\nracy. Results: BayeSlope achieves an F1 score of 99.3% in\nexperiments during intense cycling exercise with 20 sub-\njects. Additionally, the online adaptive process achieves an\nF1 score of 99% across \ufb01ve different exercise intensities,\nwith a total energy consumption of 1.55\u00b10.54 mJ. Conclu-\nsion: We propose a highly accurate and robust method,\nand a complete energy-ef\ufb01cient implementation in a mod-\nern ultra-low-power embedded platform to improve R peak\ndetection in challenging conditions, such as during high-\nintensity exercise. Signi\ufb01cance: The experiments show that\nBayeSlope outperforms state-of-the-art QRS detectors up\nto 8.4% in F1 score, while our online adaptive method can\nreach energy savings up to 38.7% on modern heteroge-\nneous wearable platforms.\nIndex Terms \u2014 Adaptive R Peak detection, Machine\nLearning, Edge Computing, Algorithm Robustness, Biosig-\nnal Processing, Heterogeneous Nodes, Energy-Accuracy\nTrade-Off, Ultra-Low Power Computing, Intense Exercise,\nWellness\nI. INTRODUCTION\nIn recent years, increasing healthcare costs [1] and hospital\novercrowding have pushed new technological advances to\nManuscript submitted July, 2022. This work was supported in part by\nthe Swiss NSF ML-Edge Project under Grant 200020 182009, in part by\nthe MyPreHealth Project funded by Hasler Stiftung under Grant 16073,\nand in part by the H2020 DeepHealth Project under Grant GA 825111.\nT.T. is supported by a Maria Zambrano fellowship (MAZAM21/29) from\nthe University of Basque Country and the Spanish Ministry of Universi-\nties, funded by the European Union-Next-GenerationEU.\nElisabetta De Giovanni and David Atienza are with the Embedded\nSystems Laboratory (ESL), EPFL, Lausanne, Switzerland.\nTomas Teijeiro is with the Department of Mathematics, University of the\nBasque Country (UPV/EHU), Spain.\nimprove remote wellness monitoring, and enable early inter-\nvention and prevention [2]. In addition, population aging and\nthe resulting higher incidence of noncommunicable diseases\n(NCDs) create the need for long-term health monitoring. For\nthese reasons, there is an increasing demand for applications\nworking on wearable platforms that continuously and remotely\nmonitor biosignals, such as electrocardiogram (ECG) [3] or\nphotoplethysmography (PPG), and extract relevant health pa-\nrameters from them. Furthermore, daily physical activity is\nhighly recommended [4] to prevent NCDs, and in particular\nhigh-intensity interval training (HIIT) are postulated as a good\nalternative to moderate intensity for health improvement [5].\nAs we illustrate in Section II, during intense physical\nexercise sudden physiological changes occur, such as short\nRR intervals, high breathing frequency and noise from res-\npiratory sinus arrhythmia, or sympathetic activation, amongst\nothers [6]. These changes induce artifacts or noise that are in\ngeneral not properly detected by standard algorithms, leading\nto a need for using advanced computing techniques, such\nas machine learning and online adaptivity, to improve the\nrobustness of the analysis. However, with the advancement\nof new complex algorithms comes the question of managing\nconstrained resources in wearable sensor nodes (WSNs), and\nthe consequent toll on energy consumption.\nIn fact, the implementation of complex biomedical appli-\ncations in traditional WSNs can cause a signi\ufb01cant draining\nof platform resources leading to frequent device charging [7].\nFurthermore, various algorithmic optimizations implemented\nto lower the device energy consumption can lead to a de-\ncrease in the output accuracy of the algorithm [8]. With the\nadvent of modern ultra-low power (ULP) platforms [9] and\ntheir capabilities, the trade-off between optimizing the device\nresources to lower the energy consumption and maintaining\na highly accurate output has become more attainable [10],\n[11]. Nevertheless, in the context of complex biomedical\napplications for WSN-based wellness monitoring, the designer\nhas to consider new challenges to achieve an optimal energy-\naccuracy trade-off. First, in the acquired biosignals of various\npathologies or physical conditions sudden events occur, which\ntraditional algorithms can miss or misinterpret (e.g., atrial\n\ufb01brillation (AF) or intense physical exercise) [6], [12]. For\nthis reason, their robustness is compromised and severely\naffects the reliability of the wellness progress in the long\nterm. Second, the static nature of traditional algorithms do\n-400-2000200400600800Amplitude (\u03bcV)\nR \namplitude\n(a) Rest\n-20002004006008001000Amplitude (\u03bcV)\nR amplitude1648 1649 1650 1651 1652 1653 1654\nTime (s)-20002004006008001000Amplitude (\u03bcV)RR1RR2\nR amplitude (b) Intense physical exercise\nFig. 1 : Effects of intense physical exercise on ECG, and, speci\ufb01cally, the R peak amplitudes and RR interval variability, compared to rest. The ECG segments\nare extracted from the database presented in Section IV. Speci\ufb01cally, the segment in Fig. 1a is extracted from the \ufb01rst 3 min of rest of the maximal exercise\ntest of Subject 3, starting at second nine. The segment in Fig. 1b is extracted close to exhaustion of Subject 3 during the maximal exercise test, starting at\napproximately 27 min .\nwhich has recently become a need in WSNs design. New\nmethods tackle self-aware applications at the algorithmic level\napplying a multi-layer classi\ufb01cation or detection system with\nincreasing complexity [13], [14]. Based on the con\ufb01dence of\nthe low complexity classi\ufb01ers, the algorithm decides whether\nto execute a more complex layer and, therefore, consumes\nmore energy. However, these methods are targeted to tradi-\ntional homogeneous platforms, and some do not consider the\nerror in the pathological events detection.\nFor the reasons above, in this work, we propose an online\nadaptive design of a new ECG R peak detection algorithm for\nwearable systems based on unsupervised machine learning,\nwhich exploits the capabilities and heterogeneity of modern\nULP platforms. In the proposed design, we introduce for\nthe \ufb01rst time BayeSlope, a slope-based R peak detector that\napplies a Bayesian \ufb01lter, non-linear normalization, and a\nclustering technique to an ECG segment. In the literature, the\nuse of slope-based QRS detectors has been extensive [15],\n[16]. There are examples of the use of the Kalman \ufb01lter for\nsmoothed estimation of the heart rate (HR), different than\nR peak detection, and using multiple signals [17]. However,\nmany of these works target ambulatory monitoring. Hence,\nto the best of our knowledge, this is the \ufb01rst time that an\nR peak detection like BayeSlope is applied in the context of\nintense physical exercise. In fact, we test the proposed method\nwith a dataset collected in collaboration with the Institut des\nsciences du sport de l\u2019Universit \u00b4e de Lausanne (ISSUL), where\nthe subjects performed a maximal exercise test on a cycle\nergometer till exhaustion. Our main contributions are:\n\u000fWe propose a new highly accurate slope-based R peak de-\ntection method that is speci\ufb01cally aimed at high intensity\nexercise application scenarios. Our new R peak detection\nmethod, called BayeSlope, applies a Bayesian \ufb01lter and\na non-linear normalization to the input ECG signal.\nThe combination of these signal processing techniques\nenhances and correctly detects the next R peak in the\nexpected position on a peak-to-peak resolution. During\nF1score, while being comparable during low intensity\nexercise.\n\u000fWe pair the newly proposed algorithm with the REWARD\nalgorithm, presented in [18], which is less complex\nthough more prone to error if sudden events occur. To\nensure the adaptive nature of the design, we propose an\nerror detection routine applied to REWARD that triggers\nBayeSlope if REWARD fails.\n\u000fTo apply adaptive management of resources at run time\naccording to the algorithm\u2019s complexity, we implement\nthe proposed method on an heterogeneous platform, that\nallows to run BayeSlope on a more capable core than\nthe one where REWARD runs, which is simpler. In fact,\nthe R peak detection step of REWARD is approximately\n104\u0002less complex than BayeSlope when running on\nthe same core. Hence, a simpler processor can handle\nit better, while a more powerful core handles better the\nmore complex BayeSlope.\n\u000fThe fully adaptive process has an F1score of up to\n99:0 %, comparable to always running BayeSlope, which\nachieves an F1score up to 99:3 %, across \ufb01ve different\nexercise intensities. Moreover, our proposed adaptive\nprocess is up to 17:5 % more accurate compared to\nrunning only REWARD, across the \ufb01ve exercise inten-\nsities. Finally, the adaptive method tailored for modern\nheterogeneous platforms can reach energy savings up to\n38:7 % compared to continuously executing BayeSlope.\nTherefore, the newly proposed adaptive design is the\nbest solution for an optimal energy-accuracy trade-off\nfor long-term wellness monitoring with latest wearable\nsystems.\nIn Section II, we describe what occurs during intense\nphysical exercise and the relevance of a highly accurate R\npeak detection in such conditions. In Section III, we present\nthe new R peak detection algorithm and its adaptive design.\nIn Section IV, we describe the protocol of the experiments\nand the platform used. Finally, in Section V and Section VI,\n\nTo motivate the newly proposed method for autonomous\nwellness monitoring, let us consider the sudden changes oc-\ncurring in the ECG during intense physical exercise. We will\nfocus speci\ufb01cally on the R peak, as it is the basis for ECG\nanalysis. Fig. 1 shows two segments of ECG acquired from a\nsubject performing a maximal exercise test (c.f. Section IV).\nThe segments were extracted from the initial rest condition\n(Fig. 1a) and a window of intense physical exercise, close\nto exhaustion (Fig. 1b). As shown in Fig. 1b, the peak-to-\npeak (RR) interval variability is signi\ufb01cantly low compared\nto a rest condition. Moreover, the amplitude of the R peaks\nis highly variable. Therefore, when standard algorithms are\nused to detect the peaks in these conditions, their robustness is\ncompromised. In this work, we consider one R peak detection\nalgorithm that was presented in [18], called REWARD, as the\nstandard base algorithm to build on and motivate our proposed\nonline adaptive method. REWARD can detect peaks within\na window of 1:75 s by adapting hysteresis thresholds based\non the average and maximum (or minimum if R is negative)\namplitude of the peaks within a window. This method works\nwell when the amplitude variability is limited, as shown in\nSection V-A. However, during intense physical exercise, the\nRR interval decreases signi\ufb01cantly and the amplitude highly\nvaries between one peak and the other\u2014within 1:75 s, there\nare many peaks signi\ufb01cantly different in amplitude\u2014with the\nresult that REWARD fails to detect smaller peaks. In Fig. 3,\nwe show an example of an ECG segment extracted from the\nanalyzed dataset and, speci\ufb01cally, a window where REWARD\nfails.\nTo capture the changes occurring during various intensities\nof physical exercise in the wellness context, there exists a gold\nstandard protocol where subjects perform a maximal exercise\ntest on a cycle ergometer or a treadmill till exhaustion. The\nsubjects wear a gas mask that measures the volume of O 2and\nCO2(VO 2, VCO 2) inhaled and exhaled [19]. Additionally,\nthe protocol includes the acquisition and analysis of a single-\nlead ECG, from which speci\ufb01c heart rate variability (HRV)\nparameters can be extracted to help in the estimation of\nthe so-called ventilatory thresholds (VT1, VT2) [20], and\nVO2max [21]. These three variables describe the cardiovas-\ncular and respiratory state during intense physical exercise.\nVT1 measures the hyperpnea (i.e., faster breathing) caused\nby the increased production of CO 2for exercise intensities\nabove the anaerobic threshold resulting in a non-linear increase\nin the ratio between ventilatory \ufb02ow (VE) and VO 2. VT2\nrepresents a phase where the hyperpnea is not enough to\neliminate the CO 2, which remains constant, leading to a sharp\nincrease of VE/VCO 2. Finally, VO 2max is the \ufb01nal stage\nwhere exhaustion is reached and, consequently, a maximum\noxygen uptake and HR. The determination of the ventilatory\nthresholds usually relies on an agreement between medical\nexperts who evaluate the gas analysis and the HRV parameters\nto \ufb01nd the position of the thresholds [22].\nThe HRV analysis uses the RR time series of an ECG signal\nBayeSlopeCLUSTER DOMAIN\nINTERCONNECT DMA FC C0C4L1 BANK\n0BANK\n1L2\nBANK BANK\n0 1\nBANK BANK\nN-1 N\nINTERCONNECT\nDMA INTERFACESBANK\nN-1BANK\nNREWARD\nError \nDetection\nError?Yes NoPreprocessingECG inputFig. 2 : On the left, data-\ufb02ow diagram of the adaptive R peak detection\nalgorithm with a raw ECG input. REWARD refers to the low complexity\nR peak detection presented in [18]. BayeSlope is a new slope-based R\npeak detection algorithm presented in this work. On the right, the PULP-\nbased [9] architecture used for the analysis. Preprocessing, REWARD, and\nerror detection run on the SoC domain in the fabric controller (FC), while\nBayeSlope runs on the cluster domain, in one core of the cluster (CL) of eight\ncores.\nThe current methods for this estimation are performed in\npost-processing with the help of medical experts and, usually,\nrequire interpolation and correction of the RR time series. The\nR peak detection needs to be accurate, robust and adapt at\nrun time to sudden changes to ensure the correct comparison\nbetween ventilatory measurements and the RR time series.\nTherefore, we propose BayeSlope, a new highly accurate and\nrobust R peak detection algorithm for wearable sensors, which\nis paired to REWARD. BayeSlope is much more complex\nthan REWARD, and, if run continuously, it can drain the\ndevice battery. For this reason, we additionally propose a\nreal-time strategy that automatically adapts the algorithm\u2019s\ncomplexity and the resources assigned based on the robustness\nof REWARD, for an enhanced energy-accuracy trade-off in\nlatest ultra-low power autonomous wearable systems.\nIII. A DAPTIVE R P EAK DETECTION IN MODERN\nWEARABLE SENSORS\nOne of the main problems in the context of edge com-\nputing in WSNs is minimizing energy consumption while\nmaximizing output accuracy. In this section, we describe\nour proposed method to detect R peaks from a single-lead\nECG that optimizes the energy-accuracy trade-off with a two-\nlevel adaptive method. Fig. 2 shows the data-\ufb02ow diagram\nof the full process and the architecture where the algorithm\nis implemented [9]. The two-level adaptivity consists in the\nrobustness and complexity of the two different R peak de-\ntection algorithms, namely REWARD [18] and BayeSlope.\nAs described in Section II, REWARD uses hysteresis thresh-\nolds that are adapted to each window of 1:75 s. However,\nthis window resolution is too small to capture peak-to-peak\nsudden changes. For this reason, we introduce BayeSlope that\nimplements peak normalization through a generalized logistic\nfunction and a Bayesian \ufb01lter to enhance and compute the\nexpected position of the next R peak. This expectation is the\nbasic guide for BayeSlope, and is based on the assumption\nFig. 3 : Missed peaks (in ellipses) in REWARD R peak detection using\nhysteresis thresholds (in orange and yellow) based on the ECG window\nmorphology. The segment was extracted from Subject 3 of the used dataset\n(c.f., Section IV-A).\nbeats, BayeSlope will offer no advantage over classical slope-\nbased methods. Once the peaks are normalized and enhanced,\nthe method applies a k-means clustering to divide the ECG\nsamples in two clusters represented by two centroids, one\ncorresponding to the baseline and one to the R peaks. The \ufb01rst\nlevel of adaptivity consists in adapting the robustness of the\nalgorithm, as shown in the data-\ufb02ow of Fig. 2. The output of\nREWARD is fed to an error detection method that checks when\nREWARD is probably failing to detect R peaks and, in this\ncase, triggers the more accurate and robust BayeSlope. The\nsecond level of adaptivity consists in adapting the resources\nto the complexity of the method. In fact, BayeSlope is a more\ncomplex algorithm, hence, it bene\ufb01ts from execution on the\ncluster of cores in the platform, which includes eight cores\nwith higher Instructions-Per-Cycle (IPC) and \ufb02oating point\nunits. Secondly, the main core, which is a simpler core, can\nhandle the less complex REWARD in a more energy-ef\ufb01cient\nway. In the next sections, we describe \ufb01rst the different blocks\nshown in Fig. 2. Then, the higher-level design within the\nheterogeneous platform is presented.\nA. Preprocessing, REWARD and Error Detection\nA standard R peak detection algorithm requires several steps\nof preprocessing of the ECG input signal. In this case, the\ninput is a single-lead ECG where a morphological \ufb01ltering\n(MF) is applied to remove the baseline and high frequency\nnoise [23]. Then, the signal is enhanced by applying the\nRelative-Energy (Rel-En) method, which ampli\ufb01es the most\ndominant peaks [18]. This preprocessing method is part of the\nREWARD algorithm presented in [18]. The second part of the\nalgorithm searches for the R peak in a window of 1:75 susing\nhysteresis thresholds based on the ECG morphology within\nthe window. However, during intense physical exercise, the\ninterval between two R peaks (i.e., RR interval) decreases sig-\nni\ufb01cantly and sudden changes in amplitude occur. Therefore,\nwithin a window of analysis, many peaks can be missed, as\nshown in Fig. 3. Moreover, right after exhaustion during a\nmaximal exercise test, there can be an increase of the T wave\namplitude\u2014the wave after the QRS complex that represents\nthe repolarization of the heart ventricles\u2014often signi\ufb01cantly\nmore dominant than the R peak itself, and a decrease of the\nFig. 4 : RR ratio distribution for the full dataset acquired for this analysis.\nThe shadowed grey areas represent the range of RR ratio for which an error\nis detected, while the light green area represents the range of RR ratio for\nwhich there is no error in the R peaks. Moreover, the darker grey areas and\nthe vertical lines represent the full range of percentile thresholds for all the\nsubjects in the used dataset (c.f., Section IV-A).\nhigher amplitude variability of the peaks within the window.\nHowever, it performs extremely well if these events do not\noccur as demonstrated in [18].\nFor this reason, we propose a statistical method to identify\npotential errors in the R peak detection within a window\nof1:75 s by analyzing the distribution of the ratioRR(n)\nRR(n\u00001),\nwhere n= 0;1;2:::, of all the data acquired. This distribution\nhas been computed of\ufb02ine using the results of BayeSlope,\nsince it is the most accurate (c.f., Section V). However, to\navoid data snooping, for each subject, the RR ratio distribution\nis computed with a leave-one-out (LOO) strategy, in which the\nanalyzed subject is not included in the distribution. The RR\nratio can capture sudden changes with a three-peak resolution,\nsuch as missing peaks, additional wrong peaks (e.g., T wave),\nand highly noisy signal segments. We want to underline that\nthe main objective of the error detection mechanism is to\nbalance the execution of REWARD and BayeSlope to optimize\nthe energy consumption. Thus, this mechanism has a marginal\nin\ufb02uence on the R peak detection accuracy. There is only\none situation, thoroughly explained in Section V, in which\na mistake in the error detection can lead to misdetected peaks.\nFirst, the method computes of\ufb02ine the RR intervals and the\ncorresponding RR ratio sequence used for the distribution from\nall the subjects, except the one that is being analyzed. Then, for\neach subject, if at least one value of RR ratio computed within\neach window falls in the tails of the distribution (below the\n0.5 or above the 99.5 percentiles of the RR ratio distribution,\nrespectively), the algorithm detects an error. This is performed\nin the online phase of the error detection applied to the\noutput R peaks of REWARD. Fig. 4 shows the distribution\nconsidering all the subjects analyzed in this work. We report\nthe overall distribution for convenience, but note that it is not\nthe one used in our proposed online error detection. Moreover,\nthe right tail is longer than reported on the \ufb01gure, as it is\nredundant. In fact, the percentile thresholds with the LOO\nstrategy are:\nP0:5= 0:65\u00060:02;P99:5= 1:46\u00060:06; (1)\nEven though the distributions are different, the standard de-\n\nError\nFig. 5 : Result of error detection on example ECG extracted from Subject 3 of\nthe dataset used (c.f., Section IV-A). The values of the RR ratio are computed\non a resolution of three R peaks. Considering the percentile thresholds for\nthe analyzed subject (bottom left), the method can detect an error where\nREWARD fails (in the red boxes).\nhand, the range of the distribution suggests a high intra-patient\nvariability. Considering these values of thresholds, Fig. 4\nshows shadowed areas in grey, which represent the range of\nRR ratio for which an error is detected. Moreover, this \ufb01gure\nshows a light green area that represents the range of RR ratio\nfor which no error in the R peaks exists. Finally, the darker\ngrey areas and the vertical lines represent the full range of\npercentile thresholds reported in (1). Therefore, if we consider\nthe ECG example in Fig. 3, the error detection results are\nshown in Fig. 5, where the values of the RR ratio over the\nsegment are reported. Considering the percentile thresholds\nP0:5= 0:64andP99:5= 1:47for the analyzed subject, the\nmethod can detect an error where REWARD fails. The last\npeak in Fig. 3 where there is an error would be detected in\nthe next window. It is worth mentioning that there are genuine\nphysiological events, such as ectopic heartbeats, that can cause\na variation in the RR ratio in the tails of the distribution, and\ntherefore they will be detected as \u201derrors\u201d. These events will\nlead to trigger the BayeSlope algorithm, but it does not mean\nthat they will be ignored or undetected, as long as they \ufb01t the\ndetection conditions of BayeSlope.\nB. BAYESLOPE: Adaptive Slope-Based R Peak\nDetection\nOnce an error is detected, a more accurate adaptive R\npeak detection, BayeSlope, is triggered. This newly proposed\nmethod applies a non-linear normalization of the signal and\na Bayesian \ufb01lter to enhance high slope areas which are near\nthe expected position of the next peak according to the current\nHR. These high slope areas are assumed to belong to the QRS\ncomplex, and to distinguish them from low slope areas, the\napproach relies on a clustering method based on K-means.\nAlgorithm 1 describes the main steps of BayeSlope. The\nmethod takes as input the Rel-En signal window, s, and it\noutputs the vector of R peaks detected. The algorithm is\nderivative-based, and considers two clusters that represent the\nhigh and low slope areas of the signal. Then, the two centroids\nare initialized beforehand, as shown in Line 3, where hcentr\n1Input : windows of RelEn signal, s(\u00b5V)\n2Output : R peaks, r\n3 Initialize centroids: hcentr =percentile(diff( s),99) andlcentr = 1\n4minrrdist= 240 ms;max qrsdur= 140 ms; .Constant parameters\n5 Initialize: mu= 75 bpm;sd= 100 ms;zeroctr = 0;qrsinit= 0;label =\n0;inqrs=false;\n6fori= 2; :::length( s)do\n7s2[i] =s[i]\u0000s[i\u00001]; .Derivative approximation\n8x=abs(s2[i]);\n9bf[i] = gaussian( i\u0000lastpeak; mu; sd ); .Bayesian \ufb01lter\n10 bt[i] = genlogfun( x; param logfun ); .Sigmoid normalization\n11 st[i] = max(x; bt[i]\u0003bf[i]); .Normalize signal\n12 Update hcentr andlcentr each as the new mean of their cluster\n13 ifinqrsthen .Peak search\n14 iflabel = 0 then\n15 zeroctr + = 1 ;\n16 else\n17 zeroctr = 0;\n18 end if\n19 ifzeroctr = 30 ORi\u0000qrsinit > max qrsdur then\n20 max minslope =argmaxmin (st\u0003sign(s2));\n21 Search for newpeak within max minslope\n22 r[i] =newpeak ;\n23 end if\n24 else\n25 iflabel = 1 ANDi > last peak +minrrdist then\n26 inqrs=true;\n27 qrsinit=i;\n28 end if\n29 end if\n30end for\nWhen a new sample is assigned to a cluster it is labeled as\n1 if it is colser to hcentr , or 0 if it is closer to lcentr . Two\nwindows of 1:75 s are used for the hcentr initialization to\naccount for enough peaks even at rest and avoid errors due\nto signal noise. Then, the algorithm initializes all the other\nparameters needed, constant and varying, in Lines 4\u20135. The\nvalues for these parameters were chosen based on common\nphysiological constraints [24], and not on any values observed\nin the data. Thus, we can be con\ufb01dent that the values are\ngeneral enough for any ECG obtained from an adult human.\nThe main process starts by considering the derivative of\nsand computing its absolute value, x, in Lines 7\u20138. We\napply this initial transformation to enhance the maximum and\nminimum slopes of the original signal s. This choice follows\nthe assumption that the R peak is located in general within the\nmaximum upward and downward de\ufb02ections within an ECG\nsignal. Next, the method computes the Bayesian \ufb01lter (Line 9),\nwhich is a Gaussian centered on the expected peak, mu, with\nstandard deviation sd, two parameters computed based on\nthe last \ufb01ve peaks. The selection of such a small number\nof peaks is to make the Bayesian \ufb01lter responsive to the\npotential fast variations of the RR interval near high intensity\nlimits [25], which are precisely the regions of greatest interest\nto our algorithm. Then, in Line 10, the algorithm computes\nthe generalized logistic function [26] with input xand its\nparameters computed based on the last hcentr andlcentr .\nThe sigmoid varies between 0 and the value of the higher k-\nmeans centroid, hcentr . The sigmoid and the Bayesian \ufb01lter\nare used to normalize the peak or, speci\ufb01cally, to increase the\namplitude of expected small peaks, as shown in Line 11 and\nFig. 6. If the analyzed sample does not reach the computed\nthreshold, the function does not increase its value. When the\ninput is approximately double the value of the lowest centroid,\nst(in Algorithm 1) reaches the threshold between lcentr andFig. 6 : Illustration of the main features of the BayeSlope algorithm. The\nbayesian \ufb01lter (i.e., prior estimation), together with the generalized logistic\nfunction (normalization sigmoid) allows to locally enhance the observed slope\nvalue ( x), leading to a posterior estimation that goes above the detection\nthreshold. The bottom-left part of the \ufb01gure illustrates the peak search\nprocedure that is triggered once the detection threshold is surpassed. All\nsymbol names correspond to those introduced in Algorithm 1.\nexpected location of the peak (i.e., the prior expectation) is\ndepicted with the Gaussian centered on it. In this case, the\noriginal peak (i.e., observed value) in xis small, and it is\nenhanced by the Gaussian multiplied by the sigmoid function,\nleading to the posterior estimation st. This situation is shown\nin the posterior estimation rectangle.\nOnce the signal is normalized, the algorithm starts a peak\nsearch within a QRS complex\u2014the ECG main wave\u2014in\nLines 13\u201329. This procedure is also illustrated in Fig. 6.\nThe distance between QRS complexes must be more than\nminrrdist, according to standard physiological character-\nistics and the sample that starts the QRS complex ( qrsinit\nin Line 25) must belong to the cluster represented by hcentr\n(i.e.,label = 1). Within the QRS complex, the algorithm waits\ntill it reaches its maximum duration according to physiology\n(max qrsdur) or for enough samples ( zeroctr = 30 ) labeled\n0 that represent the end of the QRS complex (Lines 14\u201319).\nOnce within this interval (Lines 20\u201322), the algorithm com-\nputes the maximum and minimum of the function st\u0003sign(s2)\nrepresenting the maximum upslope and downslope of the\noriginal signal. The sign function is used in case these values\nfall in the Q, S or T wave, which are not distinguished if only\nstis used, as it is positive by de\ufb01nition. Finally, the newpeak\nis found and stored in the vector r.\nAs shown in Fig. 2, the modules of the algorithm run\nin different cores of the wearable computing architecture\naccording to the complexity of the corresponding module.\nThe wearable architecture used in this work is based on one\nof the evolutions of the open-source PULP platform [27],\ncalled Mr.Wolf [9]. The PULP structure consists of a main\nstreamlined processor, the fabric controller (FC), and an 8-\ncore parallel compute cluster (CL). Moreover, PULP includes\na direct memory access (DMA) that can transfer data to a\nmulti-banked 512 KiB L2 memory during acquisition time or\nfrom L2 to a shared multi-banked 64 KiB L1 memory, which\nhas a single-cycle latency in the cluster side. Both FC and CL\nare power-gated while the DMA \ufb01lls the required L2 memory\nbank during sample acquisition. The FC is clock-gated when\nthe CL is active, and each of the cores in the CL can be\nindependently clock-gated to reduce dynamic power. Mr.Wolf\nincludes a core for the FC (Zero-riscy) that is simpler than\nthe RI5CY cores of the CL, but it has a lower IPC. On the\nother hand, the cores of the CL have more capabilities [28].\nTherefore, this work considers the Mr.Wolf architecture by\nselectively using the FC and one core of the CL.\nConsidering this design, the modules of preprocessing (MF),\nREWARD (which includes Rel-En and R peak detection via\nhysteresis thresholds), and error detection run in the FC.\nREWARD is a very lightweight integer-based algorithm, as\ndemonstrated in [18]. In a preliminary analysis, considering\nthe dataset (c.f., Section IV-A), we performed a test executing\nthe R peak detection step of REWARD on the FC and on one\ncore of CL. The algorithm executed on CL is 1:23\u0002slower (in\nterms of execution time) and consumes 1:35\u0002more energy.\nTherefore, REWARD bene\ufb01ts from running on the FC, which\nis a simpler core, clocked at a higher frequency ( 170 MHz\nvs.110 MHz of the CL). On the contrary, BayeSlope is about\n100\u0002more complex than REWARD, hence, it bene\ufb01ts from\nrunning on a more advanced core with higher IPC. This\nhelps to meet real-time constraints and limits the amount of\ntime the system is active. Additionally, the Gaussian and the\ngeneralized logistic function of BayeSlope are implemented in\n\ufb02oating-point. Since the FC does not have a \ufb02oating-point unit,\nBayeSlope should be converted to \ufb01xed-point representation.\nTherefore, we adapted these functions of BayeSlope to employ\n\ufb01xed-point arithmetic, using a 32-bit representation with 1\nsign bit, 15 integer bits, and 16 decimal bits. The results\nreveal that during the clustering step the algorithm quickly\nreaches the maximum range representable (i.e., approximately\nwithin 15 s of signal processing), with a consequent drop\nin accuracy. In contrast, this does not occur in the 32-bit\n\ufb02oating-point representation as the maximum range is reached\nafter approximately 27 h of signal processing. Therefore, we\ndecided to implement BayeSlope on one core of the CL\n(RI5CY), which has a \ufb02oating point unit and higher IPC.\nAfter the signal \ufb01ltering and REWARD running on the\nFC, the error detection (also running on the FC) checks the\naccuracy of the R peaks output. If an error is detected, the\nFig. 7 : Sketch of the BIOPAC [29] sensors positioning (left) during the\nexperiment and the sensors themselves (right)\nVT2 VO2max\n20s 20s 20s\n20s20s\n30s 60s30s 60s\nRecoverytimeVT2 VO2max\n20s 20s 20s\n20s20s\n30s 60s30s 60s\nseg1 seg2 seg3 seg5\nseg410s 10s\nRecoverytime\nFig. 8 : Position in time through the maximal exercise test of the \ufb01ve 20-second\nsegments extracted from the full ECG of each subject. The numbers of the\nsegments are sorted in time in ascending order. The \ufb01rst segment was extracted\n30 s before VT2 and corresponds to heavy intensity; the second 60 s after VT2\n(severe intensity); the third 30 s before VO 2max (highly severe intensity up to\nexhaustion); the fourth at the moment of exhaustion (centered in VO 2max);\nthe \ufb01fth 60 s post-exercise, i.e. during the recovery after exhaustion.\ngated. Since BayeSlope needs an initialization of the R peaks\nof two windows of 1:75 s, the previous window error needs\nto be checked. If the error in the previous window is 0, then\nthe DMA transfers two windows, otherwise it transfers only\none. This is an optimization applied in case REWARD fails\nmore frequently and to avoid recomputing the same window.\nBayeSlope runs on the CL while the FC is clock-gated.\nThe \ufb01nal output is the combination of correct R peaks from\nREWARD and BayeSlope. The full code for the adaptive R\npeak detection has been published as open-source software1.\nIV. E XPERIMENTAL SETUP\nA. Database Acquisition Protocol\nThe database was acquired considering 22 subjects perform-\ning an incremental test to exhaustion on a cycle ergometer for\nan average of 30 minutes each until VO 2max was reached,\nplus at least 1 minute post-exercise. The power of the cycle\nergometer was increased every 3 min by30 W , after initial\n3 min of rest. Moreover, a three-minute recovery period was\nrecorded right after exhaustion. A single-lead ECG sampled at\n500 Hz was acquired using the BIOPAC system [29], together\nwith other biosignals and oxygen uptake measurements that\nwere not used for this work. Fig. 7 shows a sketch of the\npositioning of biosignals sensors and the equipment used. The\nprotocol was ethically approved by the Commission Cantonale\n(VD) d\u2019Ethique de la Recherche sur l\u2019Etre Humain (CER-\nVD), with reference 2016-00308, on 01/03/2018. For the\nexperiments, the ECG was downsampled to 250 Hz since\nREWARD was validated only for this frequency in [18].\nTwo of the 22 subjects were discarded because one did not\ncomplete the protocol and for the second one the majority\nof the recording was corrupted. Therefore, the statistics and\nanalysis were performed on 20 subjects. Next, \ufb01ve 20-second\nsegments were extracted from the full ECG of each subjectto be manually annotated by experts. The 20-second duration\nhas been selected as a minimum to enable posterior HRV\nanalysis [20]. The annotations were initially made by an\nengineer with background on ECG analysis, and then individ-\nually assessed by a cardiologist. A consensus was achieved\namong both annotators after just one iteration. The annotation\nprocess was done on PDF \ufb01les with the standard ECG grid of\n0:2s\u00020:5mV, as shown in Figure 10. The segments were\nchosen based on the different phases of the maximal exercise\ntest, namely, considering higher intensities of exercises where\nit is more likely that sudden changes occur. Then, these\nsegments were extracted and reported in the order shown\nin Fig. 8: the \ufb01rst, 30 s before VT2; the second, 60 s after\nVT2; the third, 30 s before VO 2max (exhaustion); the fourth,\nat the moment of exhaustion (centered in VO 2max); \ufb01nally,\nthe \ufb01fth, 60 s after VO 2max, i.e. during the recovery after\nexhaustion. The segments at rest were ignored since REWARD\nperforms very well in this condition, and there is no need to\nrun BayeSlope. Moreover, also the segments near VT1 are\nnot considered as they represent lower intensities of exercise\nfor which the performance of REWARD is satisfactory. Only\none out of 100 segments was not extracted and annotated\n(subject 9, segment during recovery). In fact, the recording\nfor this subject was stopped right after exhaustion (instead\nof after three minutes of recovery expected by the protocol)\nand it was not possible to have a 20-second segment 60 s\nafter VO 2max. The input segments to the peak detection\nwere extracted considering the 20 s given to the experts and\ngoing backward of 0:6 s + 0 :95 s + 1 :75 s, which represents,\nrespectively, the initial delay of the MF, the initial delay of\nRel-En, and one additional window of analysis for BayeSlope\ninitialization; and going forward 1:75 s to avoid missing the\nlast peaks. Thus, each segment is approximately 25 slong. The\naccuracy of R peak detection is measured according to the\nstandard tolerance of 150 ms between the detected peaks and\nthe manual annotations [30]. We also report for each subject\nthe mean and standard deviation of the time difference between\nthe two. We \ufb01rst compare the accuracy of BayeSlope against\na broad spectrum of state-of-the-art methods, including:\n1) The Pan-Tompkins algorithm [31], which is the most\nwidely used QRS detector in the literature. It is based on\na combination of bandpass \ufb01ltering and differentiation.\n2) A variation of the Engelse-Zeelenberg (EngZee) method,\nwhich is based on a heavy difference \ufb01lter and which is\nconsidered particularly robust to noise and artifacts [32].\n3) The GQRS detector [33], which belongs to the matched-\n\ufb01lter family of methods.\n4) A more modern method based on adaptive thresholding\non the Stationary Wavelet Transform (SWT) of the\nECG [34].\nWe believe these four methods give a fair and complete\noverview of the different families of approaches that are typi-\ncally used in embedded implementations. All the experiments\nwere done with open-source implementations of the algorithms\n(speci\ufb01cally, [33] for GQRS and [35] for the other methods).\na) Preprocessing (MF) and always running REWARD (Rel-\nEn + peak detection);\nb) Preprocessing (MF + Rel-En) and always running the\nnewly proposed BayeSlope;\nc) Our proposed adaptive design including preprocessing\n(MF), REWARD (Rel-En + peak detection), error detec-\ntion and running BayeSlope only when REWARD fails.\nAll the segments used in the experiments, as well as the man-\nual annotations, have been published as an open dataset [36].\nB. Test Benches on the Heterogeneous Platform\nThe three designs are mapped on the Mr.Wolf platform to\nestimate their overall energy consumption and perform the\nenergy-accuracy analysis. In all test benches, the preprocessing\nalways runs on the FC. The \ufb01rst two test benches consist of\n1) REWARD running on the FC with the CL power-gated,\nand 2) BayeSlope always running on the CL. The third test\nbench consists of the fully adaptive process, including the error\ndetection, with REWARD running on the FC and BayeSlope\nrunning on CL when REWARD fails. Each of the test benches\nis applied to the 99segments described in Section IV-A.\nTo measure the execution time of the three con\ufb01gurations,\nwe used the open PULP platform [27]. PULP provides an SDK\nto run RTL simulations, using Modelsim, in order to obtain a\ncycle-accurate pro\ufb01ling. To estimate the energy consumption\nof our proposed system, we use the power numbers reported\nfor a chip based on the PULP architecture implemented in\nTSMC 40 nm LP CMOS technology, namely, Mr.Wolf [9].\nWe consider the lowest energy point of the platform, at 0:8 V.\nThe platform requires 3:6\u00b5W[37] when power-gated2and\n12:6\u00b5Wwith full L2 retention. To implement better memory\nmanagement of the activated banks as done in [38], we reduce\nthe L2 to 128 KiB , with a resolution of 16 KiB per memory\nbank, since the application does not need more memory. When\nthe System-on-Chip (SoC) architecture of PULP is active,\nit consumes 0:98 mW with its main processor clock-gated,\nand6:66 mW while operating at 170 MHz . Once the CL is\nactivated, it consumes 0:61 mW with all the cores clock-gated\nand18:87 mW with the eight cores running at 110 MHz .\nThe three designs are compared \ufb01rst in terms of accuracy,\nthen energy consumption of their mapping on Mr.Wolf, and\nthen in their energy-accuracy trade-off for all the subjects and\nas a summary for worst, average and best cases.\nV. E XPERIMENTAL RESULTS\nA. Accuracy Analysis of the Test Benches\nIn Fig. 9, we report the percent of the error rate (ErrRate%)\nin the peak detection of the three designs, described in Sec-\ntion IV-A, and its evolution through the type of segments for\nthree example subjects. These examples illustrate three cases\nwithin the worst, best, and average groups in terms of accuracy\nof the new algorithm, BayeSlope, and the fully adaptive design\n(REWARD+Error detection (ErrDet)+BayeSlope) compared to\n2As reported for GAP-8 [37], which is an industrial version of PULP\n\nscore measures the peak detection performance as:\nF1=TP\nTP+1\n2\u0001(FP+FN)(2)\nwhere TP is the set of the correctly detected peaks that match\nthe manual annotations. FN represents all the misdetected\npeaks by the algorithm. FP is the set of all the peaks in the\nalgorithm that do not match any manual annotation. The dif-\nferent segments shown in Fig. 9 represent increasing exercise\nintensities till the recovery after exhaustion (segment 5), as\ndescribed in Section IV. In Fig. 9a, Subject 7 has one of\nthe worst error rates for the new algorithm, and the reason\nis that segment 3 is quite noisy. The quality of the segment\nis shown in Fig. 10, where the amplitude of the ECG has\na high variability due to changes caused by the exercise\nintensities near exhaustion (segment 3 is before VO 2max).\nHowever, BayeSlope and its adaptive design, with an F1score\nat approximately 60:5 %and56:8 %, respectively, gains within\n13:5 %and9:9 %in performance, compared to REWARD. In\nFig. 9b, Subject 3 represents an average case where REWARD\nhas a lower error rate compared to the worst case (Subject 7),\nthough still signi\ufb01cant. In fact, the adaptive design performs\nsigni\ufb01cantly better, with an error rate up to 3 %, slightly worse\nthan BayeSlope. In Fig. 9c, Subject 16 is one of the best cases\nwhere REWARD fails only during more intense exercise (at\nexhaustion), with an error rate up to 5:5 %, while BayeSlope\nhas an error rate of only 1 %.\nConsidering the \ufb01ve exercise intensities, a relevant summary\nof the algorithms\u2019 performance is depicted in Table I. Here,\nwe report the F1score, sensitivity, and positive predictive\nvalue (PPV) of the four reference algorithms and the three\ntest benches for each of the \ufb01ve types of segment computed\nacross the subjects, as well as the mean and standard deviation\nof the time difference between each test bench output and the\nmanual annotations. Our results show that BayeSlope is the\nmost accurate of the three designs over all the performance\nparameters. In particular, in comparison with state-of-the-art\nalgorithms, only GQRS achieves a comparable F1score during\nlower intensity exercises, while BayeSlope is superior to all\nthe compared methods in the rest of the situations. We can see\nthat the main bene\ufb01t of our proposal comes from an increased\nsensitivity during intense physical exercise (before and after\nVO2max), which is precisely the primary \ufb02aw observed in\nthe other methods. This supports our starting hypothesis,\naccording to which general algorithms are not suited to handle\nthe artifacts and sudden changes in the ECG arising from\nintense exercise. Indeed, the F1score and the sensitivity\nof REWARD during intense exercise are below acceptable\nmedical standards, compared to less intense exercise. However,\ncombining both methods in an adaptive design is as accurate\nas BayeSlope (up to 1:7 %of difference in F1score).\nRarely, the adaptive design could perform better (less than\n1 % difference in score) as it is shown in the sensitivity\nvalues. This is due to the initialization process of BayeSlope,\nwhich requires the signal to be stable as it does not use\n020406080100 ErrRate%\n(a) Worst case\n020406080100 ErrRate%1 2 3 4 5\nSegments020406080100 ErrRate%Percent\terror\trate\tfor\tSubject\t3\nREWARD only\nBayeSlope only\nREWARD+ErrDet+BayeSlope (b) Average case\n020406080100 ErrRate%1 2 3 4 5\nSegments020406080100 ErrRate%Percent\terror\trate\tfor\tSubject\t16\nREWARD only\nBayeSlope only\nREWARD+ErrDet+BayeSlope (c) Best case\nFig. 9 : Percent error rate with respect to the manual annotations of the three designs described in Section IV-A, for the worst, average, and best case subjects\nalong \ufb01ve segments of increasing exercise intensities.\nTABLE I :F1score, PPV, sensitivity (%) for the three test benches and the \ufb01ve exercise intensities computed across the subjects.\nBefore VT2 After VT2 Before VO 2max VO2max Recovery Total\nF1(%)Pan-Tompkins 96.4 95.8 86.9 85.4 97.0 92.2\nEngZee 92.9 94.5 84.0 82.9 92.8 89.3\nGQRS 99.3 99.1 89.5 91.3 98.6 95.4\nSWT 96.8 97.3 89.2 88.5 97.2 93.7\nREWARD (RW) 92.1 90.9 78.7 80.2 92.5 86.7\nBayeSlope (BS) 99.0 99.1 97.9 98.8 99.3 98.8\nRW + ErrDet + BS 98.9 99.0 96.2 97.1 98.5 97.9\nPPV (%)Pan-Tompkins 99.7 99.8 98.3 98.1 99.4 99.1\nEngZee 100.0 99.6 99.4 99.5 100.0 99.7\nGQRS 99.6 99.5 99.4 99.7 100.0 99.6\nSWT 99.8 100.0 99.8 100.0 99.8 99.9\nREWARD (RW) 98.2 98.2 97.1 96.3 98.1 97.6\nBayeSlope (BS) 98.6 98.6 98.9 98.6 98.6 98.7\nRW + ErrDet + BS 98.3 98.4 97.3 96.2 97.5 97.5\nSensitivity (%)Pan-Tompkins 93.3 92.2 77.9 75.6 94.7 86.1\nEngZee 86.8 89.9 72.8 71.0 86.6 80.9\nGQRS 99.0 98.7 81.4 84.2 97.2 91.6\nSWT 94.0 94.8 80.6 79.4 94.8 88.2\nREWARD (RW) 86.8 84.5 66.1 68.7 87.4 78.0\nBayeSlope (BS) 99.3 99.5 96.9 98.9 100.0 98.9\nRW + ErrDet + BS 99.4 99.6 95.2 98.0 99.6 98.3\nTime (ms)\nfrom manual\nannotationPan-Tompkins 91.9\u000626.8 91.6\u000628.3 92.0\u000631.4 91.7\u000630.0 87.7\u000630.3 91.0\u000629.4\nEngZee 0.1\u00062.9 0.9\u00069.9 3.9\u000621.4 8.8\u000633.2 2.0\u000616.5 3.0\u000619.6\nGQRS 32.5\u000610.7 30.9\u000611.3 25.4\u000621.8 27.1\u000622.5 31.1\u000616.3 29.4\u000617.4\nSWT 60.6\u000618.6 61.4\u000618.8 63.4\u000624.2 65.1\u000623.0 59.3\u000618.5 61.9\u000620.8\nREWARD (RW) 0.6\u00068.4 1.1\u000611.2 10.4\u000635.7 20.6\u000648.6 9.2\u000634.8 8.1\u000632.0\nBayeSlope (BS) 0.5\u00066.5 0.3\u00064.6 4.9\u000624.0 6.8\u000629.1 1.0\u000610.3 2.9\u000618.6\nRW + ErrDet + BS 0.5\u00066.5 0.3\u00064.6 4.3\u000622.3 7.3\u000630.1 1.1\u000611.3 2.8\u000618.5\nFig. 10 : ECG segment 3 (i.e., before VO 2max) for Subject 7. The amplitude\nof the peaks is highly variable due to the changes in the exercise intensity.\nThe signal is shown on a standard ECG sheet with a grid of 0:2 s\u00010:5 mV .\nsegment where BayeSlope is triggered and will be initialized,\ncompared to the initialization at the beginning of the segment\n(when always running BayeSlope). This can also cause a\ndelay in the adaptation and very few peaks missed and result\ninstead in a slightly worse accuracy. Another reason for a\nlower performance in the adaptive design compared to always\nrunning BayeSlope, speci\ufb01cally for more intense exercise\n(before and after VO 2max) and during recovery, as shown in\nTable I, is due to an edge case in the error detection. In fact,\nis performed on the full dataset and accounting for differentexercise intensities. Within more intense exercises, as the RR\nintervals get smaller, it can happen that even if REWARD\nmisses one peak, the RR ratio is still within the distribution.\nThis is shown in Fig. 11, where the RR ratio computed on the\nsmall peaks not detected by REWARD is close to the P99:5of\nthe distribution but not enough to trigger an error. This results\nin a lower accuracy for the adaptive design. One way to \ufb01x\nthis problem is to compute different distributions for different\nexercise intensities. In the case of this dataset, it could be\n\ufb01ve distributions or two groups of low and high intensities.\nAnother way is to adapt the distribution online by detecting the\nintensity type and choose the correct tail thresholds. Finally,\nwith the more advanced capabilities of modern heterogeneous\nplatforms, the distribution can be computed directly on the\nsignal acquired through a small training process on BayeSlope\nand then adapting the tail thresholds.\nIn conclusion, the accuracy results show that always running\n\n-1000100200300400500Amplitude (\u03bcV)\nFig. 11 : ECG segment 5 (i.e., recovery after exhaustion) for Subject 3 with\nthe R peaks from the three designs. For the misdetected small R peaks, the\nRR ratio is close to P99:5but not enough to trigger an error.\nwith the intensity of the exercise. However, BayeSlope is\napproximately 100\u0002more complex than the R peak detection\nstep of REWARD. Therefore, we propose the adaptive design\nthat combines both algorithms and has a similar accuracy\ncompared to BayeSlope. In the next section, we will show the\nadvantages in terms of energy consumption of the adaptive\ndesign on the PULP platform.\nB. Energy Consumption of Test Benches in PULP\nFigure 12 shows the energy consumption of the platform\nfor the three subjects described in Section V-A. In Subject 7\n(Fig. 12a), the worst case scenario, the fully adaptive design\nconsumes the same amount of energy in almost all the win-\ndows. In segment 3, the adaptive design achieves 6:5 % of\nenergy savings compared to always running BayeSlope, with\na3:7 %difference in F1score. However, the overall accuracy\nis far from the required medical standard, and even the best-\nperforming state-of-the-art algorithms only reach 75 % . In\nSubject 3 (Fig. 12b), for all the exercise intensities except\nsegment 4, during exhaustion, the fully adaptive wearable\ndesign we propose has energy savings up to 48 % compared\nto BayeSlope with a loss in accuracy of only up to 2 %\n(c.f. Fig. 9b). For segment 3, even if the energy savings are\none of the lowest at approximately 3:3 %, the fully adaptive\ndesign is as accurate as BayeSlope and 18:8 %more accurate\ncompared to REWARD. Therefore, on average cases such\nas Subject 3, in most exercise intensities, choosing the fully\nadaptive design can improve the energy-accuracy trade-off.\nSubject 16, representing one of the best case scenarios in\nFig. 12c, highlights the adaptivity of the full design and its\nerror detection through the segments, starting with a minimum\nenergy consumption, since only REWARD is running, and\nmaximum attainable accuracy. Then, when the exercise inten-\nsity increases, REWARD fails more frequently, and BayeSlope\ntakes over the R peak detection. Finally, during recovery,\nwhen the ECG stabilizes and REWARD fails less compared\nto exhaustion, the energy consumption drops to a lower level.\nOur fully adaptive design maintains a high level of accuracy\n(approximately 99 % ), while limiting the energy consumption\ncompared to executing BayeSlope for the full segment, with\nenergy savings from 31:8 %up to 58:6 %.\n\nREWARD\n(RW)BayeSlope\n(BS)RW +\nErrDet +\nBS\nEnergy\n(mJ)Before VT2 0.479\u00060.004 2.078\u00060.016 1.348\u00060.573\nAfter VT2 0.479\u00060.003 2.070\u00060.032 1.469\u00060.556\nBefore\nVO2max0.476\u00060.004 2.071\u00060.037 1.840\u00060.299\nVO2max 0.476\u00060.003 2.075\u00060.032 1.820\u00060.409\nRecovery 0.477\u00060.002 2.080\u00060.020 1.275\u00060.562\nTotal 0.477\u00060.004 2.075\u00060.028 1.553\u00060.536\nsegment for the three cases analyzed. Considering the windows\nwhere an error occurs and triggers BayeSlope, the previous\nwindow also counts as triggered since BayeSlope needs an ad-\nditional window for the initialization process (c.f., Section III-\nC). As expected, the trend is similar to the energy reduction\ncompared to always running BayeSlope shown in Fig. 12.\nThe large differences between the three subjects show how\nthe proposed design can adapt to the subject and different\nexercise intensities to reduce energy consumption instead of\nconstantly falling in the worst case scenario. This personalized\nand adaptive reduction in energy consumption can lead to a\nlonger battery lifetime for WSNs and better usability.\nTable II shows a summary of the average energy con-\nsumption for the \ufb01ve exercise intensities. As shown before\nin our accuracy analysis, higher exercise intensities require to\nrun BayeSlope more often in the adaptive design. However,\nthe algorithm achieves signi\ufb01cant energy savings compared\nto always running BayeSlope. The reason is that as long as\nBayeSlope is not triggered, the adaptive design uses only the\nFC. In that situation, the power of the platform corresponds to\nthe power of the FC and the leakage power of the CL, which\nis signi\ufb01cantly lower (approximately 5\u0002) than the power of\nthe CL executing BayeSlope on one of its cores, with the other\nones clock-gated. Therefore, the energy consumption over\nthe 25-second segment is reduced. As a result, the adaptive\ndesign achieves energy savings up to 38:7 %, considering the\naverage for the \ufb01ve exercise intensities. Moreover, it reaches\nup to 74:2 %energy savings for the overall dataset analyzed,\ncompared to the scenario where the CL is always active and\nexecutes BayeSlope.\nC. Energy-Accuracy Trade-Off on Test Benches\nFigure 14 shows the energy-accuracy comparison between\nthe three test benches and an analysis on the different exercise\nintensities. We use once again the F1score as a measure of al-\ngorithm detection accuracy. For the three segments before and\nafter VT2, and during the recovery after VO 2max, REWARD\nis accurate within the medical acceptability, and consumes\nthe minimum energy for this application. However, the fully\nadaptive design (in purple) is always more advantageous in\nterms of accuracy, with a performance increase of up to 8:2 %.\nMoreover, it is comparable in F1score to BayeSlope although\nmore energy-ef\ufb01cient, with energy savings up to 38:7 %.\n00.511.522.53Energy (mJ)\n(a) Worst case\n00.511.522.53Energy (mJ)1 2 3 4 5\nSegments00.511.522.53Energy (mJ)Energy\tconsumption\tfor\tSubject\t3\nREWARD only\nBayeSlope only\nREWARD+ErrDet+BayeSlope (b) Average case\n00.511.522.53Energy (mJ)1 2 3 4 5\nSegments00.511.522.53Energy (mJ)Energy\tconsumption\tfor\tSubject\t16\nREWARD only\nBayeSlope only\nREWARD+ErrDet+BayeSlope (c) Best case\nFig. 12 : Energy consumption of the test benches described in Section IV-B for the worst, average, and best case subjects along \ufb01ve segments corresponding\nto increasing exercise intensities.\n020406080100Percentage over full segment (%)\nSubject 161 2 3 4 5\nSegments020406080100Percentage over full segment (%)Percentage\tof\tBayeSlope\trunning\tin\tadaptive\tdesign\nSubject 7\nSubject 3\nSubject 16\nFig. 13 : Percentage of windows over the full segment where BayeSlope is\ntriggered during the adaptive design for three worst, average, and best case\nscenarios. Comparing these trends with the ones shown in Fig. 12, it is evident\nthat the adaptive design reduces energy consumption by reducing the number\nof times BayeSlope runs on the CL.\n\nREWARD\nREWARD+\nErrDet+\nBayeSlope70 75 80 85 90 95 100\nF1 score (%)00.511.522.53Energy (mJ)Energy-accuracy\ttrade-off\tby\ttype\tof\texcerpt\tfor\tthe\t3\ttest\tbenches\nREWARDBayeSlope\nREWARD+\nErrDet+\nBayeSlopeBefore VT2\nAfter VT2\nBefore VO2max\nVO2max\nRecovery after VO2max\nFig. 14 : Energy-accuracy analysis of the three test benches and different\nexercise intensities.\nthe hysteresis thresholds of REWARD do not adapt to the\nhigh amplitude variability of the peaks within a window of\nanalysis ( 1:75 s), as described in Section III-A and Fig. 3. In\nfact, before VO 2max the exercise intensity is about to reach its\nmaximum, and more sudden changes in the ECG occur, which\nexplains the decreased accuracy of REWARD. The segment\nextracted during exhaustion (i.e., when reaching VO 2max)\nrepresents the highest intensity and, hence, disruption of the\nECG morphology, speci\ufb01cally in the amplitude of the R peak\nand the RR intervals (HRV reaches its minimum). Therefore,\nscore of the fully adaptive design is onlyup to 1:7 %lower than BayeSlope, which is the most accurate.\nThe energy savings for these two segments are lower than the\nother three, though still signi\ufb01cant (up to 12:2 %).\nOur experimental results show how the proposed BayeS-\nlope algorithm is highly accurate and more robust than the\nlightweight REWARD when sudden changes in the ECG\nmorphology occur. Moreover, in these conditions, BayeSlope\nand, consequently, the adaptive design are also more robust\nthan state-of-the-art methods, such as the GQRS or SWT de-\ntectors. However, if we consider the design where BayeSlope\nis mapped on a PULP-based platform and running on the\nCL (with the preprocessing modules running on the FC), the\ndevice consumes on average 4:6\u0002more than the mapping\nof REWARD (and the preprocessing) in the FC. In contrast,\nthe adaptive design enhances the energy-accuracy trade-off,\nmaximizing accuracy while limiting energy consumption on\nmodern ULP platforms. This adaptive design is not limited to\napplications where intense physical exercise is involved, but it\ncan also be applied to pathologies where the ECG morphology\nchanges. Moreover, if BayeSlope is parallelized in the 8-\ncore CL, more computing resources can be assigned to HRV\nanalysis and pathology detection for fully on-node processing\nto ensure low-rate transmission and data privacy according to\nthe latest remote monitoring healthcare requirements.\nVI. C ONCLUSION\nIn health and wellness monitoring, speci\ufb01cally on the car-\ndiovascular context using wearable systems, there exist multi-\nple pathologies and physical conditions where sudden changes\nin the measured biosignals occur. In particular, during intense\nphysical exercise, sudden changes in the ECG heart beats\namplitude and rhythm cause errors in state-of-the-art standard\nR peak detection algorithms and, therefore, on any further\nanalysis based on the HR. Moreover, more accurate algorithms\noften require a higher amount of computing resources leading\nto a need for more capable wearable platforms with \ufb02exible\nresource management approaches.\nIn this work, we have proposed a new online machine\nlearning-based design to detect R peaks in a single-lead\nECG signal, which adapts at run time to the changes in its\nmorphology. Furthermore, this adaptive design exploits the\ncore heterogeneity of modern ULP wearable platforms, which\ncan run ef\ufb01ciently more complex algorithms using different\nmethod to measure the algorithm\u2019s accuracy. When REWARD\nfails, a novel algorithm called BayeSlope, which focuses on\nrobustness to sudden variations in the signal properties though\nmore complex, is triggered and runs in a more capable core.\nIn the context of a maximal exercise test, and, in particular,\nduring high intensity exercise, our proposed BayeSlope out-\nperforms state-of-the-art standard algorithms. Similarly, our\nonline adaptive design achieves a high F1score, up to 99:0 %\nacross \ufb01ve different exercise intensities, which is comparable\nto always running BayeSlope, and up to 17:5 %more accurate\ncompared to running only REWARD. By implementing the\nnewly proposed adaptive method in the heterogeneous PULP\nSoC wearable architecture, it can reach energy savings up\nto38:7 % compared to always running the more complex\nBayeSlope. Therefore, the newly proposed online adaptive\ndesign maximizes the accuracy while minimizing the energy\nconsumption for an optimal energy-accuracy trade-off when\nused in latest SoC architectures of wearable systems.\nACKNOWLEDGMENT\nThe authors acknowledge the help of Dr. Fabio Montagna\nfor the initial implementation of BayeSlope in the PULP plat-\nform, and Dr. Miguel P \u00b4eon-Quir \u00b4os for the help in the design\nof the experiments in PULP and the insightful comments on\nthe paper. Additionally, the authors acknowledge Dr. Nicolas\nBourdillon and Leandre Tschanz for the help in the preparation\nof the ethical protocol and the collection of the data.\nREFERENCES\n[1] K. Xu et al. , \u201cPublic spending on health: A closer look at global trends,\u201d\nWHO , 2018.\n[2] M. Al-khafajiy et al. , \u201cRemote health monitoring of elderly through\nwearable sensors,\u201d Multimedia Tools and Applications , Jan. 2019.\n[3] A. Kumar, R. Komaragiri, and M. Kumar, \u201cFrom pacemaker to wearable:\nTechniques for ecg detection systems,\u201d Journal of Medical Systems ,\nvol. 42, p. 34, Feb. 2018.\n[4] V . Ilkka et al. , \u201cNew report reveals the role of physical activity\nin preventing and treating cardiovascular diseases,\u201d European Heart\nNetwork , Jan. 2020.\n[5] E. Stamatakis et al. , \u201cUntapping the Health Enhancing Potential of\nVigorous Intermittent Lifestyle Physical Activity (VILPA): Rationale,\nScoping Review, and a 4-Pillar Research Framework,\u201d Sports Medicine ,\nvol. 51, no. 1, pp. 1\u201310, Jan. 2021.\n[6] S. Sharma and G. Whyte, Practical ECG for Exercise Science and Sports\nMedicine. Human Kinetics, 2010.\n[7] A. P. Chandrakasan, N. Verma, and D. C. Daly, \u201cUltralow-Power\nElectronics for Biomedical Applications,\u201d Annual Review of Biomedical\nEngineering , vol. 10, no. 1, pp. 247\u2013274, Aug. 2008.\n[8] D. Zoni, A. Galimberti, and W. Fornaciari, \u201cAn FPU design template to\noptimize the accuracy-ef\ufb01ciency-area trade-off,\u201d Sustainable Computing:\nInformatics and Systems , p. 100450, Oct. 2020.\n[9] A. Pullini, D. Rossi, I. Loi, G. Tagliavini, and L. Benini, \u201cMr.Wolf:\nAn energy-precision scalable parallel ultra low power SoC for IoT edge\nprocessing,\u201d IEEE Journal of Solid-State Circuits , vol. 54, no. 7, pp.\n1970\u20131981, Jul. 2019.\n[10] S. Benatti et al. , \u201cOnline Learning and Classi\ufb01cation of EMG-Based\nGestures on a Parallel Ultra-Low Power Platform Using Hyperdimen-\nsional Computing,\u201d IEEE Transactions on Biomedical Circuits and\nSystems , vol. 13, no. 3, pp. 516\u2013528, Jun. 2019.\n[11] E. De Giovanni, A. Arza Valdes, M. Pe \u00b4on-Quir \u00b4os, A. Aminifar, and\nD. Atienza, \u201cReal-Time Personalized Atrial Fibrillation Prediction on\nMulti-Core Wearable Sensors,\u201d IEEE Transactions on Emerging Topics\nin Computing , Aug. 2020.\n[12] P. Kirchhof et al. , \u201c2016 ESC Guidelines for the management of atrial\n\ufb01brillation developed in collaboration with EACTS,\u201d Eur. Heart J.vol. 37, no. 38, pp. 2893\u20132962, Oct. 2016.[13] D. Sopic, A. Aminifar, A. Aminifar, and D. Atienza, \u201cReal-time event-\ndriven classi\ufb01cation technique for early detection and prevention of\nmyocardial infarction on wearable systems,\u201d IEEE Transactions on\nBiomedical Circuits and Systems , vol. 12, pp. 982\u2013992, Oct. 2018.\n[14] F. Forooghifar et al. , \u201cA self-aware epilepsy monitoring system for real-\ntime epileptic seizure detection,\u201d Mobile Networks and Applications ,\nAug. 2019.\n[15] B. U. K \u00a8ohler, C. Hennig, and R. Orglmeister, \u201cThe principles of software\nQRS detection,\u201d pp. 42\u201357, 2002.\n[16] J. P. Mart \u00b4\u0131nez, R. Almeida, S. Olmos, A. P. Rocha, and P. Laguna, \u201cA\nwavelet-based ECG delineator: evaluation on standard databases.\u201d IEEE\nTrans. Biomed. Eng. , vol. 51, no. 4, pp. 570\u201381, Apr. 2004.\n[17] Q. Li, R. G. Mark, and G. D. Clifford, \u201cRobust heart rate estimation\nfrom multiple asynchronous noisy sources using signal quality indices\nand a Kalman \ufb01lter,\u201d Physiological Measurement , vol. 29, no. 1, pp.\n15\u201332, Jan. 2008.\n[18] L. Orlandic et al. , \u201cREWARD: Design, optimization, and evaluation of a\nreal-time relative-energy wearable R-peak detection algorithm,\u201d in Proc.\nof Engineering in Medicine and Biology Conference (EMBC) . IEEE,\nJul. 2019.\n[19] R. Gosselink, T. Troosters, and M. Decramer, \u201cExercise testing: why,\nwhich and how to interpret,\u201d Breathe , vol. 1, pp. 120\u2013129, Dec. 2004.\n[20] F. Cottin et al. , \u201cAssessment of ventilatory thresholds from heart rate\nvariability in well-trained subjects during cycling,\u201d International Journal\nof Sports Medicine , vol. 27, pp. 959\u2013967, Dec. 2006.\n[21] D. J. Bentley, V . E. Vleck, and G. P. Millet, \u201cThe Isocapnic Buffering\nPhase and Mechanical Ef\ufb01ciency: Relationship to Cycle Time Trial\nPerformance of Short and Long Duration,\u201d Canadian Journal of Applied\nPhysiology , vol. 30, no. 1, pp. 46\u201360, Feb. 2005.\n[22] M. Buchheit, R. Solano, and G. P. Millet, \u201cHeart-Rate De\ufb02ection\nPoint and the Second Heart-Rate Variability Threshold during Running\nExercise in Trained Boys,\u201d Pediatric Exercise Science , vol. 19, no. 2,\npp. 192\u2013204, May 2007.\n[23] R. Braojos, G. Ansaloni, D. Atienza, and F. J. Rincon, \u201cEmbedded real-\ntime ECG delineation methods: A comparative evaluation,\u201d in Proc.\nof 12th International Conference on Bioinformatics & Bioengineering\n(BIBE) . IEEE, Nov. 2012, pp. 99\u2013104.\n[24] M. S. Thaler, The Only EKG Book You\u2019ll Ever Need , 9th ed. LWW,\n2018.\n[25] M. P. Tulppo, T. H. Makikallio, T. E. Takala, T. Seppanen, and H. V .\nHuikuri, \u201cQuantitative beat-to-beat analysis of heart rate dynamics\nduring exercise,\u201d American Journal of Physiology-Heart and Circulatory\nPhysiology , vol. 271, pp. H244\u2013H252, 7 1996.\n[26] F. J. Richards, \u201cA \ufb02exible growth function for empirical use,\u201d Journal\nof Experimental Botany , vol. 10, pp. 290\u2013301, Jun. 1959.\n[27] \u201cGitHub - pulp-platform/pulp-sdk,\u201d 2019.\n[28] P. Davide Schiavone et al. , \u201cSlow and steady wins the race? A\ncomparison of ultra-low-power RISC-V cores for Internet-of-Things\napplications,\u201d in PATMOS , Sep. 2017.\n[29] \u201cResearch \u2014 biopac,\u201d https://www.biopac.com/research/.\n[30] AAMI, Testing and reporting performance results of cardiac rhythm and\nST-segment measurement algorithms . The Association, 2008.\n[31] J. Pan and W. J. Tompkins, \u201cA real-time qrs detection algorithm,\u201d IEEE\nTransactions on Biomedical Engineering , vol. 32, pp. 230\u2013236, 1985.\n[32] A. Lourenc \u00b8o, H. Silva, P. Leite, R. Lourenc \u00b8o, and A. Fred, \u201cReal time\nelectrocardiogram segmentation for \ufb01nger based ecg biometrics,\u201d in\nProceedings of the International Conference on Bio-inspired Systems\nand Signal Processing - Volume 1: BIOSIGNALS, (BIOSTEC 2012) ,\nINSTICC. SciTePress, 2012, pp. 49\u201354.\n[33] G. Moody, T. Pollard, and B. Moody, \u201cWFDB Software Package\n(version 10.6.2),\u201d Physionet , 2021.\n[34] V . Kalidas and L. Tamil, \u201cReal-time qrs detector using stationary wavelet\ntransform for automated ecg analysis,\u201d in Proceedings of the 2017 IEEE\n17th International Conference on Bioinformatics and Bioengineering,\nBIBE 2017 . IEEE, 7 2017, pp. 457\u2013461.\n[35] B. Porr, L. Howell, I. Stournaras, and Y . Nir, \u201cPopular ECG R peak de-\ntectors written in python,\u201d Jun. 2022, DOI: 10.5281/ZENODO.3353396.\n[36] E. De Giovanni, T. Teijeiro, D. Meier, G. Millet, and D. Atienza,\n\u201cECG in High Intensity Exercise Dataset,\u201d Nov. 2021, Zenodo Dataset\n10.5281/zenodo.5727800.\n[37] E. Flamand et al. , \u201cGAP-8: A RISC-V SoC for AI at the edge of the\nIoT,\u201d in Int. Conf. on Application-speci\ufb01c Systems, Architectures and\nProcessors (ASAP) . IEEE, Jul. 2018.\n[38] E. De Giovanni et al. , \u201cModular Design and Optimization of Biomedi-\ncal Applications for Ultralow Power Heterogeneous Platforms,\u201d IEEE\n", "arxiv88": "Date of publication xxxx 00, 0000, date of current version xxxx 00, 0000.\nDigital Object Identifier 10.1109/ACCESS.2017.DOI\nWi-Fi and Bluetooth Contact Tracing\nWithout User Intervention\nBROSNAN YUEN1, YIFENG BIE1, DUNCAN CAIRNS1, GEOFFREY HARPER1, JASON XU1,\nCHARLES CHANG1, XIAODAI DONG1(Senior Member, IEEE), and TAO LU1(Member, IEEE)\n1Department of Electrical and Computer Engineering, University of Victoria, Victoria, BC, Canada (Emails: {brosnany, xdong, taolu}@uvic.ca)\nCorresponding author: Xiaodai Dong (e-mail: xdong@ece.uvic.ca) and Tao Lu (e-mail: taolu@ece.uvic.ca).\nThis work was supported in part by the Nature Science and Engineering Research Council of Canada (NSERC) Discovery (Grant No.\nRGPIN-2020-05938), and Threat Reduction Agency (DTRA) Thrust Area 7, Topic G18 (Grant No.GRANT12500317), NSERC Grant\n520198, Fortinet Research under Contract 05484 and NVidia under GPU Grant program.\nABSTRACT\nPrevious contact tracing systems required the users to perform many manual actions, such as installing\nsmartphone applications, joining wireless networks, or carrying custom user devices. This increases the\nbarrier to entry and lowers the user adoption rate. As a result, the contact tracing effectiveness is reduced.\nUnlike the systems above, we propose a new privacy preserving Wi-Fi and Bluetooth (BLE) contact tracing\nsystem that does not require smartphone applications, joining wireless networks, or custom user devices.\nOur specially built routers seamlessly track smartphones, laptops, smartwatches, BLE headphones, and\ntablets without any user action, but do not trace user identity. Mapping between devices and users is only\ncarried out for confirmed cases and suspected contacts. Moreover, we can track the absolute positions of user\ndevices within 1.0 m due to using bidirectional long short-term memory neural networks that are trained with\ndata pre-collected by an autonomous robot. This allows public health authorities to track indirect droplet\nand surface transmissions that other contact tracing systems often overlook.\nINDEX TERMS Contact tracing, Received signal strength indicator (RSSI), Round trip time (RTT), Fine\ntime measurement (FTM), Wi-Fi indoor localization, Bluetooth indoor localization\nI. INTRODUCTION\nWhen a new outbreak appears with unknown pathogens,\nvaccines and treatments are not available immediately to\nreduce the spread of the disease. Therefore, governments\nand public health agencies use extensive disease testing to\nidentify infected individuals. However, testing the entire pop-\nulation is inefficient because of the limited testing capacity,\nfalse negative cases, and the associated costs. Contact tracing\nhas been developed to make efficient use of the limited testing\nresources, where the closest contacts of the confirmed cases\nor symptomatic cases are tested and isolated.\nA. CONTACT TRACING\nContact tracing is difficult because super-spreaders could in-\nfect thousands of people a day [1] and exponentially increase\nthe number of people in the contact tracing list. Traditionally,\ncontact tracing has been done by hand, where the authorities\ninterview each confirmed case to get the contacts and visited\nplaces. Afterwards, suspected cases are isolated and tested.\nSymptomatic cases and high exposure cases get a higher pri-\nority in testing. With a high enough contact tracing efficiency,diseases can be locally contained and sometimes be eradi-\ncated [2]. However, performing contact tracing manually is\nvery inefficient because the infected people might forget who\nthey met and where they visited. Staff shortages, incorrect\ntraining, and slow turnaround times can also cause inefficient\ncontact tracing.\nMany countries have moved to automated means of con-\ntact tracing [3]\u2013[5] via smartphones, cameras, custom track-\ning devices, or genome sequencing. Cameras can be used\nin-conjunction with facial recognition software to track indi-\nvidual people. Researchers collected a database of faces and\napplied a convolutional neural network (CNN) to classify the\npresences of the people in the database [6]. They are able\nto perform contact tracing via a web interface. Instead of\nonly classifying faces, other researchers have used multiple\ncameras to track movements in real time [7]. Furthermore,\nthey can determine the actual paths of the confirmed cases\nfor contact tracing.\nGenome sequencing enables contact tracing without in-\nterviewing patients or requiring tracking devices. This par-\nticularly useful for incapacitated or unidentified patients.\nJennifer L. Gardy et al. [8] applied hierarchical clustering\nto sequenced genomes in order to create a genome tree\nof a tuberculosis outbreak. Moreover, the genome tree per-\nfectly matches the contact traced social network created from\npatient questionnaires. The main disadvantage of genome\nsequencing is the genome tree can only be created after the\npatients are infected.\nOn the other hand, smartphones are readily available and\ncan be used for tracking the movements of individuals. Thus,\nmany governments, public health agencies, and software\ncompanies have implemented smartphone applications for\ncontact tracing. The Singaporean government released one of\nthe first contact tracing applications for COVID-19 [9]. Each\nsmartphone application broadcasts Bluetooth Low Energy\n(BLE) exposure notification packets containing temporary\nIDs of the users. Furthermore, each smartphone receives\nexposure notifications from all other smartphones and checks\nthe received temporary IDs against a database of confirmed\ncases. If the temporary ID is in the database of confirmed\ncases, then the application warns the user about an exposure.\nSimilarly, Apple and Google have developed their own con-\ntact tracing system using BLE [10], [11], where they built\ncontact tracing functionality into iOS and Android operating\nsystems. This allows them to do contact tracing on a scale\nof multiple countries, which is far greater than any other re-\nsearch study. On the other hand, researchers have developed\nDigitalPPE [12], a wearable BLE smartwatch, that tracks\nsocial interacts between people. DigitalPPE gives a vibration\nwarning if two people get too close and records the IDs of the\nsmartwatches with the relative distance. T. Shelby et al. [13]\nperformed two BLE contact tracing studies: one study using\na smartphone application and the other study using external\nBLE tags on the user. The custom BLE tags had a higher\naccuracy compared to the smartphone application because\nthe BLE tags had a higher transmit rate and power. Also,\nother researchers have relentlessly applied BLE for contact\ntracing [14]\u2013[21].\nAlternatively, T. Yasaka et al. [22] used QR codes for\ntracking social gatherings between groups of people. The\nhost of the social gathering creates a QR code using the\napplication, and the participants scan the QR code to build\na time series graph. When a user indicates a positive test\nresult, all users within 3 traversals of the time series graph\nare notified. A few more research papers have used the QR\ncode approach [23]\u2013[25]. Moreover, the smartphones\u2019 GPS\ncan be used to track users in the outdoor environments [26].\nThis would provide a higher position accuracy than BLE and\nQR codes.\nWi-Fi can be a useful tool for localization and contact\ntracing. A. Trivedi et al. [27] developed a Wi-Fi based contact\ntracing system without the need to install an application onto\nthe smartphone. They used the access points (APs) of two\nuniversities to collect packets from smartphones, where the\nuser\u2019s trajectory is built using the closest APs. Furthermore,\na graph search algorithm takes the user\u2019s trajectory and pro-\nduces a location and proximity report of the exposed users.Other research groups have used Wi-Fi based smartphone\napplications [28] to capture beacon frames from nearby APs\nand upload the data to the cloud. This allows the authorities\nto track the visited places and the positions of the confirmed\ncases. Moreover, the lifespan of the disease can be known due\nto the recorded timestamps of the beacon frames.\nB. INDOOR LOCALIZATION\nLocalization is fundamental to contact tracing, and it has\ntwo major categories: outdoor and indoor localization. Out\nof all the outdoor localization methods, Global Positioning\nSystem (GPS) is the most popular and is robust against signal\ninterference and jamming [29]. However, GPS requires direct\nline-of-sight (LoS) between the satellites and the handset,\nwhich is unsuitable for indoor localization.\nIndoor localization has drawn more attention in the indus-\ntry for its wide variety of use cases, such as autonomous\nindoor vehicles (AIVs) [30], unmanned aerial vehicles\n(UA Vs) [31], home automation, and smart buildings [32].\nRadio Frequency (RF) waves penetrate materials like tables\nand walls, making RF-based indoor localization the most\nadopted solution. Moreover, RF performs better than other\nmethods [33]. RF-based systems employ mobile phones\nfor capturing wireless parameters such as angle of arrival\n(AOA), time of arrival (TOA), and received signal strength\nindication (RSSI). There are two types of RF based local-\nization methods: ranging and trilateration/triangulation, and\nfingerprinting. The first method requires deploying known\nanchor nodes with coordinate information and synchroniza-\ntion among nodes, while the second method does not. In this\npaper, we use the wireless fingerprinting approach where the\nRF parameters act as fingerprints for positioning. With the\nhelp of machine learning, the average localization error of\nfingerprinting is around 1 m [34], [35].\nOur interests lie in estimating the positions of people to\ndetermine COVID-19 exposures. As a result, indoor local-\nization is more useful than outdoor localization due to indoor\nenvironments having a higher infection rate [36]. Moreover,\nindoor localization is extremely helpful for tracking COVID-\n19 outbreaks in complex environments such as supermarkets\nand airports.\nC. FEATURES OF THE PROPOSED CONTACT TRACING\nSYSTEM\nEvery contact tracing system has its own unique features and\nadvantages, as shown in Table 1. Camera contact tracing sys-\ntems [6] do not require any smartphone applications, wireless\nnetwork connections, and external user devices. Moreover,\nthey have an accuracy of 0.5 m and can track droplet and\nsurface transmissions. However, setting up multiple cameras\nper building and a video processing system is extremely\ncostly. Similar to the camera contact tracing system, genome\nsequencing [8] is highly accurate and precise. However, it\nrequires viral samples from each user and processing each\nsample is expensive.TABLE 1 :Feature Comparison of Indoor Contact Tracing Systems\nContact Tracing System Tracking\nMethodRequires\nSmartphone\nApplications ?Requires\nWireless\nNetwork\nConnections ?Requires\nExternal User\nDevices ?Tracks\nDroplet\nand Surface\nExposures ?Accuracy Cost\nN. Nanthini et al. [6] Camera No No No Yes Absolute\nPosition Within\n0.5 m1 Camera\nper Room\nJennifer L. Gardy et\nal. [8]Genome Se-\nquencingNo No No Yes 1% Error Rate >$400\nUSD per\nSequence\nTraceTogether [9] BLE Yes Yes No No Relative\nPosition Within\n1.0 mFree\nApple and Google Ex-\nposure Notification [10],\n[11]BLE No, Requires\nManual\nActivationYes No No Relative\nPosition Within\n1.0 mFree\nDigitalPPE [12] BLE No No Yes No Relative\nPosition Within\n1.0 m1 Wearable\nper Person\nT. Yasaka et al. [22] QR codes Yes Yes No No Requires Users\nto Scan QR\nCodesFree\nA. Trivedi et al. [27] Wi-Fi No Yes No No Position Within\nthe Room>$340\nUSD per\nRouter\nvContact [28] Wi-Fi Optional app\nautomates\ncontact\ntracing*Optional app\nautomates\ncontact\ntracing*No Yes Absolute\nPosition Within\n2.0 mFree*\nProposed Contact Trac-\ning SystemWi-Fi and\nBLENo No No Yes Absolute Posi-\ntion Within 1.0\nm$30\nUSD per\nRouter\n*Note: If the user does not install the optional smartphone application, then a medical personnel manually performs contact tracing by revisiting every\nlocation the user has been to.\nBLE contact tracing systems are cheap and easy to set up.\nHowever, they usually require the user to manually install\nsmartphone applications [9] or manually activate exposure\nnotifications in the settings [10], [11]. This results in a\nlow participation rate and decreases the accuracy of contact\ntracing. Furthermore, those systems only record the relative\npositions of the users, of which are highly ineffective in\ntracking droplet and surface transmissions. Using custom\nBLE smartwatches [12] or tags [13] eliminates the need\nfor smartphone applications, but they only record relative\npositions and have the exact same problems.\nA few Wi-Fi contact tracing systems [27] do not re-\nquire the user to install smartphone applications. Instead, the\nrouters record the positions of the smartphones, whenever the\nuser manually logs into the wireless network. This approach\nhas low position accuracy due to users getting disconnected\nor logging out. Furthermore, the RSSI ranking system has\nlocation ambiguity due to multiple positions having the same\nRSSI ranking. As a result, they can not determine if a user\nis within 2.0 m of another user. Moreover, their system is\nexpensive due to them using Cisco and HP/Aruba equipment\nthat cost >$340 USD per router.\nUnlike the previous systems in Table 1, we propose a new\nprivacy preserving Wi-Fi and BLE indoor contact tracing\nsystem that does not require the users to perform any actions.\nSpecifically, the users do not need to install any smartphoneapplications. The users do not need to connect to any wireless\nnetworks, which improves localization accuracy due to elim-\ninating wireless network disconnects and users logging out.\nInstead, we use custom designed ESP32C3 routers to capture\nWi-Fi and BLE packets emitted from the wireless devices.\nThe overall system contains four modules: an autonomous\nrobot for site survey, a BiLSTM network for trajectory\nprediction, WiFi routers designed with special features to\ncollect sufficient RF data and pre-process the data, and graph\nbased contact tracing algorithm. In each module, there are\ninnovations in design solution and practical implementation,\nas detailed in the next sections. This system allows us to\ntrack smartphones, smartwatches, tablets, and laptops of\nusers seamlessly in the background. Although user tracking\nand device tracking are used interchangeably throughout the\npaper, the system does not obtain user identity for privacy\npurpose but only trace device WiFi interface MAC addresses.\nOur contact tracing system also tracks droplet and surface\ntransmissions due to our neural networks providing absolute\npositions. Subsequently, indirect or delayed infections can\nbe tracked even-though the infected individual has left the\narea multiple days ago. As for localization accuracy, our\ncontact tracing system has an average error of 1.0 m, which is\nsimilar to the other BLE and Wi-Fi contact tracing systems.\nHowever, the camera and genome sequencing methods have\nhigher localization accuracy at a cost of much more expen-\nsive equipment.\nThe paper is organized as follows. Section II is a big\npicture overview of the proposed contact tracing system.\nThe site survey is conducted in Section III, while the data\nprocessing is shown in Section IV. The actual contact tracing\nalgorithm is depicted in Section V. Section VI shows the\nresults and discussions of identifying unique mobile devices,\nlocalization performance, and contact tracing. A conclusion\nis presented in Section VII.\nII. OVERVIEW OF THE PROPOSED CONTACT TRACING\nSYSTEM\nFig. 1 shows the overview of the proposed contact tracing\nsystem. It consists of four components: 1) An autonomous\nrobot for site survey to generate a location-fingerprint\ndatabase; 2) A BiLSTM neural network trained by the site\nsurvey dataset for user trajectory prediction; 3) WiFi routers\nfor capturing packets without user action in prediction, test-\ning and training stages; 4) Contact tracing algorithm and\nengine based on the localization data.\nWe propose to use a bidirectional long short term memory\n(BiLSTM) neural networks to predict the trajectories of\nmobile devices. The BiLSTM requires many datasets such as\nthe training dataset, the testing dataset, and the production\ndataset. The training dataset is used to train the BiLSTM,\nwhile the testing dataset measures the accuracy of the BiL-\nSTM. Moreover, the production dataset is the real life dataset\nthat only contains input features without any labels.\nWireless fingerprinting for localization does not need to\ninstall known anchor nodes but does need to have a location-\nfingerprint database of a site. This site survey if done man-\nually is very laborious. The purpose of the Turtlebot3 site\nsurvey is to obtain the training dataset and the testing dataset\nusing a robot. The Turtlebot3 executes autonomous site\nsurveys by meticulously visiting all positions on the floor.\nA smartphone is mounted on the robot, and it broadcasts\nwireless packets while moving in order to simulate mobile\ndevice trajectories. On the other hand, the ESP32C3 routers\ncapture Wi-Fi and BLE packets for the training dataset, the\ntesting dataset, and the production dataset. For the production\ndataset, the Turtlebot3 is not involved, and the routers directly\ncapture packets from the users without the users needing to\nperform any action. Afterwards, the packets\u2019 transmit power\n(TX power), received signal strength indication (RSSI), and\ntime of flight (ToF) are used to predict the user trajectories.\nFinally, we design a graph based contact tracing algorithm\nto build a social contact graph. Every user is assigned to a\nunique node on the graph. For every intersection between the\ntrajectory of a confirmed case and the trajectory of a user,\nwe add an edge that connects the node of the confirmed case\nto the node of the user. After repeating this process multiple\ntimes, a graph of the suspected cases is displayed together\nwith their trajectories.\nIn the next sections, each component of the system is\ndescribed in details.\nFIGURE 1 :Overview of the proposed contact tracing system.III. TURTLEBOT3 FOR SITE SURVEY\nTypically, mobile devices transmit many Wi-Fi and BLE\npackets as they move around the building. By implementing\npacket sniffing on the router side, mobile devices can be\ntracked throughout the day. However, the localization algo-\nrithms require large amounts of training and testing data.\nMeasurement of the training data is done in the form of a\nsite survey, where a mobile device transmits packets at every\nposition and the signal information is recorded at the router\nside.\nCollecting data by hand is extremely tedious and intro-\nduces position errors. Instead, we built a custom Turtle-\nbot3 [37] for the site survey. The Turtlebot3 continuously\ntransmits packets to the routers, while visiting every position\nin the building. The original Turtlebot3 has a height of 19\ncm, which is too short for the height of a smartphone on a\ntable or in a user\u2019s pocket. A platform is added to the custom\nTurtlebot3 in order to increase the smartphone\u2019s height to\n75 cm. Moreover, the custom Turtlebot3 is also equipped\nwith RPLIDAR A2, Intel D415 RGBD camera, Nvidia Jetson\nTX2, and Raspberry Pi 3.\nA. ROBOT OPERATING SYSTEM 2\nRobot Operating System 2 (ROS2) [38] is an open-source\nrobotics framework that collects sensor information, executes\ndata processing, implements inter-process communications,\nand allows real-time control. ROS2 has four main concepts:\nnodes, topics, services, and actions. Nodes are individual pro-\ncesses, of which execute a singular task like collecting sensor\ndata or filtering information. Nodes can commence one way\ncommunications with other nodes by publishing messages to\ntopics. All nodes that subscribe to a specific topic receive\nthe same messages. Unlike topics, services are a two-way\ncommunications channel. Nodes can send service requests\nand receive service responses once the specific operation is\ncompleted. Actions are an extension of services, where the\nnodes receive periodic feedback status messages instead of\nnot receiving feedback messages.\nThe RPLIDAR A2 is a 2D laser ranging device that mea-\nsures the distances to the nearest opaque objects. It is a 360\u00b0\nLIDAR that completes 1 revolution every 0.1 seconds. The\n360\u00b0 scans are divided into 360 angle intervals. For each\nangle interval, the RPLIDAR A2 returns a distance value.\nThe laser scans feed into ROS2 SLAM_toolbox, of which\nit produces a 2D grid map and publishes the transform from\nmap to odometry (odom). It essentially determines the posi-\ntion and orientation of the Turtlebot3. On the other hand, the\nIntel D415 RGBD is used for obstacle avoidance. The D415\nproduces a RGBD point cloud at 720p 30 frames per second\n(FPS). Camera sensors have false positive readings, where\nthe sensor outputs a ghost point in the absence of objects.\nIn order to eliminate the false positives, multiple RGBD\npoint cloud frames are joined together and are uniformly\ndecimated. Afterwards, the point cloud is organized into\nclusters, where the cluster centres and standard deviationsare calculated. If a point is 1 standard deviation away from\nthe cluster centre, then it is removed.\nB. DETECTING OBSTACLES IN THE LOCAL MAP\nIn order for the routers to collect data, the Turtlebot3 needs\nto visit every position on the floor and stand there for a\nfew minutes. To accomplish that, we create an autonomous\nnavigation algorithm that is able to avoid static objects and\nmoving obstacles in order to operate in various buildings and\nenvironments. There are 4 main steps in Algorithm 1 : detect-\ning obstacles in the local map, finding the start positions of\nthe paths, generating the best path using the start positions,\nand moving along the planned path.\nBefore planing a path and moving along it, the Turtlebot3\nneeds to determine the obstacles in the local vicinity. The\nfunction constructCostmap retrieves the odometry, 2D laser\nscans (LaserScans), and 3D point cloud (PointCloud) to\nconstruct a 2D occupancy grid (Costmap). Each pixel in\nthe occupancy grid has a status of occupied, free space, or\nunknown depending on the sensor information. This helps\nthe robot to avoid obstacles, which are labelled as occupied.\nAnother function, detectObstacles determines if an input\nposition is near any obstacles in the costmap. It checks every\noccupied position in the costmap to determine if any of them\nare closer to the input position than the robot radius. If there\nis an obstacle closer than the robot radius, then the function\nindicates the presence of an obstacle by returning HasObsta-\ncles, otherwise there are no obstacles and the function returns\nNoObstacles.\nC. FINDING THE START POSITIONS OF THE PATHS\nPrior to generating new paths, we must first select the start\npositions of the paths. As shown in the function findStartPos,\nrays are created starting at the Turtlebot3\u2019s current position\n(Odom) and ending at the occupied positions in the costmap.\nFor each individual ray, it is checked against the costmap\nfor potential obstacles. If the ray has an obstacle in its path,\nthen the ray is discarded. Afterwards, a random position is\nselected from the ray\u2019s line and is appended to the list of\nstart positions (StartPositionList). The list of start positions\nrepresent candidate positions for generating the best path.\nD. GENERATING THE BEST PATH USING THE START\nPOSITIONS\nAfter finding the start positions, we use the function cre-\natePath to generate new paths and score them for finding\nthe best path. One of the inputs to the function is a list of\npreviously visited positions (VisitedPositionList), of which is\nused to avoid visiting the same locations. Subsequently, the\nbest path (BestPath) and best path score (BestPathScore) are\ninitialized with the worst possible path. A low path score in-\ndicates an undesirable path, while a high path score indicates\na desirable path. Afterwards, the algorithm generates every\npossible combination of candidate path starting from the start\nposition list and ending at an obstacle in the costmap. The\ncandidate path is a straight line that has evenly spaced points\nAlgorithm 1: Path Planning and Autonomous Navi-\ngation\nfunction constructCostmap() :\nOdom \u2190getOdom();\nLaserScans \u2190getLIDAR();\nPointCloud \u2190getCamera();\nCostmap \u2190newCostmap(Costmap,LaserScans);\nCostmap \u2190newCostmap(Costmap,PointCloud);\nreturn Costmap, Odom\nfunction detectObstacles( Costmap, Position ):\nforeach OccupiedPosition inCostmap do\nDistance \u2190magnitude(OccupiedPosition -\nPosition);\nifDistance < RobotRadius then\nreturn HasObstacles\nend if\nend for\nreturn NoObstacles\nfunction findStartPos( Costmap, Odom ):\nRays\u2190Costmap - Odom;\nStartPositionList \u2190[];\nforeach RayVec inRays do\nDetect \u2190detectObstacles(Costmap,RayVec);\nifDetect == NoObstacles then\nRandNum \u2190randomUniform(0, 1);\nPosition \u2190RandNum*RayVec;\nStartPositionList.append(Position);\nend if\nend for\nreturn StartPositionList\nfunction createPath( StartPositionList, Costmap,\nVisitedPositionList ):\nBestPath \u2190initPath();\nBestPathScore \u21900;\nforeach StartPos inStartPositionList do\nforeach EndPos inCostmap do\nDirection \u2190EndPos - StartPos;\nNum\u2190Int(magnitude(Direction)/0.5);\nPath\u2190arange(0,1,Num)*Direction +\nStartPos;\nDetect \u2190detectObstacles(Costmap,Path);\nifDetect == HasObstacles then\ncontinue;\nend if\nPathScore \u2190\ncomputeScore(Path,VisitedPositionList);\nifPathScore >BestPathScore then\nBestPathScore \u2190PathScore;\nBestPath \u2190Path;\nend if\nend for\nend for\nreturn BestPathfunction moveAlongPath( BestPath, Odom,\nCostmap, VisitedPositionList ):\nforeach Position inBestPath do\nDetect \u2190detectObstacles(Costmap,Position);\nifDetect == HasObstacles then\nmoveRobotToPosition(Odom);\nbreak;\nend if\nmoveRobotToPosition(Position);\nsleep();\nVisitedPositionList.append(Position);\nend for\nreturn VisitedPositionList\nbetween the start position and end position. Each position\nin the candidate path has a minimum distance of 0.5 m to\nthe other positions. If a candidate path has an obstacle in\nits way, then it is rejected. A path score is computed for\neach candidate path, depending on the length of the path and\nthe number of overlaps between the candidate path and the\npreviously visited positions. When the candidate path goes\nthrough many of the previously visited positions, its path\nscore is decreased. However, if the candidate path goes to\nunvisited locations, then its path score is increased. Longer\npaths also increase the path score. The candidate path with\nthe highest path score is selected as the best path.\nE. MOVING ALONG THE PLANNED PATH\nAs depicted in the function moveAlongPath, ROS2 Naviga-\ntion 2 is used to move the Turtlebot3 along the best path.\nNavigation 2 controls the velocity and angular velocity in\norder to visit all the evenly spaced points in the best path.\nBefore moving to a new location, the algorithm checks to see\nif there is an obstacle in the way. Upon detecting a blockage\nin its path, Turtlebot3 retraces its steps back to the start\nposition (Odom). When the Turtlebot3 arrives at one of the\nplanned positions, the current position is appended to the list\nof previously visited positions (VisitedPositionList). Subse-\nquently, the robot waits at that location for a few minutes,\nwhile the ESP32C3 routers collect Wi-Fi and BLE packets\nfrom the Turtlebot3. Moreover, the ESP32C3 routers record\nthe Unix times and positions of the robot for the training\nand testing databases. The process above repeats until all free\npositions on the map are sampled by the Turtlebot3.\nIV. PACKET PROCESSING\nA. ESP32C3 ROUTER\nIn order to capture packets, we built a custom router based\non the ESP32C3 chip-set because it supports monitor mode\non Wi-Fi and BLE simultaneously. It is able to determine\nRSSI from all Wi-Fi/BLE packets and supports Wi-Fi FTM\nto get the round trip time (RTT). For some BLE packets,\nthe ESP32C3 provides the TX power of the mobile devices.\nAn RF front end is added to increase the RX power and thedynamic range of the received packets, while a SD card is\nadded to store the data.\nAt the start of the day, the routers\u2019 real-time clocks (RTCs)\nare synchronized via simple network time protocol (SNTP)\nto the master server. The non FTM packets are timestamped\nby the RTCs with an accuracy of 1 \u00b5s. However, the FTM\npackets have a timestamp accuracy of 1 ns provided by the\nESP32C3\u2019s high-resolution timer. Subsequently, raw packet\ndata is written live to the SD card, and it is sent back to\nthe master server at the end of the day. Most of the packet\nprocessing is done at the master server to reduce CPU load\non the ESP32C3.\nB. INCREASING WI-FI RESPONSE RATE USING THE\nESP32C3\nManufacturers limit the power consumption of the Wi-Fi\nchipsets on the mobile devices to conserve battery charge.\nAs a result, the number of packets transmitted by the mobile\ndevices is small, and the localization accuracy is low. How-\never, we can increase the localization accuracy by sending\npackets to the mobile devices using the ESP32C3 and getting\na higher response rate. In order to cover most Wi-Fi channels,\nthe routers alternate between channels 1, 6, and 11. After\nswitching to a channel, the ESP32C3 transmits a request-\nto-send (RTS) packet to a mobile device. In response, the\nmobile device transmits a clear-to-send (CTS) packet back\nto the router, which contains information pertaining to the\nmobile device. The ESP32C3 can also send NULL packets\nto get an ACK response from the mobile devices. Moreover,\nspecial mobile devices can respond to Wi-Fi FTM requests,\nof which greatly increases the localization accuracy.\nC. INCREASING BLE RESPONSE RATE USING THE\nESP32C3\nSimilar to the Wi-Fi case, the ESP32C3 alternates between\nBLE channels 37, 38, and 39. Upon switching to a channel,\nthe router sends a BLE scan request to a mobile device. After-\nwards, the mobile device replies with a BLE scan response,\nof which contains BLE capabilities and sometimes model\nspecific information. If the mobile device advertises a BLE\nservice, then the ESP32C3 will send a pairing request packet\nto the device. Even if the pairing request is denied, the router\nwill still receive a pairing response packet and the position of\nthe mobile device.\nD. SORTING WI-FI PACKETS BY SOURCE TYPE\nOnce the packets from the routers are collected, they are\nsorted and processed. The routers record the packets in non-\nchronological order. Therefore, the packet processor sorts the\npackets by timestamp in order to synchronize the packets\nfrom multiple routers. Note that malformed Wi-Fi packets are\ndiscarded due to having incorrect information. Afterwards,\nthe packets are sorted by the type of wireless device: AP,\nwireless distribution system (WDS), bridged device, or mo-\nbile device. APs are found by looking at the source MAC\naddresses of the beacon frames. WDS are identified when thepackets have ToDS=1 and FromDS=1. Bridged devices are\nidentified when the packets have FromDS=1 and the source\nMAC addresses do not equal the BSSIDs. The remaining\nwireless devices are categorized as mobile devices. For the\npurposes of this paper, only the packets from the mobile\ndevices are used for contact tracing.\nE. SORTING BLE PACKETS BY SOURCE TYPE\nSame as the Wi-Fi packet sorting and processing, the BLE\npackets are sorted by their arrival time. Subsequently, BLE\npackets with invalid cyclic redundancy check are discarded\ndue to having incorrect protocol data unit types and incorrect\nmanufacturer specific information. Afterwards, BLE packets\nare sorted by the type of TX address: public MAC addresses\nand random MAC addresses. Public BLE MAC address are\nstable and constant for long periods of time, so they are\neasily tracked and localized. On the other hand, random BLE\nMAC addresses rapidly change from one packet to another\npacket, and they require special BLE MAC de-randomization\nalgorithms for tracking.\nF. DEFEATING WI-FI MAC ADDRESS RANDOMIZATION\nMany mobile devices randomize their Wi-Fi MAC addresses\nto prevent user tracking and identification [39]. In order\nto defeat Wi-Fi MAC address randomization, we create an\nalgorithm to categorize mobile devices using model specific\ninformation from the probe requests. Firstly, we capture\nprobe request frames emitted by the mobile devices. Every\nmobile device regularly transmits probe request packets, so\nthis is not a problem. Secondly, we extract model specific\ninformation from the probe requests. Each device model type\nhas unique model specific information such as supported\nrates, extended supported rates, high throughput (HT) capa-\nbilities, direct sequence (DS) parameter set, and vendor spe-\ncific organizationally unique identifier (OUI). Furthermore,\nthose model specific information are fixed and do not change\nover the lifetime of the device [40].\nThirdly, the model specific information is converted into\na binary fingerprint vector. For example, if transmit beam-\nforming is supported on the device, then it is set to \"1\"\nin the binary fingerprint vector, otherwise it is set to \"0\".\nIn order to make the binary fingerprint vectors the same\nlength, missing values are padded with \"0\". Fourthly, we use\nthe binary hamming distance to compare binary fingerprint\nvectors. Even though two packets might have completely\ndifferent MAC addresses, if the hamming distance of two\npackets\u2019 binary fingerprint vectors is zero, then the two\npackets originated from the same model type. This allows\nus to track and locate individual model types by collecting\npackets with the same binary fingerprint vectors. Finally,\nwe use a ball tree clustering algorithm to categorize binary\nfingerprint vectors into their respective device types. The\nball tree is constructed such that each leaf node contains the\nexact same binary fingerprint vector. Moreover, each branch\ncontains device types from the same device family. As a\nresult, we can cluster unknown and new device types around\nwell known device types.\nG. EXTRACTING FEATURES FROM WI-FI PACKETS FOR\nLOCALIZATION\nSpecific Wi-Fi packet features are extracted as fingerprints\nfor localization. Wi-Fi RSSI and Wi-Fi Signal Quality Index\n(SQI) correlate to the received (RX) powers of the routers.\nHigh RSSI values indicate the mobile devices are close to the\nrouters and the RX power of the routers is large. Low RSSI\nvalues indicate mobile devices are far away from the routers\nand the RX power of the routers is small. Some wireless\ninterfaces report the noise power of specific channels and\npackets. SQI is a function of RSSI and noise power. If the\nRSSI values are high, then the SQI values are high. Moreover,\nif the noise power is high, then the SQI values are low.\nRSSI and SQI are susceptible to the type of mobile device,\ntransmit (TX) power, and noise power. This makes RSSI and\nSQI somewhat unstable and dependent on the environmental\nconditions. On the other hand, some mobile devices sup-\nport Wi-Fi FTM, of which greatly increases the robustness.\nTo initiate FTMs, the router sends an FTM packet to the\nmobile device containing the FTM packet\u2019s departure time.\nAfterwards, the mobile device sends an ACK packet to the\nrouter containing the FTM packet\u2019s arrival time and the ACK\npacket\u2019s departure time. The router records the ACK packet\u2019s\narrival time and computes the RTT. In order to obtain a\nmore precise RTT, multiple series of FTM exchanges are\nperformed and are averaged. ToF can be computed from RTT,\nand ToF is invariant to the type of mobile device, TX power,\nand noise power. In conclusion, ToF is far less susceptible to\nthe external environment when compared to RSSI and SQI.\nH. EXTRACTING FEATURES FROM BLE PACKETS FOR\nLOCALIZATION\nThe main disadvantage of Wi-Fi packets is the lack of TX\npower information. Every mobile device has a different TX\npower, and it results in different RX powers. Inconsistent RX\npowers produce incorrect localization predictions and invalid\ncontact tracing paths. This is an open problem. We propose\nto use BLE packets to assist the Wi-Fi RX power calibration.\nNote that BLE packets contain the information of both TX\npowers and RX powers. The BLE path loss LBLE\nLBLE(\u20d7X) =PBLETX \u2212PBLERX (\u20d7X) (1)\nis computed using the constant BLE TX power PBLETX\nand the BLE RX power PBLERX as a function of position\n\u20d7X. It is invariant to the type of mobile device, since the\npath loss only depends on the distance to the router and the\nchannel environment. Thus, the BLE path loss LBLE is used\nas one of the inputs to the neural networks. Assuming the\nBLE path loss is equal to the 2.4 GHz Wi-Fi path loss at the\nsame position LBLE(\u20d7X) =LWiFi(\u20d7X), the Wi-Fi TX power\nPWiFiTX\nPWiFiTX =LBLE(\u20d7X) +PWiFiRX (\u20d7X) (2)can be calculated. Since the Wi-Fi TX power PWiFiTX is\nconstant for a specific model of mobile device, the Wi-Fi path\nlossLWiFi\nLWiFi(\u20d7X) =PWiFiTX \u2212PWiFiRX (\u20d7X) (3)\ncan be computed. As a result, localization predictions using\npath loss have a higher accuracy.\nI. NEURAL NETWORKS FOR LOCALIZATION\nAfter extracting the features from the packets, they are fed\ninto the BiLSTM neural networks to predict the positions\nof mobile devices. However, the BiLSTM neural networks\nrequire a large number of continuous trajectories for train-\ning. The training trajectories are generated via a simple\nrecursive algorithm from the site survey sample locations.\nFirstly, a random position is selected as the current position\n\u20d7Pi. Secondly, another random position is selected as the\ncandidate position \u20d7PCfor the next position \u20d7Pi+1. If the\nEuclidean distance between the candidate position and the\ncurrent position is less than a distance threshold |\u20d7PC\u2212\u20d7Pi|<\n|k|, then the candidate position becomes the next position\n\u20d7Pi+1\u2190\u20d7PC; otherwise a new random position is selected\nas the candidate position \u20d7PC. The distance threshold kis a\nrandom normal number that has a standard deviation of 1 m.\nFinally, the process above repeats until a trajectory of posi-\ntions{\u20d7P0,\u20d7P1,\u20d7P2, . . . , \u20d7PN}is completed. For each floor in\nthe building, 20,000 trajectories are randomly generated for\ntraining. Moreover, each trajectory has 20 different positions.\nOnce the training dataset is generated, it is used to train the\nBiLSTM neural networks. The mentioned neural networks\nhave special neurons because they can retain information\nsuch as the past positions and the past features. This allows\nthe BiLSTM to predict future positions using past positions\nand past features. Moreover, the inverse is also true because\nthe BiLSTM can use future positions and future features to\npredict past positions. If ToF or SQI features are available,\nthen they are fed into the network as a time series of features.\nIf TX power is present, then signal path loss is used as an\ninput feature to the network. When the features listed above\nare not available, the neural network defaults to RSSI for\npredicting the trajectories of mobile devices.\nAs shown in Fig. 1, the BiLSTM neural network consists\nof 2 BiLSTM layers followed by 2 dense layers. The number\nof input features to the network is denoted by Finput as\nit changes depending on the number of routers. Each BiL-\nSTM layer consists of 7Finput neurons with tanh activation\nfunctions. The first dense layer has 14Finput neurons with\nLeakyReLU activation functions, while the second dense\nlayer has 2 neurons with no activation function. Furthermore,\nthe second dense layer outputs the predicted positions of a\nmobile device.\nV. CONTACT TRACING ALGORITHM\nThe contact tracing algorithm takes a mobile device\u2019s MAC\naddress/model name, an initial time and/or an initial position\nof a confirmed case as input and allows us to precisely trackAlgorithm 2: Contact Tracing\nfunction lookupConfirmedCase( Database,\nInitialTime, InitialPos, MACaddr, ModelName ):\nUserInfos \u2190getValues(data=Database,\nkey=InitialTime);\nifMACaddr != NULL then\nUserInfos \u2190getValues(data=UserInfos,\nkey=MACaddr);\nelse\nUserInfos \u2190getValues(data=UserInfos,\nkey=ModelName);\nend if\nMinDistList \u2190[];\nforeach User inUserInfos do\nAbsPos \u2190square(IntialPos - User.Pos);\nDist\u2190sum(AbsPos, 2);\nIndex\u2190minIndex(Dist);\nMinDistList.append(Dist[Index]);\nend for\nIndex\u2190minIndex(MinDistList);\nreturn UserInfos[Index]\nfunction pathIntersect( UserInfo1, UserInfo2,\nDistanceThres, TimePeriodThres ):\nDoesIntersect \u2190False;\nTimeMatrix \u2190transpose(UserInfo1.Times) -\nUserInfo2.Times;\nTimeMatrix \u2190abs(TimeMatrix);\nIndex\u2190select(TimeMatrix <TimePeriodThres);\nPosMatrix \u2190transpose(UserInfo1.Pos[Index]) -\nUserInfo2.Pos[Index];\nPosMatrix \u2190square(PosMatrix);\nPosMatrix \u2190sqrt( sum(PosMatrix, 3) );\nIndex\u2190select(PosMatrix <DistanceThres);\nifIndex.size >0then\nDoesIntersect \u2190True;\nend if\nreturn DoesIntersect\nfunction findContacts( InputUsers,\nUserInfoList, AdjMat ):\nUserSize \u2190UserInfoList.size;\nOutputUsers \u2190[];\nfori\u21901ToUserSize do\nTargetUser \u2190UserInfoList[i];\nif!InputUsers.contains(TargetUser) then\ncontinue;\nend if\nforj\u21901ToUserSize do\nCurrentUser \u2190UserInfoList[j];\nResult \u2190pathIntersect(TargetUser,\nCurrentUser);\nAdjMat[i][j] \u2190Result;\nifResult then\nOutputUsers.append(CurrentUser);\nend if\nend for\nend for\nreturn AdjMat, OutputUsersfunction createGraph( ConfirmedCases,\nUserInfoList, SearchDepth ):\nUserSize \u2190UserInfoList.size;\nAdjMat \u2190zeroMatrix(UserSize, UserSize);\nInputUsers \u2190ConfirmedCases;\nforDepth \u21901ToSearchDepth do\nAdjMat, OutputUsers \u2190\nfindContacts(InputUsers, UserInfoList,\nAdjMat);\nInputUsers \u2190OutputUsers;\nend for\nreturn AdjMat\nthe paths of confirmed and suspected cases with an accuracy\nof 1.0 m. Furthermore, we can track droplet and surface expo-\nsures due to knowing the absolute positions of the users. The\ncontact tracing procedure described in Algorithm 2 consists\nof 4 main parts: the key-value database system, looking up\nthe paths of the confirmed cases, finding the suspected cases\nusing path intersection, and creating a graph connecting the\nconfirmed cases to the suspected cases.\nA. KEY-VALUE DATABASE SYSTEM\nFor simplicity, a key-value database system is used to store\nthe user information for the contact tracing system. Given a\nunique key, the algorithm can use it to look up a specific value\nin the database. Searching for values by comparing each key\nindividually is extremely slow because it takes O(N)time.\nHowever, hashmaps can decrease the search time to O(1)\nconstant time. Our system is built on Redis, a hash based\nkey-value database system, where it hashes the unique key\nto obtain a pointer. Afterwards, the pointer is used to access\nthe memory location of the associated value. In particular,\nRedis uses the cyclic redundancy check (CRC) hash function\nfamily to lookup key-value pairs because it is simple and has\nhardware acceleration in modern CPUs. As a result, Redis\nspeeds up the user information look-ups in the contact tracing\nsystem.\nThe contact tracing database contains many key-value\npairs. Each value contains the user\u2019s device model name,\nMAC addresses, positions, date/time, medical test results,\nand contacts with other users. Furthermore, an initial position\nor a MAC address can be used as a key to look up those\nvalues. These properties are useful for looking up the paths\nof the confirmed cases.\nB. LOOKING UP THE PATHS OF THE CONFIRMED\nCASES\nThe first step of the contact tracing algorithm is to lookup\nuser information of the confirmed cases. However, many\nusers have the exact same identifiers such as the same tra-\njectory, the same device model name, and the same random\nMAC addresses. As a result, significant ambiguity is present\nin the lookup process. To solve the problem above, we create\nthe lookupConfirmedCase function to reduce the identifier\nambiguity. There are 4 main scenarios, where the function\nhas to perform look-ups:\nScenario A: all mobile devices do not have MAC address\nrandomization. This causes each mobile device to have a\nsingle unique MAC address that is easily identified and\ntracked by the algorithm. When a patient has a positive test\nresult, they only need to provide their single MAC address\n(MACaddr) and initial time (InitialTime) to look-up user\ninformation (UserInfos). The initial time requires the specific\nday and hour of the arrival in the location.\nScenario B: all mobile devices have MAC address ran-\ndomization, but each mobile device has a unique model\nname. Due to the fact that each unique model name emits\na unique probe request signature, we can still identify and\ntrack individual mobile devices. This time, the patient has to\nprovide the device model name (ModelName) and the initial\ntime. For example, the device model name could be iPhone\n13, Galaxy S22, or Pixel 6. As a result, the algorithm can look\nup the information on the confirmed case without knowing\nthe actual MAC addresses.\nScenario C: all mobile devices have MAC address ran-\ndomization and multiple devices have the exact same model\nname. However, devices with the same model names have\nunique trajectories that do not have intersecting points with\neach other. This scenario is far more difficult than Scenario\nB, and the algorithm can only tell users apart by their unique\ntrajectories. Thus, the patient needs to provide the initial\nposition (InitialPos), model name, and initial time. The input\ninitial position could be any position on the patient\u2019s trajec-\ntory. The algorithm selects the user information that contains\nthe closest trajectory to the initial position.\nScenario D: all mobile devices have MAC address ran-\ndomization and multiple devices have the exact same model\nname. Furthermore, multiple devices with the same model\nnames have intersecting trajectories with each other or near\nmisses. In some situations, two physically separated trajec-\ntories might be mislabelled as having an intersecting point\nbecause the neural networks predicted the wrong positions.\nSubsequently, the algorithm falsely groups multiple individ-\nual users as a single confirmed case. This increases the false\npositive rate and adds more users to the list of suspected\ncases. On the other hand, the false negative rate stays the\nsame because the algorithm still traces the correct social\ncontacts.\nC. FINDING THE SUSPECTED CASES USING PATH\nINTERSECTION\nAfter retrieving the user information of the confirmed cases,\nwe use the pathIntersect function to find the suspected cases.\nGiven the paths of User1 and User2, the function determines\nif their paths intersect within a certain distance and time\nthreshold. Firstly, we compute the time differences (TimeMa-\ntrix) between both user paths. Secondly, we select specific\npositions (PosMatrix) from the user paths that have time\ndifferences less than the time period threshold (TimePeri-\nodThres). Typically, public health authorities will input adifferent time period threshold for each type of pathogen.\nThirdly, we select positions from the user paths that are\ncloser than the distance threshold (DistanceThres). We set\nthe distance threshold equal to 2.0 m because our localization\naccuracy is around 1.0 m. If there exists at least one distance\nless than the distance threshold, then the function indicates\nan intersection, otherwise the function does not indicate an\nintersection.\nD. CREATING A GRAPH CONNECTING THE\nCONFIRMED CASES TO THE SUSPECTED CASES\nUsing the path intersection function, we create a graph\nconnecting the confirmed cases to the suspected cases. A\ngraph is defined as a set of nodes that are connected by\nedges. The adjacency matrix AdjMat describes every edge\nconnection, where AdjMat [i][j] =True represents a con-\nnection between node iand node j. On the other hand,\nAdjMat [i][j] =False represents no connection between\nnode iand node j. In particular, each user is assigned to a\nunique node and each social contact is represented by an edge\nconnection. To begin, the function createGraph retrieves the\ntotal number of users (UserSize), and the adjacency matrix\nis initialized as a zero matrix of size UserSize by UserSize.\nAfterwards, the list of confirmed cases (ConfirmedCases) is\nselected as the list of input users (InputUsers). The findCon-\ntacts function compares the input users\u2019 paths to every other\nuser path in the list of total users. If their paths intersect,\nthen the corresponding element in the adjacency matrix is\nupdated AdjMat [i][j] =True and the new social contact\nis appended to the output list (OutputUsers). Pathogens can\nspread very rapidly due to infecting their primary contacts\nand later the secondary contacts of those primary contacts.\nThe contact tracing algorithm gets ahead of the disease\nspread by recursively applying the findContacts function un-\ntil the search depth (SearchDepth) is reached. This produces\na social contact graph that is very deep and has many degrees\nof separation. In conclusion, the createGraph function returns\nthe fully built adjacency matrix connecting the confirmed\ncases to the suspected cases.\nE. USER PRIVACY CONSIDERATIONS\nPrivacy is a very important aspect to keeping collected in-\nformation safe and within regulations with Canadian and\nBritish Columbia Privacy Acts. In our system, phone num-\nbers, email addresses, and legal names are not collected\nby the routers and are not stored in the database. Only\nthe MAC addresses of the Wi-Fi/BLE chipsets and device\nmodel names are obtained as the identification of the mobile\ndevices. Note that MAC addresses cannot directly identify\nusers, and MAC address randomization also complicates the\nmapping of multiple MAC addresses to user devices. Public\nhealth authorities will only map the MAC addresses to user\nidentities for confirmed cases and suspected contact cases,\nwith the help of additional information of user identity and\ndevice wireless interface MAC addresses. Furthermore, as\npart of the privacy protection, users that enter a buildingwith the contact tracing system in place need to be aware of\nwhat the system does and actively consent to their data being\ncollected. Users also have the ability to retroactively erase\ntheir information in the contact tracing database. Finally, the\ncollected data such as MAC addresses, device model name,\nand positions are encrypted with AES256 algorithm.\nVI. RESULTS AND DISCUSSION\nMultiple datasets were collected at the University of Victo-\nria, Victoria, British Columbia, Canada in the Engineering\nOffice Wing (EOW) 3rd floor, EOW 4th floor, Engineering\nComputer Science (ECS) 1st floor, and ECS 5th floor. At\neach floor, the Turtlebot3 physically moves along 3 unique\ntrajectories. Every trajectory contains unique positions that\nthe other trajectories do not have. One of the trajectories\nis randomly selected for the training dataset, while another\nis selected for the testing dataset. The remaining trajectory\nis appended to the cross-validation dataset. Furthermore,\nwe artificially generated more training trajectories using the\ndata points from the training dataset as described in Sec-\ntion II Subsection D. However, we did not create artificial\ntrajectories using the testing and cross-validation datasets.\nThe quality of the data collected by the ESP32C3 routers\nis unknown, thus we use commercial off the shelf (COTS)\nrouters as a reference to validate the quality of the data from\nthe ESP32C3 routers. The data collected are organized into\ntwo main groups: Dataset A is collected using the COTS\nrouters and Dataset B is collected using the ESP32C3 routers.\nA. DATASET INFORMATION\nDataset A contains the packets collected by COTS routers. At\nevery position, at least 50 samples are obtained by the routers.\nEach sample contains a timestamp, X position, Y position, \u03b8\norientation, Wi-Fi RSSI, Wi-Fi SQI, BLE RSSI, and BLE TX\npower. For the EOW 3rd floor, 11 Wi-Fi routers and 7 BLE\nrouters are deployed to obtain the dataset. Note that some\nWi-Fi routers share the same locations as the BLE routers.\nThe raw dataset contains approximately 500,000 samples at\n1,000 different positions, where each sample has 31 wireless\nparameter features. For the EOW 4th floor, 9 Wi-Fi routers\nand 7 BLE routers are deployed to obtain the dataset. There\nare fewer routers on this floor due to the lack of power\noutlets. The raw dataset contains approximately 300,000\nsamples at 600 different positions, where each sample has\n29 wireless parameter features. For the ECS 1st floor, 7\nWi-Fi routers and 7 BLE routers are deployed to obtain\nthe dataset. The raw dataset contains approximately 200,000\nsamples at 1000 different positions, where each sample has\n24 wireless parameter features. For the ECS 5th floor, 8 Wi-Fi\nrouters and 6 BLE routers are deployed to obtain the dataset.\nThe raw dataset contains approximately 300,000 samples at\n600 different positions, where each sample has 24 wireless\nparameter features extracted from the packets.\nDataset B is sampled at the same locations and with the\nsame procedures as Dataset A. However, Dataset B uses\nESP32C3 routers, and it provides a new wireless featureknown as Wi-Fi FTM. Moreover, the ESP32C3 routers oc-\ncupy 40 MHz bandwidth instead of the 20 MHz bandwidth\nin Dataset A. These new additions increase the localization\naccuracy of the BiLSTM and the precision of the contact\ntracing algorithm.\nB. IDENTIFYING UNIQUE MOBILE DEVICES FROM\nRANDOM MAC ADDRESSES\nIn this section, the effectiveness of the clustering algorithm\nfor identifying unique mobile devices from random MAC\naddresses is tested. For the test setup, MAC address ran-\ndomization is enabled on the devices, and they are forced to\njoin a wireless network. Every time a mobile device joins\na new wireless network, the operating system generates a\nnew random MAC address for that specific network. Ground\ntruth MAC addresses are obtained by looking at the settings\nmenu. Simultaneously, the devices\u2019 probe request packets\nare captured at the router side. Afterwards, the clustering\nalgorithm is applied to the probe requests to identify unique\nmobile devices from random MAC addresses.\nTable 2 shows the results of the clustering algorithm on the\ntesting dataset. Each row of the table contains a single bucket,\nof which each bucket contains MAC addresses that belong to\nthe same mobile device. Galaxy S4 is loaded with LineageOS\n16, of which does not have MAC address randomization.\nTable 2 shows the clustering algorithm assigning Galaxy S4\u2019s\nsingle MAC address to a single bucket and MAC addresses\nfrom other devices are not present in that bucket. The result\nmatches the Galaxy S4\u2019s ground truth MAC address. Similar\nto the Galaxy S4, the HTC One X does not have MAC\nrandomization, and it results in a single MAC address found\nin Table 2. However, Galaxy S6 is loaded with LineageOS\n18.1, and it generates a new random MAC address upon\njoining a new wireless network. Galaxy S6 is forced to join\n7 different wireless networks, and the clustering algorithm\nplaces all 7 of the Galaxy S6\u2019s random MAC addresses\nin the same bucket. Note that the clustering algorithm has\n100% accuracy because all the MAC addresses in Galaxy\nS6\u2019s bucket in Table 2 matches all the MAC addresses in\nthe ground truth. On the other hand, Android 11 on Galaxy\nA11 adds a new feature that randomizes MAC addresses\nwhile scanning for nearby SSIDs. The exact same test is\nperformed on the Galaxy A11, of which the ground truth\nMAC addresses matches the clustering result found in Table\n2. Note that the extra MAC addresses of Galaxy A11 are gen-\nerated when scanning for SSIDs. We have also observed that\nAndroid only generates a new random MAC address on the\nfirst network connection. Rejoining a previously connected\nnetwork yields the same MAC address.\nThe iPhone SE supports MAC address randomization be-\ncause it has iOS 15.1 firmware. For the test, iPhone SE is\nforced to join 7 different wireless networks, and the cluster-\ning algorithm places all 7 of the iPhone SE\u2019s random MAC\naddresses in the same bucket. Again, the clustering algorithm\nachieves 100% accuracy because all the ground truth MAC\naddresses are found at the iPhone SE\u2019s bucket in Table 2.\nTABLE 2 :Test Results of the Clustering Algorithm for Identifying Unique Mobile Devices from Random MAC Addresses.\nBucket Device MAC Addresses\n0 Galaxy S4 D0:22:BE:F5:7C:B4\n1 HTC One X E8:99:C4:99:57:24\n2 Galaxy S6 4E:0F:A0:57:F8:75, 26:45:19:1E:D5:FE, 1A:5B:0A:B1:7D:4A, 0E:BF:6D:4D:ED:A7, 42:B2:3B:14:49:F9, 1A:CF:16:13:A2:CB,\n8C:F5:A3:3D:16:DA, 3A:DC:D3:0A:46:B6\n3 Galaxy A11 6A:E0:23:0C:20:0F, 56:5C:AC:D6:13:30, E2:01:19:D0:64:2D, FA:05:BB:EA:47:2D, A0:27:B6:EE:6A:A7, 7E:69:90:C6:C4:04,\nDA:00:FD:35:82:25, 56:2F:2B:64:BC:C5, F6:08:C4:AF:61:94, 16:0D:FA:80:F8:1F, 5E:99:98:7B:5A:BF, 96:96:27:97:22:4C,\nFE:CB:1A:2E:F5:9A, B2:78:9D:5C:B9:1A 16:3C:FC:DF:1C:CA, 96:38:7C:5D:20:5C\n4 iPhone SE 82:31:01:8A:F3:AD, AE:9E:BE:7A:F3:D3, A6:E9:93:A7:9D:3E, D2:C5:A7:8B:9E:2C, 46:33:10:CE:43:3B, AA:CB:57:97:5E:5F,\n1A:40:6D:01:B4:05, 96:C2:5B:09:D8:4E, 3A:E6:E3:9B:8E:6D, 56:D3:41:61:0B:0A, A2:68:13:44:B2:EF, 8E:6A:CF:EF:6E:1F,\n56:A2:4A:EE:D4:46, E2:F7:83:DC:1E:E4, 22:29:5A:0D:F3:24, B6:33:3F:4F:89:1A, 9E:3D:78:F4:38:5D, ...\n5 iPhone X 86:98:6E:73:89:1D, 86:AD:C7:47:02:39, 3E:6F:2D:B3:4D:BB, 76:8A:CB:74:73:90, 9A:2D:E5:A8:F1:5A, 76:34:D2:C0:89:71,\nFE:B8:15:02:43:7C, 76:55:81:98:C3:78, CE:56:BC:E7:3E:72, 46:C9:78:16:41:B6, BE:F2:DB:37:1A:8A, 2A:2F:3E:B1:C7:A0,\n6E:4C:1E:F1:8E:E8, A2:97:F2:BA:2A:D5, 6A:DD:55:59:2E:68, DA:D2:D1:55:18:60, F2:C5:62:AD:29:04, ...\n6 PinePhone 7A:26:59:B4:C6:6D, D6:8A:05:6A:62:F5, 96:61:D9:88:25:45, 7E:53:9C:5F:BE:D0, B6:13:70:3F:28:C9, 0A:70:BB:F2:2D:9D,\n52:A2:3B:BD:6D:DF, D6:DB:E0:37:8C:CE, 62:0B:F8:3C:3A:E2, BA:12:FB:78:53:F4, A2:3E:F7:DF:14:03, BE:B6:47:61:BC:31,\nEA:14:84:75:F9:00, 8E:B7:F1:4D:1A:FC, C6:41:5C:E2:C6:7B, 92:47:59:89:C4:37, CA:DC:C0:CF:39:FB, ...\nThe extra MAC addresses found in the iPhone SE\u2019s bucket\nare generated when scanning for nearby SSIDs. The iPhone\nX\u2019s results are the same as the iPhone SE\u2019s results because\nthey both have the same iOS 15.1 firmware.\nThe full Arch Linux distribution is installed onto the\nPinePhone, of which allows full control over MAC address\nrandomization. We wrote a script to generate 25 new random\nMAC addresses and to save them into a file as the ground\ntruth. Afterwards, the clustering algorithm\u2019s results found in\nTable 2 are compared to the ground truth. The clustering\nalgorithm is able to place all the PinePhone\u2019s MAC addresses\ninto the same bucket without any other MAC addresses from\nother devices being there. Overall, the clustering algorithm\ncorrectly classified every single test device into their respec-\ntive buckets, even though their MAC addresses are random-\nized. However, any two mobile devices that have the same\nmodel number at the same spacetime might cause the system\nto produce incorrect results. This is due to identical devices\nproducing indistinguishable probe request information and\nRSSI information.\nC. PATH ANALYSIS OF DATASET A\nThe BiLSTM neural networks are applied to many environ-\nments, and their RMSE and MAE performances are shown\nin Table 3. At EOW 3rd floor, the BiLSTM with Wi-Fi has\na RMSE of 0.83 m and a MAE of 0.58 m. Moreover, only\nusing BLE information yields a similar RMSE of 0.88 m\nand a MAE of 0.56 m because the Wi-Fi routers share the\nsame positions as the BLE routers. Combining Wi-Fi and\nBLE information together results in a RMSE of 0.82 m and\na MAE of 0.58 m, of which has no discernible difference.\nFor error analysis, the ground truth trajectory is compared\nagainst the BiLSTM\u2019s predicted trajectory in Fig. 2a. The\npath begins at (X = 0 m, Y = 0 m) with medium error of\n1.0 m. However, the error increases to 1.5 m at the corners\nbecause that position has the least amount of LoS from the\nrouters. Subsequently, the highest error of 2.5 m occurs in\nthe east hallway because there are multiple objects blocking\nthe signal paths of the routers. Afterwards, the error rapidlydrops to 0.5 m as the BiLSTM recovers itself and gets\nback on the correct trajectory. For the rest of the path, the\nerror predominantly stays below 1.0 m, but there are a few\nlocations where the error jumps above 1.0 m due to corners.\nAt EOW 4th floor, the BiLSTM with Wi-Fi has a RMSE of\n0.92 m and a MAE of 0.61 m. The RMSE of EOW 4th floor\nis slightly higher than the RMSE of EOW 3rd floor because\nthe routers\u2019 signal paths in EOW 4th floor are blocked by\nmore walls and doors. Moreover, the number of routers is\nreduced from 11 to 9 due to the lack of power outlets.\nUsing only BLE produces a similar RMSE of 0.93 m and\na MAE of 0.63 m due to the number of Wi-Fi and BLE\nrouters being similar. Combining Wi-Fi and BLE information\ntogether results in a slightly lower RMSE of 0.84 m and a\nMAE of 0.60 m. The lower RMSE and MAE is caused by\nthe increased bandwidth and the increased channel diversity.\nJust as before, the ground truth trajectory is compared to\nthe BiLSTM\u2019s predicted trajectory in Fig. 2b. This time, the\nhighest error of 2.3 m occurs at the starting position of (X\n= 0 m, Y = 0 m). The large error is caused by not having\nenough space and power outlets to place more routers at the\nstarting position. Soon after, the error quickly decreases to\n1.0 m as the BiLSTM recovers and gets back on the correct\ntrajectory. There are a few instances where the error jumps\nsignificantly due to the objects blocking the router\u2019s signals,\nbut those errors are lower than the starting position errors.\nECS 1st floor is very different from the other floors\nbecause the packets are collected in an open area instead\nof an enclosed hallway. In an open area, Wi-Fi RSSI and\nBLE RSSI changes approximately 5 dBm per 10.0 m. The\nrouters are not sensitive enough to detect the small changes\nin RSSI and creates errors in localization. Moreover, there\nis an extra degree of freedom compared to the hallways, of\nwhich creates more ambiguity in the trajectory. As a result,\nlocalization errors on this floor are much larger than the\nother floors. For Wi-Fi, the RMSE is 1.69 m and the MAE\nis 1.42 m, of which the localization errors are significantly\nhigher than EOW 3rd floor, EOW 4th floor, and ECS 5th\nFIGURE 2 :BiLSTM\u2019s predicted locations vs ground truth at: a) EOW 3rd floor b) EOW 4th floor c) ECS 1st floor d) ECS 5th floor e)\nprobability distributions of Dataset A Wi-Fi+BLE\nfloor. Localization using BLE information has a larger RMSE\nof 2.13 m and a larger MAE of 1.73 m. This is caused by\nthe BLE having a lower transmit power and worse antennas.\nCombining Wi-Fi and BLE slightly lowers the RMSE to 1.30\nm and the MAE to 1.03 m because the antenna diversity\nand the channel diversity are increased. The ground truth\ntrajectory is compared to the BiLSTM\u2019s predicted trajectory\nin Fig. 2c. The trajectory starts off well at the origin of (X = 0\nm, Y = 0 m) with an error of 0.5 m. However, the error rapidlyincreases to above 2.0 m because the predicted trajectory\nquickly diverges from the ground truth. The BiLSTM never\nrecovers from incorrect predictions, and the error remains\nabove 2.0 m. The large errors are caused by the ambiguity of\nthe wireless features. Multiple unique positions on the map\nhave the same Wi-Fi RSSI, SQI, and BLE RSSI.\nThe ECS 5th floor has a similar layout to EOW 3rd floor\nand EOW 4th floor because they are all located in a hallway.\nAs a consequence, the localization performance on ECS\nTABLE 3 :Dataset A: BiLSTM\u2019s localization performance at different locations.\nLocation Method APs RMSE (m) MAE (m) Training Time (s) Testing Time ( \u00b5s)\nEOW 3rd Floor BiLSTM+Wi-Fi 11 0.83 0.58 3.67 420\nEOW 3rd Floor BiLSTM+BLE 7 0.88 0.56 3.12 399\nEOW 3rd Floor BiLSTM+Wi-Fi+BLE 18 0.82 0.58 4.34 445\nEOW 4th Floor BiLSTM+Wi-Fi 9 0.92 0.61 3.55 410\nEOW 4th Floor BiLSTM+BLE 7 0.93 0.63 3.02 402\nEOW 4th Floor BiLSTM+Wi-Fi+BLE 16 0.84 0.60 3.96 405\nECS 1st Floor BiLSTM+Wi-Fi 7 1.69 1.42 4.72 340\nECS 1st Floor BiLSTM+BLE 7 2.13 1.73 3.31 361\nECS 1st Floor BiLSTM+Wi-Fi+BLE 14 1.30 1.03 4.32 417\nECS 5th Floor BiLSTM+Wi-Fi 8 0.83 0.62 3.72 370\nECS 5th Floor BiLSTM+BLE 6 0.87 0.68 3.38 373\nECS 5th Floor BiLSTM+Wi-Fi+BLE 14 0.92 0.63 4.13 391\nNote: Wi-Fi implies Wi-Fi RSSI and SQI,while BLE implies BLE RX power and TX power.\nTABLE 4 :Dataset B: BiLSTM\u2019s localization performance at different locations.\nLocation Method APs RMSE (m) MAE (m) Training Time (s) Testing Time ( \u00b5s)\nEOW 3rd Floor BiLSTM+Wi-Fi FTM 8 0.80 0.57 4.59 360\nEOW 3rd Floor BiLSTM+Wi-Fi RSSI 8 0.82 0.62 5.57 366\nEOW 3rd Floor BiLSTM+Wi-Fi FTM+Wi-Fi RSSI 16 0.75 0.55 5.93 442\nEOW 5th Floor BiLSTM+Wi-Fi FTM 8 0.75 0.57 4.21 461\nEOW 5th Floor BiLSTM+Wi-Fi RSSI 8 0.77 0.59 3.70 428\nEOW 5th Floor BiLSTM+Wi-Fi FTM+Wi-Fi RSSI 16 0.70 0.52 3.52 373\nECS 1st Floor BiLSTM+Wi-Fi FTM 8 1.52 1.31 11.63 426\nECS 1st Floor BiLSTM+Wi-Fi RSSI 8 1.63 1.41 11.89 409\nECS 1st Floor BiLSTM+Wi-Fi FTM+Wi-Fi RSSI 16 0.89 0.70 12.07 446\nNote: Wi-Fi RSSI implies Wi-Fi RSSI and SQI, while Wi-Fi FTM implies RTT using IEEE 802.11mc .\n5th floor is very similar to the other floors. This is further\nevidenced by the BiLSTM with Wi-Fi on ECS 5th floor\nhaving an RMSE of 0.83 m and a MAE of 0.62 m, which\nis comparable to the RMSE of 0.83 m and the MAE of 0.58\nm on EOW 3rd floor. Moreover, the BiLSTM with BLE on\nECS 5th floor has a RMSE of 0.87 m and a MAE of 0.68 m\nthat is similar to the RMSE of 0.88 m and the MAE of 0.56 m\non EOW 3rd floor. The ground truth trajectory is compared to\nthe BiLSTM\u2019s predicted trajectory in Fig. 2d. The predicted\npath has low RMSE at the origin as it is surrounded by many\nrouters. Moreover, the localization RMSE is stable when\nthe trajectory moves upwards. However, the RMSE jump\nincreases drastically to 2.0 m at the end of the path due to\nthe signal reflections at the corner of the hallway.\nThe cumulative distribution function (CDF) of the local-\nization errors is shown in Fig. 2e, and it tells the same story as\nabove. The EOW 3rd floor, EOW 4th floor, and ECS 5th floor\nhave very similar CDFs with expected localization errors of\napproximately 0.89 m. Again, this is due to the floors having\nsimilar map layouts. On the other hand, ECS 1st floor is an\noutlier with significantly different CDF. Most of the errors\nin ECS 1st floor occur between 1.0 m and 3.0 m, raising the\nexpected localization error to 2.3 m. The significant increase\nin error is caused by the ECS 1st floor having more degrees\nof freedom, more possible trajectories, and ambiguity in the\nwireless features.D. PATH ANALYSIS OF DATASET B\nIntroducing Wi-Fi FTM to the Dataset B generally improves\nlocalization accuracy due to having more independent wire-\nless features. For EOW 3rd floor, Table 4 shows the BiLSTM\nwith Wi-Fi RSSI has a RMSE of 0.82 m and a MAE of 0.62\nm. This is very similar to BiLSTM and Wi-Fi RSSI in Dataset\nA. However, using Wi-Fi FTM yields a RMSE of 0.80 m and\na MAE of 0.57 m. Combining Wi-Fi RSSI amd Wi-Fi FTM\ntogether results in a RMSE of 0.75 m and a MAE of 0.55\nm, of which have slightly lower errors than Wi-Fi and BLE\nin Dataset A. For error analysis, the ground truth trajectory\nis compared against the BiLSTM\u2019s predicted trajectory in\nFig. 3a. The path begins at (X = 0 m, Y = 0 m) with low error\nof 0.5 m. As the trajectory moves in the counterclockwise\ndirection, the error stays below 1.0 m. However, the error\nincreases to above 1.5 m at specific corners because the\nrouters\u2019 LoS are broken. Moreover, the error also increases\nto 1.5 m at the end of the trajectory due to signal scattering\nin the room.\nIn the open area of ECS 1st floor, the BiLSTM and Wi-\nFi RSSI yields a RMSE of 1.63 m and a MAE of 1.41 m.\nThe localization error is very large and is comparable to the\nBiLSTM and Wi-Fi in Dataset A. Localization using Wi-Fi\nFTM has a RMSE of 1.52 m and a MAE of 1.31 m, of which\nhas little change in error. Combining Wi-Fi RSSI and Wi-Fi\nFTM drastically lowers the RMSE to 0.89 m and the MAE to\n0.70 m because having more independent wireless features\ndecreases the position ambiguity in localization. Moreover,\nFIGURE 3 :BiLSTM\u2019s predicted locations vs ground truth at: a) EOW 3rd floor b) EOW 4th floor c) ECS 1st floor d) probability distributions\nof Dataset B Wi-Fi+FTM\nhaving more features increases redundancy in case one of the\nfeatures is corrupted by the channel noise. The ground truth\ntrajectory is compared to the BiLSTM\u2019s predicted trajectory\nin Fig. 3c. The trajectory at the origin starts a high error of\n1.3 m. On the first turn, the error drops to 0.5 m. Moreover,\nthe error hovers around 1.0 m when moving in a straight line.\nHowever, the error increases to 2.0 m at the second turn due\nto BiLSTM failing to predict sharp turns. Afterwards, the\nBiLSTM recovers and the error drops below 1.0 m for the\nrest of the path.\nE. CONTACT TRACING WEBSITE\nWe developed a contact tracing website that allows the public\nhealth authorities to find the suspected cases using the details\nof the confirmed cases. Fig. 4 shows an example of the\nwebsite, where the authorities enter the initial date, time, andposition of the confirmed case. Afterwards, the authorities\nenter the MAC address/model name of the specific mobile\ndevice. The pathogen\u2019s lifetime is inputted as the search time\nperiod. A longer time period increases the search window and\nfinds more social contacts. Subsequently, the search graph\ndepth controls the traversal depth of the social contact graph.\nA graph depth of 1, lists suspected cases that have direct\ncontact with the confirmed case. On the other hand, a graph\ndepth of 3, lists suspected cases within 3 social contacts of the\nconfirmed case. Moreover, the graph depth provides indirect\ncontacts together with direct contacts.\nFor simplicity, the confirmed case is marked in red, while\nthe suspected cases are marked in green, blue, orange, purple,\nand pink. On the top right, we plot the x and y positions of\nthe suspected and confirmed cases. The bottom right lists the\nsuspected cases along with the model name, MAC addresses,FIGURE 4 :The contact tracing website allows users to find the suspected cases using the details of the confirmed cases.\nintersection point, and closest distance. The red path inter-\nsects with the green path, and this is indicated in the first row\nof the suspected cases list, where it shows the intersection\npoint of (-0.38 m, -4.17 m) and the closest distance of 0.6\nm. Furthermore, a social contact graph is displayed in the\nbottom left, where it shows a link between the red circle and\nthe green circle.\nVII. CONCLUSION\nWe have created a novel, privacy preserving Wi-Fi and\nBLE contact tracing system for finding the detailed paths of\nthe infected individuals without any user intervention. The\nsystem tracks smartphones, but it does not require smart-\nphone applications, connecting to the routers, or any other\nextraneous devices on the users. A custom built autonomous\nTurtlebot3 is used for site survey simulating user movement\nand smartphone transmission. The smartphones\u2019 received\npower, transmit power, and round trip time are collected by\ncustom ESP32C3 routers. Even though MAC randomization\nis employed in modern smartphones, we have defeated it to\ntrack many devices. Afterwards, the wireless parameters col-\nlected are converted to signal path loss and ToF, of which the\nBiLSTM takes and predicts the absolute paths of the users.The localization performance and the RMSE is always below\n0.9 m for Wi-Fi RSSI + Wi-Fi FTM. Public health authorities\ncan use the designed website to find the paths of the con-\nfirmed cases and suspected cases, together with their MAC\naddresses/smartphone model specific information. They can\nalso track indirect contact transmissions originating from\nsurfaces and droplets.\nREFERENCES\n[1] D. Majra, J. Benson, J. Pitts, and J. Stebbing, \u201cSARS-CoV-2 (COVID-19)\nsuperspreader events,\u201d Journal of Infection, 2020.\n[2] K. T. Eames and M. J. Keeling, \u201cContact tracing and disease control,\u201d Pro-\nceedings of the Royal Society of London. Series B: Biological Sciences,\nvol. 270, no. 1533, pp. 2565\u20132571, 2003.\n[3] R. A. Kleinman and C. Merkel, \u201cDigital contact tracing for COVID-19,\u201d\nCMAJ, vol. 192, no. 24, pp. E653\u2013E656, 2020.\n[4] S. Altmann, L. Milsom, H. Zillessen, R. Blasone, F. Gerdon, R. Bach,\nF. Kreuter, D. Nosenzo, S. Toussaert, J. Abeler et al., \u201cAcceptability of app-\nbased contact tracing for COVID-19: Cross-country survey study,\u201d JMIR\nmHealth and uHealth, vol. 8, no. 8, p. e19857, 2020.\n[5] R. Hinch, W. Probert, A. Nurtay, M. Kendall, C. Wymant, M. Hall,\nK. Lythgoe, A. B. Cruz, L. Zhao, A. Stewart et al., \u201cEffective configu-\nrations of a digital contact tracing app: a report to NHSX,\u201d Retrieved July,\nvol. 23, p. 2020, 2020.\n[6] N. Nanthini, B. M. Shankar, S. S. Kumar, and R. S. Ganesh, \u201cDeep\nlearning approach for minimizing disease spread using face identification\nand contact tracing,\u201d 2020 Fourth International Conference on I-SMAC(IoT in Social, Mobile, Analytics and Cloud)(I-SMAC), pp. 527\u2013532,\n2020.\n[7] M. Yaghi, T. Basmaji, R. Salim, J. Yousaf, H. Zia, and M. Ghazal, \u201cReal-\ntime Contact Tracing During a Pandemic using Multi-camera Video Object\nTracking,\u201d 2020 International Conference on Decision Aid Sciences and\nApplication (DASA), pp. 872\u2013876, 2020.\n[8] J. Gardy, J. Johnston, S. Sui, V . Cook, L. Shah, and et al., \u201cWhole-genome\nsequencing and social-network analysis of a tuberculosis outbreak,\u201d New\nEngland Journal of Medicine, vol. 364, no. 8, pp. 730\u2013739, 2011.\n[9] Hallam Stevens and Monamie Bhadra Haines, \u201cTraceTogether: Pandemic\nResponse, Democracy, and Technology,\u201d East Asian Science, Technology\nand Society: An International Journal, vol. 14, no. 3, pp. 523\u2013532, 2020.\n[Online]. Available: https://doi.org/10.1215/18752160-8698301\n[10] T. Sharon, \u201cBlind-sided by privacy? Digital contact tracing, the Ap-\nple/Google API and big tech\u2019s newfound role as global health policy\nmakers,\u201d Ethics and Information Technology, vol. 23, no. 1, pp. 45\u201357,\n2021.\n[11] S. Ahmed, Y . Xiao, T. T. Chung, C. Fung, M. Yung, and D. D. Yao,\n\u201cPrivacy guarantees of Bluetooth Low Energy contact tracing: A case\nstudy on COVIDWISE,\u201d Computer, vol. 55, no. 2, pp. 54\u201362, 2022.\n[12] K. Woodward, E. Kanjo, D. O. Anderez, A. Anwar, T. Johnson, and\nJ. Hunt, \u201cDigitalPPE: low cost wearable that acts as a social distancin-\ngreminder and contact tracer,\u201d Proceedings of the 18th Conference on\nEmbedded Networked Sensor Systems, pp. 758\u2013759, 2020.\n[13] T. Shelby, T. Caruthers, O. Y . Kanner, R. Schneider, D. Lipnickas, L. E.\nGrau, R. Manohar, L. Niccolai et al., \u201cPilot evaluations of two Bluetooth\ncontact tracing approaches on a university campus: Mixed methods study,\u201d\nJMIR Formative Research, vol. 5, no. 10, p. e31086, 2021.\n[14] L. Reichert, S. Brack, and B. Scheuermann, \u201cA survey of automatic contact\ntracing approaches using Bluetooth Low Energy,\u201d ACM Transactions on\nComputing for Healthcare, vol. 2, no. 2, pp. 1\u201333, 2021.\n[15] Q. Zhao, H. Wen, Z. Lin, D. Xuan, and N. Shroff, \u201cOn the accuracy of mea-\nsured proximity of Bluetooth-based contact tracing apps,\u201d International\nConference on Security and Privacy in Communication Systems, pp. 49\u2013\n60, 2020.\n[16] D. J. Leith and S. Farrell, \u201cCoronavirus contact tracing: Evaluating the po-\ntential of using bluetooth received signal strength for proximity detection,\u201d\nACM SIGCOMM Computer Communication Review, vol. 50, no. 4, pp.\n66\u201374, 2020.\n[17] P. Di Marco, P. Park, M. Pratesi, and F. Santucci, \u201cA Bluetooth-based\narchitecture for contact tracing in healthcare facilities,\u201d Journal of Sensor\nand Actuator Networks, vol. 10, no. 1, p. 2, 2021.\n[18] E. Hern\u00e1ndez-Orallo, C. T. Calafate, J.-C. Cano, and P. Manzoni, \u201cEvalu-\nating the effectiveness of COVID-19 Bluetooth-based smartphone contact\ntracing applications,\u201d Applied Sciences, vol. 10, no. 20, p. 7113, 2020.\n[19] P. G. Madoery, R. Detke, L. Blanco, S. Comerci, J. Fraire, A. G. Montoro,\nJ. C. Bellassai, G. Britos, S. Ojeda, and J. M. Finochietto, \u201cFeature\nselection for proximity estimation in COVID-19 contact tracing apps based\non Bluetooth Low Energy (BLE),\u201d Pervasive and Mobile Computing,\nvol. 77, p. 101474, 2021.\n[20] M. Cunche, A. Boutet, C. Castelluccia, C. Lauradoux, and V . Roca, \u201cOn\nusing Bluetooth-Low-Energy for contact tracing,\u201d Inria Grenoble Rh\u00f4ne-\nAlpes; INSA de Lyon, 2020.\n[21] H. Gorji, M. Arnoldini, D. F. Jenny, A. Duc, W.-D. Hardt, and P. Jenny,\n\u201cSTeCC: Smart Testing with Contact Counting Enhances COVID-19\nMitigation by Bluetooth app based contact tracing,\u201d medRxiv, 2020.\n[22] T. M. Yasaka, B. M. Lehrich, and R. Sahyouni, \u201cPeer-to-peer contact\ntracing: development of a privacy-preserving smartphone app,\u201d JMIR\nmHealth and uHealth, vol. 8, no. 4, p. e18936, 2020.\n[23] I. Nakamoto, S. Wang, Y . Guo, and W. Zhuang, \u201cA QR code\u2013based contact\ntracing framework for sustainable containment of COVID-19: Evaluation\nof an approach to assist the return to normal activity,\u201d JMIR mHealth and\nuHealth, vol. 8, no. 9, p. e22321, 2020.\n[24] A. S. Hoffman, B. Jacobs, B. van Gastel, H. Schraffenberger, T. Sharon,\nand B. Pas, \u201cTowards a seamful ethics of Covid-19 contact tracing apps?\u201d\nEthics and Information Technology, pp. 1\u201311, 2020.\n[25] D. Mobo, A. L. R. Garcia et al., \u201cUsing automated contact tracing system\napp with QR code to monitor and safeguard parishioners against COVID-\n19 at St. Anthony of Padua Parish, Subic, Zambales,\u201d American Research\nJournal of Computer Science and Information Technology, vol. 4, no. 1,\npp. 1\u20134, 2020.\n[26] S. Wang, S. Ding, L. Xiong et al., \u201cA new system for surveillance\nand digital contact tracing for COVID-19: spatiotemporal reporting overnetwork and GPS,\u201d JMIR mHealth and uHealth, vol. 8, no. 6, p. e19457,\n2020.\n[27] A. Trivedi, C. Zakaria, R. Balan, A. Becker, G. Corey, and P. Shenoy,\n\u201cWiFiTrace: Network-based contact tracing for infectious diseases Using\npassive WiFi sensing,\u201d Proceedings of the ACM on Interactive, Mobile,\nWearable and Ubiquitous Technologies, vol. 5, no. 1, pp. 1\u201326, 2021.\n[28] G. Li, S. Hu, S. Zhong, W. L. Tsui, and S.-H. G. Chan, \u201cvContact: Private\nWiFi-based IoT contact tracing with virus lifespan,\u201d IEEE Internet of\nThings Journal, 2021.\n[29] K. Fallahi, C.-T. Cheng, and M. Fattouche, \u201cRobust Positioning Systems\nin the Presence of Outliers Under Weak GPS Signal Conditions,\u201d IEEE\nSystems Journal, vol. 6, no. 3, pp. 401\u2013413, 2012.\n[30] V . Gokhale, G. M. Barrera, and R. V . Prasad, \u201cFEEL: Fast, Energy-\nEfficient Localization for Autonomous Indoor Vehicles,\u201d arXiv preprint\narXiv:2102.00702, 2021.\n[31] J. Tiemann and C. Wietfeld, \u201cScalable and precise multi-UA V indoor\nnavigation using TDOA-based UWB localization,\u201d 2017 international\nconference on indoor positioning and indoor navigation (IPIN), pp. 1\u20137,\n2017.\n[32] V . Moreno, M. A. Zamora, and A. F. Skarmeta, \u201cA low-cost indoor\nlocalization system for energy sustainability in smart buildings,\u201d IEEE\nSensors Journal, vol. 16, no. 9, pp. 3246\u20133262, 2016.\n[33] H. Obeidat, W. Shuaieb, O. Obeidat, and R. Abd-Alhameed, \u201cA review\nof indoor localization techniques and wireless technologies,\u201d Wireless\nPersonal Communications, pp. 1\u201339, 2021.\n[34] M. T. Hoang, B. Yuen, X. Dong, T. Lu, R. Westendorp, and K. Reddy,\n\u201cRecurrent neural networks for accurate RSSI indoor localization,\u201d IEEE\nInternet of Things Journal, vol. 6, no. 6, pp. 10 639\u201310 651, 2019.\n[35] M. T. Hoang, Y . Zhu, B. Yuen, T. Reese, X. Dong, T. Lu, R. Westendorp,\nand M. Xie, \u201cA soft range limited k-nearest neighbors algorithm for indoor\nlocalization enhancement,\u201d IEEE Sensors Journal, vol. 18, no. 24, pp.\n10 208\u201310 216, 2018.\n[36] B. Kane, C. A. Zajchowski, T. R. Allen, G. McLeod, and N. H. Allen, \u201cIs it\nsafer at the beach? Spatial and temporal analyses of beachgoer behaviors\nduring the COVID-19 pandemic,\u201d Ocean and Coastal Management, vol.\n205, p. 105533, 2021.\n[37] R. Amsters and P. Slaets, \u201cTurtlebot 3 as a robotics education platform,\u201d\nInternational Conference on Robotics in Education (RiE), pp. 170\u2013181,\n2019.\n[38] E. Er \u02ddos, M. Dahl, K. Bengtsson, A. Hanna, and P. Falkman, \u201cA ROS2\nbased communication architecture for control in collaborative and intelli-\ngent automation systems,\u201d Procedia Manufacturing, vol. 38, pp. 349\u2013357,\n2019.\n[39] J. Martin, T. Mayberry, C. Donahue, L. Foppe, L. Brown, C. Riggins,\nE. C. Rye, and D. Brown, \u201cA Study of MAC address randomization in\nmobile devices and when it fails,\u201d Proceedings on Privacy Enhancing\nTechnologies, vol. 4, pp. 268\u2013286, 2017.\n[40] Q. Robyns, Bonne and Lamotte, \u201cNoncooperative 802.11 MAC Layer\nfingerprinting and tracking of mobile devices,\u201d Hindawi Security and\nCommunication Networks, vol. 5, pp. 1\u201327, 2017.\n"}