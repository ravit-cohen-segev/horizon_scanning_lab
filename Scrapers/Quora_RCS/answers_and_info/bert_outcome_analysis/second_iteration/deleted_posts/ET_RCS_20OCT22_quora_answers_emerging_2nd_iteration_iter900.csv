,Answer,followerCount,name,upvoteCount,answerCount,answerViews,question
0,"The use of the word fabric is simply a crutch to help our poor human minds try to grasp the concept of time and space being interrelated.  There is no ""fabric"" or layer or surface or cloth or woven pattern, etc. to space time.  It is a functional concept primarily known to us only by mathematics.  To ""experience"" any aspects of space-time, we must inject very high speed, very large distances and highly accurate metrics into our thinking.  Even then, we are only capable of small scale effects.  We can, of course, model or compute changes on any scale desired by making assumptions or imagining vThe use of the word fabric is simply a crutch to help our poor human minds try to grasp the concept of time and space being interrelated.  There is no ""fabric"" or layer or surface or cloth or woven pattern, etc. to space time.  It is a functional concept primarily known to us only by mathematics.  To ""experience"" any aspects of space-time, we must inject very high speed, very large distances and highly accurate metrics into our thinking.  Even then, we are only capable of small scale effects.  We can, of course, model or compute changes on any scale desired by making assumptions or imagining values and scales that will yield large and obvious effects - this includes math or modeled abrupt changes that might be construed as a tear or hole.That's the official and boring answer.  Now let's kick in some thinking outside the box.  Space and time are affected by speed and gravity so what if you could negate gravity and change the concept of speed?  Would that alter time and space as we know it?  OK, here's a thought experiment - The Higgs Field has been found to be the force that imparts mass to particles.  Mass creates gravity.  The Higgs Field is created by the  Higgs Boson.  The Higgs Boson is a particle that seems to permeate the entire universe but what if it is NOT evenly distributed.  In fact, what if we could find some energy, frequency, force, emission or radiation that can move, repel, attract or negate the Higgs Boson?  Not all that impossible considering forces and energy levels that exist in super novas, high powered lasers, etc.If we can vacate a space of the Higgs Boson, then most likely the Higgs Field would also be vacated-  That means that the particles of matter inside of this space that has no Higgs Field - will have no mass and therefore no gravity.  Without mass, the laws of physics say that any force would push the matter to the speed of light very easily - think ""photons"".  So, if we have a space ship that has a device that creates a bubble around the ship so that there are no Higgs Bosons within the bubble, then the ship will have no mass.  It will be weightless.  Now we turn on an ion engine that ejects electrons at the speed of light.  It will easily push the ship to the speed of light.  Because the people in the ship also have no mass, there is no momentum or inertia so they will have no sense of speed.  Even if they took a 90 degree turn at light speed.You might think of this bubble that is emptied of Higgs to be a warping of the Higgs Field - you might call it a warp field.If I can go at light speed because I am inside of this warp field, what happens to the time dilation prediction of Einstein's equation?  If I can move at light speed, how does space relate to distance and time if the speed is C and time is outside the reference field of the rest of the universe?At speed C, time stops for those traveling at that speed so you can travel billions of miles at that speed while someone not traveling with you experiences almost no time lapse.  The net effect is to appear that the distance has been reduced to almost nothing.  Is that a hole in space-time?  Is that a tear in space time?  All we can do is use our imagination.",2 followers,Richard Muller,4.4K,2.3K,202M,https://www.quora.com/If-we-consider-space-time-as-a-fabric-then-can-we-tear-it-or-cut-a-hole-through-it
1,"If you are comfortable with thinking of space as a fabric, then you also need to get comfortable with thinking that your scissors or ice-pick are also made of the same fabric. Then think about cutting fabric with fabric scissors or trying to puncture the fabric with a fabric ice-pick.Black holes are like cysts in space, but black holes will eventually evaporate and space will reoccupy the entire region as if no hole had ever been there.Space does not willingly cut, fold, staple or mutilate though it will happily bend and  stretch. It's very much the ideal self-mending material.9",614 followers,Byomkesh Panda,618,208,1.5M,https://www.quora.com/If-we-consider-space-time-as-a-fabric-then-can-we-tear-it-or-cut-a-hole-through-it
2,"Black holes, White holes, and Wormholes all cause the real world version of what you're thinking of. The Large Hadron Collider creates small ones every day. We can create an artificial black hole by firing laser beams into a mirrored sphere that all focus on one point at the center. The energy needed is insane, but give us another 50 years and we could be able to make one. It’s called a kugelblitz.But, just to be clear: There is nothing that actually “tears” the fabric. The dimensions are infinite from our perspective. We can no more escape through a “tear” than a drawing could escape the papBlack holes, White holes, and Wormholes all cause the real world version of what you're thinking of. The Large Hadron Collider creates small ones every day. We can create an artificial black hole by firing laser beams into a mirrored sphere that all focus on one point at the center. The energy needed is insane, but give us another 50 years and we could be able to make one. It’s called a kugelblitz.But, just to be clear: There is nothing that actually “tears” the fabric. The dimensions are infinite from our perspective. We can no more escape through a “tear” than a drawing could escape the paper its drawn on. It would take more energy than exists within the universe to ever escape it. And if we somehow could; the laws of reality that make us up (gravity, EM, Strong, Weak) would all cease to work in the same way that we need. Our atoms would breakdown and even they would break down and the energy they give off would even might fall apart. Its more likely than not. But we can't be sure.Ockham's Razor would dictate: Entering such a “nothing” would make us nothing as well.","28,175 followers",Garrett Reisman,16.2K,0,0,https://www.quora.com/If-we-consider-space-time-as-a-fabric-then-can-we-tear-it-or-cut-a-hole-through-it
3,"The question is:Scientists have shown that if we do, indeed, consider space-time as a fabric then it is possible to, for instance, distort it with mass or create wormholes connecting different time zones. It is said that Einstein’s equations allow this. However, we don’t seem to be any nearer in understanding our (dual) universe and I think it’s time for a complete rethink and I wouldn’t rule out Chaos being involved as many ancient peoples thought (or were told).",0 followers,Ashok Bishnoi,12.8K,314,7.6M,https://www.quora.com/If-we-consider-space-time-as-a-fabric-then-can-we-tear-it-or-cut-a-hole-through-it
4,"I wasn’t, you know, actuallyI have thoughts.The first, and largest, is that UNIX was not conceivedI wasn’t, you know, actuallyI have thoughts.The first, and largest, is that UNIX was not conceived in a time when “distributed computing” was even remotely on the radar. Tony Hoare’s “Communicating Sequential Processes” is where things started to jell, and Needham’s and Lauer’s paper is where I mark the start of real work in the space: an operant model for making networks of computers function as de facto a single unit.Note that UNIX per se was ten years old at that point, even though V7 had just started shipping around the time of publication.Note as well that “networks” were just coming into conception at that point as well - prior to around the same time as all this was happening, networks were at best point to point serial connections (and not very damn fast either!). Metcalf formed 3Com, the first commercial source for Ethernet cards in ’79 as well. Which barely worked. And were ridiculously expensive. And initially only available for really, really big systems. I digress.For further context, my good friend the late Bruce Nelson just starting the work that culminated in inventing remote procedure calls as a paradigm in his ’82 dissertation.So.I think we can agree then that UNIX as conceived by Ken and Dennis didn’t have a clue that the world existed outside the very real physical bounds of the single machine on which it ran.Further, shared memory multiprocessors were also thin on the ground. The CMU “PMS” switch that cross-bar’d the memory of 16 PDP-11s together in a “clusterfuck of doom” configuration (not that I have opinions, mind you) which later evolved into the cm* system (still PDP-11s) was very late 70s — ’78 or ’79 I think. I built my first shared-memory machine in ‘81, around the time that BBN was building the Butterfly. (theirs was significantly bigger and arguably more elegant; mine was faster).UNIX was positively creaking with old age by this point.So the issues around which we find problematic behavior of the UNIX file semantics, regarding security and in particular both race conditions and unfederated access control, were not even on the table at any point in the evolution. And by the early 80s, the paradigms were very fully set, and theThe bare economy of the security management and enforcement in the UNIX kernel was mind blowing. Compared to commercial systems of the day, the notion that all I/O happened to a file, and more importantly that files were typeless (I’d like to think that the BCPL origins of UNIX played a part there, but have no confirmation of this) was radically different from say IBM systems where you not only had different file types between tape, cards and disk, but different file types on the different storage media, and god help you if you managed to mis-align your code and your JCL pointing your program at the specific stored bits!The identity and control paradigm was super simple and effective too. A operant entity (“user”) owned it’s processes and files. And as in the real world, was part of “everyone” and also part of at least one (and often many) groups. You could read, edit, or execute based on the union of your permissions and the permissions on the file (which could be anything)As long as you’re on one box, with one single threaded CPU (no weird race conditions) this works swimmingly. Worked swimmingly, for a decade and a half.The introduction of sockets in 4bsd and IPC and shared memory in System V were interesting - they were very carefully crafted to provide off-system access paradigms (sockets much more so than IPC)So the opportunity to say “you know… this whole paradigm gets aPart of this was also the firestorm raging over in TCP/IP-land where the notion of identity and federated identity was beaten to death, burned, and then the ashes scattered in moving water time and again. The fear was that we would be creating the opportunity for “settlements” — basically charges for usage of the network, much like the then hideously expensive long distance voice networks — which would completely stifle all experimentation with the networks.Think about it: if it cost you real money every time you sent a DM on your favorite platform, how many cat videos and memes would get passed? Face it, if every packet had to pay a toll, since ’81 when TCP went on-line, the world as we know it would not have come to exist.It was the right call, for sure. But it brought a lot of pain with it, and for my money the biggest of those pain points is that we have no way to truly and effectively tie a network action to a known identity.Which is where the security model breaks on cross-system UNIX file permissions.That was true even back in the very early days, when NFS rolled out in ‘84. It was all based on UNIXWe’ve come up with, over time, a number of interesting work-around and hedges and hacks in this space. But nothing - literally nothing - in common usage will let a particular human being identify themselves across the board to every computing system with which they interact in a way that assures that system (where/what-ever it is) that the remote interaction is in fact coming from that person.This is a central issue in identity and security.We had an opportunity to prevent this almost 40 years ago, but other pressures prevailed. I personally think that given what we knew at the time, that those were the right decisions. Remember, we were still arguing about how big “the Internet” was going to be, and most of the best guesses were in the “maybe a hundred thousand systems” range (!).So yeah, there are deficits in the design of UNIX. And they’re completely appropriate for the time and context of the time.",0 followers,Lucas Taylor,2.6K,1.7K,2M,https://www.quora.com/If-we-consider-space-time-as-a-fabric-then-can-we-tear-it-or-cut-a-hole-through-it
5,"Did Unix “everything is a file” turn out to be a bad idea since it enables some types of security vulnerabilities?Nope.It enabled a lot control that prevents most security vulnerabilities. Enforced separation between system and user, separation between groups of users and other groups of users, and between everyone else and designated user/groups.That foundation became more generalized by the addition of access control lists.Sure, some things were over looked (the ability to have reliable write only append to a file for instance), which was solved by using a service process to manage the additDid Unix “everything is a file” turn out to be a bad idea since it enables some types of security vulnerabilities?Nope.It enabled a lot control that prevents most security vulnerabilities. Enforced separation between system and user, separation between groups of users and other groups of users, and between everyone else and designated user/groups.That foundation became more generalized by the addition of access control lists.Sure, some things were over looked (the ability to have reliable write only append to a file for instance), which was solved by using a service process to manage the additions…It promoted the use of complex data storage by using service processes… (now called databases).NFS file access has expanded the list of controls on files from just the read/write/execute list… but still being mediated by service processes…The one known weak point was having an all powerful single identity… which has also been addressed by removing access to that identity on some systems. Shown to work.It has even provided the foundation for expanded security control by adding the definition of mandatory access controls that can be used to impose controls that users don’t necessarily have access to.",0 followers,Chris Rapier,2K,495,1.3M,https://www.quora.com/If-we-consider-space-time-as-a-fabric-then-can-we-tear-it-or-cut-a-hole-through-it
6,"Very much so.Let’s say you’re trying to find an uninitialized memory bug in a single-threaded program using a tool like valgrind.But if you have a supercomputer, you can runVery much so.Let’s say you’re trying to find an uninitialized memory bug in a single-threaded program using a tool like valgrind.But if you have a supercomputer, you can runGeneralizing this, single-threaded programs that are performing a search in a sufficiently large space can gain parallel speedup by running lots of them and having each explore a different area of the space.","44,244 followers",Kurt Guntheroth,10.4K,13.7K,166.9M,https://www.quora.com/If-we-consider-space-time-as-a-fabric-then-can-we-tear-it-or-cut-a-hole-through-it
7,"Wow there’s a lot of wrong answers here.The reason clock speeds topped out doesn’t have to do with the speed of light, and the speed of light in solids is only half what it is in vacuum. The processor die isn’t as big as the package, and modern dice hold as many as 16 processors, which are much smaller each than the entire die. All modern processors overlap instruction execution, and individual instructions execute in 10–20 clocks or more.The reason processor speeds topped out is the difficulty of cooling the chip.The two things that consume energy, and thus produce heat in a CMOS device, areWow there’s a lot of wrong answers here.The reason clock speeds topped out doesn’t have to do with the speed of light, and the speed of light in solids is only half what it is in vacuum. The processor die isn’t as big as the package, and modern dice hold as many as 16 processors, which are much smaller each than the entire die. All modern processors overlap instruction execution, and individual instructions execute in 10–20 clocks or more.The reason processor speeds topped out is the difficulty of cooling the chip.The two things that consume energy, and thus produce heat in a CMOS device, are (1) switching state from a 1 to a 0 or from a 0 to a 1, and (2) leakage current when the device is in a steady state. Doubling the clock rate about doubles the number of transitions, so that doubles power consumption, all other things being equal. Designers fight this dissipation by making transistors smaller and voltages lower, so that less energy is dissipated on each transition. But making gates smaller increases the leakage current, so there’s really no way to win. We can still make devices a little smaller, but we can’t make ’em faster just by turning the Moore’s Law process crank. Sorry.Get a chip too hot, and sensitive parts of it melt, with catastrophic results. Just because the bulk of the chip is silicon doesn’t mean the chip has to get hot enough to melt glass. It only needs to get hot enough to melt or chemically alter whatever part is most sensitive.Yes, if you cool a chip with a big-ass fan and heat sink, you can overclock it to 5 GHz. If you bathe it in a nonconductive liquid, you can go faster, and faster still if you cool it with liquid nitrogen, but there’s still a limit that has to do with the thermal conductivity of the die.",10 followers,Ali Kazmi,1K,378,1.7M,https://www.quora.com/If-we-consider-space-time-as-a-fabric-then-can-we-tear-it-or-cut-a-hole-through-it
8,"The current top speed any processor has attained isCurrently, the IBM zEC12 has the highest clock speed for a production (ie not overclocked) CPU and it has a frequency of 5.5 GHz.With the technology we have at the moment, it’d be impossible to make a processor capable of attainingThe current top speed any processor has attained isCurrently, the IBM zEC12 has the highest clock speed for a production (ie not overclocked) CPU and it has a frequency of 5.5 GHz.With the technology we have at the moment, it’d be impossible to make a processor capable of attaining a clock speed of 1 THz. There are a number of factors that play a role in this:The FutureWhile no one knows for sure what the future holds, unless we come up with a new material which somehow defies the laws of physics or we come up with a method to dump the excess heat that’s practical (won’t it be convenient if we could dump all the excess heat to a parallel dimension?), a processor clocked at 1 THz is pretty much impossible.",260 followers,Andrew Lane,739,1.2K,7.3M,https://www.quora.com/If-we-consider-space-time-as-a-fabric-then-can-we-tear-it-or-cut-a-hole-through-it
9,"No. Supercomputers rely on massive parallelism and concurrent execution of hundreds/thousands of threads to provide ""speedup"". However, they are are still limited by the serial execution of each thread, as well as portions of the application that cannot be serialized. (Look up Amdahl's Law)So, unless a single core in the super computer is capable of executing a single threaded application faster than whatever your baseline execution machine is, no speedup can be seen.In fact, in some cases, it may slower. Supercomputers are designed for massive parallelism rather than single threaNo. Supercomputers rely on massive parallelism and concurrent execution of hundreds/thousands of threads to provide ""speedup"". However, they are are still limited by the serial execution of each thread, as well as portions of the application that cannot be serialized. (Look up Amdahl's Law)So, unless a single core in the super computer is capable of executing a single threaded application faster than whatever your baseline execution machine is, no speedup can be seen.In fact, in some cases, it may slower. Supercomputers are designed for massive parallelism rather than single threaded performance. When compared to a desktop processor, some applications may infact be better suited for a desktop processor, which are designed for executing sequential code optimally. This of course is very specific to the system under consideration.Good luck!","3,652 followers",Anthony Yeh,3.5K,392,4.3M,https://www.quora.com/If-we-consider-space-time-as-a-fabric-then-can-we-tear-it-or-cut-a-hole-through-it
