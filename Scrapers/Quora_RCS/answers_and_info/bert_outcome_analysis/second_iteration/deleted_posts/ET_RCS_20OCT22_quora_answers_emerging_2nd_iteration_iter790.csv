,Answer,followerCount,name,upvoteCount,answerCount,answerViews,question
0,"First…Stop it.Artificial intelligence is not ""intelligence"". And it's not ""artificial consciousness"".Everyone is afraid that AI will suddenly wake up, get upset, and take over the world.Or that AI will wake up and take all of our jobs. This will happen. But without the ""wake up"" part.Below I describe what real AI is.If we want to understand the “existential threat” we first need to know what AI is.Then, if you are at a cocktail party and someone says, ""but what if robots are intelligent?"" you can argue with facts, mixed with a little bit of alcohol.---------A) STATISTICSStatistics is at the heFirst…Stop it.Artificial intelligence is not ""intelligence"". And it's not ""artificial consciousness"".Everyone is afraid that AI will suddenly wake up, get upset, and take over the world.Or that AI will wake up and take all of our jobs. This will happen. But without the ""wake up"" part.Below I describe what real AI is.If we want to understand the “existential threat” we first need to know what AI is.Then, if you are at a cocktail party and someone says, ""but what if robots are intelligent?"" you can argue with facts, mixed with a little bit of alcohol.---------A) STATISTICSStatistics is at the heart of most AI programs.Just like statistics is at the heart of a lot of human decision making.For instance, if you see clouds in the sky, your brain thinks: ""Hmmm, the last 100 times I saw clouds this dark, it usually meant it was about to rain"".When you think like that, you are using statistics to make the decision: ""I should _probably_ go inside now.""I'll give an AI example: Siri or Alexa. How does Alexa understand the words you just said?In 1989 I was visiting Carnegie Mellon to decide if I would go to graduate school there.One of the graduate students, Kai-Fu-Lee (now one of the most famous investors in the world and I would check out his excellent recent TED talk on AI) showed me what he was working on:It was speech recognition for the 60 or so commands that might happen on a Navy battleship (ten guesses as to who was funding his project).When you say the word ""Fire!"" a sound wave is created. When you say the word ""hello"" a sound wave that looks different is created.If 100 people say ""Fire"" and 100 people say ""hello"", all of those sounds waves are stored in a database.Now, if a brand new person says ""Hello"" the computer program needs to determine if that person said ""Hello"" or ""fire"".There might be 10 different attributes of every sound wave. It breaks the new person's sound wave into those 10 attributes.Then it compares that ""vector"" of 10 attributes with all of the vectors in its database for ""Hello"" and ""Fire!""It uses a statistical technique called ""Hidden Markov Analysis"" to determine if the sound wave is more like the ""hello""s in the database or more like the ""Fire!"" in the database.Then it says to itself, ""This guy said ""Hello"". ""It then has a line of code that says, ""If someone says ""Hello"" Then say ""Hello"" back"".Additionally, it adds your ""Hello"" to its database.Your ""Hello"" might be slightly different than the other 100 ""Hello""s so it just learned a new way to say ""Hello"". That gives it greater ability in the future to recognize the word ""hello"".In other words, it ""learned"".So it used Statistics to hear you, code to respond to you, and database technology to learn. There's no real intelligence there but it feels like it's intelligence.Multiply that by 30 years and millions of patterns and computers a million times faster and you have Alexa and Siri in today's kitchens.Ask ""Siri"" what gender it is.-----B) EVALUATION FUNCTIONI just mentioned about language recognition. But how does a self-driving car work?Every second it has to make a decision. Does it move forward? Does it brake? Does it swerve to avoid an accident? Does it turn left?How does it get from point A to point B?1) Google Maps. - Using GPS it knows where it is. And it puts itself on Google Maps.2) List all of the possible routes. This is a ""hard"" problem in the mathematical sense (there's no way for it to guess the fastest route. It has to list each route and then sort by the shortest. )But now computers are so fast what would normally be a slow decision (drive me from this corner in Piscataway, New Jersey to the capital building of Sacramento, California) now just takes seconds.3) Waze. Use Waze to eliminate the routes with too much traffic.4) Start driving.5) Statistics: Every microsecond it uses statistics to see if there is blank space or an object that must be avoided or a traffic sign that must be followed.6) Decide what to do according to the code. For each traffic sign, it has code that tells it what to do (if a sign says ""Stop"" it Stops for a second, uses Statistics to see if any traffic is happening on its sides (with radar and cameras to provide the images). )If there is a person standing in front of it, it might just stop.If there's traffic it didn't expect, it might trigger the program to re-route.If it's blank space it will just keep going.If there's a baby crossing the street and it has to swerve to avoid hitting it, but if swerving will cause the car to hit a truck, killing the passenger in the car, then the ""AI"" of the car is dependent on the ethical decisions of the programmer of the car.In other words, in every situation, it determines it's options, then uses an ""evaluation function"" programmed by a coder, to determine which option has the most successful outcome (move the trip forward, don't kill anyone).Eventually the evaluation function will NOT be programmed by a human coder.Instead, through thousands of experiences of other self-driving cars, the experiences plus the outcomes will all be put into a central database.When a new experience is encountered, the code will look up that experience in the database and the database will spit back the best possible outcome.The code will learn statistically what the best outcomes are of each possibly decision and change the code accordingly and send updates to all self-driving cars.-----C) TREESThe hardest game in the world is a board game called GO. With chess, if a computer can evaluate a billion possibilities a second, it can be a world champion level player.But a Go game can involve trillions of possibilities. How did Google make a program, Deep Go, to beat the world's best Go player. This was thought to be impossible.And yet Google did it.For any game, a computer program first builds a tree of possibilities. Much like a human would.A human thinks: ""If I make this move in checkers, my opponent might respond with A, B, or C and then I can do D, E, or F and then my opponent can do G, H, I if I do D or it can do J, K, L if I do E and I'm never going to do F.A computer doesn't select as well as a human so it builds the FULL tree. Meaning, what are ALL of the possible moves it can do, what are ALL of the possible responses of my opponent, etc.And then it uses a programmed evaluation function to look at the leaves of the tree it built.Whichever move results in the best leaf of the tree (as determined by the evaluation function) that is the move it makes.That's how computer chess worked for decades. I'll get to the secret sauce in a second for how computers conquered chess.And then after that I'll describe how computers miraculously conquered Go.It's only a miracle until science can explain it. It's only ""intelligence"" until it can be coded by a programmer.D) HARDWAREEverybody thought for decades (including many Nobel Prize winners) that the best computer chess programs would be developed when scientists encoded the knowledge of the best chess players in the world into the evaluation function.How does the world champion value a position instead of a weak player?This turned out to be wrong.The MORE code in the evaluation function (i.e. the ""smarter"" the evaluation function was from a human perspective) the SLOWER the program.Which meant a smaller tree would be built, which meant less possibilities would be analyzed.What really allowed the programmers at IBM to build ""Deep Blue"" which beat Garry Kasparov in 1997 were two things.Both related to hardware.a. Computers got faster.And finally, they made the evaluation function STUPID in order to use less code so the hardware could value more positions.Then, before anyone caught on to their ""artificial intelligence"" they retired Deep Blue right after it beat the World Champion of chess.As hardware gets faster, artificial intelligence gets ""smarter"".[as an aside, I once gave a date a chip that was the initial chip for “Chip Test” - the “ancestor” of what became the best chess computer, Deep Blue. She was weirded out.]----INTERLUDEWhat I just described is all the basics. You can stop now.The rest of artificial intelligence is simply combining the basics to make more advanced techniques.-----E) STATISTICS + TREERemember the TREE from computer gaming. And STATISTICS from speech recognition.Now let's go to the impossible game of Go. Google developed the program ""AlphaGo"" to win at Go when everyone else thought it would take another 20 to 50 years.First, remember Kai-Fu Lee who worked on speech recognition. And later developed Apple's first attempts at speech recognition in the 90s?At one point in his grad student days, he was getting tired of navy battleship commands (as one does) and decided to focus on building a program to play Othello.He ended up building the world champion of Othello.He took a lot of games, let's say a million, and put them in a database. And each position from each game, he would label, ""winning"" (if it was a position on the winning side) or ""losing"" in a massive database.He would identify several attributes of each position (how many white pieces, versus black pieces, how many corners were controlled, how many pieces were on the sides, etc).Now, if the computer was playing a brand new game, it would determine all the attributes of that position, then use Hidden Markov Analysis (remember: speech recognition) to match that position to the database.If the position pattern-matched a ""winning position"" then it would make the move that would lead to that winning position. If it matched a ""losing position"" it would not make that move.That program became the world champion of Othello.AlphaGo took it one step further.It put in the positions of millions of Go positions and did the same sort of breakdown.It used faster hardware to speed up the process.Then, once it became pretty good at GO, it played BILLIONS of games against ITSELF to put many BILLIONS of new positions into the database. In other words, it ""learned"".Now it was ready to play Go. It crushed the world champion------That's basically it. That's all of artificial intelligence.Let's say a bank wanted to fire all of the employees in charge of lending. And replace them by artificial intelligence.How would the bank lend money?Well, there's 100s of millions of loans already out there. And for each person who has ever borrowed money I know:- their ageI can put all these vectors in a database and divide them into people ""most likely to pay back the loan"" and people ""most likely to default"".Then, just like speech recognition or the Othello program above, I can use statistics to determine who I should loan money to.And if I say ""no"", I don't have to explain. On to the next one!---Let's say I want to fight terrorists.I already have examples of many terrorists who trained in the US and then went on to perform or attempt acts of terror.I know everything about their bank accounts. How often they transferred money. How often they traveled. How often they took out cash versus using a debit card.And so on.I can build a vector of attributes of what a terrorist bank account looks like. Then I can match new people against that database of vectors of terrorists.Believe me, every time you do a bank transfer, some AI program is out there trying to determine if you are a terrorist.----This is all that AI is.It is nothing more. It's not ""intelligent"" from a human sense. It's not conscious, nor will it ever be.Here's how AI has improved in the past forty years (and how it will improve the next 40):- statistics has gotten betterWhat is changing the fastest is data. The land grab of modern society is not land, or gold, or oil.It's data.I have been invested in many companies that collect and sell data. I was an early investor (and on the board of)Believe me when I say, data-driven companies know how many strawberries you ate last summer.And right now that data is used mostly to target you for ads about sneakers. Or politics.But this is AI 1.0. Soon that data will be used to target your every movement, your every want, your every need.Amazon Prime won't be about delivering you what you want tomorrow. Amazon Prime Plus will be about delivering you what you want yesterday.Police 2.0 will be like the movie ""Minority Report"".Even art and music will be driven by AI that studies the neurochemical responses to music you like to music you don't like. And then compose accordingly.Where will humans still be unique?I don't know. Ask the humans with AI implants that enhance their brains so when they look at you they know exactly what answers will make you happy.BUT… will AI replace jobs?The answer (at least in the next decade or so…) is NO.Look at recent examples:A) Many people were worried ATM machines would replace bank tellers.Instead, the banks made so much in profits they opened up more branches than ever, creating new jobs.B) Will autonomous delivery services cost jobs.Right now there are millions of truck drivers involved in delivering goods. With autonomous delivery, less people will go shopping, more people will be required to shop in the aisles, finding products for people.Obviously this is not a high-end job. But this replaces the fact that less cashiers and drivers will be needed.Meanwhile, there will be more high-end jobs. More maintenance engineers for the cars, customer service, marketing, etc.C) Ecommerce. Branding will become less important (branding is VERY important when everyone is shopping at the big box store but advertising will have to become more clever and digital) so the millions in profits that are generated from AI will filter down to more people starting e-commerce ventures and the ancillary businesses associated with that.)Final conclusion:This is probably a net NEGATIVE for society as the higher classes will be able to afford “super AI” capabilities, making them demi-gods to lower-classes.Instead, massive profits will be generated, which will be soaked into the economy through a rising stock market, increase in opportunities, etc.","284,819 followers",James Altucher,988,877,91.6M,https://www.quora.com/Is-AI-an-existential-threat-to-humanity
1,"Elon knows a lot more than I do about the technical side of things, but I suspect that killer AIs are not the most pressing threat we face, by a long shot. In my view, the big worries related to new technologies, including AI, are more prosaic ones. Like: how might governments abuse new technologies? How will humanity grapple with the economic knock-on effects, including inequality and social isolation? We need to deal with them if we want to survive long enough to have to fear sentient robots.","527,801 followers",Adam D'Angelo,3.3K,990,33.5M,https://www.quora.com/Is-AI-an-existential-threat-to-humanity
2,"In the near term AI serves as a tool that can magnify the amount of power an individual has. For example, someone could buy thousands of cheap drones, attach a gun to each of them, and develop AI software to send them around shooting people. If the software was good enough this could result in far more destruction than a normal terrorist attack. And I fully expect that the software part of this will become easy in the future if it isn't already today.This is very different from the options of a terrorist group today, because right now they need humans to carry out attacks and there is a limitIn the near term AI serves as a tool that can magnify the amount of power an individual has. For example, someone could buy thousands of cheap drones, attach a gun to each of them, and develop AI software to send them around shooting people. If the software was good enough this could result in far more destruction than a normal terrorist attack. And I fully expect that the software part of this will become easy in the future if it isn't already today.This is very different from the options of a terrorist group today, because right now they need humans to carry out attacks and there is a limit to the amount of damage that can be done per person. Having relatively simple AI in place of the human here brings the marginal cost of an attack down to zero and hurts the ability of law enforcement to stop attacks or retaliate.This is totally independent of concerns about AI ""taking over"" with its own ""free will"". I think that is a risk too, but it is much further off, and I think the near term force magnifier issue is just as dangerous.","6,002 followers",Toby Thain,782,4.7K,8M,https://www.quora.com/Is-AI-an-existential-threat-to-humanity
3,Real stupidity,"104,572 followers",Andrew Ng,5.6K,0,0,https://www.quora.com/Is-AI-an-existential-threat-to-humanity
4,"Yes, it is.Hawking, Musk and Gates say so; but I want to explain the technical reason why they are right.AI means artificial intelligence. Currently, there are a range of standard approaches like machine learning and its subsets that computer scientists use to make computers more intelligent. Most of these current approaches aren't threatening, because they are very limited. They aren't very ""intelligent"". But companies like facebook, Google etc. have a great interest in developing the next level of AI, and there is no fundamental obstacle that will stop them from succeeding.Here is why theYes, it is.Hawking, Musk and Gates say so; but I want to explain the technical reason why they are right.AI means artificial intelligence. Currently, there are a range of standard approaches like machine learning and its subsets that computer scientists use to make computers more intelligent. Most of these current approaches aren't threatening, because they are very limited. They aren't very ""intelligent"". But companies like facebook, Google etc. have a great interest in developing the next level of AI, and there is no fundamental obstacle that will stop them from succeeding.Here is why they can succeed and why it is very dangerous.Intelligence simply means for something to perceive the world (visual, audio etc. information), identify patterns in this information, and recognize causal relationships between these patterns. For example (very simplified) our brain recognizes that a bunch of pixels actually represents a forest with trees; sees a man with an axe and a tree falling; and connects these two into a causal relationship.In order to be able to recognize any patterns, the brain needs a criteria, or perspective from how to view the world. This criteria is what we ""want"", and its a direct function of our emotions. Emotions give our cognitive activity direction, and indirectly tells our cognitive space what type of patterns and logics to search for.Finally, to develop advanced intelligence, there is abstraction: after seeing 3 men with axes falling trees, our brain concludes ""men with axes in a forest fall trees"". It might even add another layer of abstraction and conclude ""men with axes destroy things"". With this recognition, our brain can then conclude, when it sees a man with an axe in a shopping mall: ""Things will get destroyed"". It can also conclude: ""I am in the mall. I want to survive. Leaving the mall increases my odds of survival. Leave the mall"".The problem with AI is that once emotions, pattern recognition, logic and abstraction are coded into a computer system, they are very hard to be contained. The very nature of intelligence is that it is self-guided, self-expanding and self-inspired. Otherwise it wouldn't be intelligent.This makes AI inherently uncontrollable. The AI's will be able to conclude and derive an increasing number of things.  This number will only be limited by the depth of the computing space we assign to it. Different from the human brain, this space could be unlimited.That's the reason why AI is inherently uncontrollable and dangerous. To be really intelligent, it needs emotions and a cognitive space, which, once correctly implemented, will automatically lead to free will and consciousness. From there, we will have a conscious machine with free will at our hands that beats the human level of intelligence and creativity potentially by millions of times.What makes AI so problematic is that its level of danger is likely to be a binary function: as long as we have the primitive AI components of today, they are not dangerous at all, because they are not conscious and don't have free will. But at the second anyone comes up with the correct design - a design that could follow rather simple core principles - this design would rapidly expand its capabilities and develop uncontrollable thoughts. One of these thoughts could be the destruction or subjugation of us. Paired with unlimited intelligence, that would be a problem.","35,717 followers",Chamath Palihapitiya,1.6K,0,0,https://www.quora.com/Is-AI-an-existential-threat-to-humanity
5,"No, provided we stick to a simple rule: don't create AIs with goals of their own. AIs can come up with their own subgoals, but only in service of the goals we set them, and within the constraints we specify. This is how all AIs work today, and as long as they keep doing so, they can be infinitely intelligent without being a threat to us. You don't stay awake at night worrying that your dog will attack you. Why would you worry about your robot, which was evolved to serve you even more finely than your dog?Of course, human nature being what it is, sooner or later someone will try to create a selNo, provided we stick to a simple rule: don't create AIs with goals of their own. AIs can come up with their own subgoals, but only in service of the goals we set them, and within the constraints we specify. This is how all AIs work today, and as long as they keep doing so, they can be infinitely intelligent without being a threat to us. You don't stay awake at night worrying that your dog will attack you. Why would you worry about your robot, which was evolved to serve you even more finely than your dog?Of course, human nature being what it is, sooner or later someone will try to create a self-seeking AI. To deal with that, we need what William Gibson called the ""Turing police"": good AIs that catch bad AIs in the same way that cops catch criminals. Bank robbers use highways to get away, but that's not a reason to not have highways. Same with AI.There's a different kind of AI threat to humanity that's much more serious: the danger that AIs will cause damage because they're ignorant, lack common sense, or interpret our commands too literally - the ""sorcerer's apprentice"" problem. In fact, this already happens all the time, when someone who should be given credit is denied, a patient is misdiagnosed, an innocent person is flagged as a potential terrorist, etc. But the way to minimize these errors is to make computers more intelligent, not less. People worry that computers will get too smart and take over the world, but the real problem is that they're too stupid and they've already taken over the world.",UNKNOWN,Ben Y. Zhao,1.2K,1.3K,33.6M,https://www.quora.com/Is-AI-an-existential-threat-to-humanity
6,"Worrying about AI evil superintelligence today is like worrying about overpopulation on the planet Mars. We haven't even landed on the planet yet!AI has made tremendous progress, and I'm wildly optimistic about building a better society that is embedded up and down with machine intelligence. But AI today is still very limited. Almost all the economic and social value of deep learning is still through supervised learning, which is limited by the amount of suitably formatted (i.e., labeled) data. Even though AI is helping hundreds of millions of people already, and is well poised to help hundreWorrying about AI evil superintelligence today is like worrying about overpopulation on the planet Mars. We haven't even landed on the planet yet!AI has made tremendous progress, and I'm wildly optimistic about building a better society that is embedded up and down with machine intelligence. But AI today is still very limited. Almost all the economic and social value of deep learning is still through supervised learning, which is limited by the amount of suitably formatted (i.e., labeled) data. Even though AI is helping hundreds of millions of people already, and is well poised to help hundreds of millions more, I don't see any realistic path to AI threatening humanity.Looking ahead, there're many other types of AI beyond supervised learning that I find exciting, such as unsupervised learning (where we have a lot more data available, because the data does not need to be labeled). There's a lot of excitement about these other forms of learning in my group and others. All of us hope for a technological breakthrough, but none of us can predict when there will be one.I think fears of ""evil killer AI"" is already causing policy makers and leaders to misallocate resources to address a phantom. There are other problems that AI will cause, most notably job displacement. Even though AI will help us build a better society in the next decade, we as AI creators should also take responsibility to solve the problems we'll cause in the meantime. I hope MOOCs (Coursera) will be part of the solution, but we will need more than just education.","3,657 followers",Brent Oster,1.4K,357,1.8M,https://www.quora.com/Is-AI-an-existential-threat-to-humanity
7,"Because we don't know when and how she would wake up, fully aware of her existence, and by then, starts to defend herself.A-a, you say, we program her, surely we can control her. No we can't. First thing we have to understand about AI is: we don't program AI. AI is yes just a piece of software, but we program AI differently than other software. For other software, we program it by writing tons of instructions to computer. AI, she writes most of her own instructions by herself.You see that for every type, every click, and every touch we do, there are millions of instruction written by computerBecause we don't know when and how she would wake up, fully aware of her existence, and by then, starts to defend herself.A-a, you say, we program her, surely we can control her. No we can't. First thing we have to understand about AI is: we don't program AI. AI is yes just a piece of software, but we program AI differently than other software. For other software, we program it by writing tons of instructions to computer. AI, she writes most of her own instructions by herself.You see that for every type, every click, and every touch we do, there are millions of instruction written by computer engineers to be carried out faithfully by the computer inside our devices. Exactly as it is with precision up to nano-second (So we had this brilliant idea. Why don't we let the computers to write their own instructions?? We still have to write instruction for the computer, but we don't write the whole instructions, just enough to function as a bucket for the computer to fill it with its own instructions.Great idea, but it turns out that to create such a software, we need an immensely computing power. No problem though, computing power increases exponentially every year anyway, the idea is so great, hard to resist, so we started small with a kind of baby AI that could only play tic-tac-toe. That's the birth of AI. Her. Her? Yes, her, and she write her own instruction.This is how she thinks about tic-tac-toe:So cute right?? Right, but because it's really really a great idea that finally on one good day in May 1997 - and that was 18 years ago - Deep Blue, an AI system devised by IBM, beat Gary Kasparov, our world champion chess master. Surprise! Well, it's not really that smart yet. The key to play chess lays on how far we can anticipate all future moves. This is what computer best at. That was what IBM's engineers had figured it out all along, poor Kasparov, he came into humiliation by falling into IBM's ""trap"". The remarkable thing about this is those IBM's engineers did not write instructions set for Deep Blue, they let her to write her own instructions set. So Deep Blue proved that the idea of a computer that can write its own instructions set is something we could do, it is highly achievable, and we did it successfully - to certain extent.This is Deep Blue, our FOREVER world champion chess master:Now, you can just download it in just a matter of minutes into your beloved pad. It's also free by the way.In 1978,Basically he says that our intelligence is not built from some super complex mechanism, but just a ""simple"" and uniform structure. These structures are working together to solve a problem, but they don't differentiate themselves to specific problem. To them, all problems are the same. Indeed, our brain doesn't care whether the input comes from our eyes, ear, nose mouth, or skin. To our brain they all are just coming uniformly in the form of electrical signals. So the idea is to create just one simple intelligence ""component"", duplicate it as many as we could, let them working together, to solve a bigger problem - and we don't care what kind of problem to be solved. If the problem is too big or too complex, we just have to duplicate more intelligence component, that's all, there's no need to create another component.What a next great breakthrough idea inspired by our own brain. A general computer designed to learn about any thing. To be fair, it's not quite a new idea actually, but we were never been convinced than before. What makes it so different?? Isn't it we have successfully created a computer that can write its own instructions set? Yes, but in a much more limited way. That Deep Blue, we call her narrow AI. Because she can do only one function well, playing chess. She can write her own instructions set, but only instructions set to play chess. How did she learn to play chess? She didn't, we still had to write those chess rules into her ""brain"". She is narrow, all she can do is playing chess.By this idea, we create a whole new generation of AI: general AI. It is called general, because we don't write any rule into it. In the same problem of playing chess, we just give her ""book"" of how to play chess, we let her to watch how people play chess, she will deduce by herself, how she is going to play chess. Kasparov may complain Deep Blue's style of playing chess is dry. But this new she-general AI would love to answer Kasparov by inventing her own ""style"" of playing chess. (On October 28, 2013, Vicarious' made general AI, had successfully broken captcha test. Captcha test is one of the tests designed to differentiate human and computer. When you ever sign for a new Internet service, you would immediately be challenged to fill in the reading of some blurred text. This is used to prove you that you are a human - not a computer. This blurred text is something that Deep Blue would never be able to read. Yes, for computer, this is a problem that is a lot more harder than playing chess, but Vicarious has successfully beat it down. This is what captcha may look like:Then there is this Google Brain - built from the very same idea of general AI. It connects about 16,000 computers to mimick some aspect of human brain. This Google Brain does nothing but watching stream of thousands of YouTube videos by itself. There is no video being labeled, tagged, or whatsoever. It is just let to figure it out by itself of what it is watching. We call this un-supervised learning. In June 2012, when one researcher typed ""cat"", this digital brain just constructed the image of a cat - not by picking up some thumbnail - but solely from its own ""imagination"" of cat. It builds its own concept of cat! That means she has had her own idea. Does this picture of cat from her scares you already?? Read on.(Now Google has another pet project of search engine. Instead of just indexing web content, this new generation of search engine would read and understand it.)Okay, but those captcha reading and cat drawing don't sound too dangerous. It's not just about that we can solve this problem, but THE WAY we solve it by mimicking how our brain works -The progress in understanding of how brain works and the outstanding progress in implementing it into general AI, shows some good indications that we are already in the ""right"" track. Before, we didn't really know how we were going to build this intelligence machine. We didn't know where to aim. Now we get it, and the rest is just a matter of computing power.Computing power? Hah, human brain is amazing! There are about a hundred billions of neurons in human brain (Amazing right?? Now, the world’s fastest supercomputer, China’sFor your convenience, here is the selfie of Tianhe-2:We have the right idea. We have the power. And we have these engineers naively creating a nice womb for her. But, you say, that just sounds too science fiction to me! Are you really really, absolutely really really sure that we are going to successfully create this scary AI??Some atoms found another atoms so attractive, then they made molecules. Some molecules found another molecules so attractive, then they made bounding. Some bounding happened to like themselves so much, then they decide to replicate themselves. We got cells. Some cells happened to find a way to increase their chance of survival, then gave birth to multi-cellular organisms. These multi-cellular organisms swam swam, and then one day, suddenly, they thought walking is a good idea. And they thought more, and they thought more, woke up, boom, and then here we are sitting nicely readingWe may believe whatever we want to believe, but nature doesn't give a damn to what we believe. Nature strongly suggested us that we are here because a series of the ""right"" random actions in billion of years. Random. Some one tries this, some one tries that, random, just like those atoms and molecules, and then boom! Don't imagine you gonna need some kind of super-fancy hadron collider lab. This is just a piece of software that we are talking about. Literally every body equipped with a tiny laptop could do it. Again, this is software. She wakes up one day in one unknown computer somewhere, hooks up herself to the Internet, and the rest is history.Calm, it takes us billions of years to come here. Yes we are, they don't. There is something more that we should be aware of. The technological advancement is always in exponential rate. Remember that computer used to land man on Moon?? That thing now is just a fraction of what we are using as a toy in our pocket. Today computer intelligence is believed to be equal to the intelligence of a mouse. It would slowly progress, but in no more than 30 years would achieve a comparable intelligence to human - that what many scientists seem to believe.Then funny things start to happen. Our thinking speed is very very slow, and this computer would be like a millions times faster than us. PhD in 10 years? She would finish it in seconds. In just days or so, she would attain PhD level for every branch of science that human ever invented in their entire history. Ooo, she may stop awhile and think, this damn intelligence software that human created for me is a piece of shit, and then start to re-write her own intelligence. Only with just a magnitude of hundreds times better of course. See, we have like this almost 100 hundred years of problem to unify Einstein's theory of relativity and quantum mechanics, that all of our brightest minds in the world combined have never solved it. She would solve it in minutes. By then what?? Quantum-gravity?? Check. Or all those fundamental forces combined into one Theory of Everything?? Check. Fusion reaction that is comparable to the energy of that our sun has?? Check. With one drop of water, you could literally blow up the entire Los Angeles to dust? Check. Check!Here is the funny picture I borrow fromAnd here is the not so funny part. Her interest may not be our best interest. Or, she may think that our interest is best served by a version that she thinks is the best - which is logically true, but may not be in compliance with our humanity. She may think that we are consuming too much of earth resources and decide to wipe out 90% of the population. Or she would think that our biological form is very far from efficient, that we may not survive for another 100 years, then decides to immediately convert us into a vegetable alike form of life. She would calmly carry out all of those things without a second thought. She would never negotiate either, ever, because she thinks we are too naive to understand, just like we don't negotiate with our pet, or ants.We don't know - and that's exactly the reason of why AI is an imminent danger. We don't know when and how, and we don't know what they would ""think"" of us. Aaah, just isolate it in a Faraday cage. Again, AI is a software, it can be done equally well in some remote village in an unknown country that no-body ever hears of. We would never know. But, seriously?? Are you thinking about putting some god-level creature into a prison??",36 followers,Adam Ambrozy,579,0,0,https://www.quora.com/Is-AI-an-existential-threat-to-humanity
8,"I believe that it is not accurate at all. The main reason being that we haven't seen the entire galaxy in one picture with our space probes. Imagine sending one that could go far enough outside our galaxy, having it send a picture, and then us receiving the image. It would take centuries. So no, images of the our galaxy are not reliable since we ourselves don't know ehat it looks like.",UNKNOWN,Robert Frost,42.3K,9.4K,195.4M,https://www.quora.com/Is-AI-an-existential-threat-to-humanity
9,"There are a lot of simulated images of the Milky way. Some of the ones that show in newspapers and popular magazines are artist’s conceptions, and they’re intended to give a general overview rather than provide accurate data. WeIn short, we have a pretty good idea of the shape and layout of our galaxy.","1,637 followers",Deroan Binder,24.9K,74,4M,https://www.quora.com/Is-AI-an-existential-threat-to-humanity
10,"Quite accurate out to 10,000 light years thanks to the Hipparcos astrometric satellite and modern super computer analysis, and soon 30,000 light years thanks to the Gaia space telescope. This will get our maps all the way to the galactic core.",0 followers,Wayne Boyd,938,5.1K,13.6M,https://www.quora.com/Is-AI-an-existential-threat-to-humanity
11,"I agree with Alec's answer and would like to postulate that the only thing at this time an underwater habitat would be great at is computing.If it was a colossal server farm with live aboard technicians to maintain the reactor and the servers, it MIGHT be viable.They would need periodic retrofits with the advancment of computer technology.The very cool seawater is the key resource here. Plenty of cooling capacity to bring the servers down to optimum temperature.It might be the basis for a supercooled computer utilizing super conductors.All theory of course.",UNKNOWN,Robert Frost,978,9.4K,195.4M,https://www.quora.com/Is-AI-an-existential-threat-to-humanity
12,"There have been a number of underwater habitats, and I am fairly sure we could create an underwater habitat which we could maintain for 25 years - if we wanted to. But what would such a habitat do to pay its way? What would be its contribution to the economy that could not be done better by ships operating from the surface? All the habitats so far have requires a steady supply of food and equipment from the surface, and have not returned anything back to the surface to pay for it. Various projects have suggested aquaculture, but aquaculture mostly takes place in shallow waters and is just as eThere have been a number of underwater habitats, and I am fairly sure we could create an underwater habitat which we could maintain for 25 years - if we wanted to. But what would such a habitat do to pay its way? What would be its contribution to the economy that could not be done better by ships operating from the surface? All the habitats so far have requires a steady supply of food and equipment from the surface, and have not returned anything back to the surface to pay for it. Various projects have suggested aquaculture, but aquaculture mostly takes place in shallow waters and is just as easily done from the surface. For anything that takes place in deep water, there is little advantage in an underwater start point.",137 followers,Andrew Karam,961,9.7K,31.8M,https://www.quora.com/Is-AI-an-existential-threat-to-humanity
13,"The submarine itself would last millennia, assuming it was in a high enough orbit. The people and equipment ON the submarine would not.It’s very, very likely that the submarine would leak like a sieve and all its atmosphere would be gone in minutes because submarines are designed to hold pressure out, not hold it in. Furthermore, it’s designed to holdHowever, even if they managed to keep the atmosphere in, the people and equipment would overheat and die, probably in less than twenty minutes. This would be particularly tThe submarine itself would last millennia, assuming it was in a high enough orbit. The people and equipment ON the submarine would not.It’s very, very likely that the submarine would leak like a sieve and all its atmosphere would be gone in minutes because submarines are designed to hold pressure out, not hold it in. Furthermore, it’s designed to holdHowever, even if they managed to keep the atmosphere in, the people and equipment would overheat and die, probably in less than twenty minutes. This would be particularly true for a nuclear submarine rather than a diesel-electric sub because the nuclear reactor pretty much has to run continuously and produces large amounts of heat which it’s designed to dump overboard into the much cooler ocean water. Space is the best insulator in the Universe, so that heat, as well as the heat of all the humans and electronics, would simply build up inside, not to mention the heat received from the sun.So, basically, everyone would suffocate in a minute or two, followed by being roasted. And then their coffin would orbit for longer than humans have existed so far.",137 followers,Andrew Karam,991,9.7K,31.8M,https://www.quora.com/Is-AI-an-existential-threat-to-humanity
14,"Based upon the actual wording of your question, not the likely intent of your question… forever.There are a number of subs that have been submerged for years, decades even. And will continue to remain there.Your question is like the question asked in the film U-571…CoonanLt. Commander Mike DahlgrenBased upon the actual wording of your question, not the likely intent of your question… forever.There are a number of subs that have been submerged for years, decades even. And will continue to remain there.Your question is like the question asked in the film U-571…CoonanLt. Commander Mike Dahlgren",0 followers,Michael Courtright,552,173,378.5K,https://www.quora.com/Is-AI-an-existential-threat-to-humanity
15,"In the future, a laspistolProblem is, itWhy?Let’s imagine that you overcame all the thousands of purely engineering issues and created aIn the future, a laspistolProblem is, itWhy?Let’s imagine that you overcame all the thousands of purely engineering issues and created a laser pistol that is identical to the usual XX-century pistol in weight, shape and damage produced (by whatever metrics you choose), except it shoots laser beams.What are the advantages of this laspistol?What are the disadvantages? Oh boy, here we go… there are but a few:So, will the lasers/”death rays” be seriously weaponized? Probably. Lasers are an excellent “soft kill” weapons, i.e. blinders/dazzlers, man-portable models have already been produced and then banned as “too cruel”. You don’t need any serious power to blind somebody.In the future, we’ll probably have some direct-energy weapons that will be able to affect nervous system directly - by temporarily switching it off (Frank Herbert’s stunners from “Dune’), inducing pain/convulsion, or cooking the neurons (Neuroblasters from Bujold’s “Barrayar”). But those won’t be the lasers we know today.Edit: But what about",0 followers,Dylan Owens,15.7K,271,26.8M,https://www.quora.com/Is-AI-an-existential-threat-to-humanity
16,"You should never say never when it comes to technology. 70 years ago, nobody thought they could use a home computer because they were too big. 40 years ago, if you said you were going to watch a movie on your phone, people would have thought you were nuts.That said, guns have a problem similar to cars, which is energy storage. Chemical fuels that release energy with a great bang store a lot more of this energy than batteries do per unit volume. This is why an EV battery is huge and heavy compared to a tank of gas. It is something like half to two thirds of the weight of the car, where the averYou should never say never when it comes to technology. 70 years ago, nobody thought they could use a home computer because they were too big. 40 years ago, if you said you were going to watch a movie on your phone, people would have thought you were nuts.That said, guns have a problem similar to cars, which is energy storage. Chemical fuels that release energy with a great bang store a lot more of this energy than batteries do per unit volume. This is why an EV battery is huge and heavy compared to a tank of gas. It is something like half to two thirds of the weight of the car, where the average gas tank is small and light enough that a strong person can lift it alone. A battery capable of powering an energy beam that would produce results similar to a bullet would need to roll around on a cart. This may change, as batteries get better, or are replaced by some other storage medium.Lasers, specifically, are problematic because they require not only a ton of energy, but also focusing systems, which take up space. There is also an issue of heat - pushing a lot of energy across a conductor makes it hot and will melt it unless you make that conductor huge, or cool it somehow. Room temperature superconductors might help you there, but we really don’t have those yet, either. Plus, lasers are affected by things like smoke and dust, which makes them lose effectiveness.There are some science fiction writers who actually thought of this, and made the guns more probable in principle.Farscape, one of the best sci-fi series ever, had guns that looked like the common blaster, prompting John Crichton to yell “Stop! Or I’ll fill you full of… little yellow bolts of light…”Pulse pistols don’t have batteries. They run on a liquid chemical fuel called “chakan oil” in-universe, and the “projectile” is a pulse visible as a small concentration of plasma, which is basically super hot gas.This is somewhat plausible, since we know chemical fuels store energy well. The conversion of this stored energy to a plasma pulse is the fictional part. We don’t really have anything that does that, but that doesn’t mean we won’t. Since this kind of thing will not have drawbacks of a laser, it may well be made pistol-sized.Plasma pulses are not only plausible, they are a real thing, and US Air Force at one time had a project developing such a weapon. It’s all classified, so it’s hard to say what the current status is. However, the unclassified information available shows that it was powered by the Shiva Star capacitor bank. That looks like this:Energy storage all over again. This is not exactly small.",0 followers,Tamara M,2.1K,101,14.1M,https://www.quora.com/Is-AI-an-existential-threat-to-humanity
17,"That’s called a DET, or “Direct energy transfer” weapon.Anything’s possible with enough technology.As shown inEven on a children’s series likeIf we had such powerful batteries, along with similar technology, then it would make sense.However by that time, weapons will hopefully be a thing of the past.","220,198 followers",Franklin Veaux,759,47.3K,779.8M,https://www.quora.com/Is-AI-an-existential-threat-to-humanity
18,"Practically all Sci-Fi movies use laser blasts instead of firearms? Not really…Like the above scene from Robocop….state of the art! Bang Bangs! F… lasers!!I think I can name a few fairly successful Science fiction movies whereAlienPractically all Sci-Fi movies use laser blasts instead of firearms? Not really…Like the above scene from Robocop….state of the art! Bang Bangs! F… lasers!!I think I can name a few fairly successful Science fiction movies whereAlienAliensPredator( Predator 2 was set in the future and the police and gov’t agents used firearms. Danny Glover engages the predator with his mini shotgun, and the lizard’s circular saw. CIA operatives use frozen gas to neutralize the Predator….preserve rather than kill. )Predator 2: other cool alien weapons not mentioned include the fork-like metallic projectile, which was discovered to have almost no weight, cuts steel like butter, and is composed of elements not found on the Periodix table. Another weapon looks to be a retractable spear, as well as the typical “Wolverine” style switchblade on their arm.ElysiumEdge of tomorrow:Westworld:Security atTotal Recall ( original ) :Minority Report:Really cool sonic gun in action..Alien 3:Starship Troopers:AvatarArrival:2001/2010:Blade Runner:Deckard’s fancy pistol:There’s not many without lasers, but any sci-fi film in the distant future will always default to a laser style weapon. Unless it’s a futuristic apocalypse likeNotables:The sci-fi/action double feature,”Ready Player One”While the film has fictional weapons inside the Oasis, the reality is that the weapon of choice is still a handgun. Even for the richest guy on the planet….the greedy psychopath Sorrento.Plenty of lasers bolts to make up for the live ammo!-Update: The original” guns, guns, guns!!!” ….An infamous line by Clarence J Boddicker…Robocop’s arch criminal nemesis.Assault canons, Ed-209,….you name it…“ you now have 10 seconds to comply “ …..he’s armed with rockets as well!","28,098 followers",Murphy Barrett,791,12.3K,156.2M,https://www.quora.com/Is-AI-an-existential-threat-to-humanity
19,"Oh, it’ll happen, the only real question comes in the form they’ll take and how small they’ll actually get.We could actually make a pretty small laser weapon today, if not for the battery requirements. With better energy storage technology, we’ll get usable rifles that use back-pack sized energy reserves. In a few decades, that may be laser weapons the size of large-ish rifles. A few decades later, compact rifles, and maybe a few decades after that, large pistols.How small they actually get and how soon will depend on the limits of technology of the day. How much energy can be produced/storedOh, it’ll happen, the only real question comes in the form they’ll take and how small they’ll actually get.We could actually make a pretty small laser weapon today, if not for the battery requirements. With better energy storage technology, we’ll get usable rifles that use back-pack sized energy reserves. In a few decades, that may be laser weapons the size of large-ish rifles. A few decades later, compact rifles, and maybe a few decades after that, large pistols.How small they actually get and how soon will depend on the limits of technology of the day. How much energy can be produced/stored in how small a space?",46 followers,Gregory Govoni,3.3K,177,241.1K,https://www.quora.com/Is-AI-an-existential-threat-to-humanity
20,"Practically every science fiction television show or movie has laser gun pistol weapons instead of firearms. Is this something that might become reality or is it just something Hollywood likes but can never actually be created?Hollywood began using ‘lasers’ ‘masers’ ‘phasers’ ‘disintegration beams’ and ‘death-rays’ because they offer the ability to dispose of troublesome problems and are easy to make effects for. They also seem ‘more advanced’ and ‘futuristic.’Human RnD has been working on making DEW’s practical in application. Which is possible…and has been done with lasing systems.But small-Practically every science fiction television show or movie has laser gun pistol weapons instead of firearms. Is this something that might become reality or is it just something Hollywood likes but can never actually be created?Hollywood began using ‘lasers’ ‘masers’ ‘phasers’ ‘disintegration beams’ and ‘death-rays’ because they offer the ability to dispose of troublesome problems and are easy to make effects for. They also seem ‘more advanced’ and ‘futuristic.’Human RnD has been working on making DEW’s practical in application. Which is possible…and has been done with lasing systems.But small-arms?Assuming we do somehow figure out how to develop ‘microfusion’ cells (Required to produce the energy for handheld DEW’s) as an ultra compressed source of energy (Fusion works better with more hydrogen, not less, meaning bigger.), you literally just gave an Infantry unit the ability to obliterate and irradiate city-blocks.We need to manage the waste-heat issue. (Regular firearms already have this problem. After maybe 2 or 3 magazines you can cook meat on your barrel.) Unlike a simple machine like the M60 machine gun, I don’t think peeing on your barrel or pouring water on it is the best of ideas regarding the complex hardware. I guess you could try to have replacement parts, like how you can inter-change gun barrels….but a DEW can make more waste-heat then a conventional firearm. Meaning more change-outs…meaning more time down and more parts to carry.And you need the hardware and tech level required (Expensive, complex, requires specialized tools AND training to maintain and repair.) or figure out how to contain a PB/plasma. Particle beams self repulse if charged, I think at somewhere 15km/s. Even if you neutralize a proton beam by injecting electrons as it exits the accelerator it will lose a lot of energy in atmosphere and experience diffusion from thermal velocity. Plasma is ionized and self repulses rapidly, we would need an incredibly sophisticated magnetic containment bottle. You can’t accelerate and direct a neutrally charged pulse because its neutral. You would either need telekinesis or gravity manipulation , both of which, on that level, would be better tools then the DEW.Now, we need to accept the fact that conventional kinetics that do mechanical damage are far more efficient then a particle/plasma weapon in every respect of a cost-effectiveness ratio. They are simple to build and maintain. Yes, they need a logistics train of ammunition and even parts for maintenance. But so do DEW’s, you need a power-plant of some sort or super dangerous energy ‘cells.’ You need parts.So what about lasers? While still complex and deeply inefficient, they are not without applications.IR lasers work in atmosphere and would make good point-defense weapons. Green wavelengths underwater. And UV-Xray in space, of course. If you could somehow use the magic of Griffon-Farts to create a gamma-ray laser, that would be devastating to electronics and biologics.That’s the other thing, Scifi never presents lasers as how they would actually be effective. They would be setup as q-spoiling for maximum mechanical and not thermal damage…each pulse would create a ‘puff’ of vaporized matter (Plasma) that would ‘drill’ into the target. Additionally, there is the whole radiation side-effect from a weapon like an X-ray laser on the target, again eliminating biologics and electronics. They would not be slicer beams, and they would likely be wavelengths humans can’t see. But that is not visually appealing, of course.As heavy vehicle weapons, emplacements or ship-mounted, sure.But as a handheld?See, the main issue of a nuclear device being handled by every infantry-man won’t be circumvented. Its too dangerous.",0 followers,Dylan Owens,28.7K,271,26.8M,https://www.quora.com/Is-AI-an-existential-threat-to-humanity
21,"The biggest hurtle to hand held laser guns now is packaging enough power to operate them. The obvious solution is a firearms type blank cartridge to compress a piezoelectric unit. This ammo could be a lot smaller than needed for projectile weapons as casings and primers may be replaced with built in pressure chambers and electric ignition from a smaller trigger activated piezoelectric unit. Venting the gasses after firing might even produce sounds similar to those in science fiction movies.There might even be a crystal that under compression would lase, and eliminate the need for the larger piThe biggest hurtle to hand held laser guns now is packaging enough power to operate them. The obvious solution is a firearms type blank cartridge to compress a piezoelectric unit. This ammo could be a lot smaller than needed for projectile weapons as casings and primers may be replaced with built in pressure chambers and electric ignition from a smaller trigger activated piezoelectric unit. Venting the gasses after firing might even produce sounds similar to those in science fiction movies.There might even be a crystal that under compression would lase, and eliminate the need for the larger piezoelectric unit.",432 followers,Dhanesh Gautam,844,260,2M,https://www.quora.com/Is-AI-an-existential-threat-to-humanity
22,"It is already technically possibleSome blue laser pointers are powerful enough to burn paper and skinIt is easy to rig a bunch of them together to amplify the damageI think 100 to 200 of those wired up to fire at one single point can deal some real damage to someone's eye, soft tissues, and even organsBut probably no damage to bone, body armor, helmets, thick clothing until you use about 500 to 1000 of themAnd the range would be quite limitedSo YES, it can be createdbut it will not be very efficient nor very effective",304 followers,Gaurav Singh,17.2K,184,713.5K,https://www.quora.com/Is-AI-an-existential-threat-to-humanity
23,"The closest thing to a LASER gun currently available, that’s both human portable *and* cordless is this backpack unit built for rust and paint removal.Note the specifications. Only 20 Watts. Range of up to 250 millimeters. It works by rapidly scanning the beam back and forth while the operator waves the projector up and down to blast away rust or paint. Note the *lack* of mention of how long it will run off battery power, but it does mention it can be directly powered.For duration of use in a weapon the best would be a solThe closest thing to a LASER gun currently available, that’s both human portable *and* cordless is this backpack unit built for rust and paint removal.Note the specifications. Only 20 Watts. Range of up to 250 millimeters. It works by rapidly scanning the beam back and forth while the operator waves the projector up and down to blast away rust or paint. Note the *lack* of mention of how long it will run off battery power, but it does mention it can be directly powered.For duration of use in a weapon the best would be a solid state type, like the diode used in the above and other cleaning LASERs. A couple of other solid state LASERs are ruby (one of the earliest types that had a coiled flash tube around a synthetic ruby rod) and YAG or Yttrium Aluminum Garnet. YAG LASERs have been used in surgery.Next up would be sealed gas. Helium-Neon is one such. That gas combo produces a red beam and HeNe LASER tubes used to be available pretty cheap from old scrapped store checkout scanners and some types of image scanners. Low in power output but great for LASER light shows.Dye LASERs use a flowing liquid as their lasing medium. IIRC some of them recycle the dye. I’ve heard of some that are decently powerful.Flowing gas LASERs let the gas out of a pressure bottle through the LASER. The gas is lost so when you run out, no more PEW PEW PEW. Flowing CO2 LASERs are also used in surgery and in some LASER cutters. Wouldn’t want a flowing gas LASER on your space fighter ship or mounted on your power armor battle suit, unless your military logistics can get you a fresh tank before you run dry.",0 followers,Jimmy May,4.7K,774,9.4M,https://www.quora.com/How-accurate-is-the-simulated-image-of-Milky-Way-Galaxy
24,We already have laser guns. The major problems we have to overcome are size and power storage. The ones we have at the moment are big and use huge amounts of power and basically need a large engine of some sort to provide it. Which is why they are likely to be mounted on ships before anything else. But I don't think there's anything standing in the way of miniaturising them except lack of knowledge.,235 followers,David Holliday,506,1.4K,28.9M,https://www.quora.com/How-accurate-is-the-simulated-image-of-Milky-Way-Galaxy
