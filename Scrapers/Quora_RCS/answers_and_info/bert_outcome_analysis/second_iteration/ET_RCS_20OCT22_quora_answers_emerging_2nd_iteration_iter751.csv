,Answer,followerCount,name,upvoteCount,answerCount,answerViews,question
0,"Polynomial vs. non-polynomial gets a lot of press, but I should mention that concerns such as “quadratic vs. subquadratic” get attention too.The main reason “polynomial” is an interesting class is because it’s invariant under changes of representation or computing model. A multi-tape Turing machine can be simulated with a single-tape Turing machine with “only” polynomial overhead. Similarly, the difference between a random-access machine and a tape machine is a polynomial time overhead.The difference between logarithmic and super-logarithmic space overhead is also relevant. A logspace reductioPolynomial vs. non-polynomial gets a lot of press, but I should mention that concerns such as “quadratic vs. subquadratic” get attention too.The main reason “polynomial” is an interesting class is because it’s invariant under changes of representation or computing model. A multi-tape Turing machine can be simulated with a single-tape Turing machine with “only” polynomial overhead. Similarly, the difference between a random-access machine and a tape machine is a polynomial time overhead.The difference between logarithmic and super-logarithmic space overhead is also relevant. A logspace reduction from one problem to another can only take polynomial time. If space overhead that isSo, transformations from computing model to computing model, and from problem to problem, are generally polynomial time cost. That means there is a natural boundary in that we can move between different polynomial time classes via these transformations, but not to exponential or worse time classes.(There are non-polynomial transformations as well such as padding or using a compact representation. Those are closer to changing the nature of the problem than the nature of the machine… but admittedly this can be a fine distinction.)","21,060 followers",Scott Aaronson,575,54,979.9K,https://www.quora.com/In-algorithm-complexity-why-is-the-polynomial-order-the-most-commonly-concerned-boundary-of-complexity-Is-it-because-the-Moores-law-is-in-the-exponential-order-of-time-so-that-the-computation-power-will-grow-faster
1,"Let me try and give you a brief breakdown.Moore’s law speaks about how computing power can grow in practice. Every 18 months or so, the amount of transistors you can cram onto a unit area can double. This just so happens to be an exponential growth in computing power but we’re already at the brink of how small we can go. Reduce the size of the transisters even more to keep the growth going and you’d have an uphill task of tackling quantumLet me try and give you a brief breakdown.Moore’s law speaks about how computing power can grow in practice. Every 18 months or so, the amount of transistors you can cram onto a unit area can double. This just so happens to be an exponential growth in computing power but we’re already at the brink of how small we can go. Reduce the size of the transisters even more to keep the growth going and you’d have an uphill task of tackling quantum mechanics. Which by the way, is also why pursuing quantum computing is a great prospect.When we talk about asymptotic complexity, we tend toWe then tried to ask ourselves what the extremities of this ordering is. Most people are okay with starting with O(n) and going until O(c^n). Some are particular about starting with O(1) but are again, okay with having an exponential function at the far end of this ordering.Can you think of any other function that grown faster than an exponential function would? GREAT! lets use that as the far end, I can pretty much guarantee that nobody would protest. So far at least, it has been just about having a meaningful ordering of functions as per their rate of growth for an easy comparison of their complexities and to find out which algorithms are better suited for a particular use case than the rest.","113,987 followers",Alon Amit,606,7.5K,118.8M,https://www.quora.com/In-algorithm-complexity-why-is-the-polynomial-order-the-most-commonly-concerned-boundary-of-complexity-Is-it-because-the-Moores-law-is-in-the-exponential-order-of-time-so-that-the-computation-power-will-grow-faster
2,"It is useful to put the boundary at some class closed under logspace reductions, which means that we use a class which does not care when the input grows polynomially. This leaves us asIt is useful to put the boundary at some class closed under logspace reductions, which means that we use a class which does not care when the input grows polynomially. This leaves us asWhy a logspace-closed boundary?Recently the theory of linear time algorithms is being developed. This is very practical in many applications (where the input is assumed to be in millions or billions), and while we have no proofs that some problem needs more than linear time (AFAIK we only have the artificial problems constructed in the time hierarchy theorem, and, as a consequence, EXPTIME-hard problems which are known to have no polynomial algorithms), “hard” problems which appear to require e.g. quadratic time are identified and reduced to other problems, thus proving these other problems appear to require superlinear time too.","20,816 followers",Michal Forišek,1K,1.2K,10M,https://www.quora.com/In-algorithm-complexity-why-is-the-polynomial-order-the-most-commonly-concerned-boundary-of-complexity-Is-it-because-the-Moores-law-is-in-the-exponential-order-of-time-so-that-the-computation-power-will-grow-faster
