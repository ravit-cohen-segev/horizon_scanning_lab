,Answer,followerCount,name,upvoteCount,answerCount,answerViews,question
0,"Voyager’s primary computer actually works at a speed of 575 trillion calculations perA 'flop' in computer terms is a single floating point operation, in other words a single calculation. 500 trillion or 500,000,000,000,000 calculations would translate as 500 teraflops. Most personal CPUs are in the Gigaflop range with Intel breaking into the teraflop range with a $2000 18 core CPU chip.Rounded up to flops (floating point operations, which is what each calculation is) this means VoyageVoyager’s primary computer actually works at a speed of 575 trillion calculations perA 'flop' in computer terms is a single floating point operation, in other words a single calculation. 500 trillion or 500,000,000,000,000 calculations would translate as 500 teraflops. Most personal CPUs are in the Gigaflop range with Intel breaking into the teraflop range with a $2000 18 core CPU chip.Rounded up to flops (floating point operations, which is what each calculation is) this means Voyager’s computer has a load speed of about 575 zettaflops, or 575 sextillion calculations per second. Or 575 with 21 zeroes.Compared to some of the fastest computers on Earth right now, Voyager’s computer isAs powerful as Summit is, it’sThis is your 122-quarillion calculations per second beast.What could make the kick even harder is that Voyager’s cores are part of its multirole function. So it can carry out scientific data but also calculate all kinds of trajectories and simulations. Summit on the other hand was designed for the US department of Energy for its Oak Ridge laboratory, one of the DoE’s top laboratories.To put it in perspective, Voyager’s computer was asked to guess what hadrasaurs would most likely look like they had 65 million years more. Not only was the computer able to work it out in a minute or so, it came up with a creature almost identical to what Voyager had in its sickbay at the time.65 million years of genetic drift and adaptational likelihood, then working out the most likely outcome all done in a few minutes.EDIT: I had a whole different answer to this before I discovered Voyager’s computer actually works at over 500 trillion calculations perEDIT 2: Oak Ridge might not be the largest or the most well-funded but it’s pretty high up there.",90 followers,Igor Nedeljkovic,1.9K,693,690.1K,https://www.quora.com/Are-todays-super-computers-at-122-3-petaflops-per-second-faster-than-the-Star-Trek-Voyager-computer-at-500-trillion-calculations-per-second
1,122.3 petaflops per secondStar Trek computers operate on a quantum-type computing system called “duotronics” (later multitronics) originally created by Dr. Richard Daystrom (“The Ultimate Computer”).So multitronic/isolinear calculations are far more precise than binary ones.,12 followers,Marc Lawrence,1K,12.5K,145.9M,https://www.quora.com/Are-todays-super-computers-at-122-3-petaflops-per-second-faster-than-the-Star-Trek-Voyager-computer-at-500-trillion-calculations-per-second
2,Latent Dirichlet Allocation.The first paper fromMight have a look there:Latent Dirichlet Allocation.The first paper fromMight have a look there:,"3,324 followers",Duane Rich,1K,0,0,https://www.quora.com/Are-todays-super-computers-at-122-3-petaflops-per-second-faster-than-the-Star-Trek-Voyager-computer-at-500-trillion-calculations-per-second
3,"Update!If you enjoy the answer below, I recommend you check out my YouTube channel,____________________________________________t-SNEHalfway through reading theFirst, let’s state a specific problem this monster solves. I give you a set of high dimensional points, each representing the grey scale of all pixels of an image of a handwritten digit. So this iUpdate!If you enjoy the answer below, I recommend you check out my YouTube channel,____________________________________________t-SNEHalfway through reading theFirst, let’s state a specific problem this monster solves. I give you a set of high dimensional points, each representing the grey scale of all pixels of an image of a handwritten digit. So this is one data point:Now, you have to return to me an informative 2D scatter plot of points, each of which represents one of the given images. It needs to be informative in the sense that it has well separated groupings, each representing 0,1,2,… 9. Here’s the tricky part; when I hand you those original points/images, I don’t label which one is which digit (and you can’t do it yourself!). All the computer gets is a big list of lists of numbers - no labels, no help.Think about that. These given images can vary over an exponentially huge range of possibilities and we have to cram those possibilities into a 2D space, preserving the character that separates digits. It’s like me asking you to re-write the work of Shakespeare, but with only 5 words and preserving his nuanced message on love. Oh, and you don’t know the meanings of the words!There are really two components to the insight to make this possible, the first of which isn’t specific to t-SNE. That is, a digit in a high dimensional space is aSo two images are likely to be the same digit if you can make small, incremental, linear changes to one and eventually arrive at the other. A 2 and an 8 are different because if you were to morph one into the other, you’d have to make an ugly, nonlinear change at some point. That simple, descriptive, almost vague rule is what traces the wild, high dimensional boundary that separates a 2 vs a 3, a 5 vs a 4, etc... I would have never guessed!But even with that insight, how do we actually create this super reduced, super representative scatter plot? Well, t-SNE characterizes the high-D and low-D spaces in terms of a distance metric between their points. (In this case, a distance metric is some funky function of a Euclidean distance). It produces a mapping (from high-D points to low-D points) such that the the distance metric between points in the low-D space produces similar outputs to the distance metric in the high-D space. So points that are far/close in the high-D space remain so in the low-D space, according to their respective metrics. In high-D, we use a Gaussian probability distribution and in low-D, we use a student t-distribution. The magic comes from the fact that the difference between these metrics mirrors the intrinsic changes to Euclidean distances as you move from high to low dimensions. This is incredibly useful! Optimizing the similarity of the output of these different metrics guides our mapping to focus precisely on the structure of the data and ignore the unavoidable/uninteresting changes inherent to reducing the dimension of a space.The consequence is that the dimensions that are ultimately chosen move youLet’s take a second here. First, we characterized digits as manifolds. Then we decide to speak of spaces in terms of their distance metrics. Then we pulled the Gaussian and student-t out of our asses and optimized a mapping such that they produce similar outputs for the high-D and low-D points. The result is to cluster points together that can be transformed into each other by successive small, simple changes. That’s extremely clever.Sources[1] Maaten, L. and G. Hinton, (2008)","6,306 followers",Muni Sreenivas Pydi,1K,150,2.1M,https://www.quora.com/Are-todays-super-computers-at-122-3-petaflops-per-second-faster-than-the-Star-Trek-Voyager-computer-at-500-trillion-calculations-per-second
4,"Ensembles--bagging, boosting, stacking, superlearners, subsembles... The ability to exploit diversity to drive down prediction error and bias is an amazing development that has changed how machine learning research is done.","3,324 followers",Duane Rich,551,0,0,https://www.quora.com/What-do-you-think-is-the-most-clever-machine-learning-algorithm
5,"Good question! People are always obsessed with the best model, the best algorithm, etc.Lets start with the most fundamental problem in machine learning - linear regression - and see if we can find the ‘Finding the best linear regressor is often cast as the following optimization problem which seeks a linear model withminimizeWhat happens if instead of minimizingGood question! People are always obsessed with the best model, the best algorithm, etc.Lets start with the most fundamental problem in machine learning - linear regression - and see if we can find the ‘Finding the best linear regressor is often cast as the following optimization problem which seeks a linear model withminimizeWhat happens if instead of minimizing the least squares error, we try to maximize it?maximizeYou may notice quickly that the least squares objective above does not have a maximum: by choosing the weights large enough you can make the objective as large as you want. But is this the end? Have we hit a brick wall? Not yet!Remember regularization?Least squares regression is sometimes regularized by adding the termmaximizeThere's still one problem: in regular linear regression the bias weightmaximizeAlright! we now have a maximization problem that we can solve e.g., by taking gradientOkay, enough math! Lets see our algorithm in action for a toy regression dataset, with three values forYup - ours is a lousy algorithm indeed!","5,853 followers",Jonathan Devor,1K,2.9K,11.5M,https://www.quora.com/What-do-you-think-is-the-most-clever-machine-learning-algorithm
6,"A lot would the best asnwer I can give you on the first part of your questionSupport Vector MachineSupport Vector Machine (SVM)SVM distinguishes classes by drawing aA lot would the best asnwer I can give you on the first part of your questionSupport Vector MachineSupport Vector Machine (SVM)SVM distinguishes classes by drawing aDecision boundary is drawn in a way that the distance to support vectors are maximized.The data points are not always linearly separable like in the figure above. In these cases, SVM usesKernel function is kind of a similarity measure. The inputs are original features and the output is a similarity measure in the new feature space. Similarity here means a degree of closeness. It is a costly operation to actually transform data points to a high-dimensional feature space. The algorithm does not actually transform the data points to a new, high dimensional feature space. Kernelized SVM compute decision boundaries in terms of similarity measures in a high-dimensional feature space without actually doing a transformation. I think this is why it is also calledSVM is especially effective in cases where number of dimensions are more than the number of samples. When finding the decision boundary, SVM uses a subset of training points rather than all points which makes it memory efficient. On the other hand, training time increases for large datasets which negatively effects the performance.","6,306 followers",Muni Sreenivas Pydi,687,150,2.1M,https://www.quora.com/What-do-you-think-is-the-most-clever-machine-learning-algorithm
7,The most common and popular algorithms for Machine Learning are:,30 followers,Robin Thomas,5.9K,731,13.7M,https://www.quora.com/What-do-you-think-is-the-most-clever-machine-learning-algorithm
8,This is a diagram that I borrowed from the internetContinue ReadingThis is a diagram that I borrowed from the internet99,0 followers,Lyken Syu,595,0,0,https://www.quora.com/What-do-you-think-is-the-most-clever-machine-learning-algorithm
9,"Over the brief time I’ve spent studying the mathematics of machine learning, I’ve come to a realization that might seem absurd to the layman:(Almost) every concept in machine learning gets mathematically more involved, the deeper you study it. Each concept is like a fractal, exhibiting ever increasing layers of complexity as you zoom into the specifics. [*]To illustrate this point, allow me to consider the simple task ofNow, let’s analyzeOver the brief time I’ve spent studying the mathematics of machine learning, I’ve come to a realization that might seem absurd to the layman:(Almost) every concept in machine learning gets mathematically more involved, the deeper you study it. Each concept is like a fractal, exhibiting ever increasing layers of complexity as you zoom into the specifics. [*]To illustrate this point, allow me to consider the simple task ofNow, let’s analyze the simplest variant of the k-NN algorithm i.e. 1-NN algorithm, withThe 1-NN algorithm classifies a test data point to be of the same class as that of its nearest neighbor. That is all. Pretty straightforward, right? Well, we’ll see.The first layer of complexity in studying the 1-NN algorithm comes from its output. It turns out that the decision boundary for the 1-NN algorithm is aIf you zoom in a bit more on this problem, you’ll see that Voronoi tessellation is actually a geometric dual for[Voronoi tessellation is shown in red, while its dual, Delaunay triangulation, is shown in black.]Now, let’s zoom out and consider another layer of complexity in studying 1-NN, specifically its statistical aspects. Suppose we implement 1-NN on a random set of training data points. How well does its performance generalize to the test set? Ideally, we would like to compare its error rate to that of the Bayes optimal classifier. This analysis was first done in the seminal paper by Cover and Hart in 1967.If you zoom in a bit more, you’ll realize the need for a non-asymptotic bound (which means a bound for finite training set size) on the error rate for 1-NN. Here’s a theorem that gives such a result from Shai Shalev-Shwartz and Shai Ben-David’s ML textbook:[My apologies for not type-setting this :|]Proving results like these require a grasp onZooming in further, you’ll notice that all the known results in error bounds work under quite restrictive assumptions on the smoothness of the conditional probability density. Also, the bounds scale up with the number of dimensions! Is it possible to derive tighter bounds under a more general setting? Is the ‘curse of dimensionality’ that is evident from the theorem above just an artifact of the analysis, or is there a deeper truth here? All these are open research problems.…and that’s not even the end of it! I’m currently studying ML theory, so I’ll mention some of the recent research directions in this area related to 1-NN. Just last year, there was a paperSo, what is the most mathematically involved machine learning algorithm? It is every one of them! You just need to see it with the right set of eyes.[*] I suspect that the statement is true for most fields of science and engineering, but I don’t feel qualified enough to make this claim.","37,422 followers",Xavier Amatriain,1.2K,297,8.4M,https://www.quora.com/What-do-you-think-is-the-most-clever-machine-learning-algorithm
10,"Here is a list of most common Machine Learning algorithms-A classifier is a function that allocates a population’s element value. For instance, Spam Filtering is a popular application of Naïve Bayes algorithm. Thus, spam filter here is a classifier that assigns a label “Spam” or “Not Spam” to all the emails.K- means is a non deterministic & interactive method. Besides, the algorithm operates on a given data set through a pre defined no. of clusters, k. Thus the output of K means algorithms is k clustHere is a list of most common Machine Learning algorithms-A classifier is a function that allocates a population’s element value. For instance, Spam Filtering is a popular application of Naïve Bayes algorithm. Thus, spam filter here is a classifier that assigns a label “Spam” or “Not Spam” to all the emails.K- means is a non deterministic & interactive method. Besides, the algorithm operates on a given data set through a pre defined no. of clusters, k. Thus the output of K means algorithms is k clusters with input data that is separated among the clusters.It is a supervised ML algorithm for classification or regression problems. In this, the dataset teaches SVM about the classes. So that SVM can classify any new data. Also, it works by classifying the data into different classes by finding a line. That we use to separates the training data set into classes.It is an unsupervised ML algorithm. That we use to generate association rules from a given data set. Also, association rule implies that if an item A occurs, then item B also occurs with a certain probability. Moreover, most of the association rules generated are in the IF_THEN format.Linear Regression shows the relationship between 2 variables. Also, shows how the change in one variable impacts the other. Basically, the algorithm shows the impact on the dependent variable. That depends on changing the independent variable. Thus, the independent variables as explanatory variables. As they explain the factors impact the dependent variable. Moreover, a dependent variable has often resembled the factor of interest or predictor.A decision tree is a graphical representation. That makes use of branching method to exemplify all possible outcomes of a decision.Random forest is an improvement over bagged decision tress. We use a bagging approach to create a bunch of decision trees with a random subset of the data. Although, we have to train a model several times on random sample of the dataset. That need to achieve good prediction performance from the random forest algorithm. Also, in this ensemble learning method, we have to combine the output of all the decision tree. That is to make the final prediction. Moreover, we derive the final prediction by polling the results of each decision tree.As Logistic Regression algorithm is for classification tasks and not regression problems. Also, the name ‘Regression’ here implies that a linear model is fit into the feature space. Further, this algorithm applies a logistic function to a linear combination of features. That need to predict the outcome of a categorical dependent variable. Moreover, it was based on predictor variables. The probabilities that describe the outcome of a single trial are modeled as a function. Also the function of explanatory variables.Hope you like the answer.PleaseFollow my account",16 followers,Cory Hicks,572,0,0,https://www.quora.com/What-do-you-think-is-the-most-clever-machine-learning-algorithm
11,TheIt had over 100 CRT consoles with a light-gun.Each console also featured a cigarette lighter and an ashtray!TheIt had over 100 CRT consoles with a light-gun.Each console also featured a cigarette lighter and an ashtray!,"9,918 followers",Brett Bergan,808,7K,82.8M,https://www.quora.com/Are-todays-super-computers-at-122-3-petaflops-per-second-faster-than-the-Star-Trek-Voyager-computer-at-500-trillion-calculations-per-second
12,"From the view point of Computer Scientist, the largest computer is one that compute the largest number of operations per second.This question is so important that there is a website and origination that keeps track of what is the “largest computer.”Their list is updated twice a year.Go to",0 followers,Michael Rutledge,1K,1.1K,925.7K,https://www.quora.com/Are-todays-super-computers-at-122-3-petaflops-per-second-faster-than-the-Star-Trek-Voyager-computer-at-500-trillion-calculations-per-second
13,"Project Density, crafted by youtuber Josh Sniffen, is fantastic piece of workmanship housing a RTX 2080Ti and a $3000 Xeon in a box the size of a large dictionary.A bit of CNC milled carbon fiber and black walnut give this engineering marvel a touch of class that would be the pride of any PC enthusiast anywhere.Please Like and Subscribe to Josh’s channelProject Density, crafted by youtuber Josh Sniffen, is fantastic piece of workmanship housing a RTX 2080Ti and a $3000 Xeon in a box the size of a large dictionary.A bit of CNC milled carbon fiber and black walnut give this engineering marvel a touch of class that would be the pride of any PC enthusiast anywhere.Please Like and Subscribe to Josh’s channel","1,418 followers",Shubhojit Chattopadhyay,7.2K,119,1.1M,https://www.quora.com/What-do-you-think-is-the-most-clever-machine-learning-algorithm
14,"Arguably SAGE:SAGEArguably SAGE:SAGE(More than twenty of these machines were connected together, and more were desired by the USAF (but not funded by Congress).Whether the SAGE network would have functioned in a crisis is a matter of speculation. After all, it required a full-time staff simply to replace the vacuum tubes as they failed during the normal course of its operation. Even a fully funded SAGE network might have been able to do little more than observe its imminent destruction, as not enough resources were allocated to air-defense and later missile-defense.It is more than likely that we can accomplish the same mission today, with ridiculously smaller equipment. Nevertheless, SAGE proved the concept — and sometimes proved where it wasn’t appropriate for use in the first place. (e.g, early-warning false-alarms)We can scoff at SAGE: equating its computational power against our own PCs and cell phones. However, when the state-of-the-art required building-sized computers to accomplish the mission, only USAF had the imagination and wherewithal to actually implement one.(nota bene): Most of the(nota bene bene):",0 followers,Azka Hafizh,843,0,0,https://www.quora.com/What-do-you-think-is-the-most-clever-machine-learning-algorithm
15,"I am not sure that size is what you are looking for. Maybe powerful is what you mean.The OLD system of say, CRAY super computers is NOT really being pursued right now, although it DID have certain advantages. AND, as usual, certain branches of the computational challenge, are following their example, but it’s mainly changed to computational clusters, of conventional PCs.The ROUGH (very rough) measure of the calculation power for a computer is the number of processor cores. It’s not unusual for academic clusters to use close to 1000 PCs right now.The key advantage of a cluster, of course, is thI am not sure that size is what you are looking for. Maybe powerful is what you mean.The OLD system of say, CRAY super computers is NOT really being pursued right now, although it DID have certain advantages. AND, as usual, certain branches of the computational challenge, are following their example, but it’s mainly changed to computational clusters, of conventional PCs.The ROUGH (very rough) measure of the calculation power for a computer is the number of processor cores. It’s not unusual for academic clusters to use close to 1000 PCs right now.The key advantage of a cluster, of course, is the ability to buy 40 PCs a year, and build a cluster with an academic budget.","113,967 followers",Alon Amit,1.3K,7.5K,118.8M,https://www.quora.com/What-do-you-think-is-the-most-clever-machine-learning-algorithm
16,"The answer depends on your definition. There are several so called supercomputers that consist of commodity off the shelf 2,4,8,16, and 32 processor systems connected using multi gigabit serial connections, that exceed 1000 total processors, 640 terabytes of memory petabytes of high speed storage and exabytes of storage accessible in less than a second. These systems require specialized operating systems, applications, and databases to run at their full potential.HP, Oracle, IBM, and a few other major manufacturers are able to repeatedly build 64 processor, 4 terabyte mainframe/supercomputer cThe answer depends on your definition. There are several so called supercomputers that consist of commodity off the shelf 2,4,8,16, and 32 processor systems connected using multi gigabit serial connections, that exceed 1000 total processors, 640 terabytes of memory petabytes of high speed storage and exabytes of storage accessible in less than a second. These systems require specialized operating systems, applications, and databases to run at their full potential.HP, Oracle, IBM, and a few other major manufacturers are able to repeatedly build 64 processor, 4 terabyte mainframe/supercomputer class systems that are fully supported and can run relatively common software.",1 follower,Rahul K Jha,5.5K,0,0,https://www.quora.com/What-do-you-think-is-the-most-clever-machine-learning-algorithm
17,"Commercial satellites throw down ~10kW of RF power, but their amplifiers are only ~50% efficient.  There is thus ~10kW of waste heat that must be removed.  Radiative heat transfer is the only way to do that, and is proportional to (Th^4-Tc^4).  When facing deep space, Tc = 4K.  We run the spacecraft at about Th = 320K.  So our temperature factor is 10.4x10^9.  If we were to run it at Th = 100K, the temperature factor would be 10x10^7 => 1/100th the performance.  The radiators would need to be impossibly large.Do you have a superlow noise HTSC amplifier with 100% efficiency?",1 follower,David Thomas,4.7K,4.8K,27.5M,https://www.quora.com/Are-todays-super-computers-at-122-3-petaflops-per-second-faster-than-the-Star-Trek-Voyager-computer-at-500-trillion-calculations-per-second
18,"1 - Quantum computing:1 - Quantum computing:2 -3 - Data visualization:4 - Autonomous systems:5 - Neural interfaces between digital and biological systems:I think we can probably think many more future topics of computer science. If we go into details I think we will see some interdisciplinary cross-breeding between medicine and computer science (very much similar to what happened in genomics and bioinformatics), and probably many more that few people can predict.",78 followers,Rajan Singh,11.6K,360,25.2M,https://www.quora.com/Are-todays-super-computers-at-122-3-petaflops-per-second-faster-than-the-Star-Trek-Voyager-computer-at-500-trillion-calculations-per-second
19,"Here are my thoughts on it:Mobile devices have become extremely popular, especially with the recent tred of laptops, ultrabooks, tablets, and smartphones.With these mobile devices, wireless networking is also a big topic. Wireless networks are inherently ""messier"" than typical wired networks, and a lot of research has gone into improving wireless communication.Social has become very big with the abundance of social networking websites (or websites with social features) - Facebook for ""general"" networking among friends, Twitter for news and following celebrities, LinkedIn for professional netwoHere are my thoughts on it:Mobile devices have become extremely popular, especially with the recent tred of laptops, ultrabooks, tablets, and smartphones.With these mobile devices, wireless networking is also a big topic. Wireless networks are inherently ""messier"" than typical wired networks, and a lot of research has gone into improving wireless communication.Social has become very big with the abundance of social networking websites (or websites with social features) - Facebook for ""general"" networking among friends, Twitter for news and following celebrities, LinkedIn for professional networking, Quora itself has a social component to it. There are many many others as well.On the topic of social and mobile is data. You may have heard of ""big data"" - ""big data"" has become even more prominent because of how much data websites like Facebook and Twitter are generating. Additionally, with all these smartphones generating sensor data like geolocation, apps that track your fitness, we have even more data.Cloud computing is also very big - look at services like Box, DropBox, Google Drive, Microsoft SkyDrive etc. The ability for users to sync files across several devices has drawn a lot of people to using these services. The fact that I can read my Kindle book on my laptop, close my laptop, take my Kindle/iPad/Android/tablet with me to a bus stop, and have the page synced to where I was on my laptop still impresses me.Datacenter networking is also becoming important - again going back to social, websites like Twitter have had issues with scalability, and have been rapidly establishing data centers everywhere to keep up with the demand.This is definitely not a complete list, but is what I can think of off the top of my head.In terms of keeping up to speed, I use a combination of books, following the key people on Twitter, article aggregation (I recommend Prismatic), and watching talks online (or going to them in real life).",47 followers,Deepak Mishra,6.1K,2.4K,138.2M,https://www.quora.com/Are-todays-super-computers-at-122-3-petaflops-per-second-faster-than-the-Star-Trek-Voyager-computer-at-500-trillion-calculations-per-second
20,"In present IT,it is very difficult to determine one particular technology as the best among others,because everyday is a evolution in computing and every single paves a way for a new technology.But,according to the present job scenario and stack overflow popularity,the below technologies have good growing opportunities:1.Artificial IntelligenceIt covers technologies that are used for prediction puIn present IT,it is very difficult to determine one particular technology as the best among others,because everyday is a evolution in computing and every single paves a way for a new technology.But,according to the present job scenario and stack overflow popularity,the below technologies have good growing opportunities:1.Artificial IntelligenceIt covers technologies that are used for prediction purpose.The technology stack of AI constitutes* Machine Learning2.Data ScienceData Science is all about cleaning,analyzing,organizing,preparing and visualizing the data.It requires the following things to be included:* Statistics3.Big Data and Cloud ComputingThese are another boom areas to be considered as the trending technologies in the present IT sector . It is because of the importance of data in the life of every individual and consistent improvement in social networks and ecommerce traffic.4.Full Stack Development using MERN/MEANWith the advent of javascript evolution in the web world,things have been vibrantly changed as it is coming up with number of frameworks every day.M-MONGODB5.ANDROID DEVELOPMENTAs the internet users are more comfortable with using android apps than websites,the demand of android development becomes very high.The two popular ways of building android apps are through:* Java6.Business Intelligence and Data VisualizationFor every business,there is a lot to deal with data.Data visualization becomes essential on every business and there is large demand in this area.The popular tools of BI and Data Visualization are:* Tableau7.AutomationAs the role of manual monitoring and surveilance is no mo...",25 followers,Ivan Chau,662,0,0,https://www.quora.com/What-do-you-think-is-the-most-clever-machine-learning-algorithm
