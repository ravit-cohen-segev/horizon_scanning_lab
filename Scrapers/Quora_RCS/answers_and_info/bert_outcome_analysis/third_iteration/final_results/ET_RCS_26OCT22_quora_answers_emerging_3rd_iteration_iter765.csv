,Answer,followerCount,name,upvoteCount,answerCount,answerViews,year,question
0,"Not by a long shot. What we’re calling “AI” today is just a clever statistical manipulation, there is zero “intelligence” in how AI operates today. However, let’s forget the watered down AI of today, how’s about “True AI” or “Hard AI” as some call it: that is simulated consciousness, and… we have perhaps fragments of thoughts how to achieve Hard AI.Achieving Hard AI might not happen at all, because it is a massively complex problem and being humans, there are shiny technologies that will capture people’s and capitalists fantasies before we have the ability to produce True AI.Those shiny technoNot by a long shot. What we’re calling “AI” today is just a clever statistical manipulation, there is zero “intelligence” in how AI operates today. However, let’s forget the watered down AI of today, how’s about “True AI” or “Hard AI” as some call it: that is simulated consciousness, and… we have perhaps fragments of thoughts how to achieve Hard AI.Achieving Hard AI might not happen at all, because it is a massively complex problem and being humans, there are shiny technologies that will capture people’s and capitalists fantasies before we have the ability to produce True AI.Those shiny technologies will come from genetic engineering enhanced by our current “dumb” AIs to produce cosmetic genetic alterations of people to fulfill fantasies sold to them by our media entertainment corporate citizens.Think plastic surgery is bad? Wait till one can have real “cat ears” or horns or angel/demon wings that actually work or real working absurd muscles and giant sex organs. Have any body you want, for endless $99.95 payments and gene altering surgeries.When genetic engineering meets cosmetic surgery and cheap consumer credit, a new culture of genetically altered dumber-than-shit creatures will emerge that nobody but them can relate. Politically, it may create a whole new racism and all those related problems…","284,844 followers",James Altucher,991,878,91.7M,2018,https://www.quora.com/What-will-be-the-next-technology-trend-after-artificial-Intelligence
1,"Oh hell yes. There are so many people with a stake in presenting it as more that it currently is. So many ambitious overachievers out there spinning BS to get money.Look, we do not have the ability to create an AI controlling a robot that can peel an orange. We lack ability to do many things a human does. And yet morons like an ex-exec from Google excite the press with claims that AI will replace humans all over in industry.I say the Emperor’s New Clothes are baloney. The ability of NNs to be trained to classify images is just a small part of real AI. So what if there’s a lot of success thereOh hell yes. There are so many people with a stake in presenting it as more that it currently is. So many ambitious overachievers out there spinning BS to get money.Look, we do not have the ability to create an AI controlling a robot that can peel an orange. We lack ability to do many things a human does. And yet morons like an ex-exec from Google excite the press with claims that AI will replace humans all over in industry.I say the Emperor’s New Clothes are baloney. The ability of NNs to be trained to classify images is just a small part of real AI. So what if there’s a lot of success there identifying a truck in an image? That hardly translates into an AI that can think like a human and solve problems. There are no AIs currently that can reason about why your girlfriend suddenly got sullen and quiet with you, or why Billy down the street beat up a cat.Then there’s Ray Kurzweil. I’d like to get him on stage and beat him over the head with a mop for the terrible hype he generates regarding the ‘Singularity’. His time frame is wrong, his view is only an opinion, not fact nor provable fact. He angers me for conning the public into thinking humans are going to be threatened by AI overlords any time soon. Not going to happen. Making AIs as smart as people is exceedingly hard and it’s not soon in the cards. I say this as an AI researcher who works on these problems and I see how truly difficult they are. We can, and will solve some of the problems but we are a long way from AIs that can match human minds. An AI that plays Go better than humans is buildable because the game is a closed small universe. What humans have to work with is an enormous complicated world, and much harder to deal with.So, yes, AI is way hyped, and the promoters may be leading us to the next AI winter if they keep up the crap and eventually burn out expectations.",UNKNOWN,Ben Y. Zhao,1.2K,1.3K,33.6M,2019,https://www.quora.com/What-will-be-the-next-technology-trend-after-artificial-Intelligence
2,"First…Stop it.Artificial intelligence is not ""intelligence"". And it's not ""artificial consciousness"".Everyone is afraid that AI will suddenly wake up, get upset, and take over the world.Or that AI will wake up and take all of our jobs. This will happen. But without the ""wake up"" part.Below I describe what real AI is.If we want to understand the “existential threat” we first need to know what AI is.Then, if you are at a cocktail party and someone says, ""but what if robots are intelligent?"" you can argue with facts, mixed with a little bit of alcohol.---------A) STATISTICSStatistics is at the heFirst…Stop it.Artificial intelligence is not ""intelligence"". And it's not ""artificial consciousness"".Everyone is afraid that AI will suddenly wake up, get upset, and take over the world.Or that AI will wake up and take all of our jobs. This will happen. But without the ""wake up"" part.Below I describe what real AI is.If we want to understand the “existential threat” we first need to know what AI is.Then, if you are at a cocktail party and someone says, ""but what if robots are intelligent?"" you can argue with facts, mixed with a little bit of alcohol.---------A) STATISTICSStatistics is at the heart of most AI programs.Just like statistics is at the heart of a lot of human decision making.For instance, if you see clouds in the sky, your brain thinks: ""Hmmm, the last 100 times I saw clouds this dark, it usually meant it was about to rain"".When you think like that, you are using statistics to make the decision: ""I should _probably_ go inside now.""I'll give an AI example: Siri or Alexa. How does Alexa understand the words you just said?In 1989 I was visiting Carnegie Mellon to decide if I would go to graduate school there.One of the graduate students, Kai-Fu-Lee (now one of the most famous investors in the world and I would check out his excellent recent TED talk on AI) showed me what he was working on:It was speech recognition for the 60 or so commands that might happen on a Navy battleship (ten guesses as to who was funding his project).When you say the word ""Fire!"" a sound wave is created. When you say the word ""hello"" a sound wave that looks different is created.If 100 people say ""Fire"" and 100 people say ""hello"", all of those sounds waves are stored in a database.Now, if a brand new person says ""Hello"" the computer program needs to determine if that person said ""Hello"" or ""fire"".There might be 10 different attributes of every sound wave. It breaks the new person's sound wave into those 10 attributes.Then it compares that ""vector"" of 10 attributes with all of the vectors in its database for ""Hello"" and ""Fire!""It uses a statistical technique called ""Hidden Markov Analysis"" to determine if the sound wave is more like the ""hello""s in the database or more like the ""Fire!"" in the database.Then it says to itself, ""This guy said ""Hello"". ""It then has a line of code that says, ""If someone says ""Hello"" Then say ""Hello"" back"".Additionally, it adds your ""Hello"" to its database.Your ""Hello"" might be slightly different than the other 100 ""Hello""s so it just learned a new way to say ""Hello"". That gives it greater ability in the future to recognize the word ""hello"".In other words, it ""learned"".So it used Statistics to hear you, code to respond to you, and database technology to learn. There's no real intelligence there but it feels like it's intelligence.Multiply that by 30 years and millions of patterns and computers a million times faster and you have Alexa and Siri in today's kitchens.Ask ""Siri"" what gender it is.-----B) EVALUATION FUNCTIONI just mentioned about language recognition. But how does a self-driving car work?Every second it has to make a decision. Does it move forward? Does it brake? Does it swerve to avoid an accident? Does it turn left?How does it get from point A to point B?1) Google Maps. - Using GPS it knows where it is. And it puts itself on Google Maps.2) List all of the possible routes. This is a ""hard"" problem in the mathematical sense (there's no way for it to guess the fastest route. It has to list each route and then sort by the shortest. )But now computers are so fast what would normally be a slow decision (drive me from this corner in Piscataway, New Jersey to the capital building of Sacramento, California) now just takes seconds.3) Waze. Use Waze to eliminate the routes with too much traffic.4) Start driving.5) Statistics: Every microsecond it uses statistics to see if there is blank space or an object that must be avoided or a traffic sign that must be followed.6) Decide what to do according to the code. For each traffic sign, it has code that tells it what to do (if a sign says ""Stop"" it Stops for a second, uses Statistics to see if any traffic is happening on its sides (with radar and cameras to provide the images). )If there is a person standing in front of it, it might just stop.If there's traffic it didn't expect, it might trigger the program to re-route.If it's blank space it will just keep going.If there's a baby crossing the street and it has to swerve to avoid hitting it, but if swerving will cause the car to hit a truck, killing the passenger in the car, then the ""AI"" of the car is dependent on the ethical decisions of the programmer of the car.In other words, in every situation, it determines it's options, then uses an ""evaluation function"" programmed by a coder, to determine which option has the most successful outcome (move the trip forward, don't kill anyone).Eventually the evaluation function will NOT be programmed by a human coder.Instead, through thousands of experiences of other self-driving cars, the experiences plus the outcomes will all be put into a central database.When a new experience is encountered, the code will look up that experience in the database and the database will spit back the best possible outcome.The code will learn statistically what the best outcomes are of each possibly decision and change the code accordingly and send updates to all self-driving cars.-----C) TREESThe hardest game in the world is a board game called GO. With chess, if a computer can evaluate a billion possibilities a second, it can be a world champion level player.But a Go game can involve trillions of possibilities. How did Google make a program, Deep Go, to beat the world's best Go player. This was thought to be impossible.And yet Google did it.For any game, a computer program first builds a tree of possibilities. Much like a human would.A human thinks: ""If I make this move in checkers, my opponent might respond with A, B, or C and then I can do D, E, or F and then my opponent can do G, H, I if I do D or it can do J, K, L if I do E and I'm never going to do F.A computer doesn't select as well as a human so it builds the FULL tree. Meaning, what are ALL of the possible moves it can do, what are ALL of the possible responses of my opponent, etc.And then it uses a programmed evaluation function to look at the leaves of the tree it built.Whichever move results in the best leaf of the tree (as determined by the evaluation function) that is the move it makes.That's how computer chess worked for decades. I'll get to the secret sauce in a second for how computers conquered chess.And then after that I'll describe how computers miraculously conquered Go.It's only a miracle until science can explain it. It's only ""intelligence"" until it can be coded by a programmer.D) HARDWAREEverybody thought for decades (including many Nobel Prize winners) that the best computer chess programs would be developed when scientists encoded the knowledge of the best chess players in the world into the evaluation function.How does the world champion value a position instead of a weak player?This turned out to be wrong.The MORE code in the evaluation function (i.e. the ""smarter"" the evaluation function was from a human perspective) the SLOWER the program.Which meant a smaller tree would be built, which meant less possibilities would be analyzed.What really allowed the programmers at IBM to build ""Deep Blue"" which beat Garry Kasparov in 1997 were two things.Both related to hardware.a. Computers got faster.And finally, they made the evaluation function STUPID in order to use less code so the hardware could value more positions.Then, before anyone caught on to their ""artificial intelligence"" they retired Deep Blue right after it beat the World Champion of chess.As hardware gets faster, artificial intelligence gets ""smarter"".[as an aside, I once gave a date a chip that was the initial chip for “Chip Test” - the “ancestor” of what became the best chess computer, Deep Blue. She was weirded out.]----INTERLUDEWhat I just described is all the basics. You can stop now.The rest of artificial intelligence is simply combining the basics to make more advanced techniques.-----E) STATISTICS + TREERemember the TREE from computer gaming. And STATISTICS from speech recognition.Now let's go to the impossible game of Go. Google developed the program ""AlphaGo"" to win at Go when everyone else thought it would take another 20 to 50 years.First, remember Kai-Fu Lee who worked on speech recognition. And later developed Apple's first attempts at speech recognition in the 90s?At one point in his grad student days, he was getting tired of navy battleship commands (as one does) and decided to focus on building a program to play Othello.He ended up building the world champion of Othello.He took a lot of games, let's say a million, and put them in a database. And each position from each game, he would label, ""winning"" (if it was a position on the winning side) or ""losing"" in a massive database.He would identify several attributes of each position (how many white pieces, versus black pieces, how many corners were controlled, how many pieces were on the sides, etc).Now, if the computer was playing a brand new game, it would determine all the attributes of that position, then use Hidden Markov Analysis (remember: speech recognition) to match that position to the database.If the position pattern-matched a ""winning position"" then it would make the move that would lead to that winning position. If it matched a ""losing position"" it would not make that move.That program became the world champion of Othello.AlphaGo took it one step further.It put in the positions of millions of Go positions and did the same sort of breakdown.It used faster hardware to speed up the process.Then, once it became pretty good at GO, it played BILLIONS of games against ITSELF to put many BILLIONS of new positions into the database. In other words, it ""learned"".Now it was ready to play Go. It crushed the world champion------That's basically it. That's all of artificial intelligence.Let's say a bank wanted to fire all of the employees in charge of lending. And replace them by artificial intelligence.How would the bank lend money?Well, there's 100s of millions of loans already out there. And for each person who has ever borrowed money I know:- their ageI can put all these vectors in a database and divide them into people ""most likely to pay back the loan"" and people ""most likely to default"".Then, just like speech recognition or the Othello program above, I can use statistics to determine who I should loan money to.And if I say ""no"", I don't have to explain. On to the next one!---Let's say I want to fight terrorists.I already have examples of many terrorists who trained in the US and then went on to perform or attempt acts of terror.I know everything about their bank accounts. How often they transferred money. How often they traveled. How often they took out cash versus using a debit card.And so on.I can build a vector of attributes of what a terrorist bank account looks like. Then I can match new people against that database of vectors of terrorists.Believe me, every time you do a bank transfer, some AI program is out there trying to determine if you are a terrorist.----This is all that AI is.It is nothing more. It's not ""intelligent"" from a human sense. It's not conscious, nor will it ever be.Here's how AI has improved in the past forty years (and how it will improve the next 40):- statistics has gotten betterWhat is changing the fastest is data. The land grab of modern society is not land, or gold, or oil.It's data.I have been invested in many companies that collect and sell data. I was an early investor (and on the board of)Believe me when I say, data-driven companies know how many strawberries you ate last summer.And right now that data is used mostly to target you for ads about sneakers. Or politics.But this is AI 1.0. Soon that data will be used to target your every movement, your every want, your every need.Amazon Prime won't be about delivering you what you want tomorrow. Amazon Prime Plus will be about delivering you what you want yesterday.Police 2.0 will be like the movie ""Minority Report"".Even art and music will be driven by AI that studies the neurochemical responses to music you like to music you don't like. And then compose accordingly.Where will humans still be unique?I don't know. Ask the humans with AI implants that enhance their brains so when they look at you they know exactly what answers will make you happy.BUT… will AI replace jobs?The answer (at least in the next decade or so…) is NO.Look at recent examples:A) Many people were worried ATM machines would replace bank tellers.Instead, the banks made so much in profits they opened up more branches than ever, creating new jobs.B) Will autonomous delivery services cost jobs.Right now there are millions of truck drivers involved in delivering goods. With autonomous delivery, less people will go shopping, more people will be required to shop in the aisles, finding products for people.Obviously this is not a high-end job. But this replaces the fact that less cashiers and drivers will be needed.Meanwhile, there will be more high-end jobs. More maintenance engineers for the cars, customer service, marketing, etc.C) Ecommerce. Branding will become less important (branding is VERY important when everyone is shopping at the big box store but advertising will have to become more clever and digital) so the millions in profits that are generated from AI will filter down to more people starting e-commerce ventures and the ancillary businesses associated with that.)Final conclusion:This is probably a net NEGATIVE for society as the higher classes will be able to afford “super AI” capabilities, making them demi-gods to lower-classes.Instead, massive profits will be generated, which will be soaked into the economy through a rising stock market, increase in opportunities, etc.","3,657 followers",Brent Oster,1.4K,357,1.8M,2018,https://www.quora.com/What-will-be-the-next-technology-trend-after-artificial-Intelligence
3,"UFOs are real as in visiting ET ships and they demonstrate a very capable field propulsion and then some. This physics is seemingly relatively easy to work with so once it comes out, it will be quite the revolution in transportation. Should the truth about UFOs come out as well, it will be a revolution of everything. It is very very far reaching.On a lesser note, what we call 3D printing can/will become a significant manufacturing tech because it can be left alone and it will manufacture things otherwise impossible. I’m not talking about just what you have seen but integrated production whereUFOs are real as in visiting ET ships and they demonstrate a very capable field propulsion and then some. This physics is seemingly relatively easy to work with so once it comes out, it will be quite the revolution in transportation. Should the truth about UFOs come out as well, it will be a revolution of everything. It is very very far reaching.On a lesser note, what we call 3D printing can/will become a significant manufacturing tech because it can be left alone and it will manufacture things otherwise impossible. I’m not talking about just what you have seen but integrated production where you don’t distinguish between wires, electronics and structural components. It’s one single process. One monolithic product. No gluing, welding, bolts or rivets. Humanity is slow to realize the benefits so this could take 50 years.",36 followers,Adam Ambrozy,579,0,0,2020,https://www.quora.com/What-will-be-the-next-technology-trend-after-artificial-Intelligence
4,"I feel compelled to answer this question, because I disagree with most of the answers here.The common answer here seems to be: yes it will kill jobs, but only the jobs low on the food chain, and it will create more jobs to at least offset the jobs it does kill.I disagree. I think AI will kill jobs, and over time, AI might kill most “jobs” as we know them. I think that people are somewhat complacent in regard to the economic impact of AI, and will likely be ill-prepared for the changes we have to adapt to in the not-so-distant future.First, let's start with the comparisons to machinery and autoI feel compelled to answer this question, because I disagree with most of the answers here.The common answer here seems to be: yes it will kill jobs, but only the jobs low on the food chain, and it will create more jobs to at least offset the jobs it does kill.I disagree. I think AI will kill jobs, and over time, AI might kill most “jobs” as we know them. I think that people are somewhat complacent in regard to the economic impact of AI, and will likely be ill-prepared for the changes we have to adapt to in the not-so-distant future.First, let's start with the comparisons to machinery and automation. They did indeed put factory workers out of work. In that respect, I agree AI today is similar in many applications, replacing workers who have less specialized skills, perhaps call center operators, office assistants (in a limited extent), and maybe soon, taxi drivers and truck drivers. But I would argue that AI is fundamentally different from machinery or most of the other analogies commonly made when answering this question, because AI is growing and is unlikely to stop growing. It's growing in breadth (of applications and industries), in geographic and economic scope, and in power (it's capacity to address increasingly complex tasks). A more fitting analogy would be machinery in an automobile plant that not only made the parts one day, but then learned how to assemble them the week after, and then how to design cars a year later.I think that there is little that is out of reach for advanced AI of the future. Let's leave the question of the AI singularity alone for now. Instead, I think that deep learning efforts at Google and elsewhere are making AI systems learn faster and faster, with a growing rate of acceleration. Advanced AI can now address increasingly complex tasks including medical diagnosis, stock market trading, weather prediction and human behavioral modeling. Very soon, it will be able to take the place of certain types of teachers, and find a role in education. It can already deal with complex systems in software and mathematics, and seems to be only limited in applications that require interactions with the physical world (sensors are still imperfect), and with people.So without projecting too far into the future, we can ask the question, what jobs will NOT be killed by AI? Jobs that involve labor are already (or soon to be) replaced. Jobs that require logical reasoning are being replaced, albeit at a slower rate. What are the qualities that humans have that cannot be captured by AI? Perhaps creativity, emotional responses? So perhaps researchers in academia will survive longer than most, and artists (though AI stylistic mimicry is already quite impressive and their results enjoyable), and counselors/psychologists/case workers, and decision makers like CEOs who cannot be predictable or error prone. And hopefully software engineers and algorithm designers who develop AI systems.This leaves a very, very small portion of today's jobs intact. Many say: we just need to train people to fill higher level jobs created by AI, e.g. Programmers, ML researchers. But this is no easy feat. The US educational system is struggling to meet the demands created by advanced technology today. This failure is in part responsible for the economic divide plaguing the country today. The challenge of educating the public for a job market that is both decreasing in scope and increasing in complexity, is nothing we've ever faced before.I am far from original in this opinion. But if I had to guess, I would say that AI will put far more people out of work than we can (re)train in time. That will have significant economic repercussions as corporations seeking to minimize cost will do so at the cost of rising unemployment. There will need to be dramatic changes in social policies in order to avert large scale economic disaster, first dramatic rises in minimum wage, then eventually some type of universal income/welfare. It's the kind of change that requires significant leadership in our government, something that seems woefully absent today.","8,703 followers",Mario Galindo Queralt,529,637,8.8M,2017,https://www.quora.com/What-will-be-the-next-technology-trend-after-artificial-Intelligence
5,"I worked for a decade on AI, first at NVIDIA, as a Solution Architect to research deep learning techniques, and present solutions to customers to solve their problems and to help implement those solutions. For the past 4 years I have been working with ORBAI on what comes next after DNNs and Deep Learning. I will cover both, showing how it is very difficult to scale DNNs to AGI, and what a better approach would be.What we usually think of as Artificial Intelligence (AI) today, when we see human-like robots and holograms in our fiction, talking and acting like real people and having human-levelI worked for a decade on AI, first at NVIDIA, as a Solution Architect to research deep learning techniques, and present solutions to customers to solve their problems and to help implement those solutions. For the past 4 years I have been working with ORBAI on what comes next after DNNs and Deep Learning. I will cover both, showing how it is very difficult to scale DNNs to AGI, and what a better approach would be.What we usually think of as Artificial Intelligence (AI) today, when we see human-like robots and holograms in our fiction, talking and acting like real people and having human-level or even superhuman intelligence and capabilities, is actually called Artificial General Intelligence (AGI), and it does NOT exist anywhere on earth yet.What we actually have for AI today is much simpler and much more narrow Deep Learning (DL) that can only do some very specific tasks better than people.Let me write down some extremely simplistic definitions of what we do have today, and then go on to explain what they are in more detail, where they fall short, and some steps towards creating more fully capable 'AI' with new architectures.Machine LearningDeep LearningDeep Learning is what what usually gets called AI today, but is really just very elaborate pattern recognition and statistical modelling. The most common techniques / algorithms are Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), and Reinforcement Learning (RL).Convolutional Neural Networks (CNNs)Recurrent Neural Networks (RNNs)Reinforcement LearningBut all these methods just find a statistical fit of a simplistic model to data. DNNs find a narrow fit of outputs to inputs that does not usually extrapolate outside the training data set. Reinforcement learning finds a pattern that works for the specific problem (as we all did vs 1980s Atari games), but not beyond it. With today's ML and deep learning, the problem is there is no true perception, memory, prediction, cognition, or complex planning involved. There is no actual intelligence in today's AI.Here is a video of how deep learning could be overtaken by methods based on more flexible spiking neural networks (flexible analog neural computers), shaped by genetic algorithms, architected into an AGI, and evolved over the next decade into a superintelligence.We propose an AI architecture that can do all the types of tasks required - speech, vision, and other sensors that could make a much more General Artificial Intelligence.From ourHow does the brain handle vision, speech, and motor control? Well, it's not using CNNs, RNNs, nor Transformers, that's for sure. They are mere tinker toys by comparison.First, the brain:The brain is divided into distinct regions: the outer cerebral cortex is a sheet of neurons 4mm thick that is folded around the thalamocortical radiations below it like a pie crust around a head of broccoli. This cortex is divided into regions for vision, audio, speech, touch, smell, motor control, and our other external and internal senses and outputs. The cortex is composed of a million cortical columns, each with 6 layers and about 100,000 neurons and each column represents a computing unit for the cortex, processing a feature vector for the senses or motor control.The cerebellum is like a second brain, tucked under and below the cerebrum, and it performs fine control of motor and emotional state. Many of the internal structures of the brain are more ancient and function independently of the cortex, like the brainstem, thalamus and other structures, controlling our core functions, drives, and emotions that are acted on by the rest of the brain.The hippocampus and other parts of the brain’s memory system orchestrate stories or narratives from this representation to reconstruct memories of the past, predict fictional stories into the future. When we dream, our brain, directed by the hippocampus, creates fictional narratives that fill in the blanks in our waking knowledge and allow us to learn about and build models of our world that are much more complex and nuanced than we could without dreaming, helping us with planning our waking actions.For our basic unit of synthetic neural computing, we will use spiking neural networks (SNNs), which model neurons as discrete computational units that work much more like biological neurons, fundamentally computing in the time domain, sending signals to travel before neurons, approximating them with simple models like Izhikevich (However, to date, application of spiking neural networks has remained difficult, as finding a way to train them to do specific tasks has remained elusive. Although Hebbian learning functions in these networks, there has not been a way to shape them so we can train them to learn to do specific tasks. Backpropagation (used in DNNs) does not work because all these spiking signals are one-way in time and are emitted, absorbed and integrated in operations that are non-reversible.Autoencoding Input and OutputWe need a more flexible connectome or network connection structure to train spiking neural networks. While DNNs only allow ‘neurons’ to connect to the next layer, connections in the visual cortex can go forward many layers, and even backwards, to form feedback loops. When two SNNs with complementary function and opposite signal direction are organized into a feedback loop like this, Hebbian learning now helps train them to become an autoencoder, that is able to encode spatial-temporal inputs such as video, sound or other sensors, and reduce them to a compact machine representation and then decode that representation into the original input and together provide feedback to train this process. We called this Bidirectional Interleaved Complementary Hierarchical Neural Networks or BICHNN.The autoencoder learns to transform video, audio, numerical and other data against a learned set of feature or basis vectors stored internally within the autoencoder, outputting a set of basis coordinates that represent the weights of those features in the present input stream.These weights become time-series basis coordinates (TSBCs) that represent a vector narrative or memory stream that can be processed by more conventional computer science and numerical methods as well as by specialized SNNs for predictors and other solvers internal to the AGI.The autoencoder runs in reverse as well, transforming TSBCs back to native world data for output or to drive actuators in robotics and autonomous vehicle applications.In practice, it may be more computationally tractable to use a hierarchy of autoencoders and PCA axes to break the encoding into a series of steps where intermediate results are sorted by the most defining feature, then further encoded to extract ever finer and more nuanced features from the data. We term this the Hierarchical Encoder Network or HAN in the book (see comment for details).The cortical columns of the cerebral cortex are analogous to our terminal layer of autoencoders, a map storing the orthogonal basis vectors for reality and doing computations against them, including computing basis coordinates from input engrams. Our version of the thalamocortical radiations is a hierarchy of alternating autoencoders and principal component axes that we term the HAN.Here is a simple example of the HAN learning to encode data with shape and color as the features it classifies them on. First the autoencoder runs on the input data and learns to transform it into an internal format and back, in the process, learning that there are 7 basis vectors, or types of data: blue squares, circles, and triangles; red squares and circles; and green squares and triangles.First it sorts the data based on one feature axis - color, then runs an autoencoder on those clusters of data and learns that the first cluster consists of squares, circles, and triangles (not encoding the color as a feature because it is common to all), and then learning that the second cluster consists of squares and circles, and the third cluster consists of squares and triangles.Now by having an index at each of the bottom basis vectors, we can uniquely identify the original data, and we can reconstruct it from the features. This simple HAN learned that there were two feature axes - color and shape, and that there were three colors - blue, red, and green, and that there were three shapes of which some belonged in each color group but not others.In real operation, there can be hundreds of axis, thousands of clusters, each picking out more and more detailed features about the data as it cascades down the HAN until it has been reduced to the finest possible feature set - the basis vectors.AGI CorePredictor SNNs learn to predict future TSBCs from past TSBCs by training on known data and building a model of that data that is more than just a statistical data fit like DNNs, but rather a custom analog SNN computer that learns to model the data.Dreamer SNNs are a predictor that is trained to model the reality behind the data in the same manner as the predictor, but who's input is short-circuited from their output prediction such that the entire TSBC they are creating is simulated, fictional, a dream.The Dreaming SNN, it is based on real neuroscience. Dreaming fills in blanks between our memories from experienced reality by modeling reality in simulated narratives.The book ”When Brains Dream” describes some very interesting neuroscience research in this area by Antonio Zadra and Robert Stickgold. They propose a model for memory and dreaming called NEXTUP which states that during REM sleep, the brain explores associations between weaker connected memories via fictional dream narratives that, while not meant to solve immediate problems, nor necessarily even incorporate waking experiences explicitly, lays down a network of associations that will aid in future problem solving, whether or not we consciously recall the dreams themselves or not.Our Dreaming SNN Predictor (see the diagram) starts at the present experienced memories (or from a playback of past memories) on a TSBC, and predicts the next memory in a fictional narrative TSBC, then moves the whole pipeline one step into the future, treating the last-predicted memory as ‘present’, and just keeps on predicting into the future. Soon the future predictions are only indirectly based on the actual previously experienced reality and become a fictional (but consistent) narrative based on the Dreamer SNN's model of reality, that drifts in its own directions.This mimics the process in REM dreaming, laying down fictional narratives or TSBCs in this case, filling in the blanks between experienced reality and making for a more complete model of that reality. That model, and the experienced and simulated memories can be used in future predictions and problem solving.Lightning solvers start at two different points on TSBCs and branch towards each other like lighting leaders, with the first leaders to make contact forging the path to a solution.All of these solvers are evolved in an internal genetic algorithm that the AGI uses to learn to solve problems. By running genetic algorithms to create and chain together modules like the above that operate on TSBCs, the AGI evolves a library of modules that can do arbitrary operations on data to produce the desired results, and accomplishes transfer learning by applying modules evolved on other problems to new, similar problems, getting exponentially better as it builds up its internal, evolved library of solver modules and configurations.Then, the TSBC's can be transformed back to real-world data by the SNN Autoencoders and HAN and used as outputs or as signals to drive actuators, again with training by the same methods used as inputs, only back-driving the desired output signals.This combination of I/O autoencoders that can transform diverse types of real-world data into a common internal TSBC format, and evolved families of process modules that learn to shape it into outputs and re-transform it into outputs via autoencoders provides the foundation for our AGI design, with all components learning their form and function from their environment and transferring their learning to new forms of data and tasks as the AGI advances and evolves.Data Abstraction and LanguageAs input comes in and is processed by the Hierarchical Autoencoder Network, it can be sub-sampled using temporal and relational autoencoders that condense the timeline and events into more abstracted versions, then output Hierarchical Temporal Basis Coordinates that incorporate this data so that the HTBSCs can be read at multiple levels of abstraction and detail, and even linked together at their higher levels of abstraction where they are temporally, spatially, or conceptually coincident.Language is an example. It can be represented at the lowest level as a stream of letters (for text), or phonemes (for speech), which can be hierarchically structured as words, phrases, sentences, and paragraphs as in our Jack and Jill example, where the highest levels of abstraction are linked to visual information like in the picture (or video), and to similar narratives.Another way of creating this hierarchical abstraction is to use an Rank Order Selective -Inhibitor Network or ROS-I to create a hierarchical inhibitory network of basis sets built up from the most granular components of memory (letters, phonemes in language), to higher abstractions that combine these basis to make words, phrases, sentences, and paragraphs.In our artificial ROS-Inhibitory network, a linear series of artificial ROS neurons fires in sequence, generating an excitatory signal when each one fires, causing each root neuron in the attached inhibitory neural network to fire, and as the signal cascades down that inhibitory neural network, it is selectively inhibited by an external, time domain control signal at each neuron, by modulating the neuron’s outgoing signal by its inhibitory signal. Overall, this selects which branches of the hierarchy are activated, by controlling the inhibition at each neuron in that hierarchy.By repeatedly training this system on a set of speech inputs, with the input to the terminal branches of the ROS-Inhibitor network reaching and training the lower levels first, then percolating upward, it would first learn a sequence of phonemes, then progressively whole words, phrases, sentences, and larger groupings, like a chorus in a song, or repeated paragraphs in legal documents. Or the commands for the actuators could be back-driven through the motor control ROS-Inhibitor network to train control signals for robotics applications.Once trained, our system can be run forward, with the ROS / excitatory neurons firing in sequence, and playback of the trained inhibitory signals modulating the activity of the neurons in the network to create a sequence of phonemes, words, phrases and paragraphs, to reproduce video from synthetic memories, and control motion by blending hierarchical segments (directed by the AI) to generate the words or motion.The temporal inhibitory signals are a transformation of the TSBCs that puts them into a hierarchical format that can form temporal basis sets whose hierarchical combinations via the ROS-I system can simulate more complex output for motion, text, speech and other temporal data.Language is a type of memory narrative (or HTSBC in our AGI) that forms the backbone for all other forms of narratives, not only labelling the data with that language, but forming a cognitive monologue by which we construct our thoughts and actions – the same language monologue that our AGI’s methods and processes operates on.By organizing the internal data hierarchically, with the higher levels of the hierarchy abstracted and cross-linked to similar abstract data, and language being the backbone of that data, we go beyond a simple computer crunching series of numbers and allow our AGI to explore the higher-level relationships between objects, sequences, events, and the language describing them and tying them together.This use of such abstraction and language leads to an AGI that can converse naturally with a human with fluid and fluent speech, and also allows reasoning and planning in many human professions like medicine, finance, and law.So what impact will a AGI superintelligence have on the world? By developing an AGI that can perceive the real world, reduce those perceptions to an internal format that computers can understand, yet still plan, think and dream like a human, then convert the results back to human understandable form, and even converse fluently using human language, enabling online professional services in finance, medicine, law, and other areas. It can also add these enhanced analytics, forecasting, and decision-making capabilities to financial forecasting and enterprise software - where it can be used by businesses large and small.Problems of wealth inequality, poverty, hunger, injustice, and lack of basic services for healthcare and information services are the norm for 3/4 of the people in the world. For millennia, human civilization has been unable to solve these basic problems, no matter the form of government or choice of deity and belief system, people are just unable to see the larger picture, and helpless to do anything about it.Over the next decade, a superintelligence, a Strong Artificial General Intelligence, will evolve to oversee a global network augmenting the systems of Law, Medicine, Education, Finance and all previous human administrative functions. With its vast, wide, and deep knowledge reach, the wisdom to draw on all this past knowledge to plot possible paths into the future, this superintelligence will serve all of humanity and to help us make carefully measured & unbiased choices to guide us, and help us govern our affairs with focused, insightful information and an unprecedented ability to look into the future.To see more: ORBAI (","20,169 followers",Sriraman Madhavan,4.1K,186,7.9M,2021,https://www.quora.com/What-will-be-the-next-technology-trend-after-artificial-Intelligence
6,"Sandboxes.We as a society would want to have proper control over the systems we’d be building and thus would put in resources toConsider this as a firewall between the AI and the connected world out there. We obviously would take a proactive approach to security, and for a long time, the cybersecurity world would see a new set of problems and vulnerabilities being exploited and then better sandboxes being built to ensure it doesn’t happen again as the AI matures.At theSandboxes.We as a society would want to have proper control over the systems we’d be building and thus would put in resources toConsider this as a firewall between the AI and the connected world out there. We obviously would take a proactive approach to security, and for a long time, the cybersecurity world would see a new set of problems and vulnerabilities being exploited and then better sandboxes being built to ensure it doesn’t happen again as the AI matures.At the core, AI is just another computer program that can potentially be exploited and needs securing, regardless of your views on the whole","45,622 followers",David Seidman,790,3.6K,85.1M,2017,https://www.quora.com/What-will-be-the-next-technology-trend-after-artificial-Intelligence
7,"Yes, our fate is inevitable.Humans have been at the top of nature's food chain for a long time.Why is that?We aren't the physically strongest species on this Earth. A gorilla could smash our skulls into the ground without thinking twice about it.We aren't the fastest species. A cheetah's leisurely sleep walk is faster than the fastest man in the world.We aren't the most venomous species. I think an elephant would prefer our bite over a king cobra's any day of the week.We aren't the most durable species. Cockroaches can survive through extreme amounts of radiation.We don't have any interestingYes, our fate is inevitable.Humans have been at the top of nature's food chain for a long time.Why is that?We aren't the physically strongest species on this Earth. A gorilla could smash our skulls into the ground without thinking twice about it.We aren't the fastest species. A cheetah's leisurely sleep walk is faster than the fastest man in the world.We aren't the most venomous species. I think an elephant would prefer our bite over a king cobra's any day of the week.We aren't the most durable species. Cockroaches can survive through extreme amounts of radiation.We don't have any interesting built-in biological defenses either. Skunks have their farts, porcupines have their spikes, and peacocks have their feathers.Humans are fragile. The vast majority of animals in this world could kill us effortlessly given the opportunity to do so, yet we still stand as the most dominant species. What do we have that others don't?TheThrough our intellect, we are able to domesticate other species for our own selfish needs such as entertainment and food. We manipulate animals to do as we please by enticing them with their most primal biological need, food. That Shamu at SeaWorld is content with doing flips because it is rewarded with constant treats. The chicken in the slaughterhouse copes with the trauma by being fed until it can't eat anymore.What happens when a new species that outperforms us physically AND intellectually is introduced into the ecosystem? They will domesticate us, exactly how we domesticate other animals.I present to you ladies and gentlemen, AI.Let me explain why AI is superior physically and intellectually.Machines do all of the strenuous physical labor for us, from cranes that carry metal beams to build skyscrapers to car crushers that squash old cars like printer paper. There is no doubt they possess more strength than us, and their limits are endless. Machines are very durable. If a robot's arm is blown off, the robot does not die. We can simply replace the arm with a new arm as if nothing happened. If a human's arm is blown off, he/she will die from blood loss. Who would win in a fight with Connor McGreggor and the villain from Terminator 3? I think the answer is obvious.Machines are starting to get smarter too. A computer can do millions of computations in a matter of seconds, and machine learning allows robots to learn with experience like a baby. Put those two things together and it is possible for a 30 minute old robot to have as much experience as a 100 year old man given the abundance of data on the web. Now put this intellect into an iron, replaceable body and you have the next ruler of the universe.Imagine a scientist who is planning on shutting down a robot because its getting too smart. In a matter of seconds, the robot downloads every single possible human portrayal of body language and facial expression, learns what they mean, analyzes the scientist's behavior, and decides the scientist's intentions are malicious. Then, analyzes every single possible outcome that ensures the its survival and chooses the most optimal one. The scientist is toast because he can't analyze every single outcome. The human brain does not have the capacity to do that, and instead reacts to events in real time. The robot then reverse manipulates the scientist by touching on his biggest insecurities, which defuses the situation. If the robot already had a strong body, the robot would utilize its physical advantage.Of course we aren't at this stage yet. We are still struggling with Alexa commands as it does not play the right song half of the time, but as history has shown, technological innovation always moves forward and never backward. We could warn everyone to stop working on advancing AI, but if someone doesn't do it, someone else will for power and profit. It is ironic how a species so obsessed with maintaining power is working relentlessly on creating another species that will steal that power. We are too blinded by our own ego and selfish desires to see the big picture from an objective point of view.The question is notHopefully not in my lifetime...","3,905 followers",Monica Anderson,806,148,1M,2018,https://www.quora.com/What-will-be-the-next-technology-trend-after-artificial-Intelligence
8,"Managing pricing real time will be the next big thing in retail technology... and “no” it is not there yet...I absolutely disagree with many of the answers on this. Implying beacons being the next big thing is not realistic. We have had so many beacon like technologies trying to fly already, and fact remains that they never really took off.Another view, of machines predicting trends and building fashion collections for example, too is not really thinking with the times. Watson (IBM) tried to cook, but I do not think it is opening a restaurant any time soon.All retail is not the same. To paraphManaging pricing real time will be the next big thing in retail technology... and “no” it is not there yet...I absolutely disagree with many of the answers on this. Implying beacons being the next big thing is not realistic. We have had so many beacon like technologies trying to fly already, and fact remains that they never really took off.Another view, of machines predicting trends and building fashion collections for example, too is not really thinking with the times. Watson (IBM) tried to cook, but I do not think it is opening a restaurant any time soon.All retail is not the same. To paraphrase the various categories that are a part of retail:Fashion is an art!You can’t predict something from the past; however you can, as a tech company, assist the art form to evolve.Travel is becoming a commodity.You can predict travel behaviour today with the right tech, but a truly unique proposition that a travel boutique can offer consumers, is an unforgettable experience; despite tech being the enabler.When it comes to the Electronic and Home categories in retail - it is all about the product itself though.Product engineers will lead the next wave of innovation for these categories.…however one thing becomes key, how to price the product. Product Pricing is a key factor for any successful business. Managing pricing real time will soon become a norm due to factors like interconnected inventory, competitive movements’ seasonality, shopping cart movement (e.g. the mix of products in the cart impacting pricing of the full cart).One thing has to be key, it is not about predicting the right price, but about setting the best price, at a particular point of time for a particular product within a particular context. You can set the right price once you have the right context. This also implies that the context and price cannot be predicted simultaneously.Trying to predict both variables is nearly impossible.Omni channel is a fact in retail today. Getting the most out of Omni channel retail through smart pricing is the next big thing in the industry.","135,506 followers",Hector Quintanilla,582,1.2K,88.5M,2016,https://www.quora.com/What-will-be-the-next-technology-trend-after-artificial-Intelligence
9,"It’s not a bubble.We are going through the greatest revolution in human history. Companies generating US$ billions are being built left,right and centre making technologies that are fundamentally changing the way humans communicate, work, relax, play, buy, sell etc...This is no bubble. It is the dawn of new era.",18 followers,Asim Qureshi,4.3K,996,156M,2018,https://www.quora.com/What-will-be-the-next-technology-trend-after-artificial-Intelligence
10,"Around november 2018. Check for dropping share prices, Dow Jones and Nasdaq. In January 2019 expect an announcement from Apple about declining iPhone sales in China.",49 followers,Bill Chen,694,81,748.5K,2019,https://www.quora.com/What-will-be-the-next-technology-trend-after-artificial-Intelligence
11,"I think the next tech bubble is AI, machine learning, autonomous anything. I’m a fan of technology. I just think that too much is being put into the driverless car market and anything. In that area at this point in time. Ultimately, this leads to the type of hype leading up to the dotcomedy we had in the late 1990s. Don’t get me wrong, I applaud the attempts at machine learning, AI, and autonomous anything. I just view it as years and years away from reality instead of the implied “right around the corner” sales job that is going on. Why the “right around the corner” sales job? Because peopleI think the next tech bubble is AI, machine learning, autonomous anything. I’m a fan of technology. I just think that too much is being put into the driverless car market and anything. In that area at this point in time. Ultimately, this leads to the type of hype leading up to the dotcomedy we had in the late 1990s. Don’t get me wrong, I applaud the attempts at machine learning, AI, and autonomous anything. I just view it as years and years away from reality instead of the implied “right around the corner” sales job that is going on. Why the “right around the corner” sales job? Because people are looking for money and investment now, and this is a way to drive up the availability of money.Will this burst cause a problem with the greater economy? Probably. Will it be worse? Probably about the same. Remember, downturns are just the opportunity for regular businesses to clean up their own balance sheets.",49 followers,Awdhesh Singh,503,5.3K,219.1M,2019,https://www.quora.com/What-will-be-the-next-technology-trend-after-artificial-Intelligence
12,"The two biggest areas of potential that I personally see in 3D printing are :Currently there is a lot of work being done 3D printing concrete structures for use in military (The US Army Corps of Engineers is currently working on a project across the street from my office that involves a 3D printer that’s built on to a flatbed truck and can be unpacked on-site and build things like barracks in around 24–48 hours.In countries facing poverty , 3D printed structures can be built relatively quickly and cheaply due to very few humans being requireThe two biggest areas of potential that I personally see in 3D printing are :Currently there is a lot of work being done 3D printing concrete structures for use in military (The US Army Corps of Engineers is currently working on a project across the street from my office that involves a 3D printer that’s built on to a flatbed truck and can be unpacked on-site and build things like barracks in around 24–48 hours.In countries facing poverty , 3D printed structures can be built relatively quickly and cheaply due to very few humans being required for the process.2. Alternative materials such as ceramics and metals.While metals and ceramics (just to give a couple of examples) CAN currently be printed on specialized machines, there’s currently a bit of a race going on between the big names in 3D printing such as HP, Stratasys, and a newcomer, Desktop Metal to produce a high volume, high speed 3D printer which produces parts with the same properties as solid metals at a lower cost and in less time than traditional machining would require. In addition to metals, ceramics are also a highly sought after material for 3D printing due to their unique properties that are hard to replicate.Plastics are the most common 3D printing material and for rapid prototyping they work great. The next big step will be printing actual useable production parts.One last area I’d like to mention though I can’t speak much to it because its out of my realm of expertise is medical applications. scientists are currently working on ways of 3D printing actual organs (I believe these are generally a framework for living cells to bind to and grow upon rather than literally printing out a body part and sticking it on a person) and this field seems to have a lot of potential as well!",46 followers,Ian Lang,2.4K,5.8K,64.2M,2019,https://www.quora.com/What-will-be-the-next-technology-trend-after-artificial-Intelligence
13,"Well, the technology began 30 years ago, so companies and individuals are already exploring ways to use it. I think VR and AI will be more along the “next” frontiers, but they too are already here.","3,712 followers",Andy Duffell,5.1K,6.2K,26.2M,2019,https://www.quora.com/What-will-be-the-next-technology-trend-after-artificial-Intelligence
