{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "import ssl\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For ignoring SSL ceritficate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function get first number in string\n",
    "\n",
    "def str_first_num(s):\n",
    "    first_num = ''\n",
    "    flag_digit=False\n",
    "    for el in s: \n",
    "        if el.isdigit():\n",
    "            first_num += el\n",
    "            flag_digit = True\n",
    "        else:\n",
    "            if flag_digit:\n",
    "                break\n",
    "    return first_num\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a helper function that removes unwanted words/sections like url links\n",
    "def strip_rgx_words(inp, regex_ = ['image','url']):\n",
    "    #remove urls or images\n",
    "    rgx_word = None\n",
    "    for rgx in regex_:\n",
    "      if rgx in inp:\n",
    "          rgx_word = rgx\n",
    "          break\n",
    "    if rgx_word is not None:\n",
    "      out = inp.split(rgx_word)[0]\n",
    "    else:\n",
    "      out =inp\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read question urls from csv file\n",
    "src_path = r\"C:\\Users\\Ravit\\Documents\\horizon_scanning_lab\\Scrapers\\Quora_RCS\\answers_and_info\\quet_indexes.csv\"\n",
    "df = pd.read_csv(src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get list of urls\n",
    "url_list = list(df['url'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.quora.com/What-will-the-worlds-technology-be-like-in-50-years',\n",
       " 'https://www.quora.com/How-long-could-the-brain-survive-theoretically-if-we-had-the-technology-to-replace-all-other-body-parts-as-you-aged-with-functioning-organs-that-are-grown-in-a-lab-using-your-DNA',\n",
       " 'https://www.quora.com/What-are-the-top-10-emerging-technologies-in-the-next-5-10-years-2020%E2%80%932025',\n",
       " 'https://www.quora.com/What-are-the-upcoming-emerging-technologies-in-software-industry',\n",
       " 'https://www.quora.com/What-will-the-worlds-technology-be-like-in-50-years',\n",
       " 'https://www.quora.com/What-are-the-most-advanced-technologies-that-people-dont-know-about-yet',\n",
       " 'https://www.quora.com/When-will-Fusion-reactors-become-a-reality',\n",
       " 'https://www.quora.com/In-future-IOT-Internet-of-things-is-trending-technology-or-not',\n",
       " 'https://www.quora.com/What-will-the-worlds-technology-be-like-in-50-years',\n",
       " 'https://www.quora.com/What-are-the-solutions-to-emerging-issues-in-communication']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answers_into_df(url):\n",
    "    '''input: url for scrapping answers to a particular question.\n",
    "        out: df with answers for each url/question'''\n",
    "    \n",
    "    #request url html\n",
    "    page = requests.get(url)\n",
    "   \n",
    "    #create soup object with htmal parser\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    answers = soup.find_all('script', {\"type\": \"application/ld+json\"})[0]\n",
    "    #convert soup object to string\n",
    "    answers = [str(a) for a in answers][0]\n",
    "    #split answers with text separator\n",
    "    answers_list = answers.split('\"text\":')\n",
    "    #first element is just the header of a page. remove it\n",
    "    answers_list = answers_list[1:]\n",
    "    \n",
    "    #create df with nans to fill it later with values\n",
    "    columns = [\"Answer\", \"upvoteCount\", \"affiliation\", \"answerCount\", \"followerCount\", \"hasCredential\",  \"knowsAbout\", \"name\"]\n",
    "    x_shape = (len(answers_list), len(columns))\n",
    "    x = np.tile(np.nan, x_shape)\n",
    "   \n",
    "    answers_df = pd.DataFrame(x, columns = columns)\n",
    "\n",
    "    for i, ans in enumerate(answers_list):    \n",
    "        #get list of categories that exist in answer post\n",
    "        existing_columns = [col for col in columns if col in ans]\n",
    "               \n",
    "        #get values to columns that exist in post \n",
    "        regex_ = [\"image\", \"url\"]\n",
    "        \n",
    "        for j, c in enumerate(existing_columns):          \n",
    "            #Fill first element column which is 'Answer'\n",
    "            if c=='Answer':\n",
    "                split_post = ans.split(c)\n",
    "                answers_df[c].iloc[i] = split_post[0]\n",
    "                split_post = split_post[1]\n",
    "                continue   \n",
    "            \n",
    "            #if category is not the last in existing list         \n",
    "            if c!=existing_columns[-1]:\n",
    "                next_c = existing_columns[j+1]\n",
    "                #get text relevant to c -column\n",
    "                split_post = split_post.split(c)\n",
    "                inter_split = split_post[-1].split(next_c)\n",
    "                #insert regex helper function here----!\n",
    "                #if category is numeric get number\n",
    "                if \"Count\" in c:\n",
    "                    answers_df[c].iloc[i] = str_first_num(inter_split[0])\n",
    "                split_post = inter_split[-1]\n",
    "                continue\n",
    "            \n",
    "            if \"Count\" in c:\n",
    "                answers_df[c].iloc[i] = str_first_num(split_post)\n",
    "                continue\n",
    "            #insert regex helper function here----!\n",
    "            answers_df[c].iloc[i] = split_post  \n",
    "    return answers_df \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ravit\\AppData\\Local\\Temp\\ipykernel_27864\\1866742848.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  answers_df[c].iloc[i] = str_first_num(split_post)\n",
      "C:\\Users\\Ravit\\AppData\\Local\\Temp\\ipykernel_27864\\1866742848.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  answers_df[c].iloc[i] = str_first_num(inter_split[0])\n",
      "C:\\Users\\Ravit\\AppData\\Local\\Temp\\ipykernel_27864\\1866742848.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  answers_df[c].iloc[i] = split_post\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Answer</th>\n",
       "      <th>upvoteCount</th>\n",
       "      <th>affiliation</th>\n",
       "      <th>answerCount</th>\n",
       "      <th>followerCount</th>\n",
       "      <th>hasCredential</th>\n",
       "      <th>knowsAbout</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"50 years is a very long time. The way I make...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Faster elevators capable of moving sideways....</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>11177</td>\n",
       "      <td>815</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\": \"T. Stephen Cornelius\", \"url\": \"https://www...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"INCOHERENT and Excessive redundancy as resou...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>12202</td>\n",
       "      <td>8904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\": \"Richard Kenneth Eng\", \"url\": \"https://www....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Well, lucky for you, I just returned from 50...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>3659</td>\n",
       "      <td>181</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\": \"Albert Hsieh\", \"url\": \"https://www.quora.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"1. 3D printing becomes the norm in hospitals...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>9824</td>\n",
       "      <td>21129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\": \"Stan Hayward\", \"url\": \"https://www.quora.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"Very easily\\nThe technology in 50 years will...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>983</td>\n",
       "      <td>104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\": \"Steve Schaefer\", \"url\": \"https://www.quora...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"I believe we are fast approaching the peak o...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>1855</td>\n",
       "      <td>111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\": \"Anthony Musk\", \"url\": \"https://www.quora.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"Look at the videos from the 80s and 90s. Peo...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>2359</td>\n",
       "      <td>3099</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\": \"EIS Intelligent Systems\"}},</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"1. Real Artificial Intelligence Takes Over.\\...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>3871</td>\n",
       "      <td>968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\": \"Ernie Dunbar\", \"url\": \"https://www.quora.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Answer upvoteCount  \\\n",
       "0    \"50 years is a very long time. The way I make...               \n",
       "1    \"Faster elevators capable of moving sideways....               \n",
       "2    \"INCOHERENT and Excessive redundancy as resou...               \n",
       "3    \"Well, lucky for you, I just returned from 50...               \n",
       "4    \"1. 3D printing becomes the norm in hospitals...               \n",
       "5    \"Very easily\\nThe technology in 50 years will...               \n",
       "6    \"I believe we are fast approaching the peak o...               \n",
       "7    \"Look at the videos from the 80s and 90s. Peo...               \n",
       "8    \"1. Real Artificial Intelligence Takes Over.\\...               \n",
       "9                                                 NaN           1   \n",
       "10                                                NaN           1   \n",
       "\n",
       "    affiliation answerCount followerCount  hasCredential  knowsAbout  \\\n",
       "0           NaN         NaN           NaN            NaN         NaN   \n",
       "1           NaN       11177           815            NaN         NaN   \n",
       "2           NaN       12202          8904            NaN         NaN   \n",
       "3           NaN        3659           181            NaN         NaN   \n",
       "4           NaN        9824         21129            NaN         NaN   \n",
       "5           NaN         983           104            NaN         NaN   \n",
       "6           NaN        1855           111            NaN         NaN   \n",
       "7           NaN        2359          3099            NaN         NaN   \n",
       "8           NaN        3871           968            NaN         NaN   \n",
       "9           NaN         NaN           NaN            NaN         NaN   \n",
       "10          NaN         NaN           NaN            NaN         NaN   \n",
       "\n",
       "                                                 name  \n",
       "0                                                 NaN  \n",
       "1   \": \"T. Stephen Cornelius\", \"url\": \"https://www...  \n",
       "2   \": \"Richard Kenneth Eng\", \"url\": \"https://www....  \n",
       "3   \": \"Albert Hsieh\", \"url\": \"https://www.quora.c...  \n",
       "4   \": \"Stan Hayward\", \"url\": \"https://www.quora.c...  \n",
       "5   \": \"Steve Schaefer\", \"url\": \"https://www.quora...  \n",
       "6   \": \"Anthony Musk\", \"url\": \"https://www.quora.c...  \n",
       "7                    \": \"EIS Intelligent Systems\"}},   \n",
       "8   \": \"Ernie Dunbar\", \"url\": \"https://www.quora.c...  \n",
       "9                                                 NaN  \n",
       "10                                                NaN  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_into_df(url_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterate through url_list and save multiple dfs\n",
    "save_path = r\"C:\\Users\\Ravit\\Documents\\horizon_scanning_lab\\Scrapers\\Quora_RCS\\answers_and_info\"\n",
    "for i, url in enumerate(url_list):\n",
    "    df = answers_into_df(url)\n",
    "    final_path = os.path.join(save_path, \"q_\"+str(i) + \".csv\")\n",
    "    df.to_csv(final_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This section is for testing on a single url. Delete it after completing the crawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#request url html\n",
    "page = requests.get(url_list[0])\n",
    "\n",
    "#create soup object with htmal parser\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = soup.find_all('script', {\"type\": \"application/ld+json\"})[0]\n",
    "#convert soup object to string\n",
    "answers = [str(a) for a in answers][0]\n",
    "#split answers with text separator\n",
    "answers_list = answers.split('\"text\":')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"Answer\", \"name\", \"knowsAbout\",  \"hasCredential\", \"upvoteCount\", \"affiliation\", \"answerCount\", \"followerCount\"]\n",
    "\n",
    "#create df with nans to fill it later with values\n",
    "x_shape = (len(answers_list)-1, len(columns))\n",
    "x = np.tile(np.nan, x_shape)\n",
    "answers_df = pd.DataFrame(x, columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get answer value\n",
    "split_post = answers_list[1].split(\"upvoteCount\")\n",
    "answers_df[\"Answer\"].iloc[0] = split_post[0]\n",
    "\n",
    "#remove answer\n",
    "split_post = split_post[1]\n",
    "\n",
    "#get upvote value\n",
    "upvote = str_first_num(split_post)\n",
    "\n",
    "answers_df[\"upvoteCount\"].iloc[0] = float(upvote)\n",
    "\n",
    "#get affiliation which is right before answercount\n",
    "split_post = split_post.split(\"affiliation\")\n",
    "#split_post = split_post[1]\n",
    "split_post = split_post.split(\"answerCount\")\n",
    "\n",
    "answers_df[\"affiliation\"].iloc[0] = split_post[0]\n",
    "\n",
    "split_post = split_post[1]\n",
    "\n",
    "#get answer count\n",
    "answers_df[\"answerCount\"].iloc[0] = str_first_num(split_post)\n",
    "\n",
    "#get followercount\n",
    "split_post = split_post.split(\"followerCount\")\n",
    "answers_df['followerCount'] .iloc[0]= str_first_num(split_post[1])\n",
    "\n",
    "split_post = split_post[1]\n",
    "\n",
    "#get person credentials (between hascredentials and knowsabout)\n",
    "split_post = split_post.split(\"hasCredential\")[1]\n",
    "split_post = split_post.split(\"knowsAbout\")\n",
    "\n",
    "#remove url from credential part\n",
    "answers_df['hasCredential'].iloc[0] = split_post[0].split(\"image\")[0]\n",
    "split_post = split_post[1]\n",
    "\n",
    "#Finally, get knowsabout and name. Remove url image from knowsabout too\n",
    "split_post = split_post.split(\"name\")\n",
    "answers_df['knowsAbout'].iloc[0] = split_post[0].split(\"image\")[0]\n",
    "\n",
    "answers_df['name'].iloc[0] = split_post[1]\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
