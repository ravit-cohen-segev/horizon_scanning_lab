{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import ssl\n",
    "import os\n",
    "import re\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For ignoring SSL ceritficate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class infine_scroll(object): \n",
    "  def __init__(self, last):\n",
    "    self.last = last\n",
    "\n",
    "  def __call__(self, driver):\n",
    "    new = driver.execute_script('return document.body.scrollHeight')  \n",
    "    if new > self.last:\n",
    "        return new\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_html_from_url(url):\n",
    "  browser = webdriver.Chrome('C:\\Program Files\\chromedriver_win32 (1)\\chromedriver') \n",
    "  browser.set_page_load_timeout(30) \n",
    "  browser.get(url)\n",
    "   \n",
    "  last_height = browser.execute_script('return document.body.scrollHeight')\n",
    "\n",
    "  flag=1\n",
    "\n",
    "  while flag==1:\n",
    "    \n",
    "    try:\n",
    "       browser.execute_script('window.scrollTo(0,document.body.scrollHeight)')\n",
    "       wait = WebDriverWait(browser, 10)\n",
    "\n",
    "       new_height = wait.until(infine_scroll(last_height))\n",
    "       last_height = new_height\n",
    "\n",
    "    except:\n",
    "        print(\"End of page reached\")\n",
    "        flag = 0\n",
    "  html = browser.page_source\n",
    "  return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function get first number in string\n",
    "\n",
    "def str_first_num(s):\n",
    "    first_num = ''\n",
    "    flag_digit=False\n",
    "    for el in s: \n",
    "        if el.isdigit():\n",
    "            first_num += el\n",
    "            flag_digit = True\n",
    "        else:\n",
    "            if flag_digit:\n",
    "                break\n",
    "    #If there are no upvotes replace '' with 0\n",
    "    if first_num == '':\n",
    "        first_num = 0\n",
    "    return first_num\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_list(li):\n",
    "    unpacked_list = []\n",
    "    for el in li:\n",
    "        if isinstance(el, list):\n",
    "            unpacked_list.extend([*el])\n",
    "        elif isinstance(el, str):\n",
    "            unpacked_list.extend([el])\n",
    "    return unpacked_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a helper function that removes unwanted words/sections like url links\n",
    "def strip_rgx_words(inp, regex_ = ['image','url']):\n",
    "    #remove urls or images\n",
    "    rgx_word = None\n",
    "    for rgx in regex_:\n",
    "      if rgx in inp:\n",
    "          rgx_word = rgx\n",
    "          break\n",
    "    if rgx_word is not None:\n",
    "      out = inp.split(rgx_word)[0]\n",
    "    else:\n",
    "      out =inp\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read question urls from csv file\n",
    "src_path = r\"C:\\Users\\Ravit\\Documents\\horizon_scanning_lab\\Scrapers\\Quora_RCS\\answers_and_info\\quet_indexes.csv\"\n",
    "df = pd.read_csv(src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get list of urls\n",
    "url_list = list(df['url'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.quora.com/What-will-the-worlds-technology-be-like-in-50-years',\n",
       " 'https://www.quora.com/How-long-could-the-brain-survive-theoretically-if-we-had-the-technology-to-replace-all-other-body-parts-as-you-aged-with-functioning-organs-that-are-grown-in-a-lab-using-your-DNA',\n",
       " 'https://www.quora.com/What-are-the-top-10-emerging-technologies-in-the-next-5-10-years-2020%E2%80%932025',\n",
       " 'https://www.quora.com/What-are-the-upcoming-emerging-technologies-in-software-industry',\n",
       " 'https://www.quora.com/What-will-the-worlds-technology-be-like-in-50-years',\n",
       " 'https://www.quora.com/What-are-the-most-advanced-technologies-that-people-dont-know-about-yet',\n",
       " 'https://www.quora.com/When-will-Fusion-reactors-become-a-reality',\n",
       " 'https://www.quora.com/In-future-IOT-Internet-of-things-is-trending-technology-or-not',\n",
       " 'https://www.quora.com/What-will-the-worlds-technology-be-like-in-50-years',\n",
       " 'https://www.quora.com/What-are-the-solutions-to-emerging-issues-in-communication']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_list_counts(inf):\n",
    "    answers_upvotes = []\n",
    "    for ans_inf in inf:\n",
    "        if ans_inf[0] == []:\n",
    "           val = 0\n",
    "        else:\n",
    "            val = ans_inf[0].find_next(text=True).strip()\n",
    "        answers_upvotes.append(val)\n",
    "    return answers_upvotes\n",
    "\n",
    "def fill_list_str(inf):\n",
    "    answers_upvotes = []\n",
    "    for ans_inf in inf:\n",
    "        if ans_inf[0] == []:\n",
    "           val = 'UNKNOWN'\n",
    "        else:\n",
    "            val = ans_inf[0].find_next(text=True).strip()\n",
    "        answers_upvotes.append(val)\n",
    "    return answers_upvotes\n",
    "\n",
    "\n",
    "def answers_into_df(url):\n",
    "    '''input: url for scrapping answers to a particular question.\n",
    "        out: df with answers for each url/question'''\n",
    "    #request url html\n",
    "    \n",
    "    #create soup object with htmal parser\n",
    "    page_html = get_html_from_url(url)\n",
    "    soup = BeautifulSoup(page_html)\n",
    "\n",
    "    boxes = soup.find_all('div', {'class':\"q-box qu-pt--medium qu-hover--bg--darken\"})\n",
    "    answers = [box.find_all('span', {'class':\"q-box qu-userSelect--text\"}) for box in boxes]\n",
    "    answers_text = [ans[0].find_next(text=True).strip() for ans in answers] \n",
    "    answers_text = unpack_list(answers_text)\n",
    "    #get a list of answer author upvotes and shares\n",
    "    #answers_info = [box.find_all('button', {'role':'button'}) for box in boxes]\n",
    "    answers_upvotes_info = [box.find_all('div', {'class':'q-text qu-overflow--hidden qu-display--inline-flex qu-ml--tiny qu-minHeight--20 qu-color--gray qu-minWidth--20'}) for box in boxes]\n",
    "    answers_upvotes = []\n",
    "    \n",
    "    #answers upvotes:\n",
    "    answers_upvotes = fill_list_counts(answers_upvotes_info)\n",
    "    \n",
    "    #########################\n",
    "    #TODO FIX share info   \n",
    "   # answers_share_info = [box.find_all('span', {'class':'q-text qu-whiteSpace--nowrap qu-display--inline-flex qu-alignItems--center qu-justifyContent--center'}) for box in boxes]\n",
    "    #answers_share_info = [ans.find_all('span', {'class':'q-text qu-visibility--hidden qu-display--inline-flex'}) for ans in answers_share_info]\n",
    "    \n",
    "    names_info = [box.find_all('div', {'class':'q-inlineFlex qu-alignItems--center qu-wordBreak--break-word'}) for box in boxes]\n",
    "    answers_name = fill_list_str(names_info)\n",
    "       \n",
    "    author_counts = [box.find_all('span', {'class':\"q-text qu-bold\"}) for box in boxes]\n",
    "    author_answers_count = [au_count.find_next(text=True).strip() for au_count in author_counts]\n",
    "    answer_views =  [au_count[1].find_next(text=True).strip() for au_count in author_counts]\n",
    "\n",
    "    \n",
    "    #create df with nans to fill it later with values\n",
    "    columns = [\"Answer\",  \"name\", \"upvoteCount\", \"answerShares\", \"answerCount\", \"answerViews\"]\n",
    "\n",
    "    x_shape = (len(answers), len(columns))\n",
    "    x = np.tile(np.nan, x_shape)\n",
    "   \n",
    "    answers_df = pd.DataFrame(x, columns = columns)\n",
    "\n",
    "    answers_df['Answer'] = pd.DataFrame(answers_text)   \n",
    "    answers_df['name'] = pd.DataFrame(answers_name)\n",
    "    answers_df['upvoteCount'] = pd.DataFrame(answers_upvotes)\n",
    "    answers_df['answerShares'] = pd.DataFrame(answers_shares)\n",
    "    answers_df['answerCount'] = pd.DataFrame(author_answers_count)\n",
    "    answers_df['answerViews'] = pd.DataFrame(answer_views)\n",
    "\n",
    "    return answers_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ravit\\AppData\\Local\\Temp\\ipykernel_18992\\4126610301.py:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  browser = webdriver.Chrome('C:\\Program Files\\chromedriver_win32 (1)\\chromedriver')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of page reached\n"
     ]
    }
   ],
   "source": [
    "#show one example\n",
    "answers_into_df(url_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"question\", \"Answer\", \"upvoteCount\", \"answerCount\", \"followerCount\", \"name\"]\n",
    "df = pd.DataFrame(data = [], columns = columns)\n",
    "\n",
    "for i, url in enumerate(url_list):\n",
    "    temp_df = answers_into_df(url)\n",
    "    temp_df[\"question\"] = url\n",
    "    #rearrange columns order to match main df columns order\n",
    "    temp_df = temp_df[columns]\n",
    "\n",
    "    df = df.append(temp_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save df to csv\n",
    "save_path = r\"C:\\Users\\Ravit\\Documents\\horizon_scanning_lab\\Scrapers\\Quora_RCS\\answers_and_info\"\n",
    "final_path = os.path.join(save_path, \"ET_RCS_22SEP15_quora_data.csv\")\n",
    "df.to_csv(final_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO -  scrape all pages from this urls,\n",
    "        #scrape all groups related to technology trends\n",
    "     \n",
    "\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
