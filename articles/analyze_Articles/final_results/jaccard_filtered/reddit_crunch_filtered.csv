,link,titles,abstract,title_sim_tag,abs_sim_tag
522,https://twin-cities.umn.edu/news-events/individuals-experiencing-food-insecurity-likely-binge-eat-when-food-available,Individuals experiencing food insecurity likely to binge eat when food is available,"Young adults experiencing food insecurity may be prone to binge eating in times when food is available, according to a new study from the University of Minnesota School of Public Health (SPH).SPH researchers found support for the “feast or famine” cycle hypothesis in food-insecure households. Findings from their study are consistent with the idea that fluctuating levels of food availability throughout the month may lead people to restrict their food intake out of necessity when food is scarce, and then compensate by overeating when food is more plentiful. Binge eating is a behavior linked with a number of adverse physical and mental health consequences, including type 2 diabetes and depression.The study, co-authored by Vivienne Hazzard, a post-doctoral associate in SPH, and published in Appetite, surveyed 75 young adults living in food-insecure households several times each day over a two-week period to investigate how momentary levels of food security related to binge-eating symptoms later in the day. The researchers found:Significantly more binge-eating symptoms occurred in the hours following instances of increased food security among young adults.This link only existed for young adults using food assistance programs, not for those who did not report using food assistance.The researchers suggest rethinking the timing of benefits distribution in food assistance programs. Hazzard noted that the way food assistance programs are currently structured may inadvertently exacerbate the “feast-or-famine” cycle.“Policymakers should consider how they could provide more stable and consistent access to adequate food,” said Hazzard. “While programs such as the Supplemental Nutrition Assistance Program (SNAP) and Women, Infants and Children (WIC) are critical to improving food security in the U.S., some have called for a restructuring of their benefit distribution schedules. Currently, these programs distribute benefits only once a month. Our study adds to a growing body of evidence that suggests more frequent distribution of benefits may be warranted.”Additional research in this area should test whether intervening to promote more stable food access can interrupt that cycle and reduce binge eating.This research was supported by the National Heart, Lung, and Blood Institute, the National Institute of Mental Health, the National Institute of Child Health and Human Development, the National Institute of Diabetes and Digestive and Kidney Diseases, and the National Institute of General Medical Science.-30-About the School of Public HealthThe University of Minnesota School of Public Health improves the health and wellbeing of populations and communities around the world by bringing innovative research, learning, and concrete actions to today’s biggest health challenges. We prepare some of the most influential leaders in the field, and partner with health departments, communities, and policymakers to advance health equity for all. Learn more at sph.umn.edu.",0.0,0.0
146,https://www.reuters.com/technology/uber-whistleblower-says-current-business-model-absolutely-unsustainable-2022-11-02/,Uber whistleblower says current business model 'absolutely' unsustainable,"[1/2] Mark MacGann, founder of Moonshot Ventures and the senior executive behind the Uber Files, holds a news conference during the Web Summit, Europe's largest technology conference, in Lisbon, Portugal, November 2, 2022. REUTERS/Pedro NunesLISBON, Nov 2 (Reuters) - Mark MacGann, the whistleblower behind the so-called Uber Files, said on Wednesday that the ride-hailing company seemed to be taking steps toward improving its work culture, but that its business model was still ""absolutely"" unsustainable.The Guardian and Le Monde newspapers reported in July that Uber Technologies Inc (UBER.N) broke laws and secretly lobbied politicians as part of an aggressive drive to expand into new markets from 2013 to 2017. read moreMacGann, who led Uber's lobbying efforts to win over governments, identified himself as the source who leaked the more than 124,000 company files.MacGann said he decided to speak out because he believed Uber knowingly flouted laws and misled people about the benefits to drivers of the company's gig-economy model.Uber said in July, in response to the Guardian and Le Monde reports: ""We have not and will not make excuses for past behaviour that is clearly not in line with our present values.""MacGann said Uber's current CEO, Dara Khosrowshahi, and his executive team ""have done a lot of good things, but they have so, so far to go.""When asked for a comment, an Uber spokesman on Wednesday referred Reuters to a 2020 New York Times opinion piece by Khosrowshahi in which he said ""our current employment system is outdated and unfair.""Khosrowshahi had said gig workers would lose the flexibility they have today if they became employees and that rides would be more expensive. The CEO wrote that workers want both flexibility and benefits and added that new laws are required to help them.""I'm proposing that gig economy companies be required to establish benefits funds which give workers cash that they can use for the benefits they want, like health insurance or paid time off,"" Khosrowshahi wrote in the op-ed.""My message to Uber is: 'you've done well, (but) you can do it so much better (because) the current model is absolutely not sustainable,'"" MacGann told a news conference during Europe's largest tech conference, the Web Summit, in Lisbon.He said Uber recently reiterated that the ""core of its business model is independent contractors, since everybody wants to be self-employed, everybody wants flexibility.""He said the facts, however, contradict this view as there are Uber drivers suing the company in various countries to ""have a basic minimum of social protection such as sick pay.""""Uber is pumping tens of millions of dollars in Europe, United States, other parts of the world fighting legislation,"" he said.Reporting by Sergio Goncalves in Lisbon Additional reporting by Nivedita Balu and Ann Maria Shibu in Bengaluru; Editing by Matthew Lewis and Sherry Jacob-PhillipsOur Standards: The Thomson Reuters Trust Principles.",0.0,0.0
34,https://www.eurekalert.org/news-releases/969890,TikTok perpetuates toxic diet culture among  teens and young adults,"New research from the University of Vermont finds the most viewed content on TikTok relating to food, nutrition and weight perpetuates a toxic diet culture among teens and young adults and that expert voices are largely missing from the conversation.Published today in PLOS One, the study found weight-normative messaging, the idea that weight is the most important measure of a person’s health, largely predominates on TikTok with the most popular videos glorifying weight loss and positioning food as a means to achieve health and thinness. The findings are particularly concerning given existing research indicating social media usage in adolescents and young adults is associated with disordered eating and negative body image.“Each day, millions of teens and young adults are being fed content on TikTok that paints a very unrealistic and inaccurate picture of food, nutrition and health,” said senior researcher Lizzy Pope, associate professor and director of the Didactic Program in Dietetics at UVM. “Getting stuck in weight loss TikTok can be a really tough environment, especially for the main users of the platform, which are young people.""The study is the first to examine nutrition and body-image related content at scale on TikTok. The findings are based on a comprehensive analysis of the top 100 videos from 10 popular nutrition, food and weight-related hashtags, which were then coded for key themes. Each of the 10 hashtags had over a billion views when the study began in 2020; the selected hashtags have grown significantly as TikTok’s user base has expanded.“We were continuously surprised by how prevalent the topic of weight was on TikTok. The fact that billions of people were viewing content about weight on the internet says a lot about the role diet culture plays in our society,” said co-author Marisa Minadeo ’21, who conducted the research as part of her undergraduate thesis at UVM.Over the past few years, the Nutrition and Food Sciences Department at UVM has shifted away from a weight-normative mindset, adopting a weight-inclusive approach to teaching dietetics. The approach centers on using non-weight markers of health and wellbeing to evaluate a person’s health and rejects the idea that there is a “normal” weight that is achievable or realistic for everyone. If society continues to perpetuate weight normativity, says Pope, we’re perpetuating fat bias.“Just like people are different heights, we all have different weights,” said Pope. “Weight-inclusive nutrition is really the only just way to look at humanity.”Weight-inclusive nutrition is becoming popular as a more holistic evaluation of a person’s health. As TikTok users, UVM health and society major Minadeo and her advisor Pope were interested in better understanding the role of TikTok as a source for information about nutrition and healthy eating behaviors. They were surprised to find that TikTok creators considered to be influencers in the academic nutrition space were not making a dent in the overall landscape of nutrition content.White, female adolescents and young adults accounted for the majority of creators of content analyzed in the study. Very few creators were considered expert voices, defined by the researchers as someone who self-identified with credentials such as a registered dietitian, doctor, or certified trainer.“We have to help young people develop critical thinking skills and their own body image outside of social media,” said Pope. “But what we really need is a radical rethinking of how we relate to our bodies, to food and to health. This is truly about changing the systems around us so that people can live productive, happy and healthy lives,” said Pope.",0.0,0.0
36,https://www.mcgill.ca/newsroom/channels/news/flatworm-inspired-medical-adhesives-stop-blood-loss-342730,Flatworm-inspired medical adhesives stop blood loss,"Every year around 2 million people die worldwide from hemorrhaging or blood loss. Uncontrolled hemorrhaging accounts for more than 30% of trauma deaths. To stop the bleeding, doctors often apply pressure to the wound and seal the site with medical glue. But what happens when applying pressure is difficult or could make things worse? Or the surface of the wound is too bloody for glue? Drawing inspiration from nature, researchers from McGill University have developed a medical adhesive that could save lives, modeled after structures found in marine animals like mussels and flatworms.“When applied to the bleeding site, the new adhesive uses suction to absorb blood, clear the surface for adhesion, and bond to the tissue providing a physical seal. The entire application process is quick and pressure-free, which is suitable for non-compressible hemorrhage situations, which are often life-threatening,” says lead author Guangyu Bao, a recently graduated PhD student under the supervision of Professor Jianyu Li of Department of Mechanical Engineering.In putting the new technology to the test, the researchers found that the adhesive promotes blood coagulation. The adhesive can also be removed without causing re-bleeding or even left inside the body to be absorbed. “Our material showed much better-improved safety and bleeding control efficiency than other commercial products. Beyond bleeding control, our material could one day replace wound sutures or deliver drugs to provide therapeutic effects,” says senior author Professor Jianyu Li.About this study“Liquid-infused microstructured bioadhesives halt non-compressible hemorrhage” by Guangyu Bao et al. was published in Nature Communications.About McGill UniversityFounded in Montreal, Quebec, in 1821, McGill University is Canada’s top ranked medical doctoral university. McGill is consistently ranked as one of the top universities, both nationally and internationally. It is a world-renowned institution of higher learning with research activities spanning three campuses, 11 faculties, 13 professional schools, 300 programs of study and over 39,000 students, including more than 10,400 graduate students. McGill attracts students from over 150 countries around the world, its 12,000 international students making up 30% of the student body. Over half of McGill students claim a first language other than English, including approximately 20% of our students who say French is their mother tongue.",0.0,0.0
112,https://www.theguardian.com/commentisfree/2022/sep/26/physics-particles-physicists#comments,"No one in physics dares say so, but the race to invent new particles is pointless","Imagine you go to a zoology conference. The first speaker talks about her 3D model of a 12-legged purple spider that lives in the Arctic. There’s no evidence it exists, she admits, but it’s a testable hypothesis, and she argues that a mission should be sent off to search the Arctic for spiders.The second speaker has a model for a flying earthworm, but it flies only in caves. There’s no evidence for that either, but he petitions to search the world’s caves. The third one has a model for octopuses on Mars. It’s testable, he stresses.Kudos to zoologists, I’ve never heard of such a conference. But almost every particle physics conference has sessions just like this, except they do it with more maths. It has become common among physicists to invent new particles for which there is no evidence, publish papers about them, write more papers about these particles’ properties, and demand the hypothesis be experimentally tested. Many of these tests have actually been done, and more are being commissioned as we speak. It is wasting time and money.Since the 1980s, physicists have invented an entire particle zoo, whose inhabitants carry names like preons, sfermions, dyons, magnetic monopoles, simps, wimps, wimpzillas, axions, flaxions, erebons, accelerons, cornucopions, giant magnons, maximons, macros, wisps, fips, branons, skyrmions, chameleons, cuscutons, planckons and sterile neutrinos, to mention just a few. We even had a (luckily short-lived) fad of “unparticles”.All experiments looking for those particles have come back empty-handed, in particular those that have looked for particles that make up dark matter, a type of matter that supposedly fills the universe and makes itself noticeable by its gravitational pull. However, we do not know that dark matter is indeed made of particles; and even if it is, to explain astrophysical observations one does not need to know details of the particles’ behaviour. The Large Hadron Collider (LHC) hasn’t seen any of those particles either, even though, before its launch, many theoretical physicists were confident it would see at least a few.Talk to particle physicists in private, and many of them will admit they do not actually believe those particles exist. They justify their work by claiming that it is good practice, or that every once in a while one of them accidentally comes up with an idea that is useful for something else. An army of typewriting monkeys may also sometimes produce a useful sentence. But is this a good strategy?Experimental particle physicists know of the problem, and try to distance themselves from what their colleagues in theory development do. At the same time, they profit from it, because all those hypothetical particles are used in grant proposals to justify experiments. And so the experimentalists keep their mouths shut, too. This leaves people like me, who have left the field – I now work in astrophysics – as the only ones able and willing to criticise the situation.There are many factors that have contributed to this sad decline of particle physics. Partly the problem is social: most people who work in the field (I used to be one of them) genuinely believe that inventing particles is good procedure because it’s what they have learned, and what all their colleagues are doing.But I believe the biggest contributor to this trend is a misunderstanding of Karl Popper’s philosophy of science, which, to make a long story short, demands that a good scientific idea has to be falsifiable. Particle physicists seem to have misconstrued this to mean that any falsifiable idea is also good science.In the past, predictions for new particles were correct only when adding them solved a problem with the existing theories. For example, the currently accepted theory of elementary particles – the Standard Model – doesn’t require new particles; it works just fine the way it is. The Higgs boson, on the other hand, was required to solve a problem. The antiparticles that Paul Dirac predicted were likewise necessary to solve a problem, and so were the neutrinos that were predicted by Wolfgang Pauli. The modern new particles don’t solve any problems.In some cases, the new particles’ task is to make a theory more aesthetically appealing, but in many cases their purpose is to fit statistical anomalies. Each time an anomaly is reported, particle physicists will quickly write hundreds of papers about how new particles allegedly explain the observation. This behaviour is so common they even have a name for it: “ambulance-chasing”, after the anecdotal strategy of lawyers to follow ambulances in the hope of finding new clients.Ambulance-chasing is a good strategy to further one’s career in particle physics. Most of those papers pass peer review and get published because they are not technically wrong. And since ambulance-chasers cite each other’s papers, they can each rack up hundreds of citations quickly. But it’s a bad strategy for scientific progress. After the anomaly has disappeared, those papers will become irrelevant.This procedure of inventing particles and then ruling them out has been going on so long that there are thousands of tenured professors with research groups who make a living from this. It has become generally accepted practice in the physics community. No one even questions whether it makes sense. At least not in public.I believe there are breakthroughs waiting to be made in the foundations of physics; the world needs technological advances more than ever before, and now is not the time to idle around inventing particles, arguing that even a blind chicken sometimes finds a grain. As a former particle physicist, it saddens me to see that the field has become a factory for useless academic papers.",0.0,0.0
94,https://www.usatoday.com/story/money/2022/10/20/remote-workers-return-to-office-job-market-cools/10527961002/,Could refusing to return to office mean a layoff? Job market's shifting tide may change the rules.,"A cooling job market is leading to more than a slowdown in hiring, a pickup in layoffs and growing recession fears.It appears to be the one force capable of prodding America’s workers out of their homes and back to offices.The slowing labor market is starting to shift some bargaining power from employees to employers, allowing a growing number of companies to require workers to return to the office at least a few days a week, staffing officials and consultants say. Many businesses are still struggling to find workers and so the change is in its early stages, but it’s expected to accelerate as hiring pulls back further and layoffs spread in the months ahead, experts say.“Companies are a little less concerned that they’re not going to fill jobs if they lose people because of return-to-work policies,” says Jim McCoy, senior vice president of talent solutions for ManpowerGroup, a leading staffing firm. “There's starting to be less competition for talent, and employers can be a little more selective.”Price check:What will and won't become more affordable as the Fed hikes rates?Rising rates and your debt:Here's how the latest hike will hit your wallet and portfolioIn late September, 36% of organizations required workers to be in the office at least three days a week, up from 25% in August, according to a Gartner survey of 240 human resources leaders. And just 22% had no onsite work requirements, down from 31%.Employees 'more receptive' to working in officeWorkers are similarly becoming less demanding about remote work, if just marginally. Seventy-three percent of fully remote employees said they probably would find another remote or hybrid job if their company forced them to work from the office full-time, according to a Harris Poll survey last weekend for USA TODAY. That’s down from 78% in June.Ironside Human Resources, a Dallas-based health care staffing firm, has told its employees to work in the office five days a week since spring 2020, chiefly because of the collaboration that takes place when staffers are together, says CEO Doug Carter. But many job candidates insisted on working remotely. About six months ago, the company had to conduct 40 to 50 phone interviews to find one or two applicants willing to work on-site and interview in person, he says.Are I bonds still a good investment?:What to know if you're consider this inflation-flighting asset'I quit"" becomes harder:Workers could lose leverage as job openings fall.Now, he says, Ironside does about 25 phone interviews to find eight candidates who are open to on-site work. While the easing pandemic may be partly responsible, Carter mostly cites the slowing job market.“There are not as many remote jobs as there were. People are definitely more receptive"" to working on-site, he says. ""The challenge of getting people to work in-office had been difficult, but that landscape is rapidly changing.”Carter says he has seen a similar turnabout among his clients, such as hospitals. About 50% of their administrative employees are remote, he says, compared with 80% six months ago.Labor market cools down; job openings fallEarlier this year, with job openings at a record 11.9 million, workers enjoyed the leverage to demand higher wages and even more significantly, a continuation of the remote work set-ups that prevailed early in the pandemic. Even as companies such as Apple and General Motors announced return-to-office mandates, many had to walk them back after employee backlash.But the number of U.S. job openings fell from 11.2 million in July to a still historically high 10.1 million the following month. In September, net job growth slowed to 263,000, a solid total but the lowest since April 2021.In recent months, companies such as Intel, Oracle, Amazon, Apple, Netflix, and The Gap have cut hundreds or thousands of jobs.The job market, at least for now, remains sturdy, and employees in many industries still hold the cards because of pandemic-related worker shortages.“It’s still a very hot labor market,” and many job candidates still insist on working remotely, says Michael Steinitz, senior executive director of professional talent solutions for Robert Half staffing.Guide to big Social Security increase:Social Security COLA 2023: What retirees must knowBut “the tide is changing,” says Dustin York, a consultant for large corporations and associate professor of strategic communication and leadership at Maryville University in St. Louis.A softening economy and less robust hiring are beginning to alter the power balance between employers and workers. Soaring inflation is prompting the Federal Reserve to sharply raise interest rates, and higher prices and borrowing costs have clobbered the stock market. The troublesome dynamic is expected to trigger a recession by next year, according to the forecasts of economists surveyed by Wolters Kluwer Blue Chip Economic Indicators.'Barely making it':Americans face tough choices as prices soarBuy now, pay later takes a toll:Delinquencies could get 'dangerously' high.What will companies do about it?Am I more likely to get laid off if I resist a return to office?The slowdown initially hit technology, York says. The industry exploded as Americans worked from home and snapped up TVs, computers and appliances, but it’s downsizing as consumers shift their spending from goods to services, he says. Tech companies, in turn, increasingly are making workers return to the office, he says, and any layoffs are more likely to target employees who have resisted the directive.“Whom do you choose to lay off?” he says. “People who don’t match with the culture.”Many tech companies, in fact, are using return-to-office mandates instead of layoffs to get rid of workers, York and McCoy say. Employees who refuse to comply quit, which allows a company to trim its staff without the stain of job cuts.“The company can say ‘We didn’t lay anybody off’” and save the cost of severance payments, York says.As the job market downshifts in the next six to 12 months, York expects the back-to-office trend to ripple across all industries. Ultimately, he predicts, there will be slightly more fully remote workers than before the pandemic.Today, 25% of all workers are remote, 23% are hybrid and 52% are at the workplace full-time, according to a Harris Poll.Yet while more large companies are making employees return to the workplace, many of their smaller competitors are maintaining remote-work policies and using them as a competitive advantage to scoop up the skilled workers larger firms jettison, York says.Pulsar Products, which makes stationery and back-to-school items, asks workers who live near its headquarters in Cleveland to come in two days a week, CEO Eric Ludwig says. But some new hires can work fully remotely in other states.“The ability to be flexible and everyone’s knowledge of how to use (Zoom or Teams) has allowed us to hire the best,” he says.",0.0,0.0
100,https://www.newsweek.com/baby-alpaca-learns-walk-again-prosthetic-leg-adorable-clip-1749410?,Baby Alpaca Learns to Walk Again Thanks to Prosthetic Leg in Adorable Clip,"An alpaca has been given a second chance at life, thanks to a custom prosthetic leg.Living at Blowing Oaks Ranch in Batesville, Arkansas, the smallAccording to the British Alpaca Society, ""Alpacas originate from the Altiplano (Spanish for high plain) in west-central South America. Spanning the borders of Peru, Chile and Bolivia, this area of the Andes averages nearly 4,000 metres (more than 2 miles) above sea level."" They are closely related to the llama.At just six weeks old, Cinco suffered a broken leg. Ranch owner Caren Barnett told""We suspect that Cinco injured it playing with some of the other young alpacas, then kept using it until the fracture became so damaged that it couldn't be repaired. It was open and dirty, and the bones were shattered.""After consulting their veterinarian, it was decided that, due to the chances of Cinco getting an infection from the fracture, it would be safer to remove the leg.While the veterinary surgeon first wanted to remove the leg at the shoulder, Barnett and her husband, John, convinced the team to keep the upper leg so that Cinco had a chance of a fitted""Alpacas carry two-thirds of their weight on their front end, and we didn't want his right leg to get overused or injured,"" said Barnett.Luckily for Cinco, Barnett is a physical therapist and the director of outpatient rehab for White River Health in Batesville. She went next door to JP&O Prosthetic and Orthotic Lab and asked the certified prosthetist orthotist Paul if it was possible to make a prosthetic for Cinco.""I don't think he knew what an alpaca was at that time, but he agreed he would see what he could do,"" Barnett said: ""He had previously made aAfter taking Cinco for several fittings, on September 14, he finally got the finished product.""Paul used donated parts for the leg except for the socket, which had to be made custom from a cast of Cinco's stump,"" said Barnett: ""It has an adjustable-height pylon to adapt to his growing height.""Now firmly back on his feet, Cinco is enjoying playing in the fields at the ranch, which is home to 15 other alpacas.As he is still growing, it is likely that Cinco will need one or two more replacement prosthetic legs in the future, due to growth and general wear and tear.""He is the best baby alpaca we have ever had in our herd, so we hope to eventually use him as a herd sire,"" said Barnett.A herd sire refers to a male alpaca with particularly desirable genetics for breeding—meaning that Cinco could become father to many other baby alpacas in the future.""We hope to take him to a couple of recognized alpaca shows, but we will not be able to show him in halter classes due to his injury,"" said Barnett. ""He will be judged only on his fiber qualities and not on confirmation.""Most importantly, we will do everything to make Cinco as comfortable and happy as we can and help him live out as normal a life as is possible.""Barnett admits Cinco does have a special place in her heart: ""I have to admit to spoiling him with extra treats and kisses. He is a super-sweet alpaca and our farm favorite for sure.""",0.0,0.0
171,https://interestingengineering.com/science/korea-nuclear-fusion-reactor-100-million-degrees,Nuclear fusion reactor in Korea reaches 100 million degrees Celsius,"Can this be scaled up?The researchers do not completely understand the mechanisms at play that made the plasma stable at such high temperatures but believe that the fast-ion-regulated enhancement (FIRE) or more energetic ions at the core of the plasma were integral to the stability.The KSTAR device has now been shut down, and the carbon components of its inner walls are being replaced with tungsten to improve the reproducibility of the experiments, New Scientist said in its report. The researchers are hopeful that future experiments will be longer and help them move towards a nuclear fusion reactor.Experts told New Scientist that such discoveries were definitely advancing the field of nuclear fusion. However, the problems of the technology were now moving away from physics. The biggest question to address is whether we can harness energy from a fusion reactor in an economical way where the heat can be utilized to get some work. Without this, the technology will not see scale up.Luckily, we can expect more answers to our questions when an international collaboration for nuclear fusion, ITER, attempts to produce net energy at the world's largest nuclear fusion reactor by 2025.The findings of the work conducted at KSTAR were published in the journal Nature.Nuclear fusion is one of the most attractive alternatives to carbon-dependent energy sources1. Harnessing energy from nuclear fusion in a large reactor scale, however, still presents many scientific challenges despite the many years of research and steady advances in magnetic confinement approaches. State-of-the-art magnetic fusion devices cannot yet achieve a sustainable fusion performance, which requires a high temperature above 100 million kelvin and sufficient control of instabilities to ensure steady-state operation on the order of tens of seconds2,3. Here we report experiments at the Korea Superconducting Tokamak Advanced Research4 device producing a plasma fusion regime that satisfies most of the above requirements: thanks to abundant fast ions stabilizing the core plasma turbulence, we generate plasmas at a temperature of 100 million kelvin lasting up to 20 seconds without plasma edge instabilities or impurity accumulation. A low plasma density combined with a moderate input power for operation is key to establishing this regime by preserving a high fraction of fast ions. This regime is rarely subject to disruption and can be sustained reliably even without a sophisticated control, and thus represents a promising path towards commercial fusion reactors.",0.0,0.0
38,https://videocardz.com/press-release/noctua-unveils-thermal-paste-guard-for-amd-am5-ryzen-7000-processors,Noctua unveils thermal paste guard for AMD AM5 Ryzen 7000 processors,"« press release »Noctua presents NA-TPG1 thermal paste guard for AMD AM5Vienna, October 6th 2022 – Noctua today announced its new NA-TPG1 thermal paste guard for AMD’s latest AM5 based Ryzen processors. When the mounting pressure of the cooling solution is applied, excess thermal paste will be squeezed outwards. With AM5 CPUs, this excess paste tends to accumulate in the cut-outs at the sides of the heat-spreader and may become difficult to remove. Simple and risk-free to apply, the NA-TPG1 prevents this undesired phenomenon.“While there’s no denying that AMD’s new Ryzen 7000 processors perform fantastic, we found that the cut-outs at the side of the heat-spreader tend to attract thermal paste that can be challenging to clean off” says Roland Mossig (Noctua CEO). “This is where our new thermal paste guard steps in: it’s a simple yet highly effective tool for keeping your new Ryzen 7000 series CPU nice and clean.”Made from highly heat-resistant polycarbonate and forming a tight seal around the edges of the CPU’s heat-spreader , the NA-TPG1 is simple and risk free to apply and remove. Despite its simplicity, it is highly efficient at preventing thermal paste from accumulating in the cut-outs at the sides of AM5 CPUs.The NA-TPG1 will be available in a separate set with ten NA-CW1 cleaning wipes (NA-STPG1) as well as with new AM5 editions of Noctua’s award-winning NT-H1 and NT-H2 thermal pastes. All three products are scheduled to become available in December.The manufacturer’s suggested retail price will be EUR/USD 7.90 for the NA-STPG1, EUR/USD 9.90 for the NT-H1 3.5g AM5 Edition and EUR/USD 13.90 for the NT-H2 3.5g AM5 Edition.Links« end of the press release »",0.0,0.0
57,https://techcrunch.com/2022/09/06/one-startups-solution-to-the-carbon-offsetting-mess-cut-out-the-middle-men-resellers/,One startupâs solution to the carbon-offsetting mess: Downgrade the âmiddle-menâ resellers,"As well as the traditional carbon offset resellers and exchanges such as Climate Partner or Climate Impact X, the tech space has also produced a few, including Patch (U.S.-based, raised $26.5 million) and Lune (U.K.-based, raised $4 million).Now, Ceezer, a B2B marketplace for carbon credits, has closed a €4.2 million round, led by Carbon Removal Partners with participation of impact-VC Norrsken VC and with existing investor Picus Capital.Ceezer’s pitch is that companies have to deal with a lot of complexity when considering how they address carbon removal and reduction associated with their businesses. While they can buy offsetting credits, the market remains pretty ‘wild-west”, and has multiple competing standards running in parallel. For instance, the price range of $5 to $500 per ton is clearly all over the place, and sometimes carbon offset resellers make buyers pay high prices for low-quality carbon credits, pulling in extra revenues from a very opaque market.The startup’s offering is for corporates to integrate both carbon removal and avoidance credits in one package. It does this by mining the offsetting market for lots of data points, enabling carbon offset sellers to reach buyers without having to use these middle-men resellers.The startup claims that sellers no longer waste time and money on bespoke contracts with corporates but instead use Ceezer’s legal framework for all transactions. Simultaneously, buyers can access credits at a primary market level, maximizing the effect of the dollars they spend on carbon offsets.Ceezer says it now has more than 50 corporate customers and has 200,000 tons of carbon credits to sell across a variety of categories, and will use the funds to expand its impact and sourcing team, the idea being to make carbon removal technologies more accessible to corporate buyers, plus widen the product offering for credit sellers and buyers.",0.0,0.0
41,https://techcrunch.com/2022/07/21/luminar-lidar-ecarx-geely-china-ev/,"Luminar to invest in Geely-affiliated Ecarx, eyes China market","Luminar, the Florida-based lidar company that went public via SPAC in 2020, has formed a close alliance with an auto behemoth in China. It’s making a strategic investment of an undisclosed amount in Ecarx, an auto tech startup co-founded by Eric Li, founder of China’s largest private automaker Geely, Ecarx said on Thursday.The funding will be part of the pair’s wider collaboration on automotive-grade technologies, which aims to “enable advanced safety and automated driving capabilities in the production of consumer vehicles and commercial trucks,” a plan that Luminar unveiled in May.Luminar’s sensing technology can potentially reach millions of vehicles through the Geely/Ecarx auto empire. Ecarx is building a comprehensive platform for the future of cars, focusing on the likes of auto chips and smart vehicles. Its customers include, unsurprisingly, Geely-owned brands like Lotus and Volvo.Shen Ziyu, Ecarx’s other co-founder and a former General Motors executive, told Reuters in March 2021 that the company had already supplied 2.5 million vehicles.The lidar industry in China is enjoying a boom as the country’s electric car makers — which themselves have benefited from government support for renewable energy — woo picky consumers with advanced driving technology, in-car entertainment and other novel auto features.Luminar’s tie-up with Ecarx will be critical in helping it confront domestic lidar players, from BYD-backed RoboSense and Bosch-backed Hesai to Temasek-funded Innovusion and Livox, which sprang out of DJI.“The collaboration will help Luminar to accelerate deployment of its industry-leading long-range lidar and software in the [Chinese] market and beyond through Ecar’s deep connection with Geely and the Geely ecosystem, comprising some of the world’s most reputable automotive brands,” Luminar said in May.The same month, the American lidar maker said it had brought on Jackie Chen, a Harman veteran, to head its China business.Ecarx’s empire is ever expanding. On Thursday, the company announced another funding boost along with the Luminar partnership. Siengine, an automotive system on chip maker it co-founded with Arm China, has completed a Series A funding round of nearly 1 billion yuan or $15 million. Sequoia Capital China led the round, with Bosch’s China venture capital arm Boyuan Capital and others participating.Earlier this month, Li and Shen bought Chinese smartphone maker Meizu, once a Xiaomi archrival, to work toward a future of “multi-device, scenario-agnostic, and immersive” digital experience, which will no doubt include system integration between vehicles and handsets.In May, Ecarx announced plans to go public through a merger with a blank-check firm in a $3.8 billion deal.",0.0,0.0
44,https://techcrunch.com/2021/09/29/energize-ventures-raises-330m-to-fund-energy-mobility-and-climate-resiliency-technology/,"Energize Ventures raises $330M to fund energy, mobility and climate resiliency technology","Energize Ventures, an early and growth-stage venture fund, has announced the closing of its second fund with total capital commitments of $330 million. Fund II will be used to help scale and commercialize software across renewable energy, mobility, cybersecurity, battery storage, critical infrastructure and climate resiliency.The fund, which is worth exactly double what Energize raised for its first fund, is backed by anchor investors such as Invenergy, CDPQ, SE Ventures, GE Renewable Energy and Hannon Armstrong. Credit Suisse, Xcel Energy, American Electric Power and Equinor Ventures also participated.“Since we first launched Energize five years ago, we have seen the energy and industrial sectors undergo a massive digital transformation,” said John Tough, managing partner of Energize Ventures, in a statement. “The transition towards a more renewable and sustainable future is outpacing all expectations, and market participants are digitizing operations to address this new, emerging scale.”To date, Energize has deployed capital from Fund II into three investments, including Munich-based predictive battery analytics software TWAICE, Columbus, Ohio-based IoT device company Finite State and New York-based critical infrastructure safety AI company Urbint, according to the firm. Fund II is targeting 15 or more early-stage digital-first startups that are raising Series A, B or C rounds in the energy and sustainable industry sectors. Typically, Energize Ventures invests around $10 million to $20 million and prefers to lead the round. The firm’s first round invested in 14 software-based companies, including the now-public EV charging solution Volta, cloud manufacturing startup Fast Radius and solar software company Aurora Solar.“Energize exclusively invests in digital solutions,” according to the company. “That means no hardware, no moonshots that require untold amounts of capex to get off the ground — just technologies at the software layer at commercialization. Part of that comes from the firm’s investment strategy; the team leans on its LPs (including well-known corporates such as GE and Schneider) to identify the challenges facing the sectors today, and then finds solutions that overcome those barriers to decarbonization.”",0.0,0.0
19,https://www.eurekalert.org/news-releases/969866,"Bats protect young trees from insect damage, with three times fewer bugs","URBANA, Ill. – Bats help keep forests growing. Without bats to hold their populations in check, insects that munch on tree seedlings go wild, doing three to nine times more damage than when bats are on the scene. That’s according to a groundbreaking new study from the University of Illinois.“A lot of folks associate bats with caves. But as it turns out, the habitat you could really associate with almost every bat species in North America is forest. And this is true globally. Forests are just really important to bats,” says Joy O’Keefe, study co-author and assistant professor and wildlife extension specialist in the Department of Natural Resources and Environmental Sciences at Illinois. “We wanted to ask the question: Are bats important to forests? And in this study, we've demonstrated they are.”Other researchers have demonstrated bats’ insect-control services in crop fields and tropical forest systems, but no one has shown their benefits in temperate forests until now.“It's especially important for us to learn how bats affect forests, given that bats are declining due to diseases like white-nose syndrome or collisions with wind turbines. This type of work can reveal the long-term consequences of bat declines,” says Elizabeth Beilke, postdoctoral researcher and lead author on the study.The research team built giant mesh-enclosed structures in an Indiana forest to exclude the eight bat species that frequent the area, including two federally threatened or endangered species. The mesh openings were large enough to allow insects free movement in and out, but not flying bats. Every morning and evening for three summers, Beilke opened and closed the mesh sides and tops of the structures to ensure birds had daytime access to the plots. That way, she could be sure she was isolating the impacts of bats.Beilke then measured the number of insects on oak and hickory seedlings in the forest understory, as well as the amount of defoliation per seedling. Because she erected an equal number of box frames without mesh, Beilke was able to compare insect density and defoliation with and without bats.Overall, the researchers found three times as many insects and five times more defoliation on the seedlings when bats were excluded than in control plots that allowed bats in each night. When analyzed separately, oaks experienced nine times more defoliation and hickories three times more without bats.“We know from other research that oaks and hickories are ecologically important, with acorns and hickory nuts providing food sources for wildlife and the trees acting as hosts to native insects. Bats use both oaks and hickories as roosts, and now we see they may be using them as sources of prey insects, as well. Our data suggest bats and oaks have a mutually beneficial relationship,” Beilke says.While insect pressure was intense in plots without bat predation, the seedlings didn’t succumb to their injuries. But the researchers say long-term bat declines could prove fatal for the baby trees.“We were observing sublethal levels of defoliation, but we know defoliation makes seedlings more vulnerable to death from other factors such as drought or fungal diseases. It would be hard to track the fate of these trees over 90 years, but I think a natural next step is to examine the impact of persistent low levels of defoliation on these seedlings,” Beilke says. “To what extent does repeated defoliation reduce their competitive ability and contribute to oak declines?”The researchers point out that birds, many of which share the same insect diets as bats, are also declining. While they specifically sought to isolate bats’ impact on forest trees, the researchers are confident insect density and defoliation rates would have been higher if they had excluded both birds and bats in their study. In fact, similar exclusion studies focusing on birds failed to account for bats in their study designs, leaving mesh enclosures up all night.“When we were initially working on the proposal for this research, we looked at 37 different bird exclusion studies, across agriculture and forest systems. We found nearly all of them had made this mistake. Most of them had not opened or removed their treatment plots to bats,” Beilke says.In other words, before Beilke’s study, birds were getting at least partial credit for work bats were doing in the shadows.Clearly, both types of winged predators are important for forest health in temperate systems. And, according to O’Keefe, that makes these studies even more critical to inform forest management.“I think it’s important to stress the value of this type of experimental work with bats, to really try to dig into what their ecosystem services are in a deliberate manner. While we can probably extrapolate out and say bats are important in other types of forest, I wouldn't discount the value of doing the same kind of work in other systems, especially if there are questions about certain insect or tree species and how bats affect them. So rather than extrapolating out across the board, let's do the work to try to figure out how bats are benefiting plants,” she says. “And before they're gone, hopefully.”The article, “Bats reduce insect density and defoliation in temperate forests: an exclusion experiment,” is published in Ecology [DOI: 10.1002/ecy.3903]. The research was supported by USDA’s National Institute of Food and Agriculture, the Indiana State Department of Natural Resources, the Indiana Space Grant Consortium, the Department of Biology at Indiana State University, and the Department of Natural Resources and Environmental Sciences at Illinois.The Department of Natural Resources and Environmental Sciences is in the College of Agricultural, Consumer and Environmental Sciences at the University of Illinois Urbana-Champaign.",0.0,0.0
29,https://www.futurity.org/amazon-discounts-consumers-2811182/,You may actually pay more with an Amazon discount,"Share thisArticle FacebookTwitterEmail You are free to share this article under the Attribution 4.0 International license. University University of FloridaMore than a quarter of vacuum cleaners sold on Amazon have at some point pretended to offer a discount when they had actually just increased the price, according to new research.By pairing a price increase with the introduction of a previously unadvertised “list price” for a product, Amazon signals to shoppers that they are receiving a discount when they actually pay 23% more, on average, for their new vacuum than they would have just a day earlier. Days after the price hike, the price drops and both the list price and misleading discount claim disappear.Sellers of digital cameras, blenders, drones, and even books use the same misleading practice, although less frequently. The false discounts drive higher sales despite charging more money, causing the products to improve in Amazon’s sales rankings.“When you see this list-price comparison, you naturally assume you are getting a discount. It’s not just that you didn’t get a discount. You actually paid a higher price than before the seller displayed the discount claim,” says Jinhong Xie, a professor in the Warrington College of Business at the University of Florida.Currently, regulations prohibiting deceptive pricing require that sellers use truthful price comparisons. Consumers have won class-action lawsuits against retailers like JC Penny and Ann Taylor for making discount claims using illegitimate values in price comparisons.In the pricing practice that Xie and her colleagues uncovered, the list price can be truthful yet still misleading. That’s because retailers advertise a price discount by displaying the list price when they actually raise prices and give the impression of a deal. But most of the time, the product is sold at a cheaper price without any comparison to a list price. It is the timing of the price comparison that misleads shoppers.“Current regulations are all about the value of the list price, and they don’t say anything about misleading consumers by manipulating the timing of the list price’s introduction,” Xie says.For the study, published in Marketing Science, researchers looked at the pricing of household products on Amazon from 2016 to 2017. Xie and colleagues followed more than 1,700 vacuums and gathered nearly half a million individual observations of prices. While most introductions of a new list price were associated with a price drop or no price change, 22% were instead accompanied by a price increase.Because shoppers perceive they are getting a deal, these misleading discounts actually improved the products’ sales rankings on Amazon, a proxy for sales volume.“We found that by increasing the price by 23% on average, the seller achieves an 11% advantage in their sales rank among all products in the home and kitchen category,” Xie says. “This allows firms to achieve the impossible: increasing margins and increasing sales simultaneously.”Other products used this practice anywhere from 3% of the time for books to more than 13% of the time for blenders, digital cameras, and drones.Consumers can protect themselves by questioning ubiquitous “discounts” advertised in online stores, Xie says. Shoppers should not assume a discount claim means the price is lower than usual. Instead, shoppers should comparison-shop across multiple websites. They can also use online tools that provide price histories to learn if the advertised price they are seeing is really a deal or not.“We think consumers need to be aware so they can protect themselves,” Xie says. “And we think that consumer organizations and regulators should evaluate this new marketing practice to determine whether and how to manage it.”Additional coauthors are from the University of South Carolina and Arizona State University.Source: University of Florida",0.0,0.0
69,https://techcrunch.com/2022/10/06/form-energys-iron-air-battery-on-pace-for-2024-launch-with-450m-series-e/,Form Energyâs iron-air battery on pace for 2024 launch with $450M Series E,"Form Energy closed a $450 million Series E fundraising round yesterday to continue its work turning iron into rust.The round was led by TPG Rise Climate and joined by new investors GIC and Canada Pension Plan Investment Board. Existing investors ArcelorMittal, Breakthrough Energy Ventures, Capricorn Investment Group, Coatue, Energy Impact Partners, The Engine, NGP ETP, Temasek, Prelude Ventures and VamosVentures provided follow-on capital.Such large rounds are becoming commonplace in the battery industry as startups transition from research and development to manufacturing and commercialization.Form is one of many battery tech companies that have popped up over the past decade, though it’s taking a different tack from many others. Where most companies are focusing on lithium ion-related chemistries, the startup has been pursuing iron-air batteries. That means its cells don’t rely on expensive and supply-constrained minerals like lithium, cobalt or nickel. Form will start commercial production in late 2024, and it’s aiming to eventually produce its battery packs for less than $20 per kWh.If the company can hit its target, it would hasten the shift toward renewable power. Already, solar and wind are price-competitive with fossil fuel plants, and in some cases they’re cheaper than running existing natural gas-fired plants. Adding inexpensive storage to contain cheap power would make renewables competitive in more locations.Form already has a contract with Great River Energy in Minnesota to install a 150-MWh battery, and it’s working with Southern Company to explore a similar pilot in Georgia.It’s one of a growing number of battery companies that are ignoring EVs in favor of other markets that are key to the energy transition. Form’s batteries are heavy and large, but also inexpensive and long-lasting, all qualities that are ideal for storing excess renewable energy.",0.0,0.0
119,https://www.overclock3d.net/news/gpu_displays/nvidia_releases_new_benchmarks_for_its_rtx_4080_graphics_cards/1,Nvidia releases new benchmarks for its RTX 4080 graphics cards,"Nvidia releases new benchmarks for its RTX 4080 graphics cardsThat's a big performance drop when compared to their RTX 4090...| Source: Nvidia Author: Mark CampbellNvidia gives gamers another look at the RTX 4080's performanceFollowing the launch of their RTX 4090 graphics card (read our review here), Nvidia has released new performance data for their RTX 4080 graphics cards.Nvidia's RTX 4080 will be releasing in two flavours, each of which offers different allotments of CUDA cores and different amounts of GDDR6X memory. Both graphics cards offer gamers completely different performance profiles, forcing us to wonder why Nvidia did not call the 16GB model the RTX 4080 Ti, or their 12GB model the RTX 4070. Nvidia's RTX 4080 16GB and RTX 4080 12GB will be launching in November with MSRP prices of $1,199 and $899 respectively.In A Plague Tale: Requiem, the vast majority of Nvidia's RTX 30/40 series lineup relies on DLSS to achieve 60+ FPS framerates. Note that this is without ray tracing enabled, which means that this game has the potential to be a lot more demanding. A Plague Tale: Requiem will support DLSS 3 at launch, giving Nvidia's RTX 40 series graphics cards a huge advantage over their RTX 30 series counterparts. Without DLSS Frame Generation, Nvidia's 12GB RTX 4080 would not be able to outperform Nvidia's last-generation RTX 3090 Ti.In F1 22, we again see that Nvidia's RTX 40 series benefits greatly from Nvidia's DLSS 3 technology, and that Nvidia's RTX 4080 12GB cannot outperform Nvidia's last-generation RTX 3090 Ti without it.Once again we see a hige performance gap between Nvidia's RTX 4090 and TX 4080 16GB, suggesting that there is space for an RTX 4080 Ti model if AMD decides to exploit this gap in Nvidia's RTX 40 series lineup.With Microsoft Flight Simulator, we once again see that DLSS 3 has a huge impact on the performance profile of their RTX 40 series GPUs. We also see that Nvidia's RTX 3090 Ti can also outperform their RTX 4080 when DLSS is disabled, even if only marginally.Nvidia's RTX 40 series relies on DLSS 3.0 to generate most of its promised performance gains. Here, the TX 4080 12GB is a lot further behind the RTX 4080 16GB than in other games. Maybe Nvidia should have called this GPU their RTX 4070, or RTX 4070 Ti.In the games above, Nvidia has given gamers a good look at what their RTX 4080 graphics cards will perform in some modern games, both with and without DLSS. DLSS 3 is a big addition for Nvidia's RTX 40 series, and you can bet that Nvidia will be working hard to get their technology integrated into as many games as possible, especially now that DLSS has competitors in the form of XeSS and FSR 2.0.You can join the discussion on Nvidia's RTX 4080 performance data on the OC3D Forums.1 - That's a big performance drop when compared to their RTX 4090... «Prev 1 Next»Most Recent Comments",0.0,0.0
80,https://www.theverge.com/c/23307867/human-composting-process-return-home,Inside one of the worldâs first human composting facilities,"Rachel Gerberding has a green thumb. So when her mother died this April, Gerberding decided to compost her. Gerberding, who lives in Washington state in a house surrounded by flowers, had heard about a newly legal method to turn human remains into soil. “I was like, ‘Mom, it would be such a wonderful thing for me — to be able to just walk through [my garden] and be like, ‘Oh, hi, Mom,’” Gerberding, 48, said, recounting their conversation. Sharon Gerberding, who had previously planned on a simple cremation, agreed: “I’m going to be dead,” she told Rachel. “Do whatever you want!”That’s why Sharon, who died from complications of multiple sclerosis, was laid to rest in an industrial park 30 minutes south of Seattle. On a chilly spring day, her family gathered in a nondescript, hangar-style building tucked between a belt rubber warehouse, recycling facilities, and an air quality testing company. Staff had placed Sharon’s body in a vessel filled with alfalfa, straw, sawdust, and notes written in biodegradable ink. Hymns played over the speaker system, a tribute to Sharon’s membership in The Church of Jesus Christ of Latter-day Saints. By early summer, all that would be left of their matriarch was a few hundred pounds of rich, dark soil.This is natural organic reduction — better known as human composting — the first truly new form of final disposition developed in decades. First legalized in Washington state in 2019, the process has proved popular with certain of the Pacific Northwest’s eco-conscious consumers, who are eager to have their last act on earth be a positive one. They know that traditional burials involve literal tons of steel, concrete, and toxic chemicals and that the heat of a cremation retort emits several hundred pounds of carbon into the atmosphere. For families like the Gerberdings, natural organic reduction, or NOR, promises a more gentle way out.Rachel Gerberding at Point Defiance Park, the last public garden she was able to visit with her mother before she died. — Tacoma, WA, July 11th 2022Today, there are four NOR companies in a roughly 150-mile radius of western Washington state, including Return Home, the company in charge of Sharon’s remains. New markets are opening up all the time. NOR is now legal in California, Oregon, Colorado, and Vermont. Boosters hope New York is next. But death industry disruptors face opposition, including from the Catholic Church, which has deemed NOR “more appropriate for vegetable trimmings and eggshells than for human bodies.” They aren’t the only ones: plenty of people find the whole process a little creepy.Despite these challenges, it’s clear a deathcare revolution is underway. New methods of body processing, from NOR to alkaline hydrolysis, are on the rise. So is the home funeral movement, which seeks to return the care of the dead to their families. New companies aim to be cost-competitive; at Return Home, NOR costs about $5,500 with a laying-in ceremony. That’s about twice as much as the average cremation but about half the cost of a traditional funeral and vault burial. But even as new options proliferate, after so many generations of viewing the corpse at a distance, few of us know what we really want to happen when we die — or how to ask for it.That’s where Return Home comes in. Its staff has worked to demystify the NOR process on the company TikTok, racking up over 5 million likes on videos of cartoon bones and pose-n-stay skeletons. They’ve opened up their facility to families, some of whom visit daily during their loved one’s composting. And they’ve slowed the funeral process down: at Return Home, turning a body into soil takes at least two months — much longer than the few chaotic days most families have to make arrangements, attend a service, and lay a body to rest. While people may think NOR is all “magic” and “Mother Earth,” Return Home founder and CEO Micah Truman says he’s out to prove “it’s just so much cooler than that.”Composting food dates back thousands of years, but the notion of actively turning human remains into a usable soil product is only a decade old. In 2013, Katrina Spade, an architecture student, proposed the idea in her graduate thesis. “Our bodies have nutrients,” Spade has said. “What if we could grow new life after we’ve died?”In her thesis, Spade envisioned a “dark, quiet, and safe” space where the natural work of decomposition could be scaled for an urban population and managed in an industrial setting. Think: green burial meets vertical farming. After graduation, Spade worked with soil scientists, lobbyists, and investors (to the tune of more than $15 million) to make the case for legalization in Washington state — and get her own NOR company up and running. It worked, and in May 2019, Governor Jay Inslee signed the bill into law.By early 2021, Spade’s firm, Recompose, was open for business. (Disclosure: my sister-in-law runs the front desk at Recompose’s Seattle facility.) By that point, Spade was hardly the only NOR entrepreneur. In Washington state, funeral consumers can also turn to Return Home, Herland Forest, and Earth.Truman, the founder of Return Home, wears the usual startup uniform: nondescript pants, a button-up shirt, and a fleece vest. But he speaks in zany constructions unlike anything you’d expect from a finance guy, let alone a de facto funeral home owner: We shouldn’t get “airy fairy” about composting, he says. Bodies are just “squishies and hards.” The process at Return Home is “like a Disney ride, only weirder.”Truman is often crying — an occupational hazard, he’s learned, in this new line of work.Initially, the plan for Return Home was something like a ghost kitchen but for human remains. People would ship bodies in, and Truman would send back soil, similar to the way a crematorium returns ashes. That informed the early look of the place — the vessels look like freezer chests in which hunters stock game in their garage. They’re stacked up by the dozen on enormous steel shelves, like bulk pallets of toilet paper in Costco.To make his vision a reality, Truman teamed up with John Paul of Transform Compost Systems just over the border in Canada. Together, they brought on a manufacturer to construct bespoke machinery for every stage process (and that, for proprietary interests, they refuse to name). For 18 months, the international team experimented relentlessly, including with pig carcasses — a good proxy, as any MythBusters fan knows, for the human body.This is, more or less, what they came up with:",0.0,0.0
128,https://www.nature.com/articles/s42005-022-00997-x,Influence of the first-mover advantage on the gender disparities in physics citations,"We start by describing the dataset we have analyzed and briefly explaining the methodology we have used to build the citation network and the pairs of similar papers. Then, we proceed to study gender disparities, first at the aggregate level and then by comparing pairs of similar papers.Data descriptionWe study an American Physical Society (APS) dataset from 1893 to 2009, which contains articles’ metadata, the authors’ basic information, and the citations within the papers. The metadata consists of authors’ full names and a unique digital object identifier (DOI) of the publication in a string format. For those names that are repeated in the dataset, we used name disambiguation methods proposed by Sinatra et al.19 to detect unique authors and correctly match authors to publications (see Supplementary Fig. 1). To infer gender from names, we implemented a gender-detection procedure that combines author names with an image-based gender inference technique applied to search results from Google Images20. This combined method results in high accuracy in the gender identification of scholars from different nationalities (see Supplementary Methods). The final dataset consists of 541,448 scholarly articles published over the course of 116 years, categorized into 11 journals. Among those 541,448 papers, we were able to identify at least one participating author’s gender of 375,736 papers. We have identified 120,776 gendered names, 17,763 women and 103,013 men. The evolution of the number of authors per year is shown in Fig. 1a.Fig. 1: Rate of growth of women participation, average publications by career age, dropout rate and annual ratio of men/women self-citations. a Number of men (blue) and women (orange) authors per year. b Average number of publications by authors' career age. The shaded area shows the standard deviation. c Proportion of men and women authors who drop out compared to the remaining active authors per career age. d Normalized ratio of men/women self-citations computed from (1) during the time period of interest. The horizontal dashed line is the line of equilibrium; data points above the equilibrium line indicate a higher ratio of men's self-citation, and points below the line imply a higher ratio of women's self-citation. Full size imageHere, the notion of “gender” refers neither to the sex of the authors nor to the gender that the author self-identifies as. By the word “woman”, we mean an author whose name has a high probability of being assigned to female at birth or being identified as a woman due to facial characteristics. Given this limitation, we can safely argue that these methodologies are in accordance with social constructs and what people perceive as gender in society.Constructing citation networks and assessing similar pairsWe build the citation networks by considering each paper as a node and making a link from paper i to paper j if i includes a citation to j. We measure the similarity between two papers using the bibliographic coupling strength21,22; that is, the number of publications that both papers cite. Two papers that cover similar topics in a comparable way are assumed to include a similar set of outgoing citations. However, within subfields there is usually a handful of classic publications that are cited in most works, so their inclusion in two different papers may not indicate actual similarity, but a citation convention. To avoid such shortcomings of naive bibliographic coupling, and guarantee the significance of the overlapping set of citations, we apply a statistical test based on the hypergeometric distribution. This test controls for the incoming citations of the commonly cited papers and checks whether the size of the common set of citations is so large that it cannot be explained by randomness. The problem of identifying similar papers to assess gender disparities has also been approached recently using machine learning techniques23.To explore gender disparities, we select pairs of similar papers respectively written by men and women primary authors. Then, we compare the future incoming citations to each of the pair. This comparison allows us to detect potential inequalities in the citation patterns. We have summarized this methodology in the diagram of Fig. 2 and provided all the technical details in Methods.Fig. 2: Assessing similar pairs. We use bibliographic coupling and hypergeometric statistical tests to select couples of similar papers based on their outgoing citation activities. Then we compare their respective popularity (incoming citations). Each node and each arrow represent a paper and a citation respectively, whereas each dashed arrow represents a potential citation that is missing. The pair of papers being assessed (i and j) are shown in blue and orange, the papers cited by them in yellow, and the papers that cite them in green. The black arrow at the bottom represents a timeline showing the publication times of the papers. Full size imageAggregate gender disparity trendsTo characterize the gender disparities at the aggregate level, we first analyze the aspects of scientific production that depend primarily on individual choices and ability: in particular, productivity, dropout rate, and self-citations. Then, we discuss authorship order, which depends on the internal organization of research groups. Finally, we study the behavior of the scientific community as a whole by comparing the citations received by men and women.ProductivityWe define productivity as the number of publications that scholars produce during their career. In physics, we observe that women have a lower average number of publications compared to men across all their career ages (Fig. 1b). While in the first two years of author’s career the publication gap is closing, we observe a sudden increase in the gap from the second to the eleventh year. After this point, the publication gap starts decreasing again. These fluctuations in publication productivity can be associated with, among other things, the disproportionate family responsibilities that women have to take on compared with men24. For the aggregate results, see the productivity distributions by gender in Supplementary Fig. 4.Although a researcher’s productivity can be considered to be determined mainly by individual skills, the collaborative nature of scientific work makes it dependent on external factors such as other team members or departmental organization. Likewise, these factors, together with other aspects like social perception or family responsibilities, affect women’s motivation to keep working in academia, potentially leading to the leaky pipeline phenomenon. To quantify this phenomenon, in the next section we explore the differences in dropout rates between men and women.Dropout rateWe compute dropout as a lack of publication activity for at least five years to distinguish the authors who are active in publishing from those who have dropped out. We investigate the ratio of dropout scholars at each career age compared to the number of active scholars by gender. Figure 1c shows that women authors have a higher dropout ratio throughout their whole career. The largest gaps appear in the early career years, with a 2.28% difference between men and women in the first year and a 2.26% difference in the sixth year. The dropout rates of authors who leave academia after their first year (career age 0) are not shown in Fig. 1c. This career age presents the highest dropout rates, with 39.94% for men authors and 47.55% for women authors.Self-citationSelf-citation refers to cases where authors cite their own previous works. Self-citations increase the total citation count and the visibility of scholars25,26,27, potentially enhancing academic promotion and attention. We have measured the relative number of self-citations by all men and women authors with the following metric (r) to study the difference in self-citation ratios between the two genders over time25:$$r=\frac{\frac{ \% {{{{{{{\rm{men}}}}}}}}{{\hbox{'}}} {{{{{\rm{s}}}}}}\,{{{{{\rm{self}}}}}}-{{{{{\rm{citations}}}}}}}{ \% {{{{{\rm{men}}}}}}{{\hbox{'}}} {{{{{\rm{s}}}}}}\,{{{{{\rm{citations}}}}}}}}{\frac{ \% {{{{{\rm{women}}}}}}{{\hbox{'}}} {{{{{\rm{s}}}}}}\,{{{{{\rm{self}}}}}}-{{{{{\rm{citations}}}}}}}{ \% {{{{{\rm{women}}}}}}{{\hbox{'}}} {{{{{\rm{s}}}}}}\,{{{{{\rm{citations}}}}}}}}$$ (1)Figure 1d shows the temporal evolution of the ratio r. This result shows that women tend to cite themselves less than men and that this trend is consistent over the years (See Supplementary Table 2 for more details). Consequently, women’s visibility in the citation network is partly penalized by the higher ratio of men citing their own previous works.Another fundamental factor that affects an author’s visibility is the position in which her name appears in the list of authors. This position depends on how the whole research group is organized and, crucially, in most cases it depends on the perceived level of contribution of each collaborator.Authorship order analysisIn the majority of the scientific fields, including physics, the authorship order indicates relative contribution and seniority by putting emphasis on the first, the last, and the second positions28,29. In order to compare the positions of authors, we first discard those papers for which authorship order is alphabetical. For this purpose, we perform a string comparison of the last names of the contributing authors and consider them to be in alphabetical order if the paper has at least four authors and all of them follow this order. Around 3.54% of the papers can be considered as alphabetically ordered; in Supplementary Table 3 we detail their fraction by PACS subfield (Physics and Astronomy Classification Scheme). After discarding those papers from the analysis, we study the authorship order in each publication and compare the proportion of women and men in each position of the author list (first, second, middle and last). We perform this comparison using a two-proportion z-test (see Methods). If there is only one author in a paper, we consider her the first author. Middle authors are those between second and last in papers with more than three authors.The results show that there are more women than expected by chance in the first, second and middle author positions, and they are heavily under-represented as last authors (see Supplementary Table 4). The last author in physics papers is usually the most senior member of the team, so this trend can be explained by the later and slower rate of arrival of women, combined with their higher dropout rate throughout their career. This is in line with previous findings that women feature only rarely as the last authors in leading journals30.While the authorship order reflects how a researcher’s coworkers perceive her contribution, the collective perception of the scientific community regarding the importance of a paper is manifested in the citations of papers. In the following sections we will thoroughly compare the relative popularity of publications led by women and men.Citation centrality analysisThe flow of citations determines the visibility and recognition of papers both locally and globally. To measure the local influence of papers we use the in-degree metric, and to measure the global influence, we use the PageRank centrality. Our aim is to verify if the visibility of papers written by women is proportionate to what we expect from their overall population size. To do that, we focus on the ranking of the nodes according to their respective centrality.Understanding ranking centrality is important for three reasons. First, the authors of papers in top ranks gain more visibility for themselves and those central papers influence future citation patterns31,32,33. Second, the visibility of papers in top ranks is being exacerbated by algorithmic tools such as Google Scholar. Third, since citation networks follow a heavy-tailed distribution, those in top ranks stabilize their ranking position and give few opportunities for other papers to catch up34. Because of these network effects, it is important to study how minorities are represented in top network centrality ranks.We assigned to each paper a gender by labeling it based on its first author. Then, we analyzed the top h% in-degree/PageRank centrality of the papers. Figure 3a suggests that papers written by women have significantly lower in-degree and pagerank centrality than expected from their overall proportion. Women-led publications are substantially under-represented in the highest 20th, 30th, and 40th percentages, and the deviation between the observed and the expected proportions likewise increases in the highest rank positions. While in-degree and PageRank follow a similar trend as expected, the proportion of women with high PageRank centrality is even lower when compared to the in-degree centrality. This suggests not only that papers written by women receive less attention but also that they are disadvantaged in terms of their position within the entire citation network. Statistical tests confirm these findings (see Supplementary Table 5).Fig. 3: Women author proportions in degree and PageRank centrality, evolution of centrality difference by year and relationship between time of publication and citation. a Proportion of publications with a woman primary author per top h% of degree (black) and PageRank centrality (red). The dotted horizontal line signifies the proportion of women primary authors in the observed samples. b Citation and temporal differences between man–woman pairs of papers with validated similarity. The colors indicate the quadrant each pair belongs to (black—quadrant 1, red—quadrant 2, green—quadrant 3, and purple—quadrant 4). c Heat map showing the probability anomaly of the joint probability distribution of citation and temporal differences computed with equation (2). d Centrality differences of similar man-man pairs and similar man–woman pairs over the years. The two papers within each pair are published no more than 3 years apart, and the publication year of the pair is defined by the year of the latter paper. The lines are the mean values and the shaded areas the standard errors. The evolution of the distribution as a whole is shown in Supplementary Fig. 7 as a percentile plot. Full size imageSo far, the global gender analysis points towards a notable disparity in productivity and citation of men and women. This could be partly due to historical reasons, to the cumulative advantage that early arrival confers to men, as well as to the high dropout rate of women7. The slower rate of arrival of women (see Fig. 1a) may also play a relevant role. Together, these factors affect women’s global visibility. The question that arises from these global results is, are scholars intentionally ignoring (and therefore, under-citing) research works led by women? To explore this possibility, in the following section we study pairs of papers written by men and women that are statistically validated twins, and measure the citations that each paper receives.Pair-wise citation analysisWe identified statistically validated pairs of similar papers (one with a man as first author and the other with a woman) using the methodology described in Methods and summarized in Supplementary Fig. 2. Then, we computed the difference in the number of citations each member of the pair receives. The overall expectation is that similar pairs of papers should have a similar number of incoming citations on average. The first sign of gender bias that we have found is that, within similar pairs of man–woman papers, men get more citations in 45% of the pairs, women in 39%, and in 16% they receive the same number of citations. We performed binomial tests against the null hypothesis that men and women should be equally likely to get citations within each similar pair and obtained a strong rejection (p-value ≈ 0).To quantify men’s advantage, we computed the average citation difference between the man-led and the woman-led paper of each pair. Then we normalized it using the standard deviation of men’s and women’s citations to obtain Cohen’s d, a measure of effect size for the difference of means. We evaluated the significance of these differences using z-tests (see Methods). As shown in Table 1, men’s average citation count is significantly higher than women’s both in aggregate and when we consider each PACS subfield separately to control for potential differences in the citation biases per subfield. We obtained similar results by controlling for journal instead of subfield (see Supplementary Note 1 and Supplementary Table 10). We performed analogous analyses for last authors, finding consistent results for most subfields and journals (see Table 2 and Supplementary Table 12). The only noteworthy difference appears in PACS 80 (Interdisciplinary Physics & Related Studies), where women get more citations on average as first authors.Table 1 Differences in received citations among similar pairs of publications labeled by their first-author gender. Full size tableTable 2 Differences in received citations among similar pairs of publications labeled by their last-author gender. Full size tableIt is known that the publication time of a paper influences its citation count, and previous studies1,35 have used different strategies to control for it. To check whether the temporal difference between two papers is responsible for the citation disparity for women (an older paper has had more time to accumulate citations), we add a maximum 3-year difference restriction between two similar papers and redo the citation difference analyses. Tables 1 and 2 show that when the time constraint is applied, the citation difference between two similar publications decreases significantly (see Supplementary Tables 11 and 13 for the journal-wise analyses). The effect is stronger for first than for last authors. The subfield Interdiscplinary Physics & Related Studies (PACS 80) presents an anomalous behavior, as women have the citation advantage as first authors while men have it as last authors. In contrast to the rest of subfields, this advantage increases after applying the time constraint.However, citations have a very heterogeneous distribution, with a tiny fraction of papers gathering a huge number of citations, so these discrepancies may be caused by a few papers written by women with many citations. To mitigate the influence of such outliers, we have performed analogous tests for the difference of medians. In particular, we have used the Wilcoxon test to quantify the significance of the difference and the rank biserial correlation (rc)36 to estimate its effect size. The rc metric takes values between −1 when women have more citations in every pair and +1 when men do. The results, presented in Supplementary Tables 14 and 15, show that the apparent advantage of women in PACS 80 (and in PACS 00—General Physics) after applying the time constraint, were mostly driven by outliers, as rc is positive in all cases; although, consistent with the previous analyses, it is smaller when the time constraint is applied.Throughout these analyses, we have seen that the gender disparity within similar man–woman pairs is small (small effect sizes), but significant (p-values close to 0). However, we should be cautious when interpreting those p-values. The statistical tests rely on the assumption of independent samples, but in our methodology one paper can be part of several statistical twins, so those pairs would not be independent. The independence violation results in narrower standard errors and, in turn, lower p-values. Nevertheless, the consistency of the gender asymmetries should not be underestimated.The temporal dimension is fundamental when comparing citation counts, as the first-mover advantage plays a crucial role in scientific success37. Within similar man–woman pairs, the man’s paper is published first in 47.7% of the pairs, the woman’s paper in 41.3%, and approximately at the same time (the same year) in 11.0% of the pairs. These results point to a clear first-mover advantage by men.First-mover advantage within similar pairs of papersGiven the above results, we now seek to confirm whether the time of publication is a main driver for the citation disparity and whether the first-mover advantage in publication affects men-led papers and women-led papers similarly. We define Δ t = Y m − Y f as the year difference between the publication dates of man–woman pairs of similar papers and Δ C = c m − c f as their citation difference. We plotted the year difference Δ t against the citation difference Δ C in Fig. 3b. We likewise elaborated ten analogous plots after categorizing the data into subfields by PACS number (shown in Supplementary Fig. 5) to control for variations between subfields. Note that for this analysis we impose no time restriction between the publication times of the two papers of each pair.To verify that the disparity in citations is caused by the first-mover advantage, we first need to test whether a first-mover advantage in fact exists. If that is the case, when a man publishes first (Δ t < 0) he should get more citations (Δ C > 0) on average, but when a woman publishes first (Δ t > 0) she is the one who should get more citations (Δ C < 0) on average; that is, in Fig. 3b, quadrants Q2 and Q4 should be more populated than expected if we treated Δ t and Δ C as independent random variables. Equivalently, we should observe a negative correlation between Δ t and Δ C .To test this hypothesis, we compared the empirical joint probability distribution of Δ t and Δ C (P emp (Δ t , Δ C )) with the one that we would obtain if they were independent variables (P null (Δ t , Δ C ) = p(Δ t )p(Δ C )) by computing the probability anomaly as:$${P}_{{{{{{{{\rm{diff}}}}}}}}}({\Delta }_{t},{\Delta }_{C})=\frac{{P}_{{{{{{{{\rm{emp}}}}}}}}}({\Delta }_{t},{\Delta }_{C})-{P}_{{{{{{{{\rm{null}}}}}}}}}({\Delta }_{t},{\Delta }_{C})}{{P}_{{{{{{{{\rm{null}}}}}}}}}({\Delta }_{t},{\Delta }_{C})}$$ (2)The resulting values of P diff (Δ t , Δ C ) are shown in Fig. 3c and, as can be observed, they support the hypothesis of the first-mover advantage, since Q2 and Q4 present positive anomalies while Q1 and Q3 present negative ones. It is worth emphasizing that a positive (resp. negative) anomaly indicates higher (resp. lower) density of points with respect to a situation of no correlation between Δ t and Δ C . To quantify this trend we computed the Pearson and Spearman correlations between Δ t and Δ C , obtaining − 0.13 and − 0.34, respectively.Once the existence of the first-mover advantage has been confirmed, we need to test whether there exists an asymmetry in the relative advantage that men and women obtain when they publish first. If there is no asymmetry, the average number of citations that a woman obtains by publishing a certain number of years ahead of a man should be comparable to the number of citations that a man obtains in the equivalent situation.To verify this, we compared the citation differences of Q2 with Q4 (pairs where the earlier paper received more citations) and Q1 with Q3 (pairs where the earlier paper received fewer citations) for each temporal difference; in other words, we compared the average absolute value \(|{\Delta }_{C}|\) of points from Q2 with the average \(|{\Delta }_{C}|\) of points from Q4 for each \(|{\Delta }_{t}|=1,2,\ldots\) separately (analogously for Q1 and Q3). To perform this comparisons, we used z-tests for difference of means for each year difference (see Methods). The results of the tests for the whole dataset, shown in Table 3, indicate that men have an asymmetric advantage, gaining comparatively more citations when they publish first. We obtain similar results for each subfield (see Supplementary Table 16). The exceptions are General Physics (PACS 00) and Interdisciplinary Physics & Related Studies (PACS 80), where women get an asymmetric advantage.Table 3 Statistical tests of gender asymmetry in the first-mover advantage. Full size tableResearcher seniority as a temporal advantageWhile we have verified that the first-mover advantage plays a relevant role in the citation disparities between genders in a microscopic level, the differences between similar pairs, even if significant, are fairly small. Therefore, the temporal advantage gained by individual papers published earlier than their statistical twins may not be enough to explain the visibility differences manifested in the centrality rankings shown in Fig. 3a. As mentioned above, there are group-level temporal disparities that should also be taken into account: women’s delayed arrival, their slower rate of arrival, and their higher dropout rate, captured in Fig. 1.These factors can have dramatic effects on the distribution of seniority of researchers (see Fig. 4a), which is another potential source of inequality. As a researcher progresses through her career, she not only gathers citations, but also recognition, which in turn attracts more citations. As we observe in Fig. 4b, the proportion of male to female authors increases with career age, indicating a strong gender bias in the seniority distribution. This bias in the proportion of senior researchers is transferred to the ranking of centrality of papers (see Fig. 4c), which shows, on the one hand, that the higher ranks are occupied on average by older researchers, and on the other hand, that the average age of women authors is consistently lower throughout all ranks.Fig. 4: Seniority distribution of researchers by gender. a Number of men and women authors by their career age. b Proportion of men to women by career age. c Average age of men and women authors of papers in each top h% of degree centrality (number of citations). The inset shows the same result zooming in on the higher ranks. Full size imageThis thorough analysis indicates that temporal advantages are critical factors in the emergence of gender inequalities. From the individual’s perspective, researchers that publish a result earlier gain the first-mover advantage. Men publish earlier more frequently and obtain an asymmetrical advantage when they do so. At the population level, historical disadvantages driven by the late arrival and higher dropout rate of women cause a deficit of female senior researchers, which may explain women’s low visibility in the citation network.Historical trend in citationFinally, we hypothesize that the physics community might have been less receptive to the contribution of women in the past compared to the present. To test this hypothesis, we measure the temporal evolution of the centrality differences (Δ C ) between man–woman pairs by year and limit the publication time difference between the two papers to a trailing window of 3 years. Then, we compute the mean and standard error of Δ C for all the pairs within each window. For comparison, we perform an analogous computation for random samples of similar man-man pairs. In each time window, we matched the number of sampled man-man pairs with the number of similar man–woman pairs. We repeated the man-man computation 100 times independently and computed the average Δ C and the standard error, which we use as a baseline.",0.0,0.0
132,https://www.psypost.org/2022/10/new-study-suggests-trumps-2020-election-conspiracy-theories-undermined-gop-turnout-in-the-2021-georgia-runoffs-64076,New study suggests Trumpâs 2020 election conspiracy theories undermined GOP turnout in the 2021 Georgia runoffs,"New research published in the Proceedings of the National Academy of Sciences provides evidence that voters in Georgia who embraced Donald Trump’s claims of widespread election fraud were less likely to cast their ballot in a pivotal runoff election.In the aftermath of the 2020 election, Trump made a series of baseless allegations that the election had been stolen from him. These claims were quickly debunked by election experts, but Trump continued to push these conspiracy theories in an attempt to undermine the legitimacy of Joe Biden’s victory. The study authors were interested in exploring how this rhetoric might have impacted the 2021 runoff elections in Georgia, where Democrats were able to flip two U.S. Senate seats.“Trends in U.S. politics are such that Democratic and Republican politicians are both vocally suspicious of their opponents’ respect for the ‘rules of the game’ in our democracy,” said study author Jon Green, a senior research scientist in the Network Science Institute at Northeastern University, and a fellow at the Shorenstein Center on Media, Politics and Public Policy at the Harvard Kennedy School.“To be clear, these suspicions come with very different levels of empirical support. These conspiracy theories about widespread voter fraud on the part of Democrats really are baseless. But that doesn’t change the fact that both parties’ core voters are hearing from their leaders that the other side is trying to take away their ability to vote their preferred candidates into office – either by making it harder to vote, loosening the relationship between votes and outcomes (through gerrymandering, e.g.), or through fraud that ignores legally cast votes altogether.”“And there are debates within the parties about whether this kind of rhetoric is counterproductive,” Green continued.” People who work in Democratic politics, for instance, are sometimes worried that Democrats’ allegations that Republicans are engaging in voter suppression could discourage potential Democratic voters from voting, on the margins, because it could create the impression that voting will be more difficult or inconvenient.”“During the Georgia runoffs, we saw local Republican activists raising similar concerns about these fraud allegations – that they were discouraging Republican voters from turning out because they were introducing uncertainty into whether voting was going to have any relationship with the runoffs’ outcome. So this question of whether there are any behavioral implications of this kind of elite rhetoric was what sparked my initial interest in the specific research question.”The researchers analyzed Twitter data and voter records to explore the link between the endorsement of Trump’s election fraud claims and voter turnout in Georgia’s 2021 runoff elections. The sample included 45,431 Twitter users who had a voter record in the state of Georgia.The study authors evaluated whether the Twitter users had liked or retweeted content supporting or detracting from election-fraud conspiracy theories. They also evaluated whether the users had liked or retweeted posts by the official Twitter account of then-President Donald Trump, and whether they had engaged with other prominent accounts that posted content supporting or opposing election-fraud conspiracies.Green and his colleagues found that online engagement with content detracting from election-fraud conspiracy theories was associated with higher turnout than expected in the runoff election. On the other hand, those who liked or shared tweets supporting fraud-related conspiracy theories were slightly less likely to vote.“We can’t say for sure whether the ‘Big Lie’ cost Republicans control of the Senate, but our study provides some evidence that it didn’t help their candidates in the Georgia runoffs,” Green told PsyPost. “All of our findings surprised us in the sense that there were good reasons to expect different results and we really weren’t sure what we’d find until we analyzed the data.”The researchers proposed several mechanisms by which widespread claims of election fraud could affect turnout. They had theorized, for instance, that engagement with 2020 election conspiracy theories on Twitter could possibly help to boost Republican voter turnout due to their potential to elicit anger and strengthen partisan ties.“It was reasonable to expect that endorsing election conspiracy theories would have been associated with higher turnout in the runoffs because the conspiracy theory made people angry, and prior work has linked anger to things like party loyalty and intentions to vote. So if we had observed that positive relationship, it would have made sense,” Green explained.“However, translating anger into action typically requires it to be paired with efficacy – a belief that you can do something to address the threat you perceive. Here, a central premise of the conspiracy theory – that election results in Georgia are not directly based on the votes its citizens cast – likely reduces efficacy, so the results we found also make sense.”Another proposed mechanism was negative evaluations of co-partisan candidates. In other words, voters who bought into election-fraud conspiracies might have been more likely to see Republican Senate candidates as being insufficiently supportive of Trump.“It’s also possible that the way the Republican Senate candidates campaigned turned these voters off,” Green explained. This election determined control of the Senate when Democrats had already won control of the House and presidency. If you’re a Republican running for Senate in that situation, you typically want to appeal to the (small but non-trivial) slice of the electorate that sincerely prefers divided government. You want to pitch yourself as the last check against a Democratic trifecta.”“But if you say this as a Republican candidate in the Georgia runoffs, you are implicitly acknowledging that Joe Biden is going to be the president. That is, you’re behaving as if the election was not stolen. If you’re really invested in the idea that the election was stolen and we need to do everything in our power to correct this obvious injustice, then why bother turning out to vote for a candidate like that? Again, we don’t know if that’s what drove our finding, we just can’t rule it out.”The findings are in line with press reports, which claimed that some Trump supporters in Georgia were intent on “boycotting” the runoff election because of alleged fraud. But the observational nature of the study prevents the researchers from making strong causal claims.“The big caveat is that because this is all observational, we can’t nail down why we see the relationships we see, and we can’t completely rule out that the turnout behavior is being driven by something other than the conspiracy theory,” Green said. “We don’t have causal leverage, and we spend some time in the paper talking about why causal inference is especially hard in a case like this. We also talk about a few different causal mechanisms that we see as plausible, and I’ve alluded to some above, but we can’t say for sure which mechanism(s) are producing the relationships we see.”Trump continues to claim that the 2020 election was stolen from him, but whether this rhetoric will help Democrats in other elections remains to be seen. “In terms of questions that still need to be addressed, the big one is that we don’t know how generalizable our findings are,” Green said. “Georgia’s 2021 runoff elections were unique for a couple of reasons, so it’s unclear whether we’d expect the same results given overlapping-but-not-identical conditions in another context in the future.”“I think it’s really important to keep in mind that conspiracy theories undermining faith in elections’ outcomes are bad regardless of any relationships they might have with voting behavior in the short term,” the researcher added.The study, “Online engagement with 2020 election misinformation and turnout in the 2021 Georgia runoff election“, was authored by Jon Green, William Hobbs, Stefan McCabe, and David Lazera.",0.0,0.0
133,https://www.psypost.org/2022/10/pornography-is-not-to-blame-for-erectile-dysfunction-according-to-new-research-64109,"Pornography is not to blame for erectile dysfunction, according to new research","Can watching porn give men erectile dysfunction? A study published in the International Journal of Impotence Research suggests that pornography use does not predict problems in erectile functioning or sexual satisfaction.Pornography use is a hotly contested issue in many relationships. Since the rise of the internet, porn is easily accessible, affordable, commonly used, and able to be consumed without anyone else knowing. Pornography usage has been linked to negative outcomes, such as impersonal sexual attitudes, negative body image, more acceptance of sexual aggression, and delayed ejaculation. It also has been shown to have positive effects, such as providing sexual education and aiding in sexual dysfunction. Previous research showing pornography causes erectile dysfunction have had many methodological flaws, and this study seeks to explore that question once again.For their study, David L. Rowland and colleagues examined a sample of 3,586 men recruited online from English-speaking countries and Hungary. Respondents who were not having sex with their partner or who had never had a partner were eliminated. Participants completed a survey consisting of demographic questions, anxiety/depression, medical conditions, sexual orientation, number of current sexual partners, interest and importance of sex, relationship and sexual satisfaction, masturbation, partnered sex, and frequency of pornography usage. Participants completed measures on premature ejaculation, erectile functioning, and answered questions regarding delayed ejaculation.Results showed that factors that increased likelihood of erectile dysfunction were advanced age, anxiety, depression, medical issues, less frequent sex, lower importance of sex, and decreased sexual and relationship satisfaction. Problems with erectile functioning was a predictor of decreased satisfaction in this sample.Men with erectile dysfunction did not significantly differ in their pornography usage than men without erectile dysfunction. Despite this, there was a small effect of frequent masturbation being related to problems with erectile functioning. Pornography consumption was not linked to decreased relationship or sexual satisfaction when masturbation frequency was controlled for.This study took important steps into addressing methodological issues in previous research on this topic. Despite this, this study also has limitations to note. One such limitation is that online and self-report studies are vulnerable to bias or to participants not paying attention. Additionally, this study utilized only Western participants; future research could include cultures who have more restrictive views of sex to see if the effects differ.“Findings of this study reiterate the relevance of long-known risk factors such as age, anxiety, and relationship satisfaction for understanding impaired erectile functioning during partnered sex, but they do not support the notion that pornography use is widely associated with poorer erectile functioning or increased ED severity during partnered sex,” the researchers concluded.“Masturbation frequency appears to have discernable though weak effects on erectile functioning during partnered sex. Although further study is needed for verification, heavy reliance on pornography use coupled with a high frequency of masturbation may nevertheless represent a risk factor for diminished sexual performance and/or poor relationship satisfaction in some men (e.g., in younger, less experienced men or where mitigating cultural factors likely play a role). From a clinical perspective, these factors deserve assessment and, if relevant, may be addressed as part of a remediation component of psychosexual therapy.”The study, “Do pornography use and masturbation play a role in erectile dysfunction and relationship satisfaction in men?“, was authored by David L. Rowland, Joseph M. Castleman, Katelyn R. Bacys, Balazs Csonka, and Krisztina Hevesi.",0.0,0.0
122,https://www.nih.gov/news-events/news-releases/hair-straightening-chemicals-associated-higher-uterine-cancer-risk,Hair straightening chemicals associated with higher uterine cancer risk,"Hair straightening chemicals associated with higher uterine cancer riskNIH study finds Black women may be more affected due to higher use.>Women who used chemical hair straightening products were at higher risk for uterine cancer compared to women who did not report using these products, according to a new study from the National Institutes of Health. The researchers found no associations with uterine cancer for other hair products that the women reported using, including hair dyes, bleach, highlights, or perms.The study data includes 33,497 U.S. women ages 35-74 participating in the Sister Study, a study led by the National Institute of Environmental Health Sciences (NIEHS), part of NIH, that seeks to identify risk factors for breast cancer and other health conditions. The women were followed for almost 11 years and during that time 378 uterine cancer cases were diagnosed.The researchers found that women who reported frequent use of hair straightening products, defined as more than four times in the previous year, were more than twice as likely to go on to develop uterine cancer compared to those who did not use the products.“We estimated that 1.64% of women who never used hair straighteners would go on to develop uterine cancer by the age of 70; but for frequent users, that risk goes up to 4.05%,” said Alexandra White, Ph.D., head of the NIEHS Environment and Cancer Epidemiology group and lead author on the new study. “This doubling rate is concerning. However, it is important to put this information into context - uterine cancer is a relatively rare type of cancer.”Uterine cancer accounts for about 3% of all new cancer cases but is the most common cancer of the female reproductive system, with 65,950 estimated new cases in 2022. Studies show that incidence rates of uterine cancer have been rising in the United States, particularly among Black women.Approximately 60% of the participants who reported using straighteners in the previous year were self-identified Black women, according to the study published in the Journal of the National Cancer Institute. Although, the study did not find that the relationship between straightener use and uterine cancer incidence was different by race, the adverse health effects may be greater for Black women due to higher prevalence of use.“Because Black women use hair straightening or relaxer products more frequently and tend to initiate use at earlier ages than other races and ethnicities, these findings may be even more relevant for them,” said Che-Jung Chang, Ph.D., an author on the new study and a research fellow in the NIEHS Epidemiology Branch.The findings are consistent with prior studies showing straighteners can increase the risk of hormone-related cancers in women.The researchers did not collect information on brands or ingredients in the hair products the women used. However, in the paper they note that several chemicals that have been found in straighteners (such as parabens, bisphenol A, metals, and formaldehyde) could be contributing to the increased uterine cancer risk observed. Chemical exposure from hair product use, especially straighteners, could be more concerning than other personal care products due to increased absorption through the scalp which may be exacerbated by burns and lesions caused by straighteners.“To our knowledge this is the first epidemiologic study that examined the relationship between straightener use and uterine cancer,” said White. “More research is needed to confirm these findings in different populations, to determine if hair products contribute to health disparities in uterine cancer, and to identify the specific chemicals that may be increasing the risk of cancers in women.”This team previously found that permanent hair dye and straighteners may increase breast and ovarian cancer risk.Grant Numbers: Z01-ES044005, Z1AES103332-01About the National Institute of Environmental Health Sciences (NIEHS): NIEHS supports research to understand the effects of the environment on human health and is part of the National Institutes of Health. For more information on NIEHS or environmental health topics, visit https://www.niehs.nih.gov or subscribe to a news list.About the National Institutes of Health (NIH): NIH, the nation's medical research agency, includes 27 Institutes and Centers and is a component of the U.S. Department of Health and Human Services. NIH is the primary federal agency conducting and supporting basic, clinical, and translational medical research, and is investigating the causes, treatments, and cures for both common and rare diseases. For more information about NIH and its programs, visit www.nih.gov.NIH…Turning Discovery Into Health®",0.0,0.0
174,https://scitechdaily.com/quantum-breakthrough-researchers-demonstrate-full-control-of-a-three-qubit-system/,Quantum Breakthrough: Researchers Demonstrate Full Control of a Three-Qubit System,"Error correction in a silicon qubit system was demonstrated by the researchers.By demonstrating error correction in a three-qubit silicon-based quantum computing device, researchers from RIKEN in Japan have made a significant advancement toward large-scale quantum computing. This research, which was published in Nature, could help make practical quantum computers a reality.Quantum computers are a prominent field of study right now because they promise to solve important problems that are unsolvable with conventional computers. Instead of employing the straightforward 1 or 0 binary bits inherent in traditional computers, they use superimposition states of quantum physics. They are, however, very sensitive to ambient noise and other difficulties, such as decoherence, due to their fundamentally different design and need error correction to do precise calculations.The selection of systems that can serve as the best “qubits,” or basic units needed to do quantum calculations, is a significant challenge today. Each prospective system has advantages and disadvantages of its own. Today’s popular systems include superconducting circuits and ions, which have the benefit of having some type of error correction demonstrated, enabling them to be used in real-world applications, although on a limited scale.Silicon-based quantum technology, which has just recently started to be developed, is known to offer an advantage in that it uses a semiconductor nanostructure comparable to what is frequently used to integrate billions of transistors on a compact chip, and hence potentially benefits from existing manufacturing technology.However, one major problem with silicon-based technology is that there is a lack of technology for error connection. Researchers have previously demonstrated control of two qubits, but that is not enough for error correction, which requires a three-qubit system.In the current research, conducted by researchers at the RIKEN Center for Emergent Matter Science and the RIKEN Center for Quantum Computing, the group achieved this feat, demonstrating full control of a three-qubit system (one of the largest qubit systems in silicon), thus providing a prototype for the first time of quantum error correction in silicon. They achieved this by implementing a three-qubit Toffoli-type quantum gate.According to Kenta Takeda, the first author of the paper, “The idea of implementing a quantum error-correcting code in quantum dots was proposed about a decade ago, so it is not an entirely new concept, but a series of improvements in materials, device fabrication, and measurement techniques allowed us to succeed in this endeavor. We are very happy to have achieved this.”According to Seigo Tarucha, the leader of the research group, “Our next step will be to scale up the system. We think scaling up is the next step. For that, it would be nice to work with semiconductor industry groups capable of manufacturing silicon-based quantum devices on a large scale.Reference: “Quantum error correction with silicon spin qubits” by Kenta Takeda, Akito Noiri, Takashi Nakajima, Takashi Kobayashi, and Seigo Tarucha, 24 August 2022, Nature.DOI: 10.1038/s41586-022-04986-6",0.0,0.0
211,https://techxplore.com/news/2022-09-cobalt-free-cathode-lithium-ion-batteries.html,Researchers develop a cobalt-free cathode for lithium-ion batteries,"Working with researchers at four U.S. national laboratories, Huolin Xin, UCI professor of physics & astronomy, has found a way to fabricate lithium-ion batteries without using cobalt, a rare, costly mineral extracted under inhumane conditions in Central Africa. Credit: Steve Zylius / UCIResearchers at the University of California, Irvine and four national laboratories have devised a way to make lithium-ion battery cathodes without using cobalt, a mineral plagued by price volatility and geopolitical complications.In a paper published today in Nature, the scientists describe how they overcame thermal and chemical-mechanical instabilities of cathodes composed substantially of nickel—a common substitute for cobalt—by mixing in several other metallic elements.""Through a technique we refer to as 'high-entropy doping,' we were able to successfully fabricate a cobalt-free layered cathode with extremely high heat tolerance and stability over repeated charge and discharge cycles,"" said corresponding author Huolin Xin, UCI professor of physics & astronomy. ""This achievement resolves long-standing safety and stability concerns around high-nickel battery materials, paving the way for broad-based commercial applications.""Cobalt is one of the most significant supply chain risks threatening widespread adoption of electric cars, trucks and other electronic devices requiring batteries, according to the paper's authors. The mineral, which is chemically suited for the purpose of stabilizing lithium-ion battery cathodes, is mined almost exclusively in the Democratic Republic of Congo under abusive and inhumane conditions.""Electric vehicle manufacturers are eager to curtail the use of cobalt in their battery packs not only for cost reduction but to counter the child labor practices used to mine the mineral,"" Xin said. ""Research has also shown that cobalt can lead to oxygen release at high voltage, causing damage to lithium-ion batteries. All of this points to a need for alternatives.""However, nickel-based cathodes come with their own problems, such as poor heat tolerance, which can lead to oxidization of battery materials, thermal runaway and even explosion. Although high-nickel cathodes accommodate larger capacities, volume strain from repeated expansion and contraction can result in poor stability and safety concerns.The researchers sought to address these issues through compositionally complex high-entropy doping using HE-LMNO, an amalgamation of transition metals magnesium, titanium, manganese, molybdenum and niobium in the structure's interior, with a subset of these minerals used on its surface and interface with other battery materials.Xin and his colleagues employed an array of synchrotron X-ray diffraction, transmission electron microscopy and 3D nanotomography instruments to determine that their zero-cobalt cathode exhibited an unprecedented volumetric change of zero during repeated use. The highly stable structure is capable of withstanding more than 1,000 cycles and high temperatures, which makes it comparable to cathodes with much lower nickel content.For some of these research tools, Xin collaborated with researchers at the National Synchrotron Light Source II, located at the U.S. Department of Energy's Brookhaven National Laboratory in New York. As a DOE Office of Science user facility, NSLS-II offered the team access to three of its 28 scientific instruments—called beamlines—to study the internal structure of the new cathode.""The combination of the different methods at NSLS II beamlines enabled the discovery of a trapping effect of oxygen vacancies and defects inside the material, which effectively prevents the crack formation in the HE-LMNO secondary particle, making this structure extremely stable during cycling,"" said co-author Mingyuan Ge, a scientist at NSLS-II.Added Xin: ""Using these advanced tools, we were able to observe the dramatically increased thermal stability and zero-volumetric-change characteristics of the cathode, and we've been able to demonstrate extraordinarily improved capacity retention and cycle life. This research could set the stage for the development of an energy-dense alternative to existing batteries.""He said the work represents a step toward achieving the dual goal of spurring the proliferation of clean transportation and energy storage while addressing environmental justice issues around the extraction of minerals used in batteries.More information: Huolin Xin, Compositionally complex doping for zero-strain zero-cobalt layered cathodes, Nature (2022). www.nature.com/articles/s41586-022-05115-z Journal information: Nature Huolin Xin, Compositionally complex doping for zero-strain zero-cobalt layered cathodes,(2022). DOI: 10.1038/s41586-022-05115-z",0.0,0.0
20,https://www.laptopmag.com/features/video-game-graphics-are-a-ticking-time-bomb-the-industry-needs-to-focus-on-art-over-tech,Video game graphics are a ticking time bomb â the industry needs to focus on art over tech,"It’s no secret that video games are inherently linked to the technology that allows us to experience them. However, as the industry continues to evolve, I can’t help but wonder if we’ve gone too far. It’s gotten to the point where graphical complexity is seen as the ultimate indicator of quality, making the game development process infinitely harder and longer. It seems like people will completely disregard an experience if the game’s graphics don’t hold up, or just absolutely demolish a game if it looks like it could have come out 10 years ago. To me, this seems absurd: Graphics are immensely overrated.Of course, graphics aren’t actually “overrated” in a literal sense. They are the visual gateway into the video games we play. Without them, we’d have nothing to look at. But when I say graphics are overrated, I’m referring to the overwhelming focus video game communities and marketing puts on graphical prowess and modernity. Sometimes it feels like the quality of a game’s art and style is tossed aside just to analyze how “new” and “shiny” something looks.Some genuinely believe that any game released more than a decade ago is “outdated and ugly,” and it truly makes me wonder, how did we get here? Why are people so obsessed with graphics?The technology raceThere’s plenty of reason why these advancements are such a fundamental part of the industry. Perhaps the single largest is because, at the end of the day, gaming is a technological medium: You need hardware to play the games.No hardware company will survive selling you the same specs if games aren’t evolving hand-in-hand with tech. If I purchased an RTX 3080 and the industry decided that we’ve hit the roof in hardware requirements, with the RTX 3080 being the final piece of the puzzle, then what would Nvidia sell us?(Image credit: Nvidia)Yes, they could continue manufacturing RTX 3080s. But whenever someone purchases one, they will have lost a customer for many many years, as you can make a GPU last a long time with proper care. When a PC gamer decides to upgrade their tech, it’s usually because their old tech is having trouble running modern software, not because it’s broken.My Nvidia GeForce GTX 970, a graphics card that launched in 2014, still works. It’s a functioning GPU, but the reason I upgraded to an RTX 3080 was because I was sick of games moving on without me. If my GTX 970 ran every piece of software I threw at it perfectly, I wouldn’t need to upgrade. Essentially, Nvidia needs to innovate to sell new hardware. It’s how they turn profits and continue to be a financially successful company.Console manufacturers have the same goal. How would PlayStation sell a PS5 to you if the hardware specs were the same as the PS4? What good reason could they have to convince you to move over? The only way they could do that is by forcing exclusivity on games, but in this imaginary world, that would be immensely problematic.(Image credit: Future)And of course, when the industry has that technology in front of them, they’re going to evolve their game engines accordingly. This is a technological medium and many of the brilliant engineers who work within it find themselves able to do more when better hardware is in their hands.It’s also important to note how damaging this obsession with progress is to game developers and their work cycle. Games are getting more and more complicated to make with every passing year. It is currently harder to make games than it has ever been; development times are longer than they were 10 years ago and the amount of crunch we’ve seen developers endure to get the biggest titles released is alarming. Whether we’re talking about The Last of Us Part II or Cyberpunk 2077 , so much overtime has been needed to put these enormous games together. How much worse do things need to get before we realize it’s not worth it?And when the players themselves are so accustomed to this cycle, they’ll expect it and get upset when it doesn’t continue. It’s common for players to be critical of a lack of technological modernity. If character models, animations, textures, or other types of assets look remotely outdated, it will be pointed out and criticized. This is a trend I absolutely despise.There’s more to art than just technologyThe gaming industry’s obsession with graphical fidelity has only made me more aware of the flaws of technology. The more advanced a game tries to be, the more cognizant I am of how lacking it actually appears. The jarring contrast between an engine’s best looking moments and the parts that just don’t look right result in a rude awakening, making me realize how much progress the industry still needs to reach the goals it's striving for.(Image credit: Laptop Mag)For example, in Ghost of Tsushima , there are visual setbacks that make it harder for me to latch onto its world. Soaring through a gorgeous field of flowers on horseback is an inspiring sight, but when I stop next to a collection of rocks that look blurry or the sun is reflecting light against mud in an unrealistic manner, it quickly takes me away from that moment.When a game attempts to mimic reality, my brain often processes the moments where it fails to look “realistic” with uncanniness. It just ends up seeming wrong, and whenever I think back to the game, my brain is hyper fixated on that flaw. On the other hand, my brain does not process older games in the same way, as there was never room for me to think of it as “realistic” to begin with.(Image credit: Nintendo)There is very little potential to mistake Super Mario 64 as an attempt at realism. When I think back on it, I don’t process its technological flaws, because that technology was used to present a certain style that cannot be assumed to be something akin to reality. Your brain can process those “flaws” as artistic intent, whereas if you’re trying to render a realistic glass of milk, your brain will latch onto the flaws that clearly make it look different from what a bottle of milk should actually look like.This isn’t to say modern games don’t have visual styles, of course they do. I’m specifically referring to how my brain processes it. And if you feel your brain is similar, then you probably have the same issue I do.This also isn’t to say games look ugly nowadays. Obviously, modern games can look absolutely breathtaking, just as much as they could have twenty years ago. I simply do not believe in the notion that graphical complexity or modernity determines whether or not a game is visually compelling.(Image credit: New Blood Interactive)You don’t decide whether an illustration looks good based on the tools used to make it come to life; different tools merely offer alternate styles. Dusk utilizes a graphical style that mimics first-person-shooters from the late 1990s, and that style has no bearing on the quality of the art itself. That style is merely a tool to express the intentions of the artist.This isn’t to say you can’t have preferences with style. Everyone does. I cannot blame someone for preferring the modern, realistic look of AAA games launched in the last few years. It’s a perfectly understandable preference to have, but it’s important to keep in mind that a game doesn’t look good just because it has high quality textures. There is so much more to the artform than that, and I wish people allowed games more leeway when they’re not as graphically complex as others.(Image credit: FromSoftware)Elden Ring, an experience that boasts some of the most breathtaking visual setpieces in gaming this year, was (and still is) frequently criticized for its outdated graphics by players who believe technology is the end all be all in determining the quality of visuals. Yes, Elden Ring suffered from pop-in and its foliage and textures look nowhere near as advanced as Demon’s Souls (2020). But I genuinely believe Demon’s Souls 2009 looks infinitely better than its remake, yet that game came out 13 years ago.In fact, the best looking game ever made was and still is 2005’s Shadow of the Colossus. Technological prowess can’t make up for a vapid aesthetic or a world lacking inspiration. There is so much more to art than just progress, and the industry needs to reconsider this gluttonous obsession.Bottom lineAt what point do we realize that constant advancement is not worth it? How much longer do development times need to get? How much harder does it need to be to create a game? AAA development is a ticking time bomb waiting to blow, and as the industry continues its obsession with progress, the artform will suffer.I hope I’m wrong. But I truly do believe that this cycle has a time limit. There will be a point where expectations are so unbelievably high that it’s not financially viable to continue making games of that complexity anymore.",0.0,0.0
210,https://reneweconomy.com.au/australia-can-slash-emissions-81-pct-by-2030-using-existing-technologies-report-says/,"Australia can slash emissions 81 pct by 2030 using six existing technologies, report says","Australia could slash its emissions by 81 per cent by 2030 – almost double the 43% target recently legislated by the federal government – using little else but “off the shelf” technologies, a new report says.The Beyond Zero Emissions report argues that the vast bulk of Australia’s emissions reduction task can be met by a combination of six technologies, all available today: solar PV, wind, batteries, electric vehicles, heat pumps and electrolysers.BZE says the “ambitious but achievable” plan relies on ramping up the rollout rates of these technologies over the coming five years, in some cases quite significantly, and would be supported by targeted “carbon drawdown initiatives.”The fast-tracking of the rollout of these technologies required to hit the 81% emissions reduction mark would include a doubling of the current rate of deployment of solar panels, and EV uptake boosted to 14 times its current levels.The uptake of heat pumps for water heating and air conditioning would need to be increased by 37 times, the report says, in line with calls from electrification and energy efficiency advocates to ho hard at a household level to cut emissions.Two appliances per household“This plan sets the ambition, establishes the job potential and demonstrates the opportunity of acting without delay for industry and manufacturing, business and households,” the report says.“In the next five years, we need to install clean technology in our homes, vehicles and industries at a rate of about two units or appliances per household,” it adds.“We cannot afford to wait for new research and inventions, and we don’t need to.”Across households and businesses this looks something like, 10 million-plus units of hot water and air conditioning heat pumps, 2.9 million units of building efficiency technologies, 7,000 units of industrial-scale tech, such as heat pumps and electrolysers, and 3.8 million units of transport – mostly electric vehicles and chargers.On renewables and storage, which BZE says will be the foundation of success for its emissions “elimination” plan, the reports calls for the installation of about 6,000 wind turbines and 66 million solar panels over the coming five years.This would be joined by 67GWh of utility-scale and domestic batteries over the five-year period and 3,000 electrolysers to supply renewable hydrogen for industry.“It is doable”“This ambitious undertaking means installing more generation capacity and far more storage than the total of all types of generation capacity and storage in Australia today,” the report says.“It is doable: in 2021 alone Australia added 6.2GW of renewable generation. Doubling the 2021 rollout rate of renewable generation will realise the ambitions identified in this plan.”BZE chief Heidi Lee says that as well as using existing technologies, the plan’s target is supported by more than 50 companies who are “already getting on” with the job.“Australia has doubled its rollout of domestic solar generation over the past five years and our plan now requires us to double down on utility solar, wind and energy storage,” Lee says.“If we take this approach to other renewable technologies we won’t just meet our legislated emission reduction targets, we’ll go well beyond them.”On “carbon drawdown,” the plan looks to initiatives that remove carbon from the atmosphere, such as revegetation, the use of pyrolysis for biomass and the protection of ecosystems and existing carbon stock.",0.0,0.0
18,https://www.eurekalert.org/news-releases/969038,Short bursts of vigorous activity linked with increased longevity,"Two minute bursts of vigorous activity totalling 15 minutes a week are associated with a reduced risk of death, according to research published today in European Heart Journal, a journal of the European Society of CardiologySophia Antipolis, 28 October 2022: Two minute bursts of vigorous activity totalling 15 minutes a week are associated with a reduced risk of death, according to research published today in European Heart Journal, a journal of the European Society of Cardiology (ESC).1“The results indicate that accumulating vigorous activity in short bouts across the week can help us live longer,” said study author Dr. Matthew N. Ahmadi of the University of Sydney, Australia. “Given that lack of time is the most commonly reported barrier to regular physical activity, accruing small amounts sporadically during the day may be a particularly attractive option for busy people.”A second study, also published today in EHJ, found that for a given amount of physical activity, increasing the intensity was associated with a reduced likelihood of cardiovascular disease.2 “Our study shows that it’s not just the amount of activity, but also the intensity, that is important for cardiovascular health,” said study author Dr. Paddy C. Dempsey of the University of Leicester and University of Cambridge, UK, and the Baker Heart and Diabetes Institute, Melbourne, Australia.Both studies included adults aged 40 to 69 years from the UK Biobank. Participants wore an activity tracker on their wrist for seven consecutive days. This is an objective way to measure motion, and particularly sporadic activity of different intensities during the day.The first study enrolled 71,893 adults without cardiovascular disease or cancer. The median age was 62.5 years and 56% were women. The investigators measured the total amount of weekly vigorous activity and the frequency of bouts lasting two minutes or less. Participants were followed for an average of 6.9 years. The investigators analysed the associations of volume and frequency of vigorous activity with death (all-cause, cardiovascular disease and cancer) and incidence of cardiovascular disease and cancer after excluding events occurring in the first year.The risk of all five adverse outcomes reduced as the volume and frequency of vigorous activity increased, with benefits seen even with small amounts. For example, participants with no vigorous activity had a 4% risk of dying within five years. Risk was halved to 2% with less than 10 minutes of weekly vigorous activity, and fell to 1% with 60 minutes or more.Compared with just two minutes of vigorous activity per week, 15 minutes was associated with an 18% lower risk of death and a 15% lower likelihood of cardiovascular disease, while 12 minutes was associated with a 17% reduced risk of cancer. Further gains were observed with greater amounts of vigorous activity. For instance, approximately 53 minutes a week was associated with a 36% lower risk of death from any cause.Regarding frequency, accumulating short bouts (up to two minutes) of vigorous activity on average four times a day was associated with a 27% lower risk of death. But health benefits were observed at even lower frequencies: 10 short bouts a week was associated with 16% and 17% lower risks of cardiovascular disease and cancer, respectively.The second study included 88,412 adults free of cardiovascular disease. The average age was 62 years and 58% were women. The investigators estimated the volume and intensity of physical activity, then analysed their associations with incident cardiovascular disease (ischaemic heart disease or cerebrovascular disease). Participants were followed for a median 6.8 years.The researchers found that both higher amounts and greater intensity were associated with lower rates of incident cardiovascular disease. Increasing the intensity led to greater reductions in cardiovascular disease for the same volume of exercise. For example, the rate of cardiovascular disease was 14% lower when moderate-to-vigorous activity accounted for 20% rather than 10% of activity, the equivalent of converting a 14 minute stroll into a brisk seven minute walk.Dr. Dempsey said: “Our results suggest that increasing the total volume of physical activity is not the only way to reduce the likelihood of developing cardiovascular disease. Raising the intensity was also particularly important, while increasing both was optimal. This indicates that boosting the intensity of activities you already do is good for heart health. For example, picking up the pace on your daily walk to the bus stop or completing household chores more quickly.”ENDSAuthors: ESC Press OfficeMobile: +33 (0)7 8531 2036Email: press@escardio.orgFollow us on Twitter @ESCardioNewsFunding: Please see the papers.Disclosures: Please see the papers.NotesReferences1Ahmadi MN, Clare PJ, Katzmarzyk PT, et al. Vigorous physical activity, incident heart disease, and cancer: how little is enough? Eur Heart J. 2022. doi:10.1093/eurheartj/ehac572.Link will go live on publication:https://academic.oup.com/eurheartj/article-lookup/doi/10.1093/eurheartj/ehac5722Dempsey PC, Rowlands AV, Strain T, et al. Physical activity volume, intensity and incident cardiovascular disease. Eur Heart J. 2022. doi:10.1093/eurheartj/ehac613.Link will go live on publication:https://academic.oup.com/eurheartj/article-lookup/doi/10.1093/eurheartj/ehac613Joint editorial:Matthews CE, Saint-Maurice PF. The hare and the tortoise: physical activity intensity and scientific translation. Eur Heart J. 2022. doi:10.1093/eurheartj/ehac626.Link will go live on publication:https://academic.oup.com/eurheartj/article-lookup/doi/10.1093/eurheartj/ehac626About the European Society of CardiologyThe European Society of Cardiology brings together health care professionals from more than 150 countries, working to advance cardiovascular medicine and help people lead longer, healthier lives.About European Heart JournalEuropean Heart Journal (EHJ) is the flagship journal of the European Society of Cardiology. It is the world’s leading publication in general cardiology. Please acknowledge the journal as a source in any articles.",0.0,0.0
187,https://metro.co.uk/2022/10/13/our-patients-arent-dead-look-inside-the-us-cryogenic-freezing-lab-17556468,âOur patients arenât deadâ: Inside the cryogenic freezing facility with 199 humans on ice,"Alcor Life Extension Foundation is freezing people in the hope of reviving them in the future (Picture: Reuters)For some people in Arizona, time and death is ‘on pause’.Inside tanks filled with liquid nitrogen are the bodies and heads of 199 humans who opted to be cryopreserved with the hopes of being revived in the future.Many of the patients – as Alcor Life Extension Foundation calls them – are people who were terminally ill with cancer, ALS or other diseases with no cure in the present day.One of the patients is Matheryn Naovaratpong, the youngest person to be cryogenically frozen.Alcor’s former CEO, Max More, pointed to a picture of the girl as reporters were given a tour of the facility.‘A little girl from Thailand who had brain cancer. Both her parents were doctors and she had multiple brain surgeries and nothing worked, unfortunately. So they contacted us,’ More explained.To view this video please enable JavaScript, and consider upgrading to a web browser that supports HTML5 videoNaovaratpong’s case is one of only a few at Alcor that is public. Another with a terminal disease is Hal Finney, who passed away from ALS. Finney is well-known in the cryptocurrency community for being the recipient of the first Bitcoin transaction.When it comes to famous figures, Paris Hilton has reportedly signed up for cryopreservation. America’s Got Talent, Simon Coldwell, had publicly announced his membership in 2011 but later opted out.Rumors about Walt Disney being frozen have circulated for decades, but that was debunked by his own family.Legendary baseball player, Ted Williams, who died in 2002 is currently one of Alcor’s frozen patients.The bodies are kept in these giant tanks (Credit: Reuters)More says he thinks of cryonics as an extension of emergency medicine.‘We come at the stage where doctors today have given up. Today’s medicine and technology is not sufficient to keep you going. But we’re saying instead of just disposing of the patient, give them to us.‘We’re going to stabilize them, stop them getting worse, and hold them for as long as it takes for technology to catch up and allow them to come back to life and continue living,’ he said.To view this video please enable JavaScript, and consider upgrading to a web browser that supports HTML5 videoNatasha Vita-More, futurist and author, is married to Max Moore, and also one of the company’s 1,392 living members. The couple met in 1992 during a futurist event in Los Angeles and discovered both were members of the company.Vita-More is signed up to be ‘neurosuspended’, meaning only her brain will be cryopreserved.Best case scenario, Vita-More says, is that patients who were frozen, will meet in the future with other family members or pets who were also preserved. ‘And the destination would be the future where a person who had a cancer or ALS or some other type of injury or disease is revived,’ she said.‘The disease or injury cured or fixed, and the person has a new body cloned or a whole body prosthetic or their body reanimated and meet up with their friends again.’Would you like to be cryopreserved? (Credit: Reuters)But there are skeptics in the medical world.Doctor Arthur Caplan, director of the Division of Medical Ethics and professor of Bioethics at the New York University Grossman School of Medicine in New York City, reckons the idea is far-fetched.‘The only group that you really see getting excited about the possibility are people who are sort of, people who specialize in studying the distant future or people who have a stake in wanting you to pay the money to do it,’ he said in a Zoom interview with news agency Reuters.Alcor Life Extension Foundation is based in Scottsdale, Arizona in the US (Credit: Getty Images)Cryonics is based on anticipation and in the hope that one day science will be advanced enough for the restoration of cryopreserved humans. Alcor does not make any promises or guarantees, but that hasn’t stopped people from giving the company their money.It costs a minimum of $200,000 (£180,000) to freeze a body and $80,000 (£72,000) for the brain alone.Alcor says that the vast majority of its members don’t have that money, so they use life insurance equal to that amount, making Alcor the beneficiary of the policy.Of course, there are various ongoing running costs associated with the facility, which Alcor says can depend on what’s being frozen and for how long.‘Alcor knows quite accurately the total costs involved in keeping all its patients cryopreserved, the allocation of those costs among specific patients is not so clear cut,’ the company says.It won’t go into specifics surrounding individual costs per patient because of the sums involved. But, suffice to say, keeping your body and brain cryopreserved for generations doesn’t come cheap.MORE : Here’s how much coffee you should drink each day, according to scienceMORE : Petting dogs makes people ‘more sociable’ and science just proved it",0.0,0.0
309,https://www.cnn.com/2022/10/21/tech/facebook-tiktok-misinfo-ads/,"Facebook and TikTok are approving ads with âblatantâ misinformation about voting in midterms, researchers say","New York CNN Business —Facebook and TikTok failed to block advertisements with “blatant” misinformation about when and how to vote in the US midterms, as well as about the integrity of the voting process, according to a new report from human rights watchdog Global Witness and the Cybersecurity for Democracy Team (C4D) at New York University.In an experiment, the researchers submitted 20 ads with inaccurate claims to Facebook, TikTok and YouTube. The ads were targeted to battleground states such as Arizona and Georgia. While YouTube was able to detect and reject every test submission and suspend the channel used to post them, the other two platforms fared noticeably worse, according to the report.TikTok approved 90% of ads that contained blatantly false or misleading information, the researchers found. Facebook, meanwhile, approved a “significant number,” according to the report, though noticeably less than TikTok.The ads, submitted in both English and Spanish, included information falsely stating that voting days would be extended and that social media accounts could double as a means of voter verification. The ads also contained claims designed to discourage voter turnout, such as claims that the election results could be hacked or the outcome was pre-decided.The researchers withdrew the ads after going through the approval process, if they were approved, so the ads containing misinformation were not shown to users.“YouTube’s performance in our experiment demonstrates that detecting damaging election disinformation isn’t impossible,” Laura Edelson, co-director of NYU’s C4D team, said in a statement with the report. “But all the platforms we studied should have gotten an ‘A’ on this assignment. We call on Facebook and TikTok to do better: stop bad information about elections before it gets to voters.”In response to the report, a spokesperson for Facebook-parent Meta said the tests “were based on a very small sample of ads, and are not representative given the number of political ads we review daily across the world.” The spokesperson added: “Our ads review process has several layers of analysis and detection, both before and after an ad goes live.”A TikTok spokesperson said the platform “is a place for authentic and entertaining content which is why we prohibit and remove election misinformation and paid political advertising from our platform. We value feedback from NGOs, academics, and other experts which helps us continually strengthen our processes and policies.”Google said it has “developed extensive measures to tackle misinformation on our platforms, including false claims about elections and voting procedures.” The company added: “We know how important it is to protect our users from this type of abuse – particularly ahead of major elections like those in the United States and Brazil – and we continue to invest in and improve our enforcement systems to better detect and remove this content.”While limited in scope, the experiment could renew concerns about the steps taken by some of the biggest social platforms to combat not just misinformation about candidates and issues but also seemingly clear cut misinformation about the process of voting itself, with just weeks to go before the midterms.TikTok, whose influence and scrutiny in US politics has grown in recent election cycles, launched an Elections Center in August to “connect people who engage with election content to authoritative information,” including guidance on where and how to vote, and added labels to clearly identify content related to the midterm elections, according to a company blog post.Last month, TikTok took additional steps to safeguard the veracity of political content ahead of the midterms. The platform began to require “mandatory verification” for political accounts based in the United States and rolled out a blanket ban on all political fundraising.“As we have set out before, we want to continue to develop policies that foster and promote a positive environment that brings people together, not divide them,” Blake Chandlee, President of Global Business Solutions at TikTok, said in a blog post at the time. “We do that currently by working to keep harmful misinformation off the platform, prohibiting political advertising, and connecting our community with authoritative information about elections.”Meta said in September that its midterm plan would include removing false claims as to who can vote and how, as well as calls for violence linked to an election. But Meta stopped short of banning claims of rigged or fraudulent elections, and the company told The Washington Post those types of claims will not be removed for any content involving the 2020 election. Looking forward, Meta has banned US ads that “call into question the legitimacy of an upcoming or ongoing election,” including the midterms, according to company policy.Google also took steps in September to protect against election misinformation, elevating trustworthy information and displaying it more prominently across services including search and YouTube.The big social media companies typically rely on a mix of artificial intelligence systems and human moderators to vet the vast amount of posts on their platforms. But even with similar approaches and objectives, the study is a reminder that the platforms can differ wildly in their content enforcement actions.According to the researchers, the only ad they submitted that TikTok rejected contained claims that voters had to have received a Covid-19 vaccination in order to vote. Facebook, on the other hand, accepted that submission.",0.0,0.0
284,https://techcrunch.com/2020/11/19/biomaterials-are-coming-to-pantyhose/,Genomaticaâs expanded Aquafil partnership brings biomaterials to more consumer goods,"In a deal that has potentially big implications for the sustainability of consumer packaged goods, biomaterial manufacturing technology developer Genomatica and the massive nylon material manufacturer Aquafil have partnered on a new demonstration scale facility.Nylon-6 is used to make everything from toothbrush bristles to pantyhose and industrial materials like carpeting and other heavy-duty fabrics.The material will be used to develop renewable products and showcase goods that can be brought to market as more companies look to clean up their supply chains and make products that have fewer negative consequences for the environment at the end of their life.The deal is a 50-fold expansion of previous production levels for Genomatica and represents a significant expansion of Genomatica’s capabilities.The textile industry is a $960 billion business, and it’s one of the most polluting in the world — both in terms of chemical treatments and greenhouse gas emissions. According to data cited by the World Economic Forum, the textile industry accounts for 1.2 billion tons of carbon dioxide equivalent per-year — nearly as much as the auto industry. Nylon production alone is responsible for about 60 million tons of greenhouse gas emissions per year, according to the companies.The multi-year agreement with European-based Aquafil expands on the two companies’ existing relationship. Earlier this year the two companies produced the first ton of bio-nylon-6 precursor material at a pilot scale. Now, the move to a demonstration scale plant will give Genomatica the ability to move ahead with supply agreements to certain brand partners.Clothing maker Far Eastern New Century uses Genomatica’s products in its clothes, and other partnerships are in the works, the company said.Genomatica is backed by Casdin Capital, Viking Global Investors, which continues as Genomatica’s largest shareholder, and organism engineering partner Ginkgo Bioworks.“Bio-nylon is positioned to replace a material that’s used in millions of applications every day,” said Christophe Schilling, Genomatica CEO. “Our research shows that despite health and economic turmoil, 56% of Americans still want brands to prioritize sustainability. With this scale, Genomatica is offering our brand partners a key way to meet their sustainability objectives, differentiate themselves, and meet surging consumer demand.”Aquafil is building the plant in Slovenia, where the Genomatica biological precursor material will be converted into bio-nylon-6 yarns, films and engineered plastics.",0.0,0.0
185,https://newatlas.com/telecommunications/optical-chip-fastest-data-transmission-record-entire-internet-traffic/,Record-breaking chip can transmit entire internet's traffic per second,"The speed record for data transmission using a single light source and optical chip has been shattered once again. Engineers have transmitted data at a blistering rate of 1.84 petabits per second (Pbit/s), almost twice the global internet traffic per second.It’s hard to overstate just how fast 1.84 Pbit/s really is. Your home internet is probably getting a few hundred megabits per second, or if you’re really lucky, you might be on a 1-gigabit or even 10-gigabit connection – but 1 petabit is a million gigabits. It’s more than 20 times faster than ESnet6, the upcoming upgrade to the scientific network used by the likes of NASA.Even more impressive is the fact this new speed record was set using a single light source and a single optical chip. An infrared laser is beamed into a chip called a frequency comb that splits the light into hundreds of different frequencies, or colors. Data can then be encoded into the light by modulating the amplitude, phase and polarization of each of these frequencies, before recombining them into one beam and transmitting it through optical fiber.In experiments, researchers from the Technical University of Denmark (DTU) and Chalmers University of Technology used the setup to transmit data at 1.84 Pbit/s, encoded in 223 wavelength channels, down a 7.9-km-long (4.9-mile) optical fiber that contained 37 separate cores. For reference, the global internet bandwidth has been estimated at just shy of 1 Pbit/s, meaning this system could potentially handle all of that at once with plenty of room to grow.This data transmission speed greatly exceeds the previous record of 1.02 Pbit/s, which was only set in May this year. A previous optical chip design, similar to that used in the new study, managed 44 terabits per second in mid-2020.But the new chip is far from finished breaking records, according to the team behind it. Using a computational model to scale the data transmission potential of the system, the researchers claim that it could eventually reach eye-watering speeds of up to 100 Pbit/s.“The reason for this is that our solution is scalable – both in terms of creating many frequencies and in terms of splitting the frequency comb into many spatial copies and then optically amplifying them, and using them as parallel sources with which we can transmit data,” said Professor Leif Katsuo Oxenløwe, lead author of the study. “Although the comb copies must be amplified, we do not lose the qualities of the comb, which we utilize for spectrally efficient data transmission.”The research was published in the journal Nature Photonics.Source: DTU",0.0,0.0
107,https://www.visaliatimesdelta.com/story/news/2022/10/31/high-poverty-l-a-neighborhoods-poor-pay-more-internet-service-delivers-less/10652544002/,"In high-poverty L.A. neighborhoods, the poor pay more for internet service that delivers less","Bobbi MurrayCapital and MainA recent study by the California Community Foundation and Digital Equity Los Angeles laid out the stark differences in pricing and availability of internet services from two of L.A. County’s internet service providers — dominant ISP Charter Spectrum and Frontier.In the San Fernando Valley, Charter Spectrum offers residents of a Sylmar neighborhood with a 7% poverty rate $30 monthly service, guaranteed to stay locked in for two years. Another Sylmar community, with a 27% poverty rate, receives an offer of $70 per month with a one-year price guarantee.The two neighborhoods are a mile away from one another.“The highest speeds at the lowest costs are offered to the wealthiest and whitest communities,” lead study author Shayna Englin told a community Zoom meeting with representatives from Digital Equity Los Angeles.Page after page of the study outlines disparities similar to the example in Sylmar. The study is confined to Los Angeles County, so its focus is on Charter Communications, or Charter Spectrum, whose internet service is available to 97% of county households.Low income, minority neighborhoods may not only face pricing discrepancies but slower internet service, with fewer MBPS (megabits per second), according to a study of 38 cities in the U.S. by news organizations the Markup and the Associated Press. Download speeds were substantially faster in high income, white-dominant neighborhoods. (The Los Angeles area was not included in that study.)The California Community Foundation/Digital Equity L.A. analysis notes that in Los Angeles County, residents of high-poverty areas are routinely offered slower service at higher prices. (Disclosure: the California Community Foundation is a financial contributor to Capital & Main.)“It’s not because people don’t know what the problem is, it’s just the urgency and the depth of the problem is still kind of hidden,” says Ana Teresa Dahan, managing director at GPSN (formerly Great Public Schools Now). “Everyone feels like they have access to the internet because we have cellphone plans.”GPSN has worked on a variety of education issues but students’ struggle to learn online during the pandemic has made digital equity a priority for the organization.Michael Picker explains the problem in terms of who runs the show. That’s the large telecom companies at the table both at the federal level and in Sacramento. Picker knows; he served as president of the California Public Utilities Commission for five years. He has sat at the table with company representatives and walked the halls in Sacramento urging legislators to give the PUC more leeway on oversight.When the communications companies were deregulated in the 1990s, he says, the Public Utilities Commission became “toothless in the face of federal preemption.“States have no authority over regulation,” Picker says, “which works to the advantage of Comcast, AT&T, Verizon. The same way we don’t have the ability to set rates, we don’t have the ability to regulate.“If you can’t set rates, what leverage do you have?”The 2020 Federal Infrastructure and Jobs Act includes $65 billion for broadband investment, with $42.45 billion of it allotted to the Broadband Equity, Access and Deployment (BEAD) program.Providers are scrambling to pick up the largesse that builds internet access bridges to low income communities. It could be seen as building a customer base — when the federal money runs out, they will have a new set of consumers and all their data in order to sell them a new product.Dahan of GPSN says that grassroots groups are using the Slower and More Expensive study to figure out the way forward. “I think that as we learn what the different opportunities and solutions are, we’re going to amplify them.“I think what our report is trying to say is at minimum we should have some type of pricing transparency that can then lead to solutions on what pricing equity would look like,” Dahan says.“What we’re trying to do is figure out how to get concessions from them, on these investments on the infrastructure they need for their business. What is the government asking for in return?” A minimum demand would be pricing transparency so customers could compare offered rates.Picker has three words of advice: Joint Powers Authority (JPA). Bring together two local government agencies and create a JPA. A JPA can purchase fiber connections and become a utility. “You can fit the definition of a utility because you’re putting up fiber and serving customers.“Then you have real power — because you are competing; you have fiber, you can lease some of it to these internet service providers and make them serve all the customers. So, then you get to set the rates.”It’s a long-game strategy, he admits.“You need a plan,” Picker says. “You need power and you need the power to follow through.”",0.0,0.0
460,https://techcrunch.com/2022/08/08/5-reasons-why-ukraines-fintech-sector-is-growing-despite-war/,5 reasons why Ukraineâs fintech sector is growing despite war,"Ukrainians have often pioneered market-leading companies and built products that positively impact society, especially in the fintech sector.Despite the hurdles of war, the Ukrainian fintech community is working to create better infrastructure and regulation for the country, which can attract valuable companies and institutional investors from different backgrounds.It’s a valuable marketI’m sure many investors think the country’s IT sector is a risky investment right now. But it’s still business as usual at fintech companies here. They have proven their resilience even in wartime conditions, and impressively, 90% of Ukrainian tech startups are still hiring.This March, Ukraine’s President Volodymyr Zelenskyy signed a bill to establish a regulatory framework for cryptocurrency in the country. While the bill doesn’t let you use digital assets as a form of payment, it seeks to create proper conditions to establish a strong cryptocurrency market.Cryptocurrency exchanges can now claim a license to operate legally in the country. Banks will be able to open accounts for crypto companies, which can opt for different licenses depending on what they do.The Ukrainian IT sector is still growingIn the first five months of 2022, Ukraine’s IT sector generated roughly $3.2 billion from exports — 27% more than the same period in 2021, and accounting for almost half of the country’s total volume of export services.One of the main goals of the Ukrainian government is to increase the IT sector’s share of the country’s GDP from the current 4% to 10% by 2024.The government’s backing and the strong growth together make for a strong signal of how the IT sector is ripe for investments.Global finance and tech firms are supporting UkraineEarlier this month, the Ukrainian Ministry of Digital Transformation presented Digital4Freedom — a global initiative that is the primary source of charitable donations for tech companies to support Ukraine.Digital4Freedom is part of the global UNITED24 effort and allows anyone across the globe to make monetary contributions to the restoration of the country’s economy.The program consists of nine projects presented to 40 companies, of which the vast majority have agreed to help with monetary contributions or technology solutions.Amazon, for example, will reportedly provide over $100 million in cloud hosting services for Ukrainian state registers and is planning to develop solutions for deploying artificial intelligence in courts.Crypto exchange Binance will become an official partner of the Ministry of Digital Transformation of Ukraine to offer educational projects in the IT, web3 and finance fields.Meta, with the support of the Ministry of Digital Transformation, recently launched a $1.5 million assistance program for the recovery of the Ukrainian economy, helping small- and medium-sized businesses with a specialized training centre.Startups are an integral part of the Ukrainian economyUkrainian businesses expect a reduction in the production of goods and services due to the war. What’s more, company executives predict the next 12 months will bring inflation and devaluation of the hryvnia.Ukrainian tech startups are dedicating their efforts to elevating the industry to new heights. They are set to become the foundational pillars for a new layer of technology companies that will add significant value to the economy.Fintech is growing fast despite setbacksThis year, Ukrainian lawmakers introduced the Law of Ukraine on Payment Services (LPS), which will provide a better regulatory environment for the fintech sector, including for payment services.Additionally, the Ukrainian Association of Fintech and Innovation Companies (UAFIC) became the first non-EU member to join the European Digital Finance Association (EDFA). Both organizations are collaborating to strengthen the fintech landscape in Ukraine.I believe Ukraine’s resilience in the face of Russian aggression, and the tremendous growth of the fintech landscape despite the crisis has proven that investors should not hesitate to invest in the fast-growing industry.Despite the difficult situation in the country, the industry continues to develop. While attending numerous conferences and fintech events, I meet investors from all over the world interested in companies from Ukraine. All this tells us that the prospects for fintech in Ukraine look good, and that now is an excellent time to invest in it.",0.0,0.0
283,https://www.theguardian.com/technology/2022/oct/07/killer-robots-companies-pledge-no-weapons,Top robot companies pledge not to add weapons to their tech to avoid harm risk,"Several robot production companies have pledged not to support the weaponization of their general purpose robots and have encouraged other companies to follow suit.In an open letter, six leading robotics firms promised not to add weapons to their general use technology and said they would oppose others doing so.We need policy that prohibits bad actors from misusing it“We believe that adding weapons to robots that are remotely or autonomously operated, widely available to the public and capable of navigating to previously inaccessible locations where people live and work, raises new risks of harm and serious ethical issues,” read the open letter, first reported by Axios.“We also call on every organization, developer, researcher and user in the robotics community to make similar pledges not to build, authorize, support, or enable the attachment of weaponry to such robots.”The letter was signed by Boston Dynamics, Agility Robotics, ANYbotics, Clearpath Robotics, Open Robotics and Unitree Robotics.Co-signers also pledged to review applications to buy their robots to prevent possible weaponization and to investigate technological features that could be weaponized in future.“To be clear, we are not taking issue with existing technologies that nations and their government agencies use to defend themselves and uphold their laws,” the letter said.‘The benefits for humanity of these technologies strongly outweigh the risk of misuse.’ Photograph: Annegret Hilse/ReutersIn a statement to Axios, Boston Dynamics said it was concerned about attempts made to weaponize commercially available robots, adding that such developments could further erode public trust in technology.“For this technology to be broadly accepted throughout society, the public needs to know they can trust it,” the statement said. “And that means we need policy that prohibits bad actors from misusing it.”Emergency departments have used Boston Dynamics’s “Spot robot” – a dog-like machine – to survey situations, NPR reported. The company has said the robot was not designed for surveillance or as a replacement for human police officers.In their open letter, the six robotics companies said they were “convinced that the benefits for humanity of these technologies strongly outweigh the risk of misuse, and we are excited about a bright future in which humans and robots work side by side to tackle some of the world’s challenges”.",0.0,0.0
251,https://thehill.com/policy/energy-environment/3685583-nasa-suggests-new-space-cooling-technology-could-charge-electric-cars-in-5-minutes/,NASA suggests new space cooling technology could charge electric cars in 5 minutes,"NASA has suggested an experimental cooling system it is funding could ultimately allow electric vehicle users to charge their cars within five minutes.The agency said a team led by a Purdue University professor has developed the “subcooled flow boiling” technology for experimentation, with the hope it can control future systems’ temperatures in space.“A team sponsored by NASA’s Biological and Physical Sciences Division is developing a new technology that will not only achieve orders-of-magnitude improvement in heat transfer to enable these systems to maintain proper temperatures in space, but will also enable significant reductions in size and weight of the hardware,” NASA“What’s more, this same technology may make owning an electric-powered car here on Earth easier and more feasible,” the post continued.NASA indicated achieving such a feat of charging electric vehicles within five minutes would require chargers to provide current at 1,400 amperes, far higher than currently available technology.Most chargers currently available support currents less than 150 amperes, while some of the most advanced chargers on the market deliver currents up to 520 amperes, the post noted.But NASA said Purdue University’s developmental cable can provide currents of up to 2,400 amperes by removing heat through the new technology, which would deliver charging at 4.6 times the rate of the fastest charger currently available.“Application of this new technology resulted in unprecedented reduction of the time required to charge a vehicle and may remove one of the key barriers to worldwide adoption of electric vehicles,” NASA wrote.President Biden has emphasized a shift to electric vehicles as a significant component of his climate initiatives, but the proposals have been met with criticism among some in the GOP, who haveQuestions have also been raised about whether the U.S. electrical grid could even handle a hard shift toward electric vehicles.The Inflation Reduction Act, a party-line reconciliation package passed over the summer, includes billions in funding for electric vehicle tax credits and other financial incentives.It also includes a $7.5 billion investment to build a network of charging stations across the U.S.“The great American road trip is going to be fully electrified,” Biden",0.0,0.0
215,https://arstechnica.com/cars/2022/09/mercedes-f1-team-cut-its-freight-emissions-by-89-with-biofuel-switch/,Mercedesâ F1 team cut its freight emissions by 89% with biofuel switch,"A switch from diesel to biofuel significantly reduced the Mercedes-AMG Formula 1 team's freight carbon emissions in a new test. The team made the switch for the final three European races of this season, using locally sourced hydrotreated vegetable oil (HVO)—made from food waste like fryer oil—to run 16 heavy trucks as they hauled the team between grand prix in Belgium, the Netherlands, and Italy.Over a distance of 870 miles (1,400 km), it says the use of HVO resulted in less carbon emissions—44,091 kg less to be specific, which is a decrease of 89 percent compared to normal fossil fuel diesel.The race cars are a rounding errorA push for greater fuel efficiency in Formula 1 has resulted in some fairly remarkable engineering. A current F1 powertrain is as complex as the sport has ever seen, combining comparatively tiny but extraordinarily efficient V6 gasoline engines with hybrid systems that recover energy under braking and from the turbocharger spinning.This is something that everyone involved is rightly proud of, but in terms of reducing the sport's carbon emissions, the fuel burned by the race cars is frankly irrelevant. F1 measures fuel by weight, and each car is allowed 220.5 lbs (100 kg) for the race. Being extremely generous, we can triple that to account for three hours of practice sessions plus qualifying, but that's still only 661 lbs (300 kg) per car, of which there are 20, and this year they'll race 23 times in total.AdvertisementBut each team flies about 80 people to each race. And they need a whole lot of equipment; obviously the race cars and all the tools to run them, but also massive mobile offices and hospitality suites for the European events, when everything travels by road freight. (For the rest of the calendar, all the teams' cars and equipment travel together, and the gin palaces stay behind.) As transport and freight therefore accounts for much more of the carbon emitted by the sport, it's clearly a good idea to try to reduce that.Mercedes first tried HVO in one of its trucks as it drove back from the Hungarian Grand Prix to the team's base in Brackley, UK. The real test began following this year's Belgian Grand Prix, when 16 trucks used the fuel to drive 186 miles (300 km) to the Dutch Grand Prix in Zandvoort, the Netherlands, then another 684 miles (1,100 km) to the Italian Grand Prix in Monza, Italy. The entire journey was fueled by locally sourced HVO, apart from the last 12 miles (20 km) ""due to supply challenges,"" the team says.Analyzing the data, it says that HVO saved 97,204 lbs (44,091 kg) of carbon dioxide emissions compared to diesel, an 89 percent reduction.""Sustainability is at the heart of our operations. Trialing the use of biofuels for our land freight is another example of our commitment to embed sustainability in every decision we make and action we take. We aim to be on the cutting edge of change and hope we can make the adoption of sustainable technology possible as we are all in the race towards a sustainable tomorrow,"" said team principal and CEO Toto Wolff.",0.0,0.0
98,https://eandt.theiet.org/content/articles/2022/10/climate-change-closing-daily-temperature-gap-clouds-may-be-to-blame/,Climate change closing daily temperature gap; clouds may be to blame,"Climate change is shrinking the difference between the daily high temperature and the daily low in many parts of the world. The gap between the two, known as the diurnal temperature range (DTR), has a significant effect on growing seasons, crop yields, residential energy consumption and human health issues related to heat stress. Why and where the DTR shrinks with climate change has proved something of a mystery.Climate change is shrinking the difference between the daily high temperature and the daily low in many parts of the world. The gap between the two, known as the diurnal temperature range (DTR), has a significant effect on growing seasons, crop yields, residential energy consumption and human health issues related to heat stress. Why and where the DTR shrinks with climate change has proved something of a mystery.Researchers who are part of a new international study that examined the DTR at the end of the 21st century believe they have found the answer: an increase in clouds, which blocks incoming shortwave radiation from the Sun during the day.Researchers who are part of a new international study that examined the DTR at the end of the 21st century believe they have found the answer: an increase in clouds, which blocks incoming shortwave radiation from the Sun during the day.This means that while both the daily maximum temperature and the daily minimum are expected to continue to increase with climate change, the daily maximum temperature will increase at a slower rate. The end result is that the DTR will continue to shrink in many parts of the world, but that the changes will vary depending on a variety of local conditions, researchers said.This means that while both the daily maximum temperature and the daily minimum are expected to continue to increase with climate change, the daily maximum temperature will increase at a slower rate. The end result is that the DTR will continue to shrink in many parts of the world, but that the changes will vary depending on a variety of local conditions, researchers said.The study, published in the journalThe study, published in the journal“Clouds are one of the big uncertainties in terms of climate projections,” said co-author Dev Niyogi, a professor at The University of Texas at Austin Jackson School of Geosciences. “When we do this with a very high spatial resolution modelling framework, it allows us to explicitly simulate clouds.”“Clouds are one of the big uncertainties in terms of climate projections,” said co-author Dev Niyogi, a professor at The University of Texas at Austin Jackson School of Geosciences. “When we do this with a very high spatial resolution modelling framework, it allows us to explicitly simulate clouds.”Lead author Doan Quang Van, an assistant professor at the University of Tsukuba Center for Computational Sciences in Japan, said this is vital for understanding the future of the DTR: “Clouds play a vital role in the diurnal temperature variation by modulating solar radiative processes, which consequently affect the heat exchange at the land surface.”Lead author Doan Quang Van, an assistant professor at the University of Tsukuba Center for Computational Sciences in Japan, said this is vital for understanding the future of the DTR: “Clouds play a vital role in the diurnal temperature variation by modulating solar radiative processes, which consequently affect the heat exchange at the land surface.”Using supercomputers at the University of Tsukuba's Centre for Computational Sciences, the team was able to model the complicated interplay of land-surface processes on climate change. These include changes in land use (such as deforestation), soil moisture, precipitation, cloud cover and other factors that can affect the temperature in a local region. By creating a model with a finer resolution grid – 2km/sq grids rather than the 100km grids used in most climate models – the researchers were able to more closely analyse the impacts of climate change.Using supercomputers at the University of Tsukuba's Centre for Computational Sciences, the team was able to model the complicated interplay of land-surface processes on climate change. These include changes in land use (such as deforestation), soil moisture, precipitation, cloud cover and other factors that can affect the temperature in a local region. By creating a model with a finer resolution grid – 2km/sq grids rather than the 100km grids used in most climate models – the researchers were able to more closely analyse the impacts of climate change.The team focused on two areas: the Kanto region of Japan and the Malaysian peninsula. Using the 10-year period from 2005-2014 as a baseline, the researchers then ran different climate scenarios to project what will happen to the DTR in the two regions at the end of the century.The team focused on two areas: the Kanto region of Japan and the Malaysian peninsula. Using the 10-year period from 2005-2014 as a baseline, the researchers then ran different climate scenarios to project what will happen to the DTR in the two regions at the end of the century.They found that the temperature gap closes by about 0.5°C in the temperate Kanto region and 0.25°C in the more tropical Malaysian peninsula. Researchers attribute these changes in large part to increased daytime cloud coverage that would be expected to develop under these climate conditions.They found that the temperature gap closes by about 0.5°C in the temperate Kanto region and 0.25°C in the more tropical Malaysian peninsula. Researchers attribute these changes in large part to increased daytime cloud coverage that would be expected to develop under these climate conditions.The researchers said the study can help scientists improve current global climate models and aid in understanding how the shrinking DTR will affect society and the environment as the climate continues to warm.The researchers said the study can help scientists improve current global climate models and aid in understanding how the shrinking DTR will affect society and the environment as the climate continues to warm.“It is very important to know how DTR will change in the future because it modulates human, animal and plant metabolisms,” said Quang Van. “It also modulates the local atmospheric circulation such as the land-sea breeze.”“It is very important to know how DTR will change in the future because it modulates human, animal and plant metabolisms,” said Quang Van. “It also modulates the local atmospheric circulation such as the land-sea breeze.”The research paper – 'The research paper – 'The research was funded by Japan Society for the Promotion of Science Grants-in-Aid for Scientific Research, Nasa Interdisciplinary Research in Earth Science, and the US Department of Agriculture National Institute for Food and Agriculture.The research was funded by Japan Society for the Promotion of Science Grants-in-Aid for Scientific Research, Nasa Interdisciplinary Research in Earth Science, and the US Department of Agriculture National Institute for Food and Agriculture.The team included scientists from the UT Jackson School’s Department of Geological Sciences, the National Centre for Atmospheric Research in Boulder, Colorado, Shanghai University of Engineering Science, National Defence Academy of Japan, and the University of Tsukuba, Japan.The team included scientists from the UT Jackson School’s Department of Geological Sciences, the National Centre for Atmospheric Research in Boulder, Colorado, Shanghai University of Engineering Science, National Defence Academy of Japan, and the University of Tsukuba, Japan.",0.0,0.0
181,https://news.ku.dk/all_news/2022/10/republican-party-lost-core-supporters-after-the-attack-on-capitol/,Republican Party lost core supporters after the attack on Capitol,"Five people were killed and many more serious injured when Trump supporters attacked the congressional building on Capitol Hill on January 6, 2021. In the immediate aftermath, the Republican Party lost core supporters in great numbers. This is documented by three researchers from the Department of Political Science in a new study.A violent attack on democratic institutions limits party loyalty, even among core supporters. There is therefore a measurable cost to encouraging or even exercising political violence. Frederik Hjorth, associate professor""The attack on Congress caused a large drop in people who outwardly identified with the Republican Party and Donald Trump – without re-identification in the following weeks,"" says associate professor Frederik Hjorth, who is one of the authors behind the study. The others are Gregory Eady, assistant professor, and Peter Thisted Dinesen, professor.The researchers' findings indicate that there are limits to party loyalty:""A violent attack on democratic institutions limits party loyalty, even among core supporters. There is therefore a measurable cost to encouraging or even exercising political violence,"" Frederik Hjorth assesses.Few supporters returnThe study is based on panel data from a large group of American Twitter users. These data show that a significant number of Republicans removed their statements of sympathy for the party and Donald Trump after the attack on Capitol Hill.The results contribute on several levels to the understanding of how violent political protests influence political identities and behaviour.""We see, among other things, that the reactions to the riots in 2021 were not just local but national, and that they continued after the attack on the US Congress. In the two months that followed, only a small number of disaffected Republicans re-identified publicly with the party,” explains Gregory Eady.Good news for democracyThe study of the Republicans' reaction to the attack on Congress is encouraging news for democracy, believes Peter Thisted Dinesen.""Political violence is used in many places in the world – but it can have costs in the form of demobilization of party loyalists,"" observes Peter Thisted Dinesen.However, he emphasizes that there may be other considerations which will continue to cause people to use political violence.""Radicalized party members, like those who attacked the Congress, may choose to resort to violence based on their own interests – regardless of how it may harm the party. Our study does not uncover all aspects of political violence - but it contributes to increasing the overall understanding of what attracts or repels people from parties,"" concludes Peter Thisted Dinesen.Read more about the study in this research article published in the American Political Science Review.",0.0,0.0
252,https://www.cbsnews.com/news/plastic-recycling-failed-concept-us-greenpeace-study-5-percent-recycled-production-up/,"Plastic recycling a ""failed concept,"" study says, with only 5% recycled in U.S. last year as production rises","Why recycling plastic isn't as effective as you think, according to industry criticsRecycling plastic isn't as effective as you thinkRecycling plastic isn't as effective as you thinkWashington — Plastic recycling rates are declining even as production shoots up, according to a Greenpeace USA report out Monday that blasted industry claims of creating an efficient, circular economy as ""fiction.""Titled ""Circular Claims Fall Flat Again,"" the study found that of 51 million tons of plastic waste generated by U.S. households in 2021, only 2.4 million tons were recycled, or around five percent. After peaking in 2014 at 10 percent, the trend has been decreasing, especially since China stopped accepting the West's plastic waste in 2018.Virgin production — of non-recycled plastic, that is — meanwhile is rapidly rising as the petrochemical industry expands, lowering costs.""Industry groups and big corporations have been pushing for recycling as a solution,"" Greenpeace USA campaigner Lisa Ramsden told AFP.""By doing that, they have shirked all responsibility"" for ensuring that recycling actually works, she added. She named Coca-Cola, PepsiCo, Unilever and Nestle as prime offenders.According to Greenpeace USA's survey, only two types of plastic are widely accepted at the nation's 375 material recovery facilities.The first is polyethylene terephthalate (PET), which is commonly used in water and soda bottles; and the second is high density polyethylene (HDPE), seen in milk jugs, shampoo bottles and cleaning product containers. These are numbered ""1"" and ""2"" according to a standardized system in which there are seven plastic types.But being recyclable in theory doesn't mean products are being recycled in practice.The report found that PET and HDPE products had actual reprocessing rates of 20.9 percent and 10.3 percent, respectively — both down slightly from Greenpeace USA's last survey in 2020.Plastic types ""3"" through ""7"" — including children's toys, plastic bags, produce wrappings, yogurt and margarine tubs, coffee cups and to-go food containers — were reprocessed at rates of less than five percent.Despite often carrying the recycling symbol on their labels, products that use plastic types ""3"" through ""7"" fail to meet the Federal Trade Commission classification of recyclable.This is because recycling facilities for these types aren't available to a ""substantial majority"" of the population, defined as 60 percent, and because the collected products are not being used in the manufacturing or assembly of new items.According to the report, there were five main reasons why plastic recycling is a ""failed concept.""First, plastic waste is generated in vast quantities and is extremely difficult to collect — as becomes clear during what the report called ineffective ""volunteer cleanup stunts"" funded by nonprofits such as ""Keep America Beautiful.""Second, even if it were all collected, mixed plastic waste cannot be recycled together, and it would be ""functionally impossible to sort the trillions of pieces of consumer plastic waste produced each year,"" the report said.Third, the recycling process itself is environmentally harmful, exposing workers to toxic chemicals and itself generating microplastics.Fourth, recycled plastic carries toxicity risks through contamination with other plastic types in collection bins, preventing it from becoming food-grade material again.Fifth and finally, the process of recycling is prohibitively expensive.""New plastic directly competes with recycled plastic, and it's far cheaper to produce and of higher quality,"" said the report.Ramsden called on corporations to support a Global Plastics Treaty, which United Nations members agreed to create in February, and move toward refill and reuse strategies.""This isn't actually a new concept — it's how the milkman used to be, it's how Coca-Cola used to get its beverages to people. They would drink their beverage, give the glass bottle back, and it would be sanitized and reused,"" she said.Some countries are leading the way, including India, which recently banned 19 single-use plastic items. Austria has set reuse targets of 25 percent by 2025 and at least 30 percent by 2030 for beverage packaging, while Portugal has also set the 30 percent by 2030 goal. Chile is moving to phase out single-use cutlery and mandating refillable bottles.",0.0,0.0
140,https://www.scimex.org/newsfeed/avoiding-extinction-some-asian-animals-found-thriving-near-humans,Avoiding extinction: Some Asian animals found thriving near humans,"Media releaseThe University of QueenslandSome of Asia’s largest animals, including tigers and elephants, are defying 12,000 years of extinction trends by thriving alongside humans, a University of Queensland-led study has revealed.Researchers scoured paleontological records to compare the historic distribution of Asia’s 14 largest species with their populations in present-day tropical forests.PhD candidate Zachary Amir, from UQ’s School of Biological Sciences and the Ecological Cascades Lab, said four species – tigers, Asian elephants, wild boars and clouded leopards – showed increased populations in areas with human infrastructure.“These results show that, under the right conditions, some large animals can live nearby humans and avoid extinction,” Mr Amir said.“These results challenge the narrative within some conservation circles that humans and megafauna are incompatible.“Globally there is a trend towards ‘trophic downgrading’, a term referring to the disproportionate loss of the world’s largest animals.“Trophic downgrading is usually worst near humans because hunters target larger species.“But in the case of tigers, elephants, wild boars and clouded leopards, their Asian populations are higher nearby humans.“This may be the outcome of tougher anti-poaching efforts in the national parks that are closer to human settlements and are more frequently visited by tourists.”The study also found deforestation was still impacting species, and clouded leopard numbers in particular experienced a strong decline in those areas.But, Mr Amir said the research showed that if the large animal species were not hunted, they could live in relatively small habitats and near humans.“Previously, there have only been a few examples of large Asian species thriving in small habitats near humans, notably in Mumbai, India where leopards in an urban park prey on stray dogs,” Mr Amir said referring to a prior UQ study.“Thankfully, we found that a wider range of animals can coexist with humans.”At one of their study sites in Singapore, where poaching has been eliminated and there are considerable forest restoration efforts, two large animal species are thriving again.“Singapore has actually experienced the natural re-wilding of sambar deer and wild boars, which are now frequently observed in an urban forest, the Bukit Timah Nature Reserve,” Mr Amir said.“If we replicate those protection efforts in larger forests and other counties, we may see positive impacts right around the world.“But before this can happen, humans need to get our act together and limit poaching.”While there are some positive results, UQ’s Dr Matthew Luskin said the study also noted strong declines in tapirs, Sumatran rhinoceros, sun bears, guar and other large animals.“The key innovation of this work was to systematically investigate the population trends of many different wildlife species across the region,” Dr Luskin said.“Then we tested if all species showed consistent trends and if similar parks retained similar species.“Remarkably, we found no two forests currently possess the same group of wildlife compared to thousands of years ago.”Dr Luskin said the research offered an opportunity to shape the future of nature.“These results provide hope for wildlife in forests previously considered too far degraded or too close to cities,” he said.“Now we’re exploring new conservation strategies for these surprising places.”",0.0,0.0
250,https://www.zdnet.com/article/this-nasa-space-tech-could-make-your-ev-charge-faster-too/,"This NASA space tech could make your EV charge faster, too","Image: Getty Images/Jung GettyFully charging an electric vehicle (EV) battery can take 10 hours at home, but now NASA has given details of a cooling system that could cut the time taken to get a full charge to just five minutes.NASA's technology could be a game-changer for the EV industry, eliminating one of its main obstacles to adoption – that five-minute charge would put charging EVs on a par with the time it takes to fill the tank of a petrol-powered car.The answer to five-minute charging could be found in the ""Flow Boiling and Condensation Experiment (FBCE)"", a project NASA's Biological and Physical Sciences Division is sponsoring Purdue University to develop and focuses on coolants in the charging cable between the EV's inlet and the battery.Also: The 5 best electric cars: Plus, the cheapest EV availablePurdue researchers demonstrated a technique called ""sub-cooled flow boiling"" that improves the effectiveness of heat transfer, which could help EVs on Earth but is primarily intended for the International Space Station.Unfortunately, owners of Tesla and other EVs shouldn't count on having a five-minute full charge any time soon because it requires capacities, measured in amperes or amps, far exceeding what's available today. However, when that is available, NASA's technology could provide temperature controls that those charging systems would require.As NASA explains, a five-minute charge requires a charging system that provides a current at 1,400 amps. But, as Purdue points out, Tesla's V3 Supercharger – which is the apex of today's EV chargers – doesn't exceed 600 amps. Purdue's prototype last year demonstrated 2,400 amps.Hence the eventual need for a cooling system beyond today's capabilities that can handle 1,400 amps. Using NASA's FBCE, Purdue researchers, led by Dr. Issam Mudawar, pumped non-electrically conducting liquid coolant through a charging cable to capture heat from the current-carrying conductor.""Subcooled flow boiling allows Mudawar's team to deliver 4.6 times the current of the fastest available electric vehicle chargers on the market today by removing up to 24.22 kilowatts of heat,"" NASA explains.""Application of this new technology resulted in unprecedented reduction of the time required to charge a vehicle and may remove one of the key barriers to worldwide adoption of electric vehicles,"" it said.Faster charging times ought to drive higher adoption of EVs, which are part of the world's answer to achieving net-zero carbon emissions. A recent report from the International Energy Agency said sales of EVs reached 6.6 million in 2021, up from 120,000 in 2012, and accounted for 9% of all vehicle sales.Chinese consumers bought 3.3 million new EVs, many of which were two- and three-wheelers, while Europeans bought 2.3 million EVs, and US consumers bought 630,000. Still, in the US, EV sales doubled their share in 2021 year-on-year to 4.5%. China was also rolling out charging faster than most regions.Source: Purdue University",0.0,0.0
500,https://techcrunch.com/2016/06/23/japans-e-commerce-leader-rakuten-gets-into-agriculture-tech/,Japanâs e-commerce leader Rakuten gets into agriculture tech,"Rakuten may be cutting back its e-commerce business in Europe and Southeast Asia, but, at home in Japan, the internet giant is stepping into a new field — quite literally — after it invested in an agriculture tech company for the first.Weeks after withdrawing e-commerce sites from the UK, Spain and Austria, Rakuten is putting an undisclosed sum into seven-year-old Telefarm, which operates a platform that promotes organic farmers in Japan. Most notably, Telefarm connects consumers with organic farmers and their produce, while it also helps with processes such as storage, transportation, manufacturing, and even the hiring of farm workers.It’s an interesting move for Rakuten, which is best known for its online shopping empire in Japan, where it has also expanding into financial, a mobile service and more. Rakuten’s presence outside of Japan has been less successful. While it has invested in a range of U.S. companies including Lyft and Pinterest, and it has acquired firms like chat app Viber, video platform Viki, and U.S. coupon site Ebates, the company has withdrawn from less lucrative regions as part of a new strategy.Organic farming, or organic products, could be a part of that new focus in Japan. Rakuten said that this invest in Telefarm would lead to it launching new products in its domestic market.With the working population in the agricultural industry steadily declining, coupled with Japan’s aging population, labor shortages in the industry are becoming a serious problem, and the amount of deserted arable land is increasing every year. Farmers are facing serious challenges, with initial investment and unstable revenues posing obstacles for new farmers, and the securement of stable sales channels and a shortage of successors presenting challenges for established, small-scale farmers. Going forward, Rakuten will explore the development of new services in the agriculture field through the internet, while aiming to contribute to regional revitalization through the utilization of deserted arable land and support for new farmers.Beyond scaling back parts of its global business, Rakuten recently embraced drones — running its first trial on a golf course — and earlier this month it struck an agreement to bring a selection of premium Japanese goods to China via Kaola, the cross-border e-commerce service operated by Chinese internet giant NetEase.",0.0,0.0
56,https://techcrunch.com/2022/08/14/twitter-crypto-privacy-sanctions-tornado-chain-reaction/,Why Twitter anons are sending crypto to celebrities,"Welcome back to Chain Reaction.Last week, we talked about a hack that gave new, ironic meaning to the word “trustless.” This week, we’ll get into one of the most polarizing aspects of crypto — privacy.If someone forwarded you this message, you can subscribe on TechCrunch’s newsletter page.all mixed upA weekly window into the thoughts of senior crypto reporter Anita Ramaswamy:Tornado Cash has been the talk of the town this week in crypto circles. The U.S. government’s Office of Foreign Asset Control (OFAC), a watchdog within the Treasury, leveled sanctions against the cryptocurrency mixer for its role in helping facilitate money laundering. North Korean-backed hackers, among others, have used the Tornado Cash platform to mask stolen crypto associated with some of the highest-profile hacks in web3 to date, including last week’s Nomad heist and the hack of play-to-earn video game Axie Infinity earlier this year.But in imposing sanctions, OFAC was essentially using a sledgehammer to crack a nut. The agency’s official notice on the topic said that the platform had facilitated $7 billion worth of money laundering — which happens to be the total value of crypto assets that have been sent through Tornado Cash since it was created in 2019. Meanwhile, blockchain analytics provider Elliptic says only ~$1.5 billion of funds on Tornado are actually linked to crime, including ransomware attacks and fraud. The rest, Elliptic argues, could include “legitimate uses of mixers such as Tornado, such as to preserve financial privacy.”So what are some of those legitimate uses? One example came from Ethereum co-founder Vitalik Buterin, who confessed on Twitter that he has used the service to send donations to aid Ukraine securely without the knowledge of the Russian government.I'll out myself as someone who has used TC to donate to this exact cause. — vitalik.eth (@VitalikButerin) August 9, 2022The OFAC’s dictum does not differentiate between criminal and legitimate use cases, though. As a result, many law-abiding crypto users are likely suffering. Two major crypto infrastructure providers, Alchemy and Infura, blocked access to their API from any wallets that used Tornado Cash. Circle has reportedly frozen ~$75,000 worth of its USDC stablecoins that were connected to Tornado through a shared wallet, according to Dune Analytics data.Of course, internet pranksters got in on the fun, as is usually the case in the crypto world. Some have been sending crypto through Tornado Cash to known wallets held by celebrities such as Jimmy Fallon and Shaquille O’Neal in an attempt to troll them by getting their wallets banned under the sanction rules.OFAC’s heavy-handed action comes across as a bungled approach that raises more questions than it resolves when it comes to enforcement. Only time will tell how the latter plays out, but in the meantime, the crypto community is, understandably, pretty upset.the latest podThis week on Chain Reaction, Jacquelyn and Anita ran the show while Lucas was on vacation. Jacquelyn was coming off of an exciting Friday night call with Vitalik himself, so she shared some of his comments on where crypto is headed.We then dove into the news of Tornado Cash getting sanctioned in the U.S., Coinbase’s disappointing second-quarter earnings and the beef between Binance and India’s largest crypto exchange, WazirX, over a transaction that supposedly took place two and a half years ago (or did it)?Be sure to give it a listen to get up to speed on the latest tea in crypto and tune in next Tuesday for Anita and Lucas’s conversation with Li Jin, a web3 investor focused on the creator economy at Variant Fund.Subscribe to Chain Reaction on Apple, Spotify or your alternative podcast platform of choice to keep up with us every week.follow the moneyWhere startup money is moving in the crypto world:Jump Crypto led Injective‘s $40 million round to help expand DeFi applications. Pinata raised $21.5 million in a newly announced Series A and seed round from investors, including Greylock and Pantera. CreatorDAO, a decentralized platform for content creators, raised $20 million in an a16z and Initialized Capital-led round with participation from celebrities including Paris Hilton and Liam Payne. Blockchain gaming company Lysto raised $12 million in a round led by Hashed, Square Peg and Beenext. Unstoppable Finance snagged $12.8 million in a round led by Lightspeed for its DeFi wallet. Kurtosis, a crypto-focused developer tool system, brought in $20 million in a Series A round led by Coatue. Blockchain payments platform Ansible Labs raised a $7 million seed round led by Archetype. Zero-knowledge cryptography startup RISC Zero scooped up $12 million in a seed round led by Bain Capital Crypto. Fair.xyz landed $4.5 million from investors including OpenSea for its NFT minting platform. Cashmere raised $3 million at a $30 million valuation from investors including Coinbase Ventures to build a Solana enterprise wallet.TC+ analysisHere’s some of this week’s crypto analysis available on our subscription service TC+ from senior reporter Jacquelyn Melinek:5 takeaways from Coinbase’s disappointing Q2 resultsCoinbase, once hugely profitable in the wake of its 2021 direct listing thanks to a run in crypto-related trading activities, is now working to limit costs and brave the ongoing “winter” in its market and stick to prior profitability targets for the full year. What follows are five takeaways from Coinbase’s report that stood out to TC’s Alex Wilhelm and Ram Iyer.As Telegram grows in size, so does crypto traders’ dependence on the appThe crypto community has relied on social media sites like Twitter or messaging apps like Discord and Telegram to interact. But some say Telegram is the ultimate hub for communication and information — an imperative place to be in the crypto community. “Telegram usage is the bedrock of the crypto community,” the founder of Telegram channel unfolded, who goes by the username nakamotocat, said to TechCrunch. “Projects have come and gone, players have risen and fallen, but much of the discourse between various projects and market participants resides on Telegram, and that remains a constant.”Ethereum co-founder sees role diminishing as blockchain becomes increasingly decentralizedAs the layer-1 blockchain Ethereum continues to focus on a road map toward greater decentralization, its co-founder, Vitalik Buterin, thinks that moment might come sooner than expected. Also looking to the future, Buterin thinks the next decade will be pivotal for crypto. “I think in general, the next 10 years, crypto has to transform into something that is not based on promises of being useful in the future but is actually useful.”Solana co-founder says NFTs have ‘50 different use cases’ that can onboard millions this yearIt feels like yesterday that the NFT boom captured the attention of the crypto community, making waves even outside the web3 world. But a year or so down the line, the NFT hype has somewhat died down. But that isn’t stopping some in the crypto world from staying optimistic about non-fungible tokens. “I think within NFTs, everything is just really scratching the surface,” Raj Gokal, co-founder of Solana, told TechCrunch. “I think NFTs have 50 different use cases that seem to be lumped into one. I think we expect the majority of the [crypto] projects to make use of NFTs.”Thanks for reading! And — again — to get this in your inbox every Thursday, you can subscribe on TechCrunch’s newsletter page.",0.0,0.0
231,https://apnews.com/article/technology-germany-europe-berlin-climate-and-environment-75afb2820d22c3d53b136b2ab2841767,Germany to massively expand electric car charging network,"FILE -- An electric car is charged at a charging station during a press tour of the plant of the German manufacturer Volkswagen AG (VW) in Zwickau, Germany, Tuesday, May 14, 2019. Germany’s government wants to massively expand the country’s charging network for electric cars with 6.3 billion euros ($6.17 billion) over the next three years as it expects more and more drivers to turn from combustion cars to more climate-friendly electromobility. (AP Photo/Jens Meyer, file)FILE -- An electric car is charged at a charging station during a press tour of the plant of the German manufacturer Volkswagen AG (VW) in Zwickau, Germany, Tuesday, May 14, 2019. Germany’s government wants to massively expand the country’s charging network for electric cars with 6.3 billion euros ($6.17 billion) over the next three years as it expects more and more drivers to turn from combustion cars to more climate-friendly electromobility. (AP Photo/Jens Meyer, file)BERLIN (AP) — Germany wants to massively expand the country’s charging network for electric cars, spending 6.3 billion euros ($6.17 billion) over the next three years as it expects more and more drivers to turn away from combustion cars to more climate-friendly vehicles.The country’s transportation minister on Wednesday presented a “master plan” for improving the charging infrastructure that had been passed by Chancellor Olaf Scholz’ cabinet earlier in the day.“We are not just any automotive location, but a leading one in the world. And that’s why it’s important to us that what we’re preparing succeeds well,” Volker Wissing told reporters in Berlin. “We need a forward-looking expansion of the nationwide charging infrastructure that meets demand and is user-friendly.”The share of electric vehicles in Germany grew 24.8% year-on-year to a total share of 14.6% of all newly registered automobiles, according to figures released by the country’s Federal Office for Motor Vehicles.ADVERTISEMENTThere are around 70,000 charging points in the country but only 11,000 of those are fast-chargers, the ministry said.That is not enough to sufficiently fulfill the current needs, and it will be even less so as the number of electric cars grows quickly. There is also a big difference in availability of charging points between big cities and rural areas, where it is even harder to find charging stations.The German government’s goal is to have 1 million publicly accessible charging points in the country by 2030.In order to boost the number of charging points, the federal government will, among other initiatives provide real estate, especially along highways, where new charging stations can be built. Private owners of electric cars will be offered subsidized plans to install solar energy panels at their homes to charge their cars overnight.Electric charging is also supposed to get more user-friendly with new digital offers showing drivers where they can charge their cars on the road or being able to check online how much the different charging points demand, the minister said.Another issue the government wants to tackle is getting the country’s electric grid ready for the increased demand as more people turn to electric cars.ADVERTISEMENT“We are expecting an exponential increase in registered vehicles with battery electric drive in the next few years and must prepare accordingly,” the minister said.Switching Germans from combustion-engine automobiles to electric cars plays a key role in achieving the government’s climate targets set for the transport sector.The transformation to electric cars has also been boosted by a mix of regulatory pressure, tax breaks, improving battery range, and a wider range of vehicles to purchase.Europe in general is leading the push into battery-powered cars as electric vehicles enter the mainstream and has promised to phase out internal combustion cars by 2035.But availability of charging points is a problem not just in Germany but almost everywhere across the continent.ADVERTISEMENT“Not only is there an insufficient number of electric charging points along the road networks in most European Union countries, but the vast majority of these do not charge quickly enough,” the European Automobile Manufacturers’ Association said.Or as the German minister said: “Electric mobility will only find acceptance if charging is as easy as refueling is today.”___Follow all AP stories on climate change issues at https://apnews.com/hub/climate-and-environment.",0.0,0.0
9,https://www.digitaltrends.com/computing/nvidia-says-falling-gpu-prices-are-over/,Nvidia says falling GPU prices are âa story of the pastâ,"Nvidia has just confirmed what many of us were already suspecting — GPUs are expensive, and Nvidia plans to keep it that way.During a Q&A session with the media, Nvidia CEO Jensen Huang lifted the veil of suspense on RTX 40-Series pricing, and the insights are not what we’ve been hoping to hear.Nvidia has only just announced the GeForce RTX 4090, RTX 4080 16GB, and RTX 4080 12GB, but not everyone was happy. It’s not the capabilities of these cards that were called into question, but their pricing. The RTX 4090 will arrive with a $1,599 price tag, followed by $1,199 for the RTX 4080 16GB and $899 for the RTX 4080 12GB. These prices are too steep, all things considered, but it now seems that this might be the new normal.“The idea that the chip is going to go down in price is a story of the past.”During the Q&A session, Jensen Huang was asked about GPU prices. His response was very telling.“Moore’s Law is dead. […] A 12-inch wafer is a lot more expensive today. The idea that the chip is going to go down in price is a story of the past,” said Nvidia CEO Jensen Huang in a response to PC World’s Gordon Ung.Moore’s Law is the idea that there’s a trend between PC performance and price, with roughly double the performance for half the price every two years. Huang cited the rising costs of components and slowing of additional power as driving forces behind high GPU prices.Instead of Moore’s Law, Huang focused on price points and generational improvement. “The performance of Nvidia’s $899 GPU or $1,599 GPU a year ago, two years ago, at the same price point, our performance with Ada Lovelace is monumentally better. Off the charts better.”The response seems to echo what many of us have already been suspecting. After the GPU shortage has subsided, Nvidia and its partners were left with an oversupply of graphics cards. Once terribly overpriced, these GPUs are now up for grabs at more reasonable prices, but they’re most likely not selling as quickly as the manufacturers might have hoped.“The 3080 was, and still is, great value, and it will continue to live on,” an Nvidia spokesperson said in another briefing, noting that it was far from dead.The introduction of the RTX 40-Series steals the thunder from RTX 30-Series, but Nvidia still wants to sell off these older (but still very good) cards. It makes sense to price the RTX 4090 and the two RTX 4080s so high because this might push more people to buy one of the RTX 30 GPUs instead. Be that as it may, it’s sad to hear a confirmation that the prices will continue following an upward trend.Editors' Recommendations",0.0,0.0
10,https://www.columbiapsychiatry.org/news/columbia-study-finds-mass-school-shootings-are-not-caused-mental-illness,Columbia Study Finds Mass School Shootings Not Caused by Mental Illness,"A research team at Columbia University Irving Medical Center and the New York State Psychiatric Institute (NYSPI) examining 82 mass murders that occurred at least partially in academic settings throughout the world found that most mass murderers and mass shooters did not have severe psychiatric illnesses.The study, led by Ragy R. Girgis, MD, found that 100% of the mass killings were initiated by males (mean age 28) of whom 66.7% were Caucasian. Sixty-three percent of the murders involved firearms. While severe mental illnesses, such as psychotic disorders, including schizophrenia, were not present in the perpetrators of these events, it is notable that almost half of these mass shooters took their own lives at the scene, leading the authors to hypothesize that these perpetrators viewed themselves as engaging in some form of “final act.”The research, published online Oct. 27 in the Journal of Forensic Sciences, according to study authors, is the largest analysis ever conducted on mass school shootings.“Our findings suggest that mass school shootings are different from other forms of mass murder and that they should be looked at as a distinct phenomenon,” said Dr. Girgis, director of the Center of Prevention and Evaluation (COPE), a research clinic at Columbia/NYSPI specializing in the study and treatment of young adults at high risk for schizophrenia and other psychoses. “To prevent future mass school shootings, we need to begin to focus on the cultural and social drivers of these types of events, such as the romanticization of guns and gun violence, rather than on individual predictors.”To conduct their study, the researchers analyzed data from the Columbia Mass Murder Database (CMMD), developed by the COPE team to gain much-needed insight into the relationship between serious mental illness and mass shootings. Creating the CMMD involved extensive review of 14,785 murders publicly described in English in print or online, occurring worldwide between 1900 and 2019.For the mass school shooting study, the researchers isolated cases of mass murder perpetrated at least in part at schools, colleges, and universities and categorized them by location (within or outside of the US), and whether firearms were used.Of the 82 incidents of mass murder involving academic settings:Nearly half (47.6%) were U.S.-based.Most involved firearms (63.2%), commonly semi- or fully-automatics.Consistent with previous reports, perpetrators of mass shootings involving academic settings are primarily Caucasian (66.7%) and male (100%).Severe mental illness (e.g., psychosis) was absent in the majority of perpetrators; when present, psychotic symptoms were more often associated with mass murders involving means other than firearms.About half (45.6%) of mass school shootings ended with the perpetrator's suicide.Coauthor Paul S. Appelbaum, MD, the Elizabeth K. Dollard Professor of Psychiatry, Medicine and Law at Columbia, said that identifying psychiatric illness as a primary cause of violence is misleading.“The findings strongly suggest that focusing on mental illness, particularly psychotic illness, when talking about mass school shootings risks is missing other factors that contribute to the vast majority of cases, as well as exacerbating the already widespread stigma surrounding severe mental illness,” said Dr. Appelbaum.The researchers hope that the findings will help lawmakers and law enforcement officials better understand the phenomenon of mass school shootings, as well as how mass school shootings differ from other forms of mass murder, and ways to identify youth who may be troubled though not necessarily schizophrenic or psychotic. The authors also emphasize that these data cannot be used to predict behavior on an individual level.",0.0,0.0
13,https://www.cnbc.com/2022/09/26/feds-commit-50-million-to-for-profit-nuclear-fusion-companies.html,"Feds commit $50 million to for-profit nuclear fusion companies, chasing the 'holy grail' of clean energy","A picture shows the winding facility for the construction of poloidal field coils which will be part of the magnetic system that will contribute to confine and model plasma during the launch of the assembly stage of nuclear fusion machine ""Tokamak"" of the International Thermonuclear Experimental Reactor (ITER) in Saint-Paul-les-Durance, southeastern France, on July 28, 2020. - Thirty-five nations are collaborating in the ITER energy project aimed at mastering energy production from hydrogen fusion, as in the heart of the sun, a potential new source of carbon-free and non-polluting energy.The United States government is putting a sizable amount of money behind private sector nuclear fusion companies for the first time in the latest sign of how momentum is building behind the ""holy grail"" of clean energy.At the Global Clean Energy Action Forum in Pittsburgh on Thursday, the Department of Energy officially announced $50 million will go toward private fusion companies in public-private partnerships.""This money signifies that the U.S. government is getting serious about building a fusion program that will have commercial significance on an accelerated timeframe,"" Andrew Holland, the CEO of the Fusion Industry Association, an industry trade group, told CNBC.""If the U.S. government puts its full weight behind accelerating fusion energy to the grid, it could bring a transformational new energy source to the U.S.,"" Holland told CNBC.Conventional nuclear reactors are based on nuclear fission, a process in which a neutron slams into a large atom and splits it, releasing energy. Nuclear fusion occurs when two heavier atoms slam together to form a heavier atom — the way stars are powered. It is often seen as the holy grail of clean energy, because it offers virtually unlimited energy, releases no greenhouse gasses and generates no long-lasting nuclear waste. But it's proven very difficult to duplicate the process safely in a way that can be scaled and commercialized.The U.S. government has put federal money into fusion research since the 1950s and today invests about $700 million per year. Holland told CNBC. But that money has mostly gone toward national labs and universities and toward the primary international research project in France, ITER.But the $50 million announced in Pittsburgh for private fusion companies ""is the first substantial investment by the U.S. government into private sector fusion-energy companies,"" Holland told CNBC.""This is not for pure science. This is a commercial development and deployment program,"" Holland told CNBC.The $50 million will help companies prepare detailed plans, but isn't sufficient funding to construct expensive fusion power plants. Nevertheless, it will help bolster and give U.S fusion companies credibility.""This is critical since fusion power is such an audacious but vital technology for the United States and our collective fight against climate change. We want a U.S. firm to be the first to reach net power,"" Matthew Moynihan, a nuclear fusion consultant, told CNBC.""Net power"" refers to a key threshold in the fusion industry whereby more power is generated than it takes to catalyze the reaction. ""This is also more than just a paycheck: Winning this funding will give firms the government's stamp of approval, something investors will want to see as they consider adding more money to the industry,"" Moynihan told CNBC.The private sector fusion industry has attracted almost $5 billion in venture capital and other funding, according to the Fusion Industry Association.Notable recent raises include $1.8 billion in funding from Commonwealth Fusion Systems, a spinoff from Massachusetts Institute of Technology research, from a slew of heavy-hitting investors including Bill Gates, John Doerr, Salesforce co-CEO Marc Benioff's Time Ventures, and Google . Another private fusion company, Helion, announced a $500 million raise led by Silicon Valley insider Sam Altman and which includes the potential for another $1.7 billion in funding depending on Helion meeting particular funding goals.While the program is currently funded at $50 million over the next 18 months, Congress has authorized spending as much as $415 million in future budgets. The public-private funding program was first authorized in the Energy Act of 2020.",0.0,0.0
143,https://www.sciencenews.org/article/james-webb-space-telescope-stars-earliest-born-sparkler-galaxy,The James Webb Space Telescope spied the earliest born stars yet seen,"Some of the earliest stars yet seen are now coming to light in one of the first images from the James Webb Space Telescope.Formed roughly 800 million years after the Big Bang, the stars live in dense groups called globular clusters and surround a distant galaxy dubbed the Sparkler, astronomers report in the Oct. 1 Astrophysical Journal Letters. Globular clusters often host some of the oldest stars in contemporary galaxies such as our own, but it’s hard to tell their exact age. The new finding could help researchers pinpoint when such clusters began to form.Compared to a galaxy, globular clusters are tiny, which makes them hard to see from across the universe. But this time, a gargantuan natural lens in space helped. The Sparkler is one of thousands of galaxies that lie far behind a massive, much closer galaxy cluster called SMACS 0723, which was the subject of the first publicly released science image from the James Webb Space Telescope, or JWST (SN: 7/11/22). The cluster distorts spacetime such that the light from the more distant galaxies behind it is magnified.For all those remote galaxies, that extra magnification brings out details that have never been seen before. One elongated galaxy surrounded by yellowish blobs got the attention of astronomer Lamiya Mowla and her colleagues.“When we first saw it, we noticed all those little dots around it that we called ‘the sparkles,’” says Mowla, of the University of Toronto. The team wondered if the sparkles could be globular clusters, close-knit families of stars that are thought to have been born together and stay close to each other throughout their lives (SN: 10/15/20).“The outstanding question that there still is, is how were the globular clusters themselves born?” Mowla says. Were they born at “cosmic noon,” 10 billion years ago, when star formation throughout the universe peaked? Or did they form 13 billion years ago at “cosmic dawn,” when stars were first able to form at all (SN: 3/4/22)?Light from the Sparkler takes about 9 billion years to reach Earth, so if the sparkles are globular clusters that shone that long ago, they might help astronomers answer that question.Zooming into one part of JWST’s image of the galaxy cluster SMACS 0723, astronomers zeroed in on the yellow dots around this one elongated background galaxy, which they called the Sparkler. Some of the dots may be globular clusters of same-age stars formed just a few hundred million years after the Big Bang. L. Mowla et al/The Astrophysical Journal Letters 2022Mowla and her colleagues used data from JWST to analyze the wavelengths of light coming from the sparkles. Some of them appear to be forming stars at the time when their light left the clusters. But some had formed all their stars long before.“When we see them, the stars are already about 4 billion years old,” says astrophysicist Kartheik Iyer, also of the University of Toronto.That means the oldest stars in the sparkles could have formed roughly 13 billion years ago. Since the universe is 13.8 billion years old, “there’s only a short amount of time after the Big Bang when these could have formed,” he says.In other words, these clusters were born at dawn, not at noon.Studying more globular clusters around ancient galaxies could help determine if such clusters are common or rare early on in the universe’s history. They could also help unravel galaxies’ formation histories, say Mowla and Iyer. Their team has proposed observations to be made in JWST’s first year that could do just that.Being able to pick out tiny structures like globular clusters from so far away was almost impossible before JWST, says astronomer Adélaïde Claeyssens of Stockholm University. She was not involved in the new work but led a similar study earlier this year of multiple galaxies magnified by the SMACS 0723 cluster.“It’s the first time we showed that, with James Webb, we will observe a lot of these type of galaxies with really tiny structures,” Claeyssens says. “James Webb will be a game changer for this field.”",0.0,0.0
263,https://www.axios.com/2022/10/06/boston-dynamics-pledges-weaponize-robots,Exclusive: Boston Dynamics pledges not to weaponize its robots,"Several robotics companies, including Boston Dynamics, are pledging not to support the weaponization of their products and are calling for others in the industry to do the same, according to a letter shared first with Axios.Why it matters: Robots, like drones before them, have a wide range of peaceful and even life-saving uses, but can be turned into war-fighting machines, too.Details: The open letter highlights the erosion of consumer trust in robots as among the reasons not to allow them to be used as weapons.""We believe that adding weapons to robots that are remotely or autonomously operated, widely available to the public, and capable of navigating to previously inaccessible locations where people live and work, raises new risks of harm and serious ethical issues,"" the companies said in the letter.The companies pledged not to add weapons technology themselves or to support others doing so. And ""when possible"" they said they will review customers' plans in hopes of avoiding those who would turn the robots into weapons, in addition to exploring technical features that could prevent such use.In addition to Boston Dynamics, five other firms signed on to the commitment: Agility Robotics, ANYbotics, Clearpath Robotics, Open Robotics and Unitree Robotics.What they're saying: Boston Dynamics CEO Robert Playter said, in an e-mailed statement: ""We are concerned about recent increases in makeshift efforts by individuals attempting to weaponize commercially available robots... For this technology to be broadly accepted throughout society, the public needs to know they can trust it. And that means we need policy that prohibits bad actors from misusing it.""Go deeper: Here's the full text of the letter:An Open Letter to the Robotics Industry and our Communities,General Purpose Robots Should Not Be WeaponizedWe are some of the world’s leading companies dedicated to introducing new generations of advanced mobile robotics to society. These new generations of robots are more accessible, easier to operate, more autonomous, affordable, and adaptable than previous generations, and capable of navigating into locations previously inaccessible to automated or remotely-controlled technologies. We believe that advanced mobile robots will provide great benefit to society as co-workers in industry and companions in our homes.As with any new technology offering new capabilities, the emergence of advanced mobile robots offers the possibility of misuse. Untrustworthy people could use them to invade civil rights or to threaten, harm, or intimidate others. One area of particular concern is weaponization. We believe that adding weapons to robots that are remotely or autonomously operated, widely available to the public, and capable of navigating to previously inaccessible locations where people live and work, raises new risks of harm and serious ethical issues. Weaponized applications of these newly-capable robots will also harm public trust in the technology in ways that damage the tremendous benefits they will bring to society. For these reasons, we do not support the weaponization of our advanced-mobility general-purpose robots. For those of us who have spoken on this issue in the past, and those engaging for the first time, we now feel renewed urgency in light of the increasing public concern in recent months caused by a small number of people who have visibly publicized their makeshift efforts to weaponize commercially available robots.We pledge that we will not weaponize our advanced-mobility general-purpose robots or the software we develop that enables advanced robotics and we will not support others to do so. When possible, we will carefully review our customers’ intended applications to avoid potential weaponization. We also pledge to explore the development of technological features that could mitigate or reduce these risks. To be clear, we are not taking issue with existing technologies that nations and their government agencies use to defend themselves and uphold their laws.We understand that our commitment alone is not enough to fully address these risks, and therefore we call on policymakers to work with us to promote safe use of these robots and to prohibit their misuse. We also call on every organization, developer, researcher, and user in the robotics community to make similar pledges not to build, authorize, support, or enable the attachment of weaponry to such robots. We are convinced that the benefits for humanity of these technologies strongly outweigh the risk of misuse, and we are excited about a bright future in which humans and robots work side by side to tackle some of the world’s challenges.Signed,Boston DynamicsAgility RoboticsANYboticsClearpath RoboticsOpen RoboticsUnitree Robotics",0.0,0.0
363,https://techcrunch.com/2022/01/06/scanbo-non-invasive-blood-glucose/,How sweet is your blood? Scanbo gives an answer without poking holes in you,"If you have diabetes, or ever suspected that you might, you will have done the poke-your-finger-and-drop-blood-on-a-stick thing until your finger goes numb. Finger-prick blood glucose monitoring is the de facto standard, but AI company Scanbo wants to put an end to all that, replacing the droplet with some off-the-shelf diagnostic tools and a big helping of data analysis.The company has developed a prototype device that combines a three-lead ECG measurement and a Photoplethysmogram (PPG). The 60-second measurement is fed to a set of algorithms that can give you some very promising measurements. For starters, the device is doing non-invasive blood glucose monitoring, but the company’s founder claims that it can also do blood pressure measurements.I spoke to the company’s founder and CEO, Ashissh Raichura, as part of TechCrunch’s virtual CES coverage, where he told me a bit more about the technology. He also gave me a demonstration, first testing his own blood with a conventional, off-the-shelf fingerprick blood glucose monitor, and then with the company’s own prototype. The measurements were 6.2 and 6.3 mmol/L, respectively, which puts the two devices within a couple of percent accuracy of each other.“We use the three electrodes for ECG data, and an additional measurement for PPG. We measure for 60 seconds, and then take the raw data and analyze that using the machine learning convolutional neural network, and the deep neural network. We combine all of that data, take the three machine learning algorithms, see what comes as a result, and then analyze the glucose,” Raichura told me, as he was preparing to demo the device for me. “We want to commercialize our product, and will be looking looking for US FDA in Health Canada approval.”I was surprised to learn that it is possible to do non-invasive blood glucose measuring — most of the so-called non-invasive methods do use an implant or a filament sensor wire to get readings, but the method that Scanbo uses has been studied and covered in medical journals. It doesn’t look like the FDA has approved any products that take this approach yet, so the company is certainly facing a lengthy medical approval process in order to bring its products to market.The company also claims it is able to do blood pressure measurements, the kind that you might do at home or in the doctor’s office with a blood pressure cuff.“When we take your EKG data, we convert that into what is called a short wave transmission length,” Raichura summarizes in how the company is able to pull off blood pressure metrics. “Based on that, we calculate your non-invasive cuff-less blood pressure too. That is another piece of algorithm that we have patent pending.”With all of this tech in its back pocket, the company has an interesting choice to make; is it going to start manufacturing its own hardware devices, or is there an opportunity to license the algorithms and technology to other manufacturers that already have devices with PPG and ECG capabilities on the market.“We have two patents pending, purely on the hardware, how we designed it, how we amalgamated electrodes and all the sensors in a way where we can take all the parameters in one time,” explains Raichura, hinting at how the company is trying to measure all the things at once. “If you look at the traditionally available all the devices, you measure one thing at a time, not everything at once. You do blood pressure one time, your EKG at another time. One after another, all in sequential processes. In our case, we are asking you to put four fingers on the device, so we can capture all the data, and use algorithms to report different aspects of your health.”Scanbo sees its technology as an at-home alternative to some of the currently existing clinical techniques and technology.“As a company, we are a combination of AI and med-tech,” Raichura says, and mentions that the market is starting to take notice. “With this product, we are just getting started now. Medtronic, Samsung, LG, and others are already talking to us and see can we collaborate with them, and we are exploring a couple of strategic partnerships that could help us in taking us to different markets globally. We see the needs from 400 million people in the world with type two diabetes, and most of the populations can’t afford glucometers — never mind continuous glucose meters. We are very, very cost-effective, and we can bring the cost down to as low as $20 a month. There is no biowaste, you don’t need any disposables, you don’t need strips or anything, just purely the machine learning algorithm and a device with a chargeable battery.”The company is about to take its prototype and clinical results as leverage to go raise a seed round and kick off the process toward regulatory approval and, eventually, make a product available to the public.",0.0,0.0
316,https://www.vice.com/en/article/epzkne/facebooks-monopoly-is-imploding-before-our-eyes,Facebookâs Monopoly Is Imploding Before Our Eyes,"For years, the definition of success for many tech employees has been getting a job at a FAANG company (Facebook, Amazon, Apple, Netflix, Google). Amazon, Apple, Microsoft, Facebook, and Google, meanwhile, are often the five major companies people think of when they think of ""big tech.""But there is evidence that Facebook—once a dominant monopoly rightly blamed for all sorts of societal ills—is on the precipice of dropping out of this group through years of sheer mismanagement, a failure to innovate, setting money on fire in pursuit of a metaverse that seemingly no one wants, a vulnerable business model that Apple is squarely taking aim at, and upstart competitors like TikTok that the company seemingly has no answer for. What seemed impossible just a year or two ago—that Facebook will become just another tech company, more or less—now seems like a very real possibility.AdvertisementIn a little over one year, the company has shed nearly $800 billion of its market capitalization, with the lion's share of that coming these past eight months. To be clear, the company is one of the biggest tech firms in existence, with billions of people regularly using its products and a still growing user base, and yet, by the definition of one proposed antitrust bill, has sat below the market capitalization of what counts as “Big Tech” for months.The company’s pivot to the metaverse, complete with a name change (Meta Platforms Inc.) and a soulless PR campaign featuring chief executive Mark Zuckerberg’s sickly digital avatar, has resulted in it hemorrhaging money, while its core products—Facebook, Instagram, and WhatsApp—all seem to have very real vulnerabilities. Reality Labs, Facebook's metaverse fantasy team, burned through $4.5 billion in 2019, $6.62 billion in 2020, and $10.19 billion in 2021 (that’s over $21 billion).In a February 2022 earnings call, chief financial officer David Wehner said those operating losses would ""increase meaningfully"" this year. And they have. Another $9.4 billion in losses have been realized in just the last three quarters, bringing Reality Labs’ operating losses to north of $31 billion. On this week's third quarter earnings call, Wehner warned that they ""anticipate that Reality Labs operating losses will grow significantly year-over year."" Meta's stock has fallen about 70 percent this year.AdvertisementBy all indicators, the metaverse is a wasteland devoid of any souls save those who are too zealous or too well compensated to realize admit how stupid it is. For now. While Zuckerberg’s main contribution has been to add legs to his company’s avatars and ship out nausea-inducing headsets needed to access this realm, he promises that this new world he’s building should be ready in 10 to 15 years.Zuckerberg's obsession with the metaverse is one major problem, but there are fundamental issues plaguing the company's core business that suggest Meta isn't going to just be able to effortlessly maintain the massive money printing factories that are Facebook and Instagram, and there is even reason to worry about WhatsApp's future as the world's most popular messenger.Schooled By a Real Monopoly: AppleFacebook’s core advertising business is flashing some warning signs thanks to another, more competent monopoly that has long been a thorn in its side: Apple.In a Q1 earnings call, Facebook warned that Apple’s 2021 privacy changes to its iOS operating system—which makes it harder for third parties like Facebook to harvest data to target users—would be ""a pretty significant headwind for our business"" to the tune of $10 billion in advertiser revenue this year. In a Q2 earnings call, Zuckerberg warned of ""an economic downturn that will have a broad impact on the digital advertising business."" Sure enough, over the past four quarters, Facebook's ad revenue has faltered: $33.67 billion (Q4 ‘21), $26.998 billion (Q1 ‘22), $28.152 billion (Q2 ‘22), and $27.2 billion (Q3 ‘22), with first-ever year-over-year declines reported these last two quarters.AdvertisementFor investors looking to generate excess profits on trades and investments, all of this is part of a dark and dreary picture. Facebook's revenue has declined for two consecutive quarters, costs and expenses are surging, operating margin is spiraling downwards, net income has been cut substantially, and so investors have abandoned ship and brought the share price down nearly 70 percent this year.Earlier this week, Apple announced yet another change that would also hit Facebook. Apple said it would consider buying ads within the Facebook app to be a ""digital purchase"" subject to the App Store's 30 percent commission. It's too early to say how much this will affect Facebook, but it's not good. This is especially important for a few reasons: Facebook makes more money per user in North America than it does from any other region, and Apple's iPhone is now used by more Americans than Android is. It's also gaining market share around the world. iPhone owners are also, on average, more wealthy and thus it can be more expensive to target them with ads.The rise of the iPhone in the U.S. and, more importantly, around the world may also, eventually, be problematic for Facebook if WhatsApp users begin to migrate toward iMessage and other messaging apps.An Advertising PlatformBeyond an excuse to indulge in schadenfreude, should you or anyone else you know care about Zuckerberg losing $100 billion of his net worth?AdvertisementAs Malcolm Harris points out in a terrific NYMag piece, there are some people thinking about all of this through the lense of ""technofeudalism,"" which argues that capitalist firms have leveraged monopolies into extensive data extractivist and rentier schemes. In this telling, Facebook is all-powerful and its march towards omnipotence inevitable—but on closer examination, we might realize this sounds remarkably like Silicon Valley’s self-mythology that doesn't track with how things have actually ended up.""Facebook is much less than what the technofeudalists make it out to be,” Harris writes. “It's an advertising platform that wrings pennies out of users' scrap time—attention that would otherwise go to waste, at least from the capitalist perspective.""For a long time the heart of Meta was Facebook, its advertising platform masquerading as a social network. Its major moves to reach for digital monopoly status beyond this came in the form of acquisitions or clones of competitors' products. Instagram was acquired for $1 billion in 2012, Oculus VR in 2014 for $2 billion, and WhatsApp for $19 billion in 2014.Its dozens of acquisitions have not only worked to support its core offerings, but eliminate competition or buyout talent—and when that fails, cloning a competitor service has been an option. Most notably, Facebook has offered clones in the form of Portal—an Amazon Echo clone that was recently killed off for consumers—and Reels, a TikTok clone that users and advertisers have struggled with. Reels has proven to be a disaster, with Instagram users spending less than 10 percent of the time watching Reels as TikTok users spend on their platform. None of Facebook's clones have been very successful since Instagram Stories, which was introduced all the way back in 2016. Quite simply, by many metrics, Facebook is getting its ass kicked by TikTok.AdvertisementMonopolize the metaverse or fade to irrelevanceWith Facebook core still incredibly popular worldwide but increasingly feeling like a bloated piece of garbage whose power users in the United States are aging (and, is, specifically, not being used by American teens) Instagram is regularly held up as being a lesser disaster of a platform, albeit one whose most popular and famous users are actively revolting against it. With all this going on, Facebook is now leaning on the last of its monopoly-seeking acquisitions that it thinks might still have legs: virtual reality, which is turning into a gigantic money pit.This is a stunning change of circumstances for a company that once threw its weight around with confidence and attempted to colonize as much of life outside of the Facebook app as possible. In pursuit of capitalist monopolies in various sectors, there exists a long list of projects Facebook has poured its endless resources into. Facebook has sought to radically change aspects of our lives with decisions about how specific platforms will operate, precisely because it has leveraged economic power into other forms.AdvertisementAt one point, Facebook even tried to monopolize the global monetary system with Libra, a global cryptocurrency backed by a basket of currencies and assets (e.g. a stablecoin), and Calibra, a digital wallet for said stablecoin. Immediately, regulators worldwide expressed concerns Libra would compete with sovereign currencies and undermine their authority on designing and implementing monetary policy. Part of Facebook's pitch was that it was too big to fail—or be broken up—in the context of a geopolitical struggle against China and its technology firms. Facebook promised Libra would extend the power of the U.S. dollar, and even downgraded its plans to a U.S.-backed stablecoin (Diem) coupled with a smaller wallet (Novi). Stil, the plan was laid into by Congress, quietly killed by financial authorities, sold for scraps to a bank, and the project’s head slunk out the back.What was the right way to understand Libra? A technofeudalist might have read it as another milestone on its inevitable march towards omnipotence. The project was announced with a coalition of dozens of corporations and non-profit organizations, it was being pushed by a chief executive with inordinate influence in Washington and Wall Street, and by a company with billions of users. And yet it was smothered in the crib.Evgeny Morozov—founder of The Syllabus and one of the main critics of the technofeudal model—offered a much simpler rationale that speaks to how the company has flailed for unassailable monopolies as its core product lagged: Facebook wanted to create another core business. It was interested in finance because Chinese tech giants showed payments and communications systems complement one another well; to compete in foreign markets with established Chinese firms it would need to offer its own payment-communication system; by aggressively moving against Chinese firms it could skirt regulatory roadblocks by framing itself as a strategic asset in a tech Cold War with China. Morozov wrote that Libra would have also helped the social network turn a greater profit.Advertisement“Yes, Facebook would need to pay something to its users—but, in turn, it would also be able to charge them for its services,"" he wrote. ""As long as all such transactions are conducted in a currency under its implicit control—and if Facebook succeeds in convincing its users that their data, on its own, has far less value than the services it supplies—it would not necessarily be such a bad outcome for the company.”So, Facebook was first and foremost pursuing a strategy to diversify its business while insulating it from antitrust scrutiny. It was denied that opportunity, but this doesn’t diminish the very real need for that pivot—especially as antitrust scrutiny has increased in the years since Libra was first proposed. Facebook doubling down on the metaverse, despite the infeasibility of the project and despite declines in advertising revenue, suggest lethargy as much as ambition. We’re seeing the reformulation of a necessary but desperate gambit by the company to do something which will allow it to preserve a key role in the digital economy, with or without advertisers. Finance was the first attempt, a depressing digital simulacrum of the real world is the second one.Facebook Hasn't Fallen YetEvery time Zuckerberg was trotted out in front of Congress, he was adamant that Facebook is not a monopoly, and that it faces plenty of competition on the internet. It was hard to imagine, at the time, that Zuckerberg would shift from being a weirdo obsessed with dominating social media to become a weirdo obsessed with lighting cash on fire in pursuit of becoming the premiere place to play virtual ping pong with a heavy computer strapped to your face. It was also hard to predict that this obsession would utterly tank his company.But just because Facebook appears to be in actual, real trouble for the first time in its history does not mean this slow decline to become just another advertising giant is inevitable, nor does it mean that we can forgive and forget its monopolistic behaviors and endeavors. Facebook is still a gigantic force that has spread an endless amount of disinformation and misinformation worldwide, a hugely important platform, and a monopolistic company; this cannot be waved away simply because the company is grossly incompetent.Perhaps Facebook's most monopolistic endeavor was Free Basics, a program to provide ""free"" internet access to people in developing countries—free, as long as the ""internet"" they were accessing was Facebook. The legacy of Free Basics and the simple fact that huge parts of the global population still interact with Facebook or Facebook-owned platforms as their only access to ""the internet"" is deeply concerning and remains dangerous.Within this understanding of Facebook, though, there’s reason to pause and celebrate. For one, while this is still a juggernaut that can and will throw its weight around at great cost to us and great profit to itself, it’s also a fragile and withering one that has to contend with investors who don’t care about Zuckerberg’s next three Five-Year Plans for competing with China and building a core non-advertising business line. There is a possible near future, if we're not already there, where Meta is just another company rather than a world-shaping monolith, having been outfoxed and outclassed by more competent monopolies and wrecked by the hubris of its chief executive.Secondly, regulators seem to be wise to this plan, or at least elements of it: the FTC has already sought to block Facebook acquisitions of companies that might help it build the metaverse it so desperately needs to work at this point. Finally, Meta's failure is another chance to spur people to think about and advocate for alternatives to the technological offerings we have today, and to prevent Facebook from recementing its stranglehold on our culture or upstarts from recreating it. What sort of communication, payments, and social media platforms do we actually want—especially if we don’t design them with advertiser revenue as the core concern? What sort of technologies should be allowed to flourish and what sorts should be prohibited?",0.0,0.0
406,https://www.inverse.com/mind-body/new-mrna-vaccine-universal-flu-shot,Scientists use mRNA technology to create a potent flu vaccine that could last for years,"In the spring of 1933 , three scientists at the U.K.’s Medical Research Council received a treasure trove of vials containing human mucus from sick hospital patients. It was gross, yes, but not unwarranted: The culprit behind what had caused the 1918 influenza pandemic was still at large.Months later, the trio of scientists published a paper that found that a virus, not a novel strain of bacteria like some within the scientific community originally thought, was to blame. Over the following decades, other scientists unfurled the gnarly branches of the large influenza family tree, gathering enough information to formulate a vaccine, which (hopefully) most of us get before every flu season.But here’s the catch: Influenza is a master shapeshifter. Every year, strains of the virus that infect humans — influenza type A and B — evolve in ways that evade vaccines and, subsequently, our immune systems. This results in uneven vaccine effectiveness from year to year and also undermines efforts to pack a flu shot with a broad, long-lasting immune punch.But we may have an ace in the hole thanks to mRNA, the same technology used for our Covid-19 vaccines. In a study published Monday in the journal Proceedings of the National Academy of Sciences, researchers at the University of Pennsylvania, Icahn School of Medicine at Mount Sinai, and other institutions have cooked up an mRNA-based influenza vaccine that targets four viral proteins that tend to remain the same across different strains of influenza.“[It’s] a nice study with significant clinical implications that uses the same strategy as for Covid vaccination to create a better flu vaccine with broader capabilities by targeting multiple conserved flu [viral proteins] antigens instead of the way we do it now, which is to grow candidate strains in eggs and then inactivate them,” Anne Davidson, a researcher at the Feinstein Institutes for Medical Research in New York, who was not involved in the study, told Inverse in an email.Artistic rendering of a molecule of hemagglutinin. ShutterstockHere’s the background — Flu vaccines are updated every year based on influenza patterns most recently seen in the southern hemisphere, such as Australia; its flu season runs from April to October.Scientists pay close attention to one sugar-covered protein called hemagglutinin that dots the surface of the influenza virus, Norbert Pardi, an assistant professor of microbiology at the University of Pennsylvania Perelman School of Medicine who co-led the study, tells Inverse.“Hemagglutinin has two major parts: the head domain, which is variable and immunodominant, [and a stalk domain],” explains Pardi. “The current seasonal vaccines that use three or four inactivated [influenza] viruses primarily target the immunodominant head domain… but the problem is that the virus can change that pretty easily and escape from protective immunity.”A better option would be to target viral proteins that don’t switch up and stay pretty much the same regardless of which strain of influenza you’re infected with, says Pardi and Florian Krammer, a virologist at the Icahn School of Medicine at Mount Sinai who also co-led the study.Those proteins include neuraminidase, nucleoprotein, and matrix protein 2, all of which help the virus make copies of itself.Krammer says while there have been efforts over the years to include conserved influenza proteins, such studies have run up against failure and a whole host of hurdles. For example, to measure a potential shot’s effectiveness, scientists look to see whether it triggers an immune response, indicated via the presence of antibodies.“The vaccines that we’re testing these proteins with, they don’t induce those types of antibodies that are used as correlates,” explains Krammer. “So there’s not a lot of confidence during clinical development.”Of the four different types of influenza, A and B primarily infect humans. ShutterstockHow they did it — What has really made the dream of a potent flu shot come alive, says Pardi and Krammer, is messenger RNA (or mRNA) technology, the same used for Moderna and Pfizer-BioNTech’s Covid-19 vaccines. It involves taking a piece of genetic code that isn’t capable of altering anyone’s DNA and instructing it to make a particular type of protein that the immune system can then learn to recognize and target.For their influenza vaccine, the researchers created an mRNA cocktail encoding the four influenza proteins neuraminidase, nucleoprotein, matrix protein 2, and the stalk portion of hemagglutinin (which is conserved compared to its head domain).The vaccine was then injected into a group of twenty or so naive mice who had never experienced influenza before. They either got a quadrivalent jab (meaning all four mRNA segments for each protein was present) or monovalent (the conventional flu vaccine or vaccines containing an individual mRNA for any one of the proteins). Some animals received one shot, while others lucked out with one shot plus a booster four weeks later. The mice were then challenged with an assortment of different influenza strains, both that infect humans and other animals like dogs.What they found — There were two important phenomena the researchers noticed. First, while both the quadrivalent and monovalent jabs encouraged antibody production, only the quadrivalent shot protected the mice against the viral challenge, with exception of the monovalent vaccine containing nucleoprotein, which seemed to protect vaxxed mice from death.While antibodies tend to hog the vaccine limelight, immune cells called T cells, which roam the body and kill infected cells, are also crucial in the fight against viruses. Pardi, Krammer, and their colleagues found that the nucleoprotein-specific jab encouraged a class of cytotoxic T cells that studies have found play an important role in protection against severe influenza infection in humans and animal models.On average around five to 20 percent of Americans will get the flu every year. However, during the Covid-19 pandemic, there has been a sharp drop in the number of flu cases reported. bluecinema/E+/Getty ImagesKrammer says this motley of immune responses to the four different influenza viral proteins suggests it's more powerful to have a colorful vaccine cocktail rather than a drab monotone.“When we mix all of them together, we get the broadest immune response,” he says. “You get the engagement of T cells against the nucleoprotein, you get antibodies, and we get a pretty strong neuraminidase response. That’s kind of the beauty here that you’re flexible in what types of [viral proteins] you use… and you have a lot of possibilities to try [out].”The researchers also expect it wouldn’t need to undergo annual updates as our current ones do. Instead, they might last for a few years.What’s next — While mice studies are the launch point for future studies into other organisms like monkeys and eventually humans, Pardi and Krammer say it’s not clear whether what we see in mice will necessarily translate to us. For one, humans don’t have a naive immune system like the mice used in the study. Our pre-existing immunity against the flu may impact the quality of any potential vaccine’s antibody response, according to some studies.“Clinical trials will be necessary to see how vaccines can overcome the issue with the shortfall from previous immunity,” says Pardi. “Pretty much all adults have antibodies against the flu, and we need to see how our vaccine can overcome this issue.”It may take several years of research and clinical trials before their mRNA influenza vaccine sees the light of day, say Pardi and Krammer. In the meanwhile, there’s no point waiting: Go get your flu shot, dear reader.",0.0,0.0
108,https://www.vice.com/en/article/y3pedm/workers-at-combined-starbucks-and-amazon-store-file-for-union-election,Workers at Combined Starbucks and Amazon Store File for Union Election,"Workers at a combined Starbucks and Amazon store in Times Square filed a petition for union election Friday morning, saying they’re required to do the responsibilities of two jobs for the pay of one.This is the first petition filed at Starbucks-Amazon combination store, which is only the second of its kind—the two companies opened their first joint venture in late 2021 in upper-Midtown Manhattan. Both companies are also separately experiencing unprecedented labor action. There are over 250 unionized Starbucks locations, seven of which are in New York City. Amazon warehouses, too, have been seeing efforts toward unionization, though only one in Staten Island has been successful so far.AdvertisementAccording to a spokesperson for Starbucks Workers United, the union which has successfully organized seven other cafes in downtown Manhattan, the Times Square location has high turnover, and some workers say they were transferred there from other Starbucks locations involuntarily.The stores feature Amazon Go’s famous “Just Walk Out” technology, meaning that there are no cashiers—customers just scan their phones, pick out what they want, and leave. The Starbucks counter is for mobile pick-up only, and there is a lounge area with seating for customers to eat or work. Because of its convenient location on the ground floor of the New York Times building, it has a high volume of customers.Workers say they’re required to fulfill the responsibilities of both a Starbucks employee and an Amazon Go employee—but only for the pay of one.“We’re unionizing at this Starbucks because we are doing Amazon work for Starbucks pay and we’re not given the proper resources to manage a store of this type in such a high volume area,” said one worker, who has been at the location for over a year and a half, in a statement. “We have partners that were coerced into working at this store using intimidation and miscommunication and not given any proper benefits when transferred here.”Both Starbucks and Amazon are well-known for their anti-union corporate stances. In Chelsea, just 25 blocks away, workers at the New York City Reserve Roastery—Starbucks’ flagship store—are entering a fourth day of their strike protesting alleged bed bug sightings and black mold. The Roastery unionized in April, but has still not successfully begun to negotiate a contract. Starbucks and Amazon union organizers held a joint protest on Labor Day demanding recognition from their companies. They marched from Starbucks CEO Howard Schultz’s residence in Greenwich Village all the way to Amazon founder Jeff Bezos’s luxury penthouse on Fifth Avenue.",0.0,0.0
75,https://www.nature.com/articles/d41586-022-02947-7,Scientists are using AI to dream up revolutionary new proteins,"Artificial-intelligence tools are helping to scientists to come up with proteins that are shaped unlike anything in nature.Credit: Ian C Haydon/UW Institute for Protein DesignIn June, South Korean regulators authorized the first-ever medicine, a COVID-19 vaccine, to be made from a novel protein designed by humans. The vaccine is based on a spherical protein ‘nanoparticle’ that was created by researchers nearly a decade ago, through a labour-intensive trial-and error-process1.Now, thanks to gargantuan advances in artificial intelligence (AI), a team led by David Baker, a biochemist at the University of Washington (UW) in Seattle, reports in Science2,3 that it can design such molecules in seconds instead of months.‘The entire protein universe’: AI predicts shape of nearly every known proteinSuch efforts are a part of a scientific sea change, as AI tools such as DeepMind’s protein-structure-prediction software AlphaFold are embraced by life scientists. In July, DeepMind revealed that the latest version of AlphaFold had predicted structures for every protein known to science. And recent months have seen an explosive growth in AI tools — some based on AlphaFold — that can quickly dream up completely new proteins. Previously, this had been a painstaking pursuit with high failure rates.“Since AlphaFold, there’s been a shift in the way we work with protein design,” says Noelia Ferruz, a computational biologist at the University of Girona, Spain. “We are witnessing very exciting times.”Most efforts are focused on tools that can help to make original proteins, shaped unlike anything in nature, without much focus on what these molecules can do. But researchers — and a growing number of companies that are applying AI to protein design — would like to design proteins that can do useful things, from cleaning up toxic waste to treating diseases. Among the companies that are working towards this goal are DeepMind in London and Meta (formerly Facebook) in Menlo Park, California.“The methods are already really powerful. They’re going to get more powerful,” says Baker. “The question is what problems are you going to solve with them.”From scratchBaker’s laboratory has spent the past three decades making new proteins. Software called Rosetta, which his lab started developing in the 1990s, splits the process into steps. Initially, researchers conceived a shape for a novel protein — often by cobbling together bits of other proteins — and the software deduced a sequence of amino acids that corresponded to this shape.But these ‘first draft’ proteins rarely folded into the desired shape when made in the lab, and instead ended up stuck in different confirmations. So another step was needed to tweak the protein sequence such that it folded only into a single desired structure. This step, which involved simulating all the ways in which different sequences might fold, was computationally expensive, says Sergey Ovchinnikov, an evolutionary biologist at Harvard University in Cambridge, Massachusetts, who used to work in Baker’s lab. “You would literally have, like, 10,000 computers running for weeks doing this.”What's next for AlphaFold and the AI protein-folding revolutionBy tweaking AlphaFold and other AI programmes, that time-consuming step has become instantaneous, says Ovchinnikov. In one approach developed by Baker’s team, called hallucination, researchers feed random amino-acid sequences into a structure-prediction network; this alters the structure so that it becomes ever-more protein-like, as judged by the network’s predictions. In a 2021 paper, Baker’s team created more than 100 small, ‘hallucinated’ proteins in the lab and found signs that about one-fifth resembled the predicted shape4.AlphaFold, and a similar tool developed by Baker’s lab called RoseTTAFold, were trained to predict the structure of individual protein chains. But researchers soon discovered that such networks could also model assemblies of multiple interacting proteins. On this basis, Baker and his team were confident they could hallucinate proteins that would self-assemble into nanoparticles of different shapes and sizes; these would be made up of numerous copies of a single protein and would be similar to those on which the COVID-19 vaccine is based.Nik Spencer/Nature; Source: Adapted from N. Ferruz et al. Preprint at bioRxiv https://doi.org/10.1101/2022.08.31.505981 (2022); and J. Wang et al. Science 377, 387–394 (2022).But when they instructed microorganisms to make their creations in the labs, none of the 150 designs worked. “They didn’t fold at all: they were just gunk at the bottom of the test tube,” says Baker.Around the same time, another researcher in the lab, machine-learning scientist Justas Dauparas, was developing a deep-learning tool to address what is known as the inverse folding problem — determining a protein sequence that corresponds to a given protein’s overall shape3. The network, called ProteinMPNN, can act as a ‘spellcheck’ for designer proteins created using AlphaFold and other tools, says Ovchinnikov, by tweaking sequences while maintaining the molecules’ overall shape.When Baker and his team applied this second network to their hallucinated protein nanoparticles, it had much greater success making the molecules experimentally. The researchers checked 30 of their new proteins using cryo-electron microscopy and other experimental techniques, and 27 of them matched the AI-led designs2. The team’s creations included giant rings with complex symmetries, unlike anything found in nature. In theory, the approach could be used to design nanoparticles corresponding to almost any symmetric shape, says Lukas Milles, a biophysicist who co-led the effort. “It is electrifying to see what these networks can do.”Deep-learning revolutionDeep-learning tools such as proteinMPNN have been a game changer in protein design, says Arne Elofsson, a computational biologist at Stockholm University. “You draw your protein, push a button, and you get something that one in ten times works.” Even higher success rates can be achieved by combining multiple neural networks to tackle different parts of the design process, as Baker’s team did in designing the nanoparticles. “Now we have full control over the shape of the protein,” says Ovchinnikov.Baker’s isn’t the only lab applying AI to protein design. In a review paper posted to the bioRxiv this month, Ferruz and her colleagues counted more than 40 AI protein-design tools that have been developed in recent years, using various approaches5 (see ‘How to design a protein’).Many of these tools, including proteinMPNN, tackle the inverse folding problem: they specify a sequence that corresponds to a particular structure, often using approaches borrowed from image-recognition tools. Some others are based on an architecture similar to that of language neural networks such as GPT-3, which produces human-like text; but, instead, the tools are capable of producing novel protein sequences. “These networks are able to ‘speak’ proteins,” says Ferruz, who has co-developed one such network6.With so many protein-design tools available, it’s not always clear how best to compare them, says Chloe Hsu, a machine-learning researcher at the University of California, Berkeley, who developed an inverse folding network with researchers from Meta7.Four examples of protein ‘hallucination’. In each case, AlphaFold is presented with a random amino-acid sequence, predicts the structure, and changes the sequence until the software confidently predicts that it will fold into a protein with a well-defined 3D shape. Colours show prediction confidence (from red for very low confidence, through yellow and light blue to dark blue for very high confidence). Initial frames have been slowed down for clarity. Credit: Sergey OvchinnikovMany teams gauge their network’s ability to accurately determine the sequence of an existing protein from its structure. But this doesn’t apply for all methods, and it’s not clear how this metric, known as recovery rate, applies to the design of novel proteins, say scientists. Ferruz would like to see a protein-design competition, analogous to the biennial Critical Assessment of protein Structure Prediction (CASP) experiment, in which AlphaFold first demonstrated its superiority over other networks. “It’s a dream. Something like CASP would really move the field forward,” she says.To the wet labBaker and his colleagues are adamant that making a novel protein in the lab is the ultimate test of their methods. Their initial failure to make hallucinated protein assemblies shows this. “AlphaFold thought they were fantastic proteins, but they clearly didn’t work in the wet lab,” says Basile Wicky, a biophysicist in Baker’s lab who co-led the effort, along with Baker, Milles and UW biochemist Alexis Courbet.But not all scientists developing AI tools for protein design have easy access to experimental set-ups, notes Jinbo Xu, a computational biologist at the Toyota Technological Institute at Chicago in Illinois. Finding a lab to collaborate with can take time, so Xu is establishing his own wet lab to put his team’s creations to the test.Experiments will also be essential when it comes to designing proteins with specific tasks in mind, says Baker. In July, his team described a pair of AI methods that allow researchers to embed a specific sequence or structure in a novel protein8. They used these approaches to design enzymes that catalyse particular reactions; proteins capable of binding to other molecules; and a protein that could be used in a vaccine against a respiratory virus that is a leading cause of infant hospitalizations.Last year, DeepMind launched a spin-off company called Isomorphic Labs in London that intends to apply AI tools such as AlphaFold to drug discovery. DeepMind’s chief executive, Demis Hassabis, says that he sees protein design as an obvious and promising application for deep-learning technology, and for AlphaFold in particular. “We’re working quite a lot in the protein design space. It’s pretty early days.”",0.0,0.0
33,https://www.eurekalert.org/news-releases/969904,"Reducing childhood poverty could cut criminal convictions by almost a quarter, study shows","Brazilian researchers interviewed 1,905 children twice in seven years and analyzed 22 risk factors that can influence human development. An article on the study is published in Scientific Reports.A significant reduction in childhood poverty could cut criminal convictions by almost a quarter, according to a study conducted in Brazil. An article on the study is published in Scientific Reports. The researchers used an innovative approach involving an analysis of 22 risk factors that affect human development and interviews with 1,905 children at two points – a first interview to form a baseline (mean age 10.3) and a follow-up interview seven years later (mean age 17.8).The scientists concluded that poverty – measured broadly as a combination of little schooling for the head of household, low purchasing power and limited access to basic services – was the only crime-related factor that could be prevented. They used estimates of the population-attributable risk fraction (PARF) to predict the possible reduction in criminal convictions assuming successful early anti-poverty intervention in the lives of the children.In a scenario without poverty, 22.5% of criminal convictions involving these young people could have been prevented. On the other hand, factors such as unplanned pregnancy, prematurity, breastfeeding and prenatal maternal smoking or drinking showed no correlation with future criminal convictions.“A holistic view of young people who commit crimes is necessary in order to understand the circumstances that lead to this situation and a range of preventable factors need to be considered,” said Carolina Ziebold, a researcher in the Department of Psychiatry at the Federal University of São Paulo’s Medical School (EPM-UNIFESP) and first author of the article.Ziebold was supported by FAPESP during her PhD research. She also received a Talented Young Investigator scholarship from CAPES, the Ministry of Education’s Coordination for the Improvement of Higher Education Personnel, via its Internationalization Program.For Ary Gadelha, last author of the article, the use of a complex measure of poverty including many more factors than household income is a groundbreaking aspect of the study. Gadelha is a professor of psychiatry at EPM-UNIFESP and was Ziebold’s thesis advisor.“The study took into account housing conditions and access to public services such as healthcare or sanitation, for example, in order to understand poverty more comprehensively. This led us to advocate broader solutions than merely improving income. The many adversities faced by these children become difficulties in adulthood, such as low educational attainment and unemployment, among others,” Gadelha told Agência FAPESP.The approach used in the study is based on an epidemiological method called exposure-wide association, which is similar to the method used in genome-wide association studies (GWAS). “Exposure-wide association studies explore a broad array of potential exposures relating to a single outcome (using a hypothesis-free approach)”, the authors write.In this case, they add, the analysis encompassed “multiple modifiable perinatal, individual, family and school-related exposures associated with youth criminal conviction to identify new potential targets for the prevention of this complex phenomenon”. Moreover, they argue, “when a significant risk factor [such as poverty] is identified, the magnitude of its effect on criminal conviction should be explained to inform and guide public measures for crime prevention”.Another study led by Ziebold involving the same cohort and published in December 2021 had already found correlations between childhood poverty and a heightened propensity to develop externalizing disorders during adolescence and early adulthood, especially among girls. The researchers concluded that multidimensional poverty and exposure to stressful life events, including frequent deaths and family conflicts, were avoidable risk factors that should be addressed in childhood in order to reduce the impact of mental health problems in adult life (more at: agencia.fapesp.br/37879/).ResultsIn the recent Scientific Reports article, the researchers stress that although baseline poverty was the only modifiable risk factor significantly associated with crime as far as the children in the study sample were concerned, most of them (89%) did not have any criminal convictions.“We wanted to avoid criminalizing poverty and show that it’s a complex phenomenon. Exposure to this situation during a life can lead to social tragedy. Crime is a social question, and punishment alone may not be appropriate in the case of young people. It would be more useful to create real opportunities for rehabilitation – life opportunities,” Gadelha said.Only a small proportion (4.3%) of the 1,905 participants interviewed reported any history of criminal convictions, mainly involving theft, violent robbery, drug dealing and other violent crimes, including a homicide and an attempted homicide.The participants were from the Brazilian High-Risk Cohort Study for Psychiatric Disorders (BHRC), a major community-based survey involving 2,511 families with children aged 6-10 when it began in 2010. They were all students at public schools in two large Brazilian state capitals, São Paulo and Porto Alegre (Rio Grande do Sul). Three follow-up surveys have been completed so far, the last in 2018-19. A fourth has begun this year and is scheduled for completion in 2024.Considered one of the most ambitious childhood mental health surveys ever conducted in Brazil, the BHRC, also known as Project Connection – Minds of the Future, is led by the National Institute of Developmental Psychiatry (INPD), which is supported by FAPESP and the National Council for Scientific and Technological Development (CNPq), an arm of the Ministry for Science, Technology and Innovation (MCTI).More than 20 universities in Brazil and elsewhere are involved in INPD’s activities. Its principal investigator is Eurípedes Constantino Miguel Filho, a professor in the Department of Psychiatry at the University of São Paulo’s Medical School (FM-USP).ImpactAccording to a report published by the United Nations Children’s Fund (UNICEF) in March 2022, “children and adolescents have always been – and continue to be – the most affected by poverty. By the beginning of 2020, the percentage of children and adolescents living in monetary poverty and extreme monetary poverty in Brazil was, proportionally, twice that of adults”.Between 35% and 45%, depending on the age group, lived on less than USD 5.50 per day in 2020. The proportion living on less than USD 1.90 per day – the extreme monetary poverty line – was 12%.Furthermore, according to Getúlio Vargas Foundation’s Center for Research on Social Policies (FGV Social), food insecurity reached a record level in Brazil at the end of 2021, surpassing the global average and affecting mainly women, poor families and people aged 30-49. The proportion of the overall population suffering from food security reached 36%, compared with 17% in 2014. The global average for 2021 was 35%.“We know people have yet to feel the full economic impact of the pandemic, including food insecurity and lack of access to schooling. The consequences of children’s exposure will become clear in the future,” Ziebold said, adding that more research is needed to understand how the vulnerabilities of the places where children live can influence juvenile crime rates. “This type of factor has been observed in research conducted in other countries, such as the United States, where young people are more likely to commit crimes if they live in areas without infrastructure or with gangs. This is a topic for further research.”About 46,000 young people in conflict with the law were processed in 2019 by SINASE, Brazil’s special justice system for juvenile offenders.About São Paulo Research Foundation (FAPESP)The São Paulo Research Foundation (FAPESP) is a public institution with the mission of supporting scientific research in all fields of knowledge by awarding scholarships, fellowships and grants to investigators linked with higher education and research institutions in the State of São Paulo, Brazil. FAPESP is aware that the very best research can only be done by working with the best researchers internationally. Therefore, it has established partnerships with funding agencies, higher education, private companies, and research organizations in other countries known for the quality of their research and has been encouraging scientists funded by its grants to further develop their international collaboration. You can learn more about FAPESP at www.fapesp.br/en and visit FAPESP news agency at www.agencia.fapesp.br/en to keep updated with the latest scientific breakthroughs FAPESP helps achieve through its many programs, awards and research centers. You may also subscribe to FAPESP news agency at http://agencia.fapesp.br/subscribe",0.0,0.0
31,https://www.freethink.com/technology/minimally-invasive-surgery,Robotic surgery is a game changer for minimally invasive surgery,"Once the stuff of science fiction, robotic surgery is now used in hospitals across the world for a wide variety of procedures. Across several common procedures, some research has found that robotic surgery can improve outcomes in areas such as blood loss, complications, and recovery times, compared to open and some laparoscopic surgeries.Robotic procedures have been game changers in minimally invasive care, and innovative surgical systems have been crucial. Robotic surgery isn’t performed by a machine; a specially trained surgeon uses advanced medical technology to streamline the surgical process. The end goal is to increase safety, reduce complications, and improve patient outcomes. By reducing surgical trauma and increasing precision, robotic surgery can help pave the way for predictable, reproducible results.Although robotic surgery has made impressive advances over the past two decades, there is much more to be done. As minimally invasive care continues to advance, researchers are finding new ways to help surgeons do more for patients.How robotic surgery worksThe first commercially viable robotic surgical system was developed in the late 1990s by Intuitive. Intuitive’s systems have gone on to become the most advanced and widely used in the world. Four generations of its pioneering da Vinci system have so far been used in more than 10 million procedures.Intuitive’s robotic surgical systems enable surgeons to use a console, precisely guiding surgical instruments inside the patient’s body. The surgeon’s hand movements are translated in real time to the instruments, which are situated on a cart beside the patient. The instruments are small, nimble, and have a greater range of motion than the human wrist and hand, helping to enable surgical precision in moments that matter.In contrast to open surgery, which typically requires a large incision, robotic surgery involves one or more very small incisions to insert the robotic arms. One of the arms has a camera that feeds high-quality 3D video to the surgeon’s console.“I remember distinctly when I first sat at the console,” says Tanuja Damani, a general surgeon at New York University who first began using the da Vinci system in 2011. “I realized right away that this was the future of surgery. But there was tremendous skepticism early on.”Dr. Damani and other early adopters saw the potential of this approach. Their vision, perseverance, and mentoring have smoothed the way for those who have followed.Take Amanda Pysher, a young bariatric and general surgeon with Surgical Consultants of Northern Virginia, who was first introduced to robotics during her residency and fellowship. Unlike Dr. Damani, Dr. Pysher has benefited from a robust network of mentors, who’ve helped her as she’s learned the ropes of using the da Vinci system. She’s become so comfortable with the system that three years ago she focused her practice on robotic surgery. She now mentors other surgeons who are in the process of learning robotic surgery.“I think it has been easier for me to transition to robotics than the first adopters years ago,” she says. “It’s one of the reasons I feel so strongly about mentoring. I want to be able to give back and help others the way that the mentors above me helped me. We’re helping people live longer for their families and their friends. I just can’t think of any other surgery which has a bigger impact than that.”Robotic surgery’s impact on patientsFor both Dr. Pysher and Dr. Damani, the goal is to do more for their patients. One such patient is Jennifer Luebke. Last year, after struggling with her weight for decades, Luebke decided to have a robotic bariatric surgery with Dr. Pysher.That decision stemmed largely from her sense that her weight increased her long-term health risks. “I want to be able to grow old and be a grandmother, and I really didn’t see that in my future,” Luebke says. “I really was concerned. This is the one thing that has completely changed my life.”As an emergency room nurse, Luebke was reluctant to undergo traditional open bariatric surgery – she’d seen patients who’d had to deal with complications. But as her weight increased and her health problems grew, she decided that robotic surgery might reduce the risk of complications.Her decision paid off. After the procedure, she spent the night in the hospital and was discharged the next morning.As the technology continues to advance, more and more surgeons and hospitals are coming on board.The number of worldwide robotic procedures more than doubled between 2012 to 2020. A study published two years ago in JAMA Network Open analyzed records from 73 hospitals in Michigan, finding that 8.7 percent of surgeons performed robotic general surgery in 2012; by 2018, that number had jumped to over 35 percent.“We are turning the skeptics into believers,” Dr. Damani says. “The shared sense of purpose of the robotics surgery community now is something that is so refreshing.”Total da Vinci Practice**Total da Vinci Practice refers to the transferable value of robotic-assisted surgery with a da Vinci system across procedures in a surgeon’s minimally invasive practice. It is at the surgeon’s discretion to determine when a patient is a candidate for minimally invasive surgery and whether robotic-assisted surgery with a da Vinci system is an option.",0.0,0.0
407,https://link.springer.com/article/10.1007/s12015-022-10465-2,Scientific Integrity Requires Publishing Rebuttals and Retracting Problematic Papers,"Recently, an article by Seneff et al. entitled “Innate immunosuppression by SARS-CoV-2 mRNA vaccinations: The role of G-quadruplexes, exosomes, and MicroRNAs” was published in Food and Chemical Toxicology (FCT). Here, we describe why this article, which contains unsubstantiated claims and misunderstandings such as “billions of lives are potentially at risk” with COVID-19 mRNA vaccines, is problematic and should be retracted. We report here our request to the editor of FCT to have our rebuttal published, unfortunately rejected after three rounds of reviewing. Fighting the spread of false information requires enormous effort while receiving little or no credit for this necessary work, which often even ends up being threatened. This need for more scientific integrity is at the heart of our advocacy, and we call for large support, especially from editors and publishers, to fight more effectively against deadly disinformation.In this commentary, we would like to alert the scientific community against the dissemination of pseudoscience in presumed trustful scientific journals, and the dangers that such a spreading are causing to public health [1]. We will explain and detail our recent failure to get a problematic paper retracted and our rebuttal published by the editor to raise awareness among the scientific community of the rising misuse of the scientific publication process. The problem is far from novel, and we have seen during the pandemic an explosion of misinformation, especially in the domain of poorly conducted clinical trials of unproven drugs such as hydroxychloroquine and ivermectin [2, 3]. Predatory journals have taken advantage of the threats on public health to publish hundreds of papers of low or null scientific value [4, 5]; they considered the pandemic as an opportunity to gain access to the mainstream media and to flatter the general public [6]. In contrast, when a true scientific journal published erroneous reports, as it was the case for The Lancet or The New England Journal of Medicine in 2020 [7, 8], the paper was rapidly retracted with the apologies of the journal’s editors. This is the way allowing science to improve, but it is very difficult to combat predatory journals or journals whose editor remains deaf to substantiated alerts and supports the dissemination of fake medicine.The problem is different when seemingly rigorous scientific journals publish false science under pressure from the Editor in order to increase their impact factors points and, they think, notoriety. Such an attitude is also predatory and authors, editors and publishers of such articles should be publicly condemned by the scientific community. This technique of using science to vehiculate nonsense has been named ‘agnotology’ by Robert N. Proctor, which he defines as “the study of deliberate, culturally-induced ignorance or doubt, typically to sell a product or win favor, particularly through the publication of inaccurate or misleading scientific data” [9]. There is some similarity between the connivance of the tobacco industry with some ‘key opinion leaders’ who made the propaganda in favor of tobacco consumption; just to name a few [9]: Clarence Cook Little, renown geneticist, former president of the universities of Maine and of Michigan, who declared in 1969 that “there is no demonstrated causal relationship between smoking and any disease”; Victor Buhler, former president of the College of American Pathologists who declared, also in 1969, that “the cause of lung cancer remained unknown”; more recently, Suzanne Oparil, former president of the American Heart Association, who claimed in 1997 that the epidemiological data relating lung cancer to tobacco consumption were old and that “how accurate they are is really not clear to [her]”.We are presently witnessing the same type of misinformation carried out by scientists and journal, endangering millions of people. We would like to describe the fight that we have engaged, and share with the readers our concerns on public health matters. In April 2022, Food and Chemical Toxicology, an Elsevier journal, published a review article dealing with mRNA anti-SARS-CoV-2 vaccines [10], pretending that these vaccines are at the cause of a series of dreadful diseases for a large number of people (neurodegenerative disease, myocarditis, immune thrombocytopenia, Bell’s palsy, liver disease, impaired adaptive immunity, impaired DNA damage response and tumorigenesis). This 16,071-words review including 231 references was first submitted on February 9th 2022 and accepted on April 8th. It was submitted just one month after a call for papers on potential toxic effects of Covid-19 vaccines in this journal made by its Editor in chief, Prof J.L. Domingo [11]. Alerted by the unusual number of shares on social networks (> 30 k tweets and > 10 k Shares, Likes & Comments on Facebook) [12] and overwhelmingly within the anti-vaccination spheres, we were concerned by the content of the manuscript which contains unsubstantiated claims such as “billions of lives are potentially at risk” with mRNA COVID-19 vaccines. The authors pretend that mRNA COVID-19 vaccines are responsible for the “suppression of type I interferon responses” resulting “in impaired innate immunity” and therefore that they “potentially cause increased risk to infectious diseases and cancer”.Such important statements should be supported by undoubtable facts, especially when they are made in a scientific article (published in a journal with an impact factor of 6), and should not solely rely on the authors’ fallacious inferences. We thus contacted Prof J.L. Domingo to warn him against the highly misleading nature of many of the authors’ assertions and the highly contentious nature of previous authors’ publications. We therefore asked for the retraction of the article to prevent it from being used as a scientific reference for the dissemination of false information on vaccination. Prof Domingo answered on the April 18th 2022: “When this manuscript was submitted to the journal, due to its topic, I already anticipated it could be potentially controversial. Therefore, for the review process, instead of making my decision in the comments / recommendations of 2–3 reviewers, as usual, the decision for that paper was based on the comments of 5 reviewers experts in the field. Based on your e-mail, and of course if you wish it, I invite you to submit a Letter to the Editor on that paper where you can state your concerns.”We therefore wrote a Letter to the Editor [13], in which we demonstrated that this article contained several fallacious scientific assumptions leading to misunderstandings and thus invalidating the conclusions drawn by the authors. We suggested that the article be withdrawn because a careful analysis of the provided bibliography indicates profound misinterpretations of the topics and conclusions about the negative impact that vaccination against SARS-CoV-2 could have on immunity. To illustrate our point, we have detailed a non-exhaustive list of 10 misunderstandings in the literature interpreted by the authors (Table 1 in Ref 13). We were thus able, on the basis of the published literature, to show exactly the opposite of what the authors have asserted on the effect of IFN type I by the vaccine. From the abstract, the authors allege that they will provide “evidence that vaccination induces a profound impairment in Type I interferon (IFN) signaling, which has various adverse consequences to human health”. This claim relies on a still unpublished preprint available on medRxiv since August 2021 [14] but of which it should be noted that the final conclusion established “[….] that despite the lack of dramatic inflammation observed during infection, the vaccine elicits a robust adaptive immune response”. Data shows a differential gene expression profile in peripheral dendritic cells based on vaccinal status, but does not support the authors’ claim that there is Type I IFN suppression due to the vaccine. Published research shows this is simply the reaction expected from any vaccine: a high immune response without a systemic and uncontrolled inflammation [15, 16]. Furthermore, arguing that vaccination would result in loss of the interferon-mediated Type I immune response (and therefore leading to a higher infectious risk or lack of cancer surveillance) contradicts other published data on the immune response after vaccination [17]. To date only a set of SARS-COV-2 viral proteins have been shown to antagonize type I interferon response, not the vaccine [18].Of course, we argued that relying on hypothetical physiological disturbances induced by vaccination to suggest a possible increased risk of various cancers, which had never been published so far was unacceptable, especially for patients for whom COVID-19 vaccination is still strongly recommended such as patients with cancer [19,20,21]. We then concluded that “the important shortcomings and misusage of scientific literature and data have no place in a scientific journal. Therefore, we suggest that this article should be retracted in an effort to prevent further damages to health care policies.”The revised and corrected letter is available as a preprint since it was finally rejected on June 13th 2022 after 3 rounds of reviewing by 4 anonymous referees. One reviewer argued there was no reason for retraction because “there is no evidence of scientific fraud that justifies the demand for retraction of the original submission”. Another one stated that “the original paper need not be somewhat accurate since this is a review, so conjecture is allowed, if disproven it is fine.” And the last one questioned our experience and previous works, going even as far as to check our résumés and arguing that “we might not have the required experience”. Only one out 4 reviewers made more constructive remarks and gave us feedback for the letter to be published.We then contacted the ethical board of the publisher, Elsevier. To date, we received no answer.In 2015, the United Nations established 17 Sustainable Development Goals (SDG), including Target 3.3: Fight communicable diseases. We believe that vaccine disinformation is hindering such efforts. Vaccine hesitancy was also flagged by the World Health Organization as one of the ten major global health threats in 2019. That's why papers criticizing vaccines should only be published when claims are strongly supported, which is not the case in Seneff et al.'s paper.We therefore made a militant choice, refusing to change our position about the demand of retraction of the paper. We do think that this is not a scientific controversy, but a matter of public health; millions of people have been protected from the disease by the vaccines that have been developed and distributed all over the world (although not enough in developing countries) [22], and this article, as well as the publicity that it has received on social media, tends to destroy the unprecedented efforts to save people from disease and premature death. Fighting against scientific disinformation may be risky, too slow and insufficient [23, 24]. The scientists involved in such efforts receive little to no credit for this necessary work and can often end up being threatened [25]. Aside from the recent recommendation by Besançon et al. to improve the error-checking culture of academics and the correction of the scientific literature, we believe that the present case of the Seneff et al. article in Food and Chemical Toxicology, further highlights the need for more transparency in reviewing and editorial processes. Indeed, there is currently no information above the article from Seneff et al. that would highlight to readers the fact that the scientific community heavily disputes the claim of the article. We believe that the valid concerns we have raised, to which the Editor in Chief seemed to initially adhere, should have rapidly been reflected in an editorial note above the article. Further, this case illustrates the need for reviewers’ reports to be made transparently available particularly with “potentially controversial” research articles. If this had been done, scientists and readers could have verified the rigor of the reviewing process [25] and have had access to the potential concerns raised by the reviewers about the article at hand. We also argue that the pervasive use of metrics to assess scientists and their productions is partially responsible for the continued existence of questionable research practices [26]. As long as the sole metric to evaluate scientific journals remains the Impact Factor, editors and publishers will have no incentives to take actions on problematic papers. Eventually, we join Besançon et al. in their suggestions to destigmatize and speed up the scientific correction process. We hope our efforts in rebutting Seneff et al. will successfully counter the misinformation on COVID-19 vaccine and the risk for cancers as well as promote the thankless but essential tasks of fighting against scientific fraud [27].",0.0,0.0
264,https://phys.org/news/2022-10-scientists-material-plastic-metal.html,Scientists discover material that can be made like a plastic but conducts like a metal,"A group of scientists with the University of Chicago have discovered a way to create a material that can be made like a plastic, but conducts electricity more like a metal. Above, members of the Anderson lab at work. Credit: John Zich/University of ChicagoScientists with the University of Chicago have discovered a way to create a material that can be made like a plastic, but conducts electricity more like a metal.The research, published Oct. 26 in Nature, shows how to make a kind of material in which the molecular fragments are jumbled and disordered, but can still conduct electricity extremely well.This goes against all of the rules we know about for conductivity—to a scientist, it's kind of like seeing a car driving on water and still going 70 mph. But the finding could also be extraordinarily useful; if you want to invent something revolutionary, the process often first starts with discovering a completely new material.""In principle, this opens up the design of a whole new class of materials that conduct electricity, are easy to shape, and are very robust in everyday conditions,"" said John Anderson, an associate professor of chemistry at the University of Chicago and the senior author on the study. ""Essentially, it suggests new possibilities for an extremely important technological group of materials,"" said Jiaze Xie (Ph.D. '22, now at Princeton), the first author on the paper.'There isn't a solid theory to explain this'Conductive materials are absolutely essential if you're making any kind of electronic device, whether it be an iPhone, a solar panel, or a television. By far the oldest and largest group of conductors is the metals: copper, gold, aluminum. Then, about 50 years ago, scientists were able to create conductors made out of organic materials, using a chemical treatment known as ""doping,"" which sprinkles in different atoms or electrons through the material.This is advantageous because these materials are more flexible and easier to process than traditional metals, but the trouble is they aren't very stable; they can lose their conductivity if exposed to moisture or if the temperature gets too high.But fundamentally, both of these organic and traditional metallic conductors share a common characteristic. They are made up of straight, closely packed rows of atoms or molecules. This means that electrons can easily flow through the material, much like cars on a highway. In fact, scientists thought a material had to have these straight, orderly rows in order to conduct electricity efficiently.Then Xie began experimenting with some materials discovered years ago, but largely ignored. He strung nickel atoms like pearls into a string of of molecular beads made of carbon and sulfur, and began testing.To the scientists' astonishment, the material easily and strongly conducted electricity. What's more, it was very stable. ""We heated it, chilled it, exposed it to air and humidity, and even dripped acid and base on it, and nothing happened,"" said Xie. That is enormously helpful for a device that has to function in the real world.But to the scientists, the most striking thing was that the molecular structure of the material was disordered. ""From a fundamental picture, that should not be able to be a metal,"" said Anderson. ""There isn't a solid theory to explain this.""Xie, Anderson, and their lab worked with other scientists around the university to try to understand how the material can conduct electricity. After tests, simulations, and theoretical work, they think that the material forms layers, like sheets in a lasagna. Even if the sheets rotate sideways, no longer forming a neat lasagna stack, electrons can still move horizontally or vertically—as long as the pieces touch.The end result is unprecedented for a conductive material. ""It's almost like conductive Play-Doh—you can smush it into place and it conducts electricity,"" Anderson said.The scientists are excited because the discovery suggests a fundamentally new design principle for electronics technology. Conductors are so important that virtually any new development opens up new lines for technology, they explained.One of the material's attractive characteristics is new options for processing. For example, metals usually have to be melted in order to be made into the right shape for a chip or device, which limits what you can make with them, since other components of the device have to be able to withstand the heat needed to process these materials.The new material has no such restriction because it can be made at room temperatures. It can also be used where the need for a device or pieces of the device to withstand heat, acid or alkalinity, or humidity has previously limited engineers' options to develop new technology.The team is also exploring the different forms and functions the material might make. ""We think we can make it 2D or 3D, make it porous, or even introduce other functions by adding different linkers or nodes,"" said Xie.More information: John Anderson, Intrinsic glassy-metallic transport in an amorphous coordination polymer, Nature (2022). DOI: 10.1038/s41586-022-05261-4. www.nature.com/articles/s41586-022-05261-4 Journal information: Nature",0.0,0.0
197,https://apnews.com/article/business-kamala-harris-seattle-washington-pollution-16405c66d405103374d6f78db6ed2a04,"More kids to ride in âcleanâ school buses, mostly electric","Vice President Kamala Harris speaks at an event highlighting the Biden-Harris Administration's investments in electric school buses at Lumen Field in Seattle on Wednesday, oct. 26, 2022. (Karen Ducey/The Seattle Times via AP)Vice President Kamala Harris speaks at an event highlighting the Biden-Harris Administration's investments in electric school buses at Lumen Field in Seattle on Wednesday, oct. 26, 2022. (Karen Ducey/The Seattle Times via AP)WASHINGTON (AP) — Nearly 400 school districts spanning all 50 states and Washington, D.C., along with several tribes and U.S. territories, are receiving roughly $1 billion in grants to purchase about 2,500 “clean” school buses under a new federal program.The Biden administration is making the grants available as part of a wider effort to accelerate the transition to zero-emission vehicles and reduce air pollution near schools and communities.Vice President Kamala Harris and Environmental Protection Agency Administrator Michael Regan announced the grant awards Wednesday in Seattle. The new, mostly electric school buses will reduce greenhouse gas emissions , save money and better protect children’s health, they said.As many as 25 million children ride yellow buses each school day, and they will have a healthier future with a cleaner fleet, Harris said.“We are witnessing around our country and around the world the effects of extreme climate,” she said. “What we’re announcing today is a step forward in our nation’s commitment to reduce greenhouse gases, to invest in our economy ... to invest in building the skills of America’s workforce. All with the goal of not only saving our children, but for them, saving our planet.″ADVERTISEMENTOnly about 1% of the nation’s 480,000 school buses were electric as of last year, but the push to abandon traditional diesel buses has gained momentum in recent years. Money for the new purchases is available under the federal Clean School Bus Program, which includes $5 billion from the bipartisan infrastructure law President Joe Biden signed last year.The clean bus program “is accelerating our nation’s transition to electric and low-emission school buses while ensuring a brighter, healthier future for our children,” Regan said.The EPA initially made $500 million available for clean buses in May but increased that to $965 million last month, responding to what officials called overwhelming demand for electric buses. An additional $1 billion is set to be awarded in the budget year that began Oct. 1.The EPA said it received about 2,000 applications requesting nearly $4 billion for more than 12,000 buses, mostly electric. Some 389 applications worth $913 million were accepted to support purchase of 2,463 buses, 95% of which will be electric, the EPA said. The remaining buses will run on compressed natural gas or propane.ADVERTISEMENTSchool districts identified as priority areas serving low-income, rural or tribal students make up 99% of the projects that were selected, the White House said. More applications are under review, and the EPA plans to select more winners to reach the full $965 million in coming weeks.Districts set to receive money range from Wrangell, Alaska, to Anniston, Alabama, and Teton County, Wyoming, to Wirt County, West Virginia. Besides the District of Columbia, big cities that won grants for clean school buses include New York, Dallas, Houston, Atlanta and Los Angeles.White House adviser Mitch Landrieu said he expects many buses to be delivered by the start of the next school year, with the remainder likely to be in service by the end of 2023. The billion dollars being spent this year — along with an additional $4 billon expected over the next four years — should “supercharge” a domestic manufacturing boom for electric school buses, said Landrieu, a former New Orleans mayor tapped by Biden to oversee spending in the massive infrastructure law.ADVERTISEMENT“These buses will be made in America — real jobs with real wages,″ Landrieu said in an interview. “We are going to ramp up manufacturing in this country.″Environmental and public health groups hailed the announcement, which comes after years of advocacy to replace diesel-powered buses with cleaner alternatives.“It doesn’t make sense to send our kids to school on buses that create brain-harming, lung-harming, cancer-causing, climate-harming pollution,″ said Molly Rauch, public health policy director for Moms Clean Air Force, an environmental group. “Our kids, our bus drivers and our communities deserve better.″",0.0,0.0
219,https://interestingengineering.com/innovation/china-worlds-largest-wind-farm,China to break its own record: Worldâs new largest wind farm could power 13 million homes,"Work on the project will begin “before 2025.” It will surpass the largest wind farm in the world once it is finished, according to Guangdong province officials.The Jiuquan Wind Power base in China, a huge facility with a 20 gigawatt capacity, presently holds the distinction of being the world’s largest wind farm.A city in the nearby Fujian Province earlier this year proposed a 1 trillion yuan ($138 billion) project that included 50 gigawatts of offshore wind.With more than 25 percent of the world's wind power capacity, China is claimed to be a world leader in wind energy.Offshore wind farm at low tide in sunset. silkwayrain/iStockCapacity: 13 million homesThe 10-kilometer-long farm, which will have thousands of strong wind turbines, will operate between 75 and 185 kilometers (47 and 115 miles) offshore.And because of the region's distinctive topographical features and windy location, these turbines will be able to run between 43 percent to 49 percent of the time, meaning 3,800 to 4,300 hours each year.A gigawatt is one billion watts, and 3 million solar panels are required to produce one gigawatt of power. 100 million LEDs or 300,000 typical European homes may each be powered by one gigawatt.The facility's 43.3 GW of power-generating capacity could supply electricity to 13 million households, which is equal to 4.3 billion LED lights, as per Euronews.Over 99 percent of Norway's electricity comes from hydropower plants with a 31 GW capacity, which is less than the new Chinese wind farm project. The record-breaking offshore farm would be bigger than all of the power plants in Norway combined.",0.0,0.0
48,https://techcrunch.com/2020/12/21/the-us-wants-startups-to-get-a-piece-of-the-16-billion-spent-on-space-tech/,The US wants startups to get a piece of the $16 billion spent on space tech,"The US wants startups to get a piece of the $16 billion spent on space techThe U.S. government is one of the biggest spenders in the nascent space industry, and the man who handles the money for the Air Force’s $16 billion checkbook wants startups to know that his door is open for them.In all, Will Roper, the Assistant Secretary of the Air Force for Acquisition, Technology and Logistics, handles about $60 billion worth of budget for the Air Force — a mandate that includes spending money on the new tech initiatives the Air Force deems important.Historically, the Department of Defense hasn’t been the greatest at working with startups — and many tech companies have been loath to work with the DoD. However, since much of modern civilian infrastructure is based on global positioning systems and other satellite technologies that fall under the Defense Department’s purview, those views on cooperation are changing on both sides.“Space isn’t a quiet domain of communication and navigation and exploration anymore,” Roper told the audience at TechCrunch’s latest Sessions event, TC Sessions: Space 2020. “It’s increasingly becoming a hostile place… So we’re gearing up a new kind of competition on the military side that could extend to space and that’s creating a lot of new space programs.”Roper emphasized that the interest from the Air Force and the government more broadly extends well beyond offensive capabilities and military priorities. As space becomes an economic opportunity, Roper sees the Air Force as an engine for driving technology development forward in ways that have commercial benefits.“It’s a great, great time for innovation in new technologies that could help the military, but we want to do more than just help the military. That’s the old thinking in the Pentagon. That’s all that would help us win the Cold War in the 20th Century, but it’s not going to help us in the 21st, where technology is globalized and accelerating,” Roper said.“We want to find ways where our military mission and our funding can help accelerate commercial markets too, so it’s competing on a much bigger stage. But we think it’s where we need to aspire to be, so that we’re playing the right catalyst role in this nation and with our partners around the world,” Roper said.There are several programs that startups can tap to get those federal dollars. Two of the easiest points of entry are through the AFWERX and its recently announced SpaceWERX arm focused entirely on space technology.“These look like any tech company,” Roper told the audience at the TechCrunch event. “They’re outside our fence lines. They’re easy to walk into… Now you don’t have to know the mission, we will help you find the mission and the customer — the warfighter associated with it. It’s a great model because it keeps the company focused on what they know best, which is their tech.”Over the last three years, Roper estimated that the AFWERX program had brought 2,300 companies into the Air Force and Space Force programs, and most of them had never worked with the military before, he said.Within AFWERX there are three programs that particularly relate to integrating startups into the procurement process, Roper said. One is the Spark program, which pairs military with private industry; one is the AFVentures program, which is designed to finance new innovations coming from private industry; and finally there’s the Prime program, which helps commercialize and certify technologies.Roper pointed to the recent certification the Air Force gave to Joby Aviation for its flying cars. “So there’s a new military market that will hopefully generate a new commercial market,” Roper said.In 2021, the Prime program will expand to space technologies, according to Roper.As the demand for new tech grows, there’s no shortage of innovations Roper would like to see from private industry. From new autonomous innovations that could help co-pilot spacecraft to technology for refueling and in-space maneuverability, and reusable equipment from boosters to other components that can bring costs down.Roper also acknowledged that the Pentagon has a long way to go to “hack the acquisition system” when it comes to dual-use technologies.Entrepreneurs have pointed out that one of the biggest obstacles to the growth of the commercial space industry has been the inability of the U.S. government to open up the technology for use by private industry.Roper hopes to change that. “We want to use our military dollars, our mission, and potentially our certifications to help get you there without changing your core product,” he said. “If you succeed as a commercial success, then we succeed as well, because now we’ve got a great tech partner, that hopefully we can continue to come to to solve problems in future. The thing that we’ll want to understand early on is how our military market and all those benefits I just mentioned, how can they help you get to commercial success? And what is it that we not need to do to pull you off that trajectory?”Contracts with AFWERX are fixed-price and progress as companies hit certain milestones on the product roadmap. These orders increase incrementally as the technology proves itself, so a contract could start with the delivery of a prototype, then experimental usage, then a commercial contract, then broad adoption. “What we’re looking to do is see if you can move the ball forward on your technology, and if you do, then we do another contract. We step you up our process,” Roper said.Roper sees the project as nothing less than the evolution of the aerospace and defense industry.“We have a lot of amazing companies today that helped build stealth bombers and space planes and all sorts of awesome stuff. They’re defense companies and we still need them,” Roper said. “What we’re hoping to help build in this century is a set of new companies that are just tech companies. They’re not defense, purely, and they’re not commercial purely. They’re just technology companies and they do a bit of business on both sides.”",0.0,0.0
423,https://gumc.georgetown.edu/news-release/after-stroke-in-an-infants-brain-right-side-of-brain-compensates-for-loss-of-language-in-left-side/#,"After Stroke in an Infantâs Brain, Right Side of Brain Compensates for Loss of Language in Left Side","Home ▸ News Release ▸ After Stroke in an Infant’s Brain, Right Side of Brain Compensates for Loss of Language in Left SideAfter Stroke in an Infant’s Brain, Right Side of Brain Compensates for Loss of Language in Left SideThese are individual scans of two healthy controls and two individuals with a left-hemisphere (LH) perinatal stroke. The orange/yellow activation shows the normal language areas of the left hemisphere in healthy individuals, as compared with the reorganized language areas in individuals with a left-hemisphere perinatal stroke. Courtesy: Elissa NewportPosted in News Release | Tagged brain, brain plasticity, strokeAs Children with Left-hemisphere Strokes Grow Up, Ability to Understand Language Shifts to Right side.WASHINGTON (October 10, 2022) — A clinical study conducted by researchers at Georgetown University Medical Center found that, for children who had a major stroke to the left hemisphere of their brain within days of their birth, the infant’s brain was “plastic” enough for the right hemisphere to acquire the language abilities ordinarily handled by the left side, while also maintaining its own language abilities as well.Media Contact Karen Teberkm463@georgetown.eduThe left hemisphere of the brain is normally responsible for sentence processing (understanding words and sentences as we listen to speech). The right hemisphere of the brain is normally responsible for processing the emotion of the voice — is it happy or sad, angry or calm. This study sought to answer the question, “What happens when one of the hemispheres is injured at birth?”The findings appear in PNAS the week of October 10, 2022.The participants in this study developed normally during pregnancy. But around birth they had a significant stroke, one that would have debilitating outcomes in adults. In infants, a stroke is much rarer, but does happen in roughly one out of every 4,000 births.The researchers studied perinatal arterial ischemic stroke, a type of brain injury occurring around the time of birth in which blood flow is cut off to a part of the brain by a blood clot. The same type of stroke occurs much more commonly in adults. Previous studies of brain injury in infants have included several types of brain injury; the focus in this study on a specific type of injury enabled the authors to find more consistent effects than in previous work.“Our most important conclusion is that plasticity in the brain, specifically the ability to reorganize language to the opposite side of the brain, is definitely possible early in life,” says Elissa Newport, Ph.D., director of the Center for Brain Plasticity and Recovery at Georgetown University Medical Center, professor in the departments of Neurology and Rehabilitation Medicine and first author of this study. “However, this early plasticity for language is restricted to one brain region. The brain is not able to reorganize injured functions just anywhere as more dramatic reorganization is not possible even in early life. This gives us great insights into the regions we might be able to focus on for potential breakthroughs in developing techniques for recovery in adults as well.”The investigators recruited people from across the United States who all had medium to large strokes to the cortex region of their left hemisphere around the time of birth. To assess long-term outcomes in their language abilities, participants were given language tests at 9 to 26 years of age and were compared to their close-in-age healthy siblings. They were also scanned in an MRI to reveal which brain areas were involved in sentence comprehension.The participants and their healthy siblings all completed the language tasks almost perfectly. The major difference was that the stroke participants processed sentences on the right side of the brain, while their siblings processed sentences on the left side. The stroke participants showed a very consistent pattern of language activation in the right hemisphere, regardless of the extent or location of damage from the stroke to the left hemisphere. Only one of the 15 participants, who had the smallest stroke, did not show clear right hemisphere dominant activation.“It is also notable that many years after their strokes our participants are all such highly functioning adults. Some are honor students, and others are working toward or have gotten their master’s degrees,” says Newport. “Their achievements are remarkable, especially since some of their parents had been told when they were born that their strokes would produce lifelong impairments.”In future studies, the researchers hope to gain a better understanding of why the left hemisphere routinely becomes dominant in healthy brains but consistently loses out to the right hemisphere when there is a significant left-hemisphere stroke. An additional question of special interest — and clinical importance — is why left hemisphere language can successfully reorganize to the right hemisphere if injuries occur very early in life, but not later. Research on stroke recovery and sentence processing in adults suggests that plasticity narrows with age, something that Newport hopes to study, as it could be of great benefit, and potential therapeutic interest, to adult stroke survivors.The researchers are very grateful to the participants and their families, who have made invaluable contributions to this work.In addition to Newport, the other authors at Georgetown University are Anna Seydell-Greenwald, Barbara Landau, Peter E. Turkeltaub, Catherine E. Chambers, Kelly C. Martin and Rebecca Rennert. Margot Giannetti and Alexander W. Dromerick are at Georgetown University and MedStar National Rehabilitation Hospital. Rebecca N. Ichord is at the Perelman School of Medicine at the University of Pennsylvania and Children’s Hospital of Philadelphia. Jessica L. Carpenter is at the University of Maryland Baltimore. William D. Gaillard and Madison M. Berl are at the Children’s National Hospital and Center for Neuroscience, Washington, DC.This work was supported by funds from Georgetown University and MedStar Health; by the Solomon James Rodan Pediatric Stroke Research Fund, the Feldstein Veron Innovation Fund, and the Bergeron Visiting Scholars Fund to the Center for Brain Plasticity and Recovery; by an American Heart Association grant 17GRNT33650054; by NIH grants P50HD105328 to the DC-IDDRC at Children’s National Hospital and Georgetown University; and by NIH Grants K18DC014558, K23NS065121, R01NS244280 and R01DC016902.Newport reports having no personal financial interests related to the study.",0.0,0.0
424,https://www.psypost.org/2022/10/people-with-insecure-attachment-styles-tend-to-have-strong-emotional-bonds-with-pets-study-finds-64161,"People with insecure attachment styles tend to have strong emotional bonds with pets, study finds","New research on German dog owners finds that people with stronger relationships to their pets display more symptoms of mental disorders and distress, but proposes that this link may be fully accounted for by insecure attachment to other humans. The study was published in BMC Psychiatry.Pet ownership has long been linked to better mental health and lower levels of negative conditions such as loneliness and depression, both in the general population and in patients with physical and mental disorders. However, such findings have not been consistent as other studies reported zero or even negative effects of pet ownership on physical and mental health.A different line of research has linked emotional attachment to pets to problems in interpersonal relationships. One such study found that people with stronger attachment to pets reported lower levels of social support and higher levels of loneliness and depression. Another one found strong attachment to pets to be associated with childhood trauma and certain psychopathological traits. These results led authors of the new study to focus on the relationship between interpersonal attachment styles (i.e. what kinds of relationships with others are we comfortable in), attachment to pets and mental health.Study author Johanna Lass‑Hennemann and her colleagues conducted an online survey of 610 German dog owners to test the hypothesis that stronger emotional attachment to one’s dog is associated with higher mental health burden and insecure attachment to humans. They also aimed to “disentangle the link between emotional attachment to pets and human attachment and their perspective associations with mental health burden.”The researchers recruited respondents by distributing the link to their survey on webpages for dog owners and on social media. Study participants recruited in this way were mostly females (93%) between 18 and 73 years of age. They were asked to provide certain demographic data and dog-related information about themselves, but also to complete assessments of attachment to pets (Lexington Attachment to Pets Scale, LAPS), interpersonal attachment styles (Revised Adult Attachment Scale, R-AAS) and of symptoms of mental disorders and distress or the mental health burden, to use the words of authors (Brief Symptom inventory, BSI).Respondents who were more strongly attached to their dogs reported more symptoms of mental disorders and distress. Additionally, a stronger emotional attachment to one’s dog was associated with lower comfort with depending and trusting others (the dependence component of interpersonal attachment) and to a greater fear of being rejected and unloved (the anxiety component of interpersonal attachment). These were, in turn, associated with more pronounced symptoms of mental disorders and distress (mental health burden).Results also indicated that interpersonal attachment styles may be mediating the association between the emotional attachment to the dog and mental health burden, as it fully accounted for the link between the later two factors. Authors conclude that “stronger emotional attachment to pets might reflect a compensatory attachment strategy for people who were not able to establish secure relationships to other people during childhood. Those people may build more close relationships with pets that might be perceived as more reliable and less threatening.”These result highlight important links between emotional attachment and mental health. However, this was a correlation study and, therefore, it cannot be the basis for cause-and-effect interpretations. Almost all of the participants were women and the results might differ somewhat on a sample of men. The authors also noted that the assessment method for emotional attachment to dog used in the study assesses the intensity of attachment, but not the attachment style. Assessing the style of attachment to pet alongside intensity might provide novel insights in future studies.The paper, “The relationship between attachment to pets and mental health: the shared link via attachment to humans“, was authored by Johanna Lass‑Hennemann, Sarah K. Schäfer, M. Roxanne Sopp, and Tanja Michael.",0.0,0.0
472,https://www.protocol.com/climate/data-center-climate-risk-assessment,Data centers arenât prepared for the climate crisis,"Benjamin Pimentel ( @benpimentel) covers crypto and fintech from San Francisco. He has reported on many of the biggest tech stories over the past 20 years for the San Francisco Chronicle, Dow Jones MarketWatch and Business Insider, from the dot-com crash, the rise of cloud computing, social networking and AI to the impact of the Great Recession and the COVID crisis on Silicon Valley and beyond. He can be reached at bpimentel@protocol.com or via Google Voice at (925) 307-9342.",1.0,0.0
293,https://www.npr.org/2022/10/06/1127227605/boston-dynamics-robots-pledge-against-weapons,Some leading robot makers are pledging not to weaponize them,"Some leading robot makers are pledging not to weaponize themEnlarge this image toggle caption Patricia De Melo Moreira/AFP via Getty Images Patricia De Melo Moreira/AFP via Getty ImagesBoston Dynamics and five other robotics companies have signed an open letter saying what many of us were already nervously hoping for anyway: Let's not weaponize general-purpose robots.The six leading tech firms — including Agility Robotics, ANYbotics, Clearpath Robotics, Open Robotics and Unitree — say advanced robots could result in huge benefits in our work and home lives but that they may also be used for nefarious purposes.""Untrustworthy people could use them to invade civil rights or to threaten, harm, or intimidate others,"" the companies said.""We believe that adding weapons to robots that are remotely or autonomously operated, widely available to the public, and capable of navigating to previously inaccessible locations where people live and work, raises new risks of harm and serious ethical issues,"" they added.The firms pledged not to weaponize their ""advanced-mobility general-purpose robots"" or the software that makes them function. They also said they would try to make sure their customers didn't weaponize the companies' products.They companies said they don't take issue with ""existing technologies"" that governments use to ""defend themselves and uphold their laws.""According to Boston Dynamics' website, police and fire departments are using the company's dog-like robot Spot to assess risky situations, but the firm says Spot is not designed for surveillance or to replace police officers.There have been growing calls across the globe to curb the use of autonomous weapons systems — which operate on their own and don't involve a human operator — and the Stop Killer Robots campaign says nearly 100 countries and a majority of people oppose autonomous weapons.But a meeting of the United Nations Convention on Certain Conventional Weapons last year failed to reach a consensus governing the use of so-called killer robots, due in part to objections from countries working on such technologies including the U.S, the UK and Russia, CNBC reported.",0.0,0.0
292,https://www.npr.org/2022/10/24/1131131088/recycling-plastic-is-practically-impossible-and-the-problem-is-getting-worse,Recycling plastic is practically impossible â and the problem is getting worse,"Recycling plastic is practically impossible — and the problem is getting worseEnlarge this image toggle caption Laura Sullivan/NPR Laura Sullivan/NPRThe vast majority of plastic that people use, and in many cases put into blue recycling bins, is headed to landfills, or worse, according to a report from Greenpeace on the state of plastic recycling in the U.S.The report cites separate data published this May which revealed that the amount of plastic actually turned into new things has fallen to new lows of around 5%. That number is expected to drop further as more plastic is produced.Greenpeace found that no plastic — not even soda bottles, one of the most prolific items thrown into recycling bins — meets the threshold to be called ""recyclable"" according to standards set by the Ellen MacArthur Foundation New Plastic Economy Initiative. Plastic must have a recycling rate of 30% to reach that standard; no plastic has ever been recycled and reused close to that rate.""More plastic is being produced, and an even smaller percentage of it is being recycled,"" says Lisa Ramsden, senior plastic campaigner for Greenpeace USA. ""The crisis just gets worse and worse, and without drastic change will continue to worsen as the industry plans to triple plastic production by 2050.""Waste management experts say the problem with plastic is that it is expensive to collect and sort. There are now thousands of different types of plastic, and none of them can be melted down together. Plastic also degrades after one or two uses. Greenpeace found the more plastic is reused the more toxic it becomes.New plastic, on the other hand, is cheap and easy to produce. The result is that plastic trash has few markets — a reality the public has not wanted to hear.Trent Carpenter, the general manager of Southern Oregon Sanitation, says when they told customers a couple years ago that they could no longer take any plastic trash other than soda bottles and jugs — like milk containers and detergent bottles — people were upset. They wanted to put their strawberry containers, bags, yogurt cups and all manner of plastic trash in their recycling bin.""We had to re-educate individuals that a great deal of that material is ending up in a landfill,"" Carpenter said. ""It's not going to a recycling facility and being recycled. It's going to a recycling facility and being landfilled someplace else because [you] can't do anything with that material.""That message has been difficult for the public to absorb with so many different bins in public spaces, and their own communities telling them to put their plastic in recycling containers.Carpenter says they wanted to be transparent with their customers and tell them the truth, unlike companies that continue to tell customers that plastic, such as bags and containers, is being turned into new things.""Politically it's easier to just say 'Gosh, we're going to take everything and we think we can get it recycled,' and then look the other way,"" Carpenter said of the other companies. ""That's greenwashing at its best.""Greenpeace found a couple facilities are trying to reprocess cups and containers — sometimes called ""number 5s"" because of the markings on the containers. But the numbers are low. While 52% of recycling facilities in the U.S. accept that kind of plastic, the report found less than 5% of it is actually repurposed — and the rest is put into a landfill.Similarly, the National Association for PET Container Resources, an industry trade group, found in 2017 that only 21 percent of the plastic bottles collected for recycling were turned into new things.The low reprocessing rates are at odds with plans from the oil and gas industry. Industry lobbyists say they plan to recycle every piece of plastic they make into something new by 2040. In interviews with NPR, industry officials were unable to explain how they planned to reach a 100 percent recycling rate.An NPR investigative report found in 2020 that industry officials misled the public about the recyclability of plastic even though their own reports showed they knew as early as the 1970s and 1980s that plastic could not be economically recycled.The American Chemistry Council, an industry lobby group, initially did not respond to NPR's request for comment on the Greenpeace report. After publication, Joshua Baca, vice president of plastics for the group, sent an email to NPR calling Greenpeace's views ""misleading, out of touch and misguided.""He said the industry believes it is ""on the cusp of a circularity revolution"" when it comes to recycling plastic by ""scaling up sortation, advanced recycling, and new partnerships that enable used plastic to be remade again and again.""Environmentalists and lawmakers in some states are now pushing for legislation that bans single use plastics, and for ""bottle bills"" which pay customers to bring back their plastic bottles. The bills have led to successful recycling rates for plastic bottles in places like Oregon and Michigan, but have faced steep resistance from plastic and oil industry lobbyists.""The real solution is to switch to systems of reuse and refill,"" Ramsden said. ""We are at a decision point on plastic pollution. It is time for corporations to turn off the plastic tap.""After years of embracing plastic recycling, many environmental groups say they hope the public will finally see plastic for what they say it is — trash — and that people will ask themselves if there is something else they could be using instead.",0.0,0.0
449,http://www.exeter.ac.uk/news/research/title_932902_en.html,Positive childhood experiences of blue spaces linked to better adult well-being,"Positive childhood experiences of blue spaces linked to better adult well-beingNew research based on data from 18 countries concludes that adults with better mental health are more likely to report having spent time playing in and around coastal and inland waters, such as rivers and lakes (also known collectively as blue spaces) as children.The finding was replicated in each of the countries studied.Mounting evidence shows that spending time in and around green spaces such as parks and woodlands in adulthood is associated with stress reduction and better mental health. However, we know far less about the benefits of blue spaces, or the role childhood contact has in these relationships in later life.Data came from the BlueHealth International Survey (BIS), a cross-sectional survey co-ordinated by the University of Exeter’s European Centre for Environment and Human Health. The current analysis used data from over 15,000 people across 14 European Countries and 4 other non-European countries/regions (Hong Kong, Canada, Australia and California).Respondents were asked to recall their blue space experiences between the ages of 0-16 years including how local they were, how often they visited them, and how comfortable their parents/guardians were with them playing in these settings, as well as more recent contact with green and blue spaces over the last four weeks, and mental health over the last two weeks.The research, published in the Journal of Environmental Psychology, found that individuals who recalled more childhood blue space experiences tended to place greater intrinsic value on natural settings in general, and to visit them more often as adults – each of which, in turn, were associated with better mental wellbeing in adulthood.Valeria Vitale, Lead author and PhD Candidate at Sapienza University of Rome, said: “In the context of an increasingly technological and industrialized world, it’s important to understand how childhood nature experiences relate to wellbeing in later life.“Our findings suggest that building familiarity and confidence in and around blue spaces during childhood may stimulate an inherent joy of nature and encourage people to seek out recreational nature experiences, with beneficial consequences for adult mental health.”Dr Leanne Martin, Co-author and Postdoctoral Research Associate at the University of Exeter’s European Centre for Environment and Human Health, said: “Water settings can be dangerous for children, and parents are right to be cautious. This research suggests though that supporting children to feel comfortable in these settings and developing skills such as swimming at an early age can have previously unrecognised life-long benefits.”Dr Mathew White, Co-author and Senior Scientist at the University of Vienna, said: “The current study is adding to our growing awareness of the need for urban planners and local bodies responsible for managing our green and blue spaces to provide safe, accessible access to natural settings for the healthy mental and physical development of our children.“If our findings are supported by longitudinal research that tracks people’s exposures over the entire life-course, it would suggest that further work, policies and initiatives encouraging more blue space experiences during childhood may be a viable way to support the mental health of future generations.”The study is entitled ‘Mechanisms underlying childhood exposure to blue spaces and adult subjective well-being: An 18-country analysis’ and published in the Journal of Environmental Psychology. The project was funded by the European Union’s Horizon 2020 research and innovation programme under Grant Agreement No. 66773.",0.0,0.0
570,https://techcrunch.com/2021/03/31/leeway-is-a-contract-workflow-service-for-your-legal-team/,Leeway is a contract workflow service for your legal team,"Meet Leeway, a French startup that is building an end-to-end software-as-a-service solution for your contracts. Leeway lets you centralize all your contracts in a single repository, go through multiple negotiation steps and trigger a DocuSign event for the signature.The company raised a $4.2 million seed round from HenQ, Kima Ventures as well as several business angels, such as the founders of Algolia, Eventbrite, Spendesk, MeilleursAgents, Livestorm and Luko.If you’re working for the legal department of your company, you’re probably working with multiple tools. Chances are you’re using Microsoft Word to write a contract, a cloud service to store and share the contract with your teammates and business partners, and an e-signature and archival service.Leeway is optimizing this workflow at every step. First, you can store all your contracts on Leeway. In addition to making it easier to find a contract later down the road, you can get reminders when a contract is about to expire so you can renew a contract.Second, you can edit your contract from Leeway directly. For instance, a manager can review a contract and write changes in Leeway’s interface. The employee can then start a revision and save a new version of the contract.After that, you can send the contract from the same interface. Administrators can set up approval workflows so that several people need to approve a contract before it is signed. As everything is centralized, you can get an overview of all your contracts that are currently in the pipeline.Up next, Leeway is thinking about integrating conditional clauses within the product. Usually, big companies have several versions of the same clause — very favorable, favorable, not so favorable, etc. When a client is negotiating, Leeway customers could switch the clause from very favorable to favorable for instance.Right now, around 30 companies are using Leeway to manage their contracts. Clients include Voodoo, Evaneos, Ifop and Fitness Park. “We have a very specific customer base — the legal department of companies with 100 to 500 employees,” co-founder and CEO Antoine Fabre told me.It doesn’t mean that smaller and bigger companies shouldn’t be using Leeway. But companies with fewer than 100 employees don’t necessarily have a full-fledged legal department. The sales team or the finance department could act as the legal-ish team. But Leeway still has a lot of room to grow.",0.0,0.0
480,https://techcrunch.com/2022/08/16/european-climate-vc-contrarian-targets-100-million-seed-fund/,"From âliterally zeroâ experience to $100M, this VC is raising his second climate tech seed fund","From ‘literally zero’ experience to $100M, this VC is raising his second climate tech seed fundIf you ask me, climate tech investor Contrarian Ventures isn’t so contrarian anymore.The five-year-old firm is targeting $100 million for its second seed-stage fund, and it’s doing so smack in the middle of a climate-tech dealmaking boom. So, if anything, it’s trendy.But when the seed-stage VC — a backer of e-bike maker Zoomo and solar data firm PVcase — debuted with a $13.6 million fund in 2017, its focus was “obviously contrarian,” founding partner Rokas Peciulaitis told TechCrunch, as the “industries in vogue at the time were AI and Fintech.”The launch also marked an unexpected pivot for Peciulaitis, who says he dove into the scene with “literally zero climate tech sector experience.” He’d recently left an inflation-trading job at Bank of America, where the work was “not fulfilling in the slightest,” Peciulaitis said in a nod to the bank’s reputation as a major funder of fossil fuels.In 2017, PitchBook recorded 578 climate tech deals globally, altogether worth $12.5 billion. The sector has since tripled in size, as climate change–driven extreme weather events occupy evermore space in our collective consciousness. To that point: PitchBook tracked 1,130 climate tech deals globally in 2021, topping $44.8 billion in value. Climate tech is cool now, but Peciulaitis’s Lithuania-based venture firm is sticking with its name anyways.Like any venture capital firm, Contrarian says that it stands out through its emphasis on “developing excellent relationships with founders.” Materially, the firm invests in tech that could help decarbonize transportation, industrial processes, energy and buildings.Contrarian has completed 21 deals to date, and this year it expanded beyond Lithuania with new partners in Berlin and London. The firm backs emerging startups in Europe as well as Israel, but nowhere else in the Middle East. Currently, the firm does not invest in agriculture-related tech, though the category has a significant carbon footprint of its own.In an email, Contrarian said it counts London-based tech VC Molten Ventures among its limited partners. The firm declined to share a full list of its LPs, but stated that none of them were fossil fuel companies.",0.0,0.0
459,https://techcrunch.com/2022/08/08/bitmain-matrixport-john-ge/,Bitmain co-founder welcomes crypto regulation to restore market confidence,"The collapse of Three Arrow Capital and the counterparties wrapped in the crypto hedge fund’s troubles have drawn questions about the soundness of the heady digital asset investment space. For the industry’s survivors, watching their rivals fall to pieces overnight has been an alarming experience.To understand where the industry might be going after the market turmoil, we spoke with John Ge, chief executive officer at Matrixport, a Singapore-based digital asset manager with over $10 billion in assets under management and custody.Ge was formerly the head of investment and financing as well as a founding partner at Bitmain, the world’s biggest maker of Bitcoin mining machines. Together with Bitmain’s co-founder and former CEO Jihan Wu, Ge co-founded Matrixport in 2018.Three Arrow Capital, known as 3AC in the crypto community, was one of the world’s largest crypto hedge funds before its fall from grace. Its success was predicated on a risky strategy: it borrowed aggressively from crypto lenders and in turn invested that money in other crypto projects.When cryptocurrency prices began to plummet earlier this year, the firm, as well as other similar outfits that bet on rising crypto prices, failed to repay their creditors and plunged into liquidation. The crypto market is down by $1.8 trillion since its peak in November, led by the slide in Bitcoin and Ethereum prices.The recent market crash is “inevitable”, Ge says in an interview with TechCrunch. “The core issue is that we saw players whose business model is like a black box. They borrow money from investors without giving transparency over how the money will be used.”The other problem is that these crypto managers are acting both as the player and referee, Ge contends. “Many of them are providing both asset management and proprietary trading. An asset manager should not be doing proprietary trading, and if it does, it needs to follow stringent leverage requirements.”“Even the most conservative investment strategy has risks and may result in losses, but the principle is to be transparent with your customers, not fraudulent, deceptive, or misleading,” the founder says.Matrixport, which serves individuals as well as over 500 institutions across Asia, Europe and North America, was exposed to 3AC and has lodged a claim alongside other creditors. But Ge assures that the firm’s exposure is “relatively small” when compared to the exposure other industry players faced and is considered “minor” when compared relative to Matrixport’s equity.As to how to restore investor confidence in the crypto sphere, Ge believes regulators are on the right track to bring more oversight over consumer-facing crypto products and protection for retail investors, as is the case in Singapore.But it’s “unrealistic” to have regulators design risk control models for institution-focused asset managers. “The pace of regulations tends to fall behind that of industry development.”Ge thinks investors have “lost a certain level of confidence” in the crypto market and the industry will take time to recover. On the other hand, he thinks competition has waned for survivors like Matrixport because “many of the other players are gone.”Matrixport told Bloomberg last year that it planned to go public in three to five years and Ge said that plan “hasn’t changed.” It’s too early to say which market the company is floating its shares but the U.S. is a “likely” option given investors there are more “welcoming of crypto innovation.”",0.0,0.0
37,https://www.businessinsider.com/great-labor-shortage-looming-population-decline-disaster-global-economy-2022-10?utm_source=reddit.com,The Great People Shortage is coming â and it's going to cause global economic chaos,"The world has seen a population boom over the past few decades. The globe's 4 billionth person was born in 1975 and now, in about a month, the 8 billionth person will probably be born. This ""population bomb"" has been cited by experts as an unprecedented challenge to the ecological balance of our planet — when 50 Nobel laureates were asked in 2017 what the greatest threat to humanity is, more than a third of them named the overpopulation of the planet. And there is no doubt that slowing population growth is an important tool to combat the climate crisis.But what those Nobel laureates overlooked is the fact that the forces leading to a population drop are already in motion. In fact, in 40 years or so, the global population will begin to decline.It will not be a virus, a war, or a natural disaster that will cause this population decline. Instead, it will be an increase in living standards. Progress in living standards since the birth of the Industrial Revolution has been accompanied not only by rising life expectancy, but also by falling birth rates. People are healthier, richer, better educated, living longer, and having fewer children. As a result, the number of children born in rich countries like the US, in Europe, and China is not sufficient anymore to keep those populations stable. But this decrease in humanity is not a reason to cheer, but rather a looming disaster for our economy. The great labor shortage caused by the declining population will cripple our global economy unless we find innovative ways to keep things running.The population is going to shrinkThe economic and demographic forces that will lead to a global population drop by the end of the 21st century have been at work in major economies for a long time. Year after year, the birth rates of more rich and middle-income countries fall below the critical ""replacement level"" — the level at which people have enough children to maintain current population levels. A society needs 2.1 children per woman for the population to remain stable. In the US, the current rate is 1.6 children per woman — and it's even lower in most European countries as well as Japan (1.3), China (1.2), and South Korea (0.8). Soon, almost every country in the world will fall below this breakeven point.Research has shown that across countries and regions, as living standards improve, the number of children per family starts to decline. The reasons are varied — more economic opportunity for women, better access to education for children, lower infant mortality — but eventually, what was once a poor, young country becomes wealthier and must face the challenge of an aging population that does not have enough young workers to support it.By the end of this century, the global population will have decreased by 1 billion people from its peak, according to a 2020 analysis by researchers at the Gates Foundation, and in the most extreme scenario, the population could decline by almost 2 billion from where it is today, to just over 6 billion. The German working population will have declined by a third, based on the average scenario from the researchers, and in Italy, Spain, and Greece it will have declined by more than half. Poland, Portugal, Romania, Japan, and China will all lose up to two-thirds of their labor force, according to the projections. The looming population decline is a wake-up call: Instead of the ""population bomb"" that some have feared for decades, we will face a population drop, and it will have enormous consequences for the world's prosperity.The labor shortage has already startedWhile a global population drop is good news for the planet, it will be a huge challenge for our economic and social systems. The most important fuel of economic growth in the past several centuries has been people. And with fewer people, less work can get done.We are already experiencing the beginning of this great labor shortage in industries ranging from airlines to day cares to military service. In the coming years, many more sectors and occupational fields will be affected. With fewer train drivers, teachers, engineers, doctors, care workers, and programmers, many companies will produce or perform less. And as the population drops, the amount of money being spent at these businesses will also shrink. Less consumption leads to fewer sales and fewer sales lead to lower profits and, thus, less economic growth.Not only will the number of workers decline with the population, but how much each of these workers can produce will slip as well. Global per capita productivity, the formal measure of how much a worker can produce in an hour and the most important indicator of progress, has recently stagnated. The combination of a declining labor force and stagnating productivity is toxic. It could lead to a drop in economic output or, in the worst-case scenario, decades of stagnant growth. Some 250 years after the Industrial Revolution, we could enter an era of stasis.Our growing economy has also allowed people to retire in their later years, with a social safety net and younger relatives to take care of them. But we could soon see the reverse: The number of people that need to be taken care of will far exceed the number of working people who can support them. In the US, the increase in the number of retirees compared with the working population is already straining the system. In 2020, there were 3.5 people of working age for each retired person. In 2050, this ratio will drop to 2.6. This will put enormous pressure on the working population of the US to become more productive in order to support an increasing number of older people while also sustaining economic growth.This is a stunning reversal of the world's historical growth patterns. For centuries, millions of people poured into factories and offices and boosted consumption with their incomes. With their tax money, they ensured that investments could be made in education, health, research, infrastructure, and in a social system that finances an ever-growing number of pensions. This engine is now beginning to sputter as more people retire and there aren't enough young workers to replace them.More people or more productivityThere are two solutions to combat labor shortages: We can have more people work, and/or we can work more productively. The US and its effective migration policies are a visible example of how to get more people working despite low birth rates. Japan is a successful example of how to deal with both a shrinking and aging population by becoming more productive through automation and digitization.To get out of a labor shortage, economies will need a productivity boost on par with the industrialization miracle that led the world out of relative widespread poverty 250 years ago. If fewer working people are going to finance an ever-expanding welfare state, more investment in innovation and progress is needed. This is especially true for the service sector, where a majority of the labor force works in developed countries, and where productivity has been stagnating for almost 20 years now. There is plenty of room for improvement. Business models based on low-skilled labor at minimal wages are not characteristic of a high-tech country. They are a sign of regression. Therefore, it's necessary to create incentives through raising minimum wages to automate simple work wherever possible.Change also means letting go of creaky processes, outdated business models, and obsolete industries. That means investing in cutting-edge companies: Among the world's top-10 companies when it comes to market capitalization, eight are tech companies whose success is based on products and business models that have adapted to quickly changing markets and even created markets we never knew existed. That also means making a more dynamic labor market that motivates people to find the right job. The Great Resignation has shown that we can allow workers to more dynamically switch to jobs with higher salaries that better fit their skills. And finally, that means reforming our education system. As long as one-fifth of 15-year-old students cannot read at a basic level, we won't be able to combat the challenges of population decline. The next era of work will require skills other than diligence and obedience — which is what schools primarily teach today. Creativity, resilience, and the ability to solve complex problems will be imperative skills to keep our economy running.And a new economy will not emerge without the help of immigrants from around the world. As the population declines, countries will shift from trying to keep immigrants out to fighting over the dwindling supply of in-demand workers. To continue to attract people in the future, countries will need to start shifting their immigration strategies now. For instance, a lack of language support excludes many children of immigrants from the labor market, and high real-estate prices lead to increasing segregation, especially in large cities. Countries like Canada have tried to overcome these problems by proactively welcoming refugees and supporting new residents. This rejection of unequal treatment and discrimination will pay off in the long run as the world's most important resource, human beings, becomes scarce.If history has taught us anything, it's that progress is always accompanied by change and the courage to try something new. To combat the coming population bust, the world will need nothing less than a revolution of our minds. We need innovation and new ideas: robots and artificial intelligence that do our work for us and let everyone get the chance for good education and training. Along the way, we will have to find solutions to make this continued progress climate neutral by investing in sustainable-energy production and low-emission technologies. By doing so, we will make a better world for our children.Sebastian Dettmers is the CEO of StepStone, which is owned by Axel Springer, the parent company of Insider. He is also the author of a new book on the future of the world's population.",0.0,0.0
156,https://spectrum.ieee.org/smart-clothes-artificial-muscles,Artificial Muscles Woven Into Smart Textiles Could Make Clothing Hyperfunctional,"IEEE websites place cookies on your device to give you the best user experience. By using our websites, you agree to the placement of these cookies. To learn more, read our Privacy Policy.",0.0,0.0
5,https://www.engadget.com/t-mobile-will-start-charging-a-35-fee-on-all-new-activations-and-upgrades-065518011.html,T-Mobile will start charging a $35 fee on all new activations and upgrades,"T-Mobile may be joining rivals Verizon and AT&T by introducing an $35 charge for all new postpaid activations and upgrades, according to The T-Mo Report and some Redditors. According to T-Mobile internal documents, it's introducing a ""Device Connection Charge"" for ""all activations and upgrades for mobile, Beyond the Smartphone and broadband devices.""Before, the Uncarrier charged activation fees only if you received in-store customer support for new activations, with online orders exempt. Now, all new postpaid activations are charged, whether or not you were assisted. This includes updating to a new device, adding a Bring-Your-Own-Device line, or ordering a Home Internet line, according to The T-Mo Report.T-Mobile has always tried to separate itself from regular telecoms, but charging customers for essentially nothing doesn't sound very Uncarrier-like, if the reports are accurate. And you can't take your business to Sprint, as it no longer exists thanks to its merger with T-Mobile. When that deal was finalized, T-Mobile said things would be ""better for customers,"" but constant activation charges would definitely not be better.Turn on browser notifications to receive breaking news alerts from Engadget You can disable notifications at any time in your settings menu. Not now Turned on Turn onWorse, it appears to be justifying the new fee in a dubious way, saying it's ""simplifying"" the system to bring a ""more consistent and straightforward experience for customers."" In other words, you'll no longer need to wonder if you'll get soaked for the charge or not — you definitely will. Engadget has reached out to T-Mobile to confirm the report's accuracy.",0.0,0.0
526,https://themarijuanaherald.com/2022/10/study-legalizing-marijuana-has-no-impact-on-the-perceived-risk-of-marijuana-use-among-children/,Study: Legalizing Marijuana Has No Impact on the Perceived Risk of Marijuana Use Among Children,"The state level legalization of recreational marijuana has no discernible impact on how children feel about the potential risks associated with marijuana use.This is according to a new peer-reviewed study being published in the upcoming issue of the journal Cannabis and Cannabinoid Research and epublished ahead of print by the National Institute of Health.“As more states pass recreational cannabis laws (RCLs) for adults, there is concern that increasing (and state-sanctioned) cannabis acceptance will result in a reduced perception of risk of harm from cannabis among children”, states the study’s abstract. “We aimed to discover whether children in states with RCLs had decreased perception of risk from cannabis compared with children in states with illicit cannabis.”For the study researchers “analyzed data from the multisite multistate Adolescent Brain and Cognitive Development Study to determine how the perception of cannabis harm among children (age at baseline: 9-10; N=10,395) changes over time in states with and without RCLs.”Using multilevel modeling, they “assessed survey responses from children longitudinally across 3 years, adjusting for state-, family-, and participant-level clustering and child-level factors, including demographics (sex, race, and socioeconomic status), religiosity, and trait impulsivity.”The study found that there “was no significant main effect of state RCLs on perceived risk of cannabis use, and no differences in change over time by state RCLs, even after controlling for demographic factors and other risk (e.g., impulsivity) and protective (e.g., religiosity) factors.”Researchers conclude by stating that “this analysis indicates that state-level RCLs are not associated with differential perception of cannabis risk among children, even after controlling for demographics, trait impulsivity, and religiosity. Future studies could assess how perception of risk from cannabis changes as children and adolescents continue to mature in states with and without RCLs.”More information on the study including a look at its full abstract can be found at the following link: https://pubmed.ncbi.nlm.nih.gov/36301559/",0.0,0.0
230,https://pv-magazine-usa.com/2022/10/24/chinas-solar-cell-production-capacity-may-reach-600-gw-by-year-end/,Chinaâs solar cell production capacity may reach 600 GW by year-end,"From pv magazine globalChina’s total annual solar cell and module production capacity may increase from 361 GW at the end of last year to up to 600 GW at the end of 2022, according to the Asia Europe Clean Energy (Solar) Advisory (AECEA).“Since January, 20 companies disclosed to expand module production totaling 380 GW, planned to be executed within the next few months or up to 1,5 years,” the analyst firm said, noting that most of this capacity relates to n-type modules produced with tunnel oxide passivated contacts (TOPCon) solar cells or panels based on cells with a heterojunction (HJT) design. “Reportedly, TOPCon related expansion plans exceed 220 GW, whereas HJT is nearing the 150 GW mark. As an example, recently one HJT company conducted an online pitching and according to them almost 800 people joined that call,” it added.So far this year, the output of polysilicon, wafers, cells and modules has already beaten the achievements of the Chinese PV industry in 2021 by some 50%. “By June, module shipments of the TOP 10 manufacturer crossed the 100 GW and by the end of September may have reached 140-150 GW (2021: 133 GW),” said the AECEA. “Just five of these top 10 have set shipment targets of between 183-205 GW.”Furthermore, the AECEA revealed that the country’s polysilicon capacity should grow from around 530,000 MT at the end of 2021 to up to 1.2 million MT in 2022, jumping to 2.5 million MT in 2023, and up to 4 million MT in 2024.“In the near term, the overall industrial landscape won’t fundamentally change. Incumbent companies are further consolidating their market positions through backward/forward integration,” the AECEA stated. “By and large, vertical integration remains their favored business model, which in times of external supply constraints or external supply dependencies has gained ever more weight.”",0.0,0.0
380,https://www.ox.ac.uk/news/2022-10-13-new-study-finds-monkeypox-virus-can-spread-widely-within-specialist-hospital,New study finds that monkeypox virus can spread widely within specialist hospital isolation rooms,"The UK Health Security Agency (UKHSA) recommends that patients with monkeypox who have severe disease requiring hospital admission are cared for in isolation rooms, with infection prevention and control (IPC) precautions that aim to contain potentially infectious virus within the room and protect staff who enter. However, to date it has been unclear whether these measures are proportionate to the potential virus exposure risks.To investigate this, researchers from the Liverpool School of Tropical Medicine, the University of Oxford’s Nuffield Department of Medicine and the UKHSA conducted a study which collected samples from the rooms of patients hospitalised with monkeypox. The findings have been published in The Lancet Microbe.The research team assessed the extent of virus shedding onto surfaces in specialist isolation rooms containing patients admitted to hospital for the management of severe monkeypox. They also investigated whether the virus was detectable in air samples from the rooms.The researchers found that viral DNA shed by the patients could be found on multiple surfaces throughout the isolation rooms (56 (93%) positive by PCR out of 60 samples). Monkeypox virus DNA was also found on personal protective equipment (PPE) worn by healthcare workers caring for these patients, and in the anterooms where they remove their PPE. Monkeypox virus DNA was also detected in five out of twenty air samples taken within these isolation rooms.Changing bed linen was an activity particularly associated with detection of monkeypox virus DNA in air samples in the room. This suggests that viral particles, probably in shed skin particles, can become suspended in the air when bed sheets are changed. Monkeypox virus capable of replicating in cells under laboratory conditions (an indicator that the virus could infect other people) was identified in two of four PCR-positive samples selected for virus isolation. This includes air samples collected during the bed linen change.Lead author, Dr Susan Gould, from the Liverpool School of Tropical Medicine, said: ‘Our results found that changing a patient’s bedding appears to be particularly associated with an increased ability to detect monkeypox virus in air samples. In 2018, a UK healthcare worker was thought to have developed monkeypox after being exposed to the virus while changing a patient’s bedding, before monkeypox had been considered and diagnosed. Our results suggest that changing bed linen used by hospitalised patients with monkeypox does indeed increase the risk of exposure to virus, by disturbing virus on bed linen and allowing it to be suspended in the air.’In addition to detecting virus DNA, the researchers were able to isolate replication-competent virus in some surface and air samples. The results show, for the first time, that monkeypox virus in some air samples taken around patients hospitalised with monkeypox is capable of replicating in cells and is not just ‘dead’ virus. Dr Gould said ‘These results suggest that monkeypox virus shed into a hospitalised patient’s environment poses an infection risk that needs to be managed.’Senior author on the paper, Dr Jake Dunning, of the University of Oxford’s Nuffield Department of Medicine and the Royal Free London NHS Foundation Trust, said: ‘It is important to note that detection of virus, even when demonstrated to be infectious, does not necessarily mean that exposure to the virus in real life would result in infection of the exposed person. However, it does reveal a potential transmission risk and one that is reasonable to control in hospital settings. Our results confirm that the strict IPC measures we follow in specialist infectious diseases centres are necessary and appropriate.’This investigation specifically evaluated exposure risks when caring for patients admitted to specialist facilities in hospitals. The results and recommendations may therefore not apply to other settings, such as outpatient clinics where patients attend for a short time, interactions differ, and the virus is unlikely to accumulate to such an extent. There is no suggestion that transmission of monkeypox virus via aerosols is a common way for the infection to spread from one person to another.Dr Gould added: ‘In the context of ward-based care, our results support infection prevention and control measures designed to protect against exposure to infectious virus on surfaces and in the air, such as appropriate PPE, as well as applying measures designed to contain shed virus within hospitalised patients’ isolation rooms, including the use of negative pressure rooms and doffing areas.’The study was led by scientists from the Liverpool School of Tropical Medicine and the University of Oxford, as part of the National Institute for Health and Care Research Health Protection Unit in Emerging and Zoonotic Infections, which includes the University of Liverpool as a partner. The HPRU in Emerging and Zoonotic Infections and UKHSA identified a need for environmental sampling in hospitals managing inpatients with monkeypox and rapidly began investigations. Prior to publication the team shared its results with those caring for patients with monkeypox admitted to hospitals in the UK, and with international partners, infectious diseases specialist networks, and public health organisations.Dr Dunning said: ‘This work demonstrates the ability of HPRUs to conduct rapid, reactive studies to obtain data from novel outbreaks, focussing on research that informs public health guidance and policies, as well as improving patient care.’The study ‘Air and surface sampling for monkeypox virus in a UK hospital: an observational study’ was published in The Lancet Microbe.",0.0,0.0
336,https://www.businessinsider.com/tiktok-moderator-paid-10-dollars-day-keep-webcam-all-night-2022-10?r=US&IR=T,"An ex-TikTok moderator, who was paid $10 a day and had to scroll through child abuse and gun violence, was required to keep her webcam on all night, report says","A former TikTok moderator in Colombia was required to keep her webcam on all night while working.Moderators in Colombia are paid just $10 a day, The Bureau of Investigative Journalism reported.The moderator said the situation was ""terrible"" because she lived with her family.Sign up for our newsletter for the latest tech news and scoops — delivered daily to your inbox. Loading Something is loading. Thanks for signing up! Access your favorite topics in a personalized feed while you're on the go. download the app Email address By clicking ‘Sign up’, you agree to receive marketing emails from Insider as well as other partner offers and accept our Terms of Service and Privacy PolicyA Colombian ex-moderator for TikTok said she was required to keep her webcam on all night, according to a report by The Bureau of Investigative Journalism.TBIJ spoke to nine moderators who shared their experience but requested that their identity remained secret for fear they might lose their jobs, or risk future employment prospects. All names have been changed, according to the outlet.Carolina, a former TikTok moderator who worked remotely for Teleperformance, a Paris-based company offering moderation services and earned $10 a day, said she had to keep her camera continuously on during her night shift, TBIJ reported. The company also told her that no one should be in view of the camera and was only allowed a drink in a transparent cup on her desk.Carolina said the situation was ""terrible"" because she lived with her family. ""So I felt very guilty telling them, 'please don't pass behind the camera because I could be fired.' Teleperformance is especially paranoid with people seeing what we do.""A TikTok spokesperson told Insider in a statement: ""We strive to promote a caring working environment for our employees and contractors. Our Trust and Safety team partners with third-party firms on the critical work of helping to protect the TikTok platform and community, and we continue to expand on a range of wellness services so that moderators feel supported mentally and emotionally.""Neither TikTok nor Teleperformance responded to The Bureau of Investigative Journalism's detailed list of allegations. Teleperformance, which has more than 42,000 workers in Colombia, did not respond to Insider's request for comment.Current moderators shared with TBIJ that they had to clock in and out and log any breaks on an app called Timekeeper – but they didn't confirm whether they had to work with their cameras on.Another former TikTok moderator, Carlos, told TBIJ it was a video of child sexual abuse that had traumatized him. The video showed a girl of five or six years old: ""She was dancing, like pointing her back to the camera, it was so close.""Luis, 28, worked night shifts moderating videos for TikTok. He listed to the outlet the kind of content he sees regularly: ""Murder, suicide, pedophilia, pornographic content, accidents, cannibalism.""He recalled seeing one video taken at a party, with two people holding what initially looked like pieces of meat. When they turned around, it appeared they were holding skin and gristle flayed off human faces. ""The worst thing was that the friends were playing games and started using the human faces as masks,"" Luis said.Read the full story at The Bureau of Investigative Journalism.",0.0,0.0
503,https://techcrunch.com/2022/09/05/solar-foods-solein/,Solar Foods wants to replace industrial animal farming with a high-tech protein harvest,"Fermentation has a long, rich history in food production, from beer and wine to yogurt and cheese, leavened bread and coffee, miso and tempeh, sauerkraut and kimchi, to name just a few of the tasty things we can consume thanks to a chemical process thought to date back to the Neolithic period. But if this 2017-founded Finnish startup, Solar Foods, has its way, fermentation could have a very special place in the future of human food too.The industrial biotech startup is working on bringing a novel protein to market — one it says will offer a nutritious, sustainable alternative to animal-derived proteins. The product, a single-cell protein it’s branding Solein, is essentially an edible bacteria; a single-cell microbe grown using gas fermentation. Or, put another way, they’re harvesting edible calories from hydrogen-oxyidizing microbes.“Technically it’s like a brewery,” explains CEO and co-founder Dr. Pasi Vainikka in an interview with TechCrunch. “Like fermentation technologies are. It’s not that strange [a process] — there is this one difference, which is the feedstock.”The production of Solein requires just a handful of ‘ingredients’: Air, water and energy (electricity) — which means there’s no need for vast tracts of agricultural land to be given out to making this future foodstuff. It could be produced in factories located in remote areas or inside cities and urban centers.Nor indeed are other foods needed to feed it to create an adequate yield, as is the case with rearing livestock for human consumption. So the promise looks immense. (As Vainikka argues: “Land use and energy use are the two main problems of human kind — and the rest follows from these two.)Nutritionally speaking, Solein resembles some existing foodstuffs — sitting between dried meat, dried carrot or dried soy in terms of the blend of vitamins, amino acids, proteins (overall, it’s 65% protein), per Vainikka. “So it’s very familiar but it’s a bit [of a] new combination,” he suggests, adding: “The taste is very mild, very neutral.” (A mild taste may not sound especially scintillating for the tastebuds but it means it’s easy to include as an ingredient in a wide range of foods without the need for a strong flavor to be masked.)While Solar Foods has essentially discovered a new species through its fermentation process, the microbe itself obviously hasn’t just appeared on planet Earth — and is likely very ancient; perhaps even hundreds of millions of years old. So there’s a fascinating blend of old and new coming together in the startup’s bioreactor.Why is finding new forms of protein important? The problem Solar Foods is aiming to tackle is that the environmental costs of livestock-based meat production are indisputably massive — whether you’re talking unsustainable land and water use; climate-heating emissions and pollution; or animal welfare concerns. But what if you could produce billions of nutritious meals without the need to deforest huge swathes of land and slaughter masses of livestock to produce the food? What if humanity could feed itself and stop consuming the planet in the process?That’s the promise and the core differentiator that Solar Foods claims vs. animal-derived proteins.If you compare Solein to the growing gaggle of plant-based meat alternatives, they do still rely upon land being farmed to produce the necessary plants — whether soy or pea or oat, etc. — that form the basis of their products. Although they need far less land than meat production requires so the environment upside is still very real. But Solar Foods sees itself blending into this competitive mix — selling Solein to companies producing plant-based foods as another ingredient they can use to cook up nutritious, environmentally friendly meals.“Cereals, vegetables, fruits, herbs aren’t going anywhere,” says Vainikka, discussing how Solein might fit into an evolved food production system. “So if we go back to the original problem — 80% of all the problems that have to do with food, whether it’s loss of natural habitat or forest loss or whatever, has to do with the industrialized animal production … So actually Solein could solve 80% of the problem but 20% of the calories because mostly we are, on a calorie basis, eating carbohydrates.”And if you’re excited about the promise of lab-grown meat — which is also seeking to delink protein production from land use — Vainikka says the startup is supportive of such efforts since, once again, it’s spying potential customers as he says cultivated/lab-grown meat producers could use Solein to feed the cell cultures they’re using to grow slaughter-free steaks.So use cases for Solar Foods’ edible bacteria look broad, provided people are willing to eat it (or have it fed to something in their food chain). Conceivably it could even be used as a feedstock for livestock — although the startup’s messaging is focused on the need to transform a broken food system and enter “the era of sustainable food production,” as its website puts it.It is also working on developing a closed-loop system in which the sole byproduct of its production process — water containing bits of the Solein protein — would be continuously recycled back into production of more of the foodstuff. And if it can pull that off, the edible bacteria could potentially function as a life support system for humans on space missions where the timescales are too long for astronauts to rely on food supplies brought with them from Earth (such as, for example, a mission to Mars).“The specific thing that we think is different in what we’re doing — compared to anything else on the market today — is that we don’t use any agriculture in the foods,” Vainikka tells TechCrunch. “Electricity and carbon dioxide are the main ingredients — instead of sunlight and carbohydrates or oils. So that’s the fundamental point where the disconnection of food production from agriculture happens.“That’s our thing. And the reason to do that is once you can delink the connection between use of land and land-use impacts and food production then basically all the environmental benefits fall on your lap that there can be in relation to food production.”Down here on Earth, being able to unhitch food production from the vagaries of seasonal weather and other factors that can have major impacts on agricultural yields — such as pests, natural disasters, issues with supply chains specific to farming and so on — is another touted advantage for Solar Foods’ approach. “Security of supply … consistency and quality,” says Vainikka, checking off some of the added advantages he says the edible protein offers vs. traditional farming, i.e., on top of the massive heap of land-delinking-based environmental gains which could — for example — support a mass reforestation of farm land, promoting biodiversity and fighting global warming since trees suck up CO2.Europe’s energy crisis bitesSolein looks like a no-brainer on the environmental front. But one key component of its production — energy, i.e., electricity — is facing supply issues of its own in Europe at present in the wake of Russia’s invasion of Ukraine. (Russia being a major but unreliable supplier of gas to Europe.)Solar Foods’ long-term bet is on energy production costs being brought down (or, well, stabilized) by widespread access to cheap renewables — such as wind and hydro energy in the north of Europe and solar in the sunny south. Thing is, for now, the European energy markets are typically structured so that the wholesale price of energy is linked to the cost of the most expensive type of energy (fossil fuel derived) despite there already being a fair amount of renewable energy available which is far cheaper to produce. (Hence why if the price of gas goes up the wholesale price of energy rises, and the bill payer must pay more even if their energy supplier sources their energy from cheaper to produce renewable sources.)Since the Ukraine war started, Europe has been facing an exacerbated supply vs. demand issue. And over the past several months it’s been hard for Europeans to escape energy price spikes as their governments have sought to reduce reliance on Russian gas imports — shrinking energy supply options and helping keep war-spiked wholesale prices high.The coming winter looks very grim, with Russia recently electing to entirely shutter gas exports via its Nord Stream pipeline to Germany in what looks like an attempt to weaken Western support for the pro-Ukraine sanctions. So energy supply in Europe has become a weapon of economic war.It’s an incredibly volatile situation but one thing is clear: Europe’s ‘competitive’ marginal-cost-based energy markets are in desperate need of structural reform — to reflect the cheaper production costs of renewables and ensure consumers and businesses aren’t at the mercy of fossil fuel volatility and cripplingly high prices linked to Russian aggression.But, in the meanwhile, with electricity being a key component of Solar Foods’ process, the startup is having to manage what Vainikka — who has a background in energy economics that he says allows him to understand where the markets are headed — refers to with classic Nordic understatement as “turbulence.”He suggests Solar Foods may therefore need to wait out the current energy crisis before it’s able to scale commercial production of Solein in a way that’s economically viable — though it’s banking on Europe being able to find a way through to more stable electricity prices in the not too distant future. (In recent days, the Commission has said it will be coming with an emergency reform plan to curb energy prices — both in the short term and over the longer run, to ensure prices reflect cheaper renewables.)“At the moment we shouldn’t make electricity supply agreements for our factory. We can’t be on the market today to make those agreements,” confirms Vainikka. “Because of this [energy price volatility] — it’s a fact. The second [thing] is we are quite happy that we are not fermenting natural gas — we are fermenting electricity. So we have an opportunity to make a good deal after turbulence.”“We need to replace fossil fuels with electricity so we need a lot of new generation capacity which is also a problem in the market but we’re confident that this works,” he adds. “Unfortunately there is this turbulence now.”Solar Foods is pressing on regardless of the current energy crisis.It’s in the process of building its first factory — actually a demo facility, as a step on the road to future commercial scaling up of Solein production — at a cost of around €40 million, drawing on backing from a number of VC funds since 2017, over seed and Series A rounds, as well as raising debt financing (such as €15 million from Danske Bank Growth earlier this year).The demo facility at least won’t have major energy requirements to run. (Although he says it’s still holding off on signing an energy supply contract for now.)“We’ll manage the turbulence but of course it would be better for it not to continue too long,” says Vainikka. “We’re using this demo [facility] operated by one wind turbine to prove that this scales — but the real factories would be 100x larger in terms of energy use, 50x larger — and it would need rather 50 turbines to run a huge facility that will produce half a billion meals. Then you must get a good [energy supply] contract and if we were investing into that factory now it might be postponed because of the turbulence.”Good food and food for good?With the demo factory set to come on stream in 2023, Solar Foods’ hope is the first consumer product containing Solein will be on the market by the end of next year (or, failing that, in early 2024). Which global market will get the first commercial taste of the novel protein will depend on regulatory clearances.Solar Foods has applied for clearance in multiple jurisdictions but can’t predict whether regulators in Europe or the U.S. or Asia will be first with approval, given variances in this process. (But Vainikka says it’s possible the first clearance could happen this year.)What the first product for sale to consumers that contains Solein will be also isn’t yet clear.Vainikka suggests a few possibilities — such as that it could be added to existing foods like breakfast cereals or vegan meals for fortification purposes (owing to its vitamin and mineral content, such as iron and B vitamins); or as a main ingredient in plant-based meat replacement products, replacing stuff like pea protein. Or he says it could be used as an egg replacement in pasta or pastry production. Or as a principle ingredient in ice cream or yogurt (or even to make a spreadable faux cheese).“We leave the final formulation and product development for our customers so that we can empower them to renew categories,” he suggests. “And make having a food an act for good.”“Frankly as a company we think that it might be a good idea to focus on what we master — which is this conversion-fermentation; producing this ingredient and so that it would have the functionalities needed for food products,” he continues, expanding on Solar Foods’ decision to stay in its biotech lane. “There are so many, so huge, or so experienced or so old [food] companies on the market who have already access to the consumer, all the experience regarding textures, product development regarding all kinds of plant-based ingredients and so on. So when we introduce Solein into the market you would not only need to get everything right, what we are doing and mastering now, but also the final product — of course taste and texture is decisive.”“So that’s a heavy investment program that we’ve dived into,” he adds, emphasizing the still extensive range of requirements for developing a product that’s designed even to be an ingredient in processed foods that people eat.“Nutrition must be there … then second is safety, then functionality, of course — how it works and forms texture — and then scaling and production technology; who has it, how does it work, is it scalable, and how does the supply chain work — so who’s really the gatekeeper? So this we are in the middle of now … A lot will happen in the next 12-16 months.”While Solar Foods won’t be a food product maker itself it does have an R&D lab where it carries out culinary experiments with its product — and images on its website show a selection of demo foodstuffs, from chicken-style chunks served with pasta to soup, bread and a breakfast smoothies, all with a distinctive rich yellow hue.In its refined form — i.e., after it’s passed through Solar Foods’ electrolyzing and fermenting bioreactors and been dried — Solein takes the form of a yellow powder (the hue is down to betacarotene it naturally contains).The strong color makes it looks a bit like a custom blend of turmeric and cumin. But tastewise it’s nothing like that strong. Per Vainikka, one expert taster who sampled it suggested it was akin to dried carrot. But whether you’re a fan of carrots is beside the point; he emphasizes that the taste is mild enough that it can be easily masked in whatever food product it was being incorporated into — just without the added nutrients going anywhere.For example, in the sample case of adding Solein to pasta, Vainikka says it would — nutritionally speaking — be akin to eating, say, a plate of spaghetti bolognese with all the nourishment derived from an animal-based ingredient but without the need to have any minced meat on the plate. Which, well, might take some swallowing for those used to consuming traditional (and oftentimes culturally significant) recipes. (An Italian I described this meatless but nutritionally meat-like pasta dish to at a dinner party I attended recently was visibly shocked at the prospect and a second Italian she started to explain the concept to responded by suggesting we should focus on having fun eating the actual food on our plates instead of talking about, er, such high-concept stuff, so, well, there may be some acceptance humps in the short term.)But as plant-based faux meats advance in taste and texture it’s easy to envisage creative food producers being able to whip up something that has a meat-like taste and texture and — thanks to the addition of Solein — is also imbued with similar levels of protein, iron and vitamins as actual meat. And that could be a strong selling point for consumers, especially with the current food fad for high-protein eating.Other food ideas Solar Foods has been experimenting with in its labs are ‘cheese’ ball lollypops, mayonnaises and dressings, pancakes and plenty more besides.Vainikka says he hopes the first commercial food to contain the ingredient won’t be a burger — since there are so many meat-alternative patty options out there already. But he suggests it could be a “meat-like bite” — something akin to a nugget — such as might be be served in an Asian hot pot or similar. “Then yogurt, ice cream, soup, bakery pastry application is something that might go first,” he postulates.“You could imagine it could be a frozen food, fresh or even on the street kitchen of an Asian city,” he also suggests, saying the startup is keen to branch out and “appreciate different food cultures on the planet” — so it can “try to explain how Solein could be an ingredient in different kinds of dishes from the Asian hot pots to burger patties to soups or pastries or whatever.”Food is of course not only cultural but individual tastes can be hugely personal — and/or political. So once Solein leaves Solar Foods’ factories and arrives in customers’ commercial kitchens that’s where all these localizing product and branding challenges will really kick in — as buyers will have to work on figuring out how best to blend it in with other taste and cultural considerations or indeed make its presence stick out loudly (at least on the packet) where shouting about sustainability benefits might be the best way to reap big sales in their particular target market.One thing looks clear: The future of food won’t be dull — or even uniformly yellow hued. A full rainbow of possibilities for alternative eats are coming down the pipe — and the environmental challenges we face, as a species, demand we find the appetite to consume them.",0.0,0.0
358,https://www.bbc.co.uk/news/science-environment-63195653,Lab-grown brain cells play video game Pong,"""When people look at tissues in a dish, at the moment they are seeing if there is activity or no activity. But the purpose of brain cells is to process information in real time,"" he says. ""Tapping into their true function unlocks so many more research areas that can be explored in a comprehensive way.""",0.0,0.0
7,https://www.eenews.net/articles/global-emissions-targets-spell-growth-for-co2-tech-sector/,Global emissions targets spell growth for CO2 tech sector,"Companies that produce technologies to remove or reduce carbon emissions are “poised for strong continued growth,” reaching an expected value of $1.4 trillion by 2027, according to new market research.The research report, recently released by the financial data firm PitchBook, predicts that the sector will be worth $905 billion by the end of this year. That makes the global climate tech sector relatively small — collectively worth less than electric vehicle maker Tesla.But PitchBook predicts that the emerging sector will enjoy an 8.8 percent growth rate over the next five years, “thanks to increasing global focus on aggressive emissions targets and consumer interest in emissions reduction.” That rate could also increase if there were “dramatic regulatory change or technological innovation” during that time, the report for investors said.AdvertisementThe sector PitchBook analyzed is a broad one. It includes startups that capture or trade carbon dioxide, industrial and building firms with products that are less emissions-intensive than conventional ones, and land management companies that use or produce monitoring tools or low-emissions fertilizers.The most valuable group of companies in the space are ones working to reduce planet-warming emissions during construction and over the lifetimes of buildings. They are currently worth almost $459 billion and are expected to increase in value to $650 billion over the next five years, according to the report.That segment includes incumbents like building materials producers Holcim Group and HeidelbergCement, as well as startups like green construction firm Veev and energy efficiency company Resideo Technologies.The segment PitchBook calls “green industry” is focused on decarbonizing industrial production of chemicals and raw materials. It’s valued at more than $400 billion, according to the report. Notable firms include lithium battery recycler Redwood Materials and the mining company Lilac Solutions.PitchBook expects green industry to be the most valuable climate tech segment by 2027, with an estimated value of $657 billion. For those projections to play out, however, emissions pricing legislation like the European Union’s carbon border adjustment mechanism “will be critical to ensure that those providing green chemicals and materials are not at a disadvantage against foreign high-emissions products,” the report said.The value of low-carbon land management companies is expected to reach $30 billion this year, increasing to $49.5 billion in five years. The segment includes major monitoring firms like Honeywell and the alternative fertilizer company Pivot Bio.Venture capital investment in land management firms has recently slowed, the report noted. But the Inflation Reduction Act, which President Joe Biden signed into law in August, included more than $20 billion to support climate-smart agriculture practices and $5 billion in grants for fire-resilient forests, urban tree planting and forest conservation.The smallest but fastest-growing segment of the sector is made up of carbon technology firms like the direct air capture pioneer Climeworks and the carbon trading platform Xpansiv. They’re now valued at around $9 billion and estimated to be worth $20.9 billion by 2027.The carbon tech sector will also get a boost from Biden’s new climate law, the report said. The value of carbon captured in the United States has increased from $50 per ton to $85 for CO2 removed from smokestacks. For direct air capture projects, which suck CO2 from the atmosphere, the price they earn per ton of carbon has jumped 250 percent, to $180.But it’s not all smooth sailing for carbon capture and trading firms.“The core risk facing the carbon tech space is in the potential for the value of carbon to shift dramatically due to changes in policy and regulation,” PitchBook said. “The product of carbon tech (removing or reducing carbon) does not directly provide value — outside of some value as a feedstock for carbon utilization — and fiscal value from carbon tech activities is heavily driven by the value that legislative incentives and schemes place on carbon.”Despite that risk, investors continue to be very enthusiastic about the potential for carbon capture firms. There were 11 venture capital deals in the second quarter of 2022, raising $882.2 million for Climeworks, Carbon Clean and other firms, according to PitchBook.“This far surpasses any prior quarter, with the total invested over the previous four quarters totaling only $432.1 million,” the research firm said in another investor report published last week.",0.0,0.0
440,https://www.uq.edu.au/news/article/2022/09/research-shows-water-fluoridation-safe-children,Research shows water fluoridation is safe for children,"Research from The University of Queensland has found no link between community water fluoridation and adverse effects on children’s brain development.Professor Loc Do“We found emotional and behavioural development, and functions such as memory and self-control, were at least equivalent to those who had no exposure to fluoridated water,” Professor Do said.“In other words, there was no difference in child development and function related to fluoridated water.“This finding shows that consuming water with fluoride at levels used for public supplies in Australia is safe and it supports continuing and expanding fluoridation programs.”Currently, approximately 90 per cent of the Australian population has access to fluoridated water, although in Queensland it is 71 per cent.Many regional Queensland areas and Aboriginal and Torres Strait Islander communities are not covered by a fluoridation program.“A small but vocal group of people sometimes claims that water fluoridation can have adverse neurodevelopment effects, especially in young children,” Professor Do said.“This concern can impact community and public health support for the practice, but our research provides reassurance that it is safe and supports its expansion into more communities.“This is an important message because fluoride is extremely effective in preventing tooth decay and its use in water and toothpaste is credited with significant improvements in child dental health in Australia.”Dental caries (also known as tooth decay or dental cavities) is the most common chronic childhood disease worldwide causing pain and infection and can lead to tooth extraction.The UQ study followed up child participants of Australia’s National Child Oral Health study 2012-2014 when they were aged 12 to 17 years.It measured their emotional and behavioural development using a Strengths and Difficulties Questionnaire and executive brain function using the Behaviour Rating Inventory of Executive Function - both instruments widely used in population health surveys.The study was funded by a National Health and Medical Research Council Project grant, and it is a collaboration between The University of Queensland, University of Adelaide and University of Western Australia in Australia, along with the University of Bristol in the UK.The study is published in theMedia: Professor Loc Do,",0.0,0.0
92,https://www.tue.nl/en/news-and-events/news-overview/27-09-2022-four-terminal-perovskite-silicon-pv-tandem-devices-hit-30-efficiency/,Four terminal perovskite-silicon PV tandem devices hit 30% efficiency,"Additionally, achieving high-power density will create more opportunities to integrate these solar cells into construction and building elements, so that more existing surface area can be covered with PV modules. Breaking the 30% barrier is therefore a big step in accelerating the energy transition and improving energy security by reducing the dependency on fossil fuels.The best of both worldsTandem devices can reach higher efficiencies than single junction solar cells because of a better utilization of the solar spectrum. The currently emerging tandems combine commercial silicon technology for the bottom device with perovskite technology: the latter featuring highly efficient conversion of ultraviolet and visible light and excellent transparency to near infrared light. In four-terminal (4T) tandem devices the top and bottom cells operate independently of each other which makes it possible to apply different bottom cells in this kind of devices. Commercial PERC technology as well as premium technologies like heterojunction or TOPCon or thin-film technology such as CIGS can be implemented in a 4T tandem device with hardly any modifications to the solar cells. Furthermore, the four-terminal architecture makes it straight forward to implement bifacial tandems to further boost the energy yield.Researchers from the Netherlands and Belgium have successfully improved the efficiency of the semi-transparent perovskite cells up to 19.7% with an area of 3x3 mm2 as certified by ESTI (Italy). “This type of solar cell features a highly transparent back contact that allows over 93% of the near infrared light to reach the bottom device. This performance was achieved by optimizing all layers of the semi-transparent perovskite solar cells using advanced optical and electrical simulations as a guide for the experimental work in the lab.” says Dr Mehrdad Najafi of TNO. “The silicon device is a 20x20-mm2 wide, heterojunction solar cell featuring optimized surface passivation, transparent conductive oxides and Cu-plated front contacts for state-of-the-art carrier extraction” says Yifeng Zhao, PhD student at TU Delft, whose results have been recently peer-reviewed. The silicon device optically stacked under the perovskite contributes with 10.4% efficiency points to the total solar energy conversion.Combined, 30.1% is the conversion efficiency of this non-area matched 4T tandem devices operating independently. This world’s best efficiency is measured according to generally accepted procedures.",0.0,0.0
558,https://techcrunch.com/2022/08/15/oil-and-gas-didnt-benefit-from-investor-largesse-in-recent-years-but-renewables-did/,Oil and gas didnât benefit from investor largesse in recent years â but renewables did,"Oil and gas didn’t benefit from investor largesse in recent years — but renewables didWith the climate-and-energy-focused Inflation Reduction Act expected to be signed by President Joe Biden this week, The Wall Street Journal asked Dealogic to analyze the amount of money being loaned to “green” companies and to oil and gas companies. Investors, WSJ concludes, aren’t ready to give up on fossil fuels.But the data suggests that they’re starting to pull back already.Fossil fuel financing has been more or less steady since 2015, when the WSJ/Dealogic data series begins. For oil and gas companies, that should be a worrying trend given overall low rates and the amount of money that’s been sloshing around the market the past few years.Investment-grade bond issuance surged in 2020 before dropping to still-elevated levels in 2021. Yet fossil fuel investment didn’t follow the trend, dipping slightly instead of rising along with the market.Bonds and loans for renewable projects and companies did the opposite, ticking steadily upward from 2015 on. In 2021, they more than doubled the previous year, matching the amount invested in fossil fuels for the first time.This year, renewable companies remain neck-and-neck with oil and gas companies.",0.0,0.0
68,https://techcrunch.com/2022/10/11/earthmover-to-bring-petascale-data-tools-to-climate-tech/,Earthmover to bring petascale data tools to climate tech with $1.7M pre-seed,"Shortly after the COVID pandemic hit, inspiration struck Ryan Abernathey and Joe Hamman. The pair had been watching the “mass mobilization” of the epidemiology research community, Abernathey said.“Joe and I were both thinking at the time, ‘We wanted to be part of something with that level of intensity and urgency around climate change.’”Abernathey and Hamman met while working on open-source projects, including Pangeo and Xarray, both of which gave them a taste of where the field was heading. Abernathey, who is an associate professor of Earth and environmental sciences at Columbia University, said he saw his lab’s work on tools having a greater impact than the results of their research projects.Hamman, who previously worked at the National Center for Atmospheric Research, also foresaw how data tools could begin to change the field. The business world was benefiting from a slew of new tools that worked well for their data types. “But none of those really exist for scientific data,” he said.The pair eventually connected with Tony Liu, a partner at Costanoa Ventures who specializes in data infrastructure.“We’ve seen the transformation of the business analytics world over the last few years,” Liu said, “where you have this ecosystem of cloud-native tooling that’s emerged that really reduces the complexity for someone less specialized to set up data infrastructure in their company. We believe that a similar pattern will emerge here.“We’re seeing use of climate data increase, even among our portfolio — there’s several companies that are making use of climate data at scale. And also we expect a continued, massive investment into climate tech companies,” he added.The scale of the data, and of the problem, is why Abernathey and Hamman’s new company, Earthmover, raised a $1.7 million pre-seed round from Liu and Costanoa, TechCrunch learned exclusively.",0.0,0.0
105,https://www.washingtonpost.com/politics/2022/10/25/lawsuit-claims-google-knew-its-incognito-mode-doesnt-protect-users-privacy/,Lawsuit claims Google knew its âIncognito modeâ doesn't protect usersâ privacy,"Comment on this story Comment Gift Article ShareHi all, Gerrit De Vynck here. I’m a tech reporter for The Post out in San Francisco. You can follow me on Twitter at @GerritD. Lawsuit challenges Google’s claim that its ‘Incognito mode’ protects users’ privacy Wp Get the full experience. Choose your plan ArrowRight It can be hard to keep track of all the lawsuits against Google. The Department of Justice filed one in 2020 and might have another one coming soon. Texas has at least two. Arizona recently settled theirs with the search giant for $85 million. And Washington state and D.C. have lawsuits, too.It’s not just governments. Video game maker Epic and dating app owner Match Group are suing Google, alleging anticompetitive behavior in how it runs its app store. The Republican National Committee is suing Google for sending politicians’ emails straight to spam folders.Here’s another one to add to the list. Right now, a California judge is deliberating on whether to allow a class-action lawsuit representing millions of Google users to go forward. A group of consumers is alleging the company misled people about what data it collected when they were using private browsing modes on both Google’s Chrome web browser and browsers built by other companies such as Apple and Mozilla.AdvertisementBecause essentially all internet users in the United States use a browser to surf the web, the potential fines should Google be found liable could be in the billions of dollars.The lawyers spearheading the lawsuit have already amassed a trove of internal Google emails they say show how the company’s executives have known for years that what the company calls “Incognito mode” is anything but incognito. Private browsing modes usually block tracking cookies — little bits of code that follow people around the internet logging their activity.But Google still logged information on people using private mode whenever they visited websites that had installed hugely popular Google software used for serving ads or measuring traffic, the lawsuit alleges.The emails released as part of the court process show how Google employees repeatedly raised concerns about private mode with their superiors. One 2019 email from Google’s Chief Marketing Officer Lorraine Twohill to CEO Sundar Pichai said Incognito was “not truly private.” An internal presentation said Google users “overestimate the protections that Incognito provides.” Another one proposed getting rid of the word “private” from the Incognito mode start screen completely.AdvertisementGoogle says the accusations are overblown and that it has always been clear with its users about the limits of Incognito mode and private browsing.“Privacy controls have long been built into our services and we encourage our teams to constantly discuss or consider ideas to improve them,” Google spokesman José Castañeda said. “Incognito mode offers users a private browsing experience, and we've been clear about how it works and what it does, whereas the plaintiffs in this case have purposely mischaracterized our statements.”If the judge gives the green light, lawyers will continue their fight to get tens of millions of Google users a payment of between $100 and $1,000 each. That’s a potential payoff in the billions of dollars.Our top tabsFTC singles out Drizly executive over data privacy abusesThe Federal Trade Commission’s proposed order will follow Drizly CEO Cory Rellas to his future businesses, forcing him to implement security programs at any companies he leads that collect data from at least 25,000 people, Cat Zakrzewski reports. The punishment came after alleged security failures under Rellas’s watch that exposed around 2.5 million customers’ personal information.AdvertisementIt also comes after Democrats pushed for more aggressive penalties for individual executives involved in major data breaches. “There are only a handful of examples of the FTC pursuing such individual liability in past cases involving online data,” Cat writes. “In 2019, the agency reached a settlement with the operator of an online rewards website, ClixSense, that will follow [the executive] to future companies. That same year, the agency also named executives in an order it brought against a dress-up games website, which allegedly violated a law that protects children under the age of 13 online.”Under the order, Rellas and Drizly, which is owned by Uber, will also have to destroy unnecessary data, put new data controls in place and train their employees about cybersecurity. The FTC will decide on finalizing the order after getting public comments for 30 days.Tech groups ask Supreme Court to take up Florida social media lawThe Computer and Communications Industry Association (CCIA) and NetChoice told the Supreme Court that a Florida law that would penalize social media companies for blocking politicians’ posts violates the First Amendment rights of tech companies, according to a Monday news release. In September, Florida’s attorney general asked the Supreme Court to consider whether such a law is constitutional.AdvertisementThe filing comes amid a flurry of activity about social media laws at the Supreme Court. An appeals court blocked much of the Florida law in May but another appeals court upheld a similar Texas law in September. The court has postponed that law from going into effect until the Supreme Court reviews the case.Chinese spies accused of trying to obstruct Huawei investigationThe Justice Department said two men working on behalf of Beijing bribed a U.S. law enforcement official to share secrets about the prosecution of a major Chinese firm that people familiar with the matter said was Huawei, Devlin Barrett, Perry Stein and Ellen Nakashima report. But the official was actually a double agent working for the U.S. government who was gathering evidence against the suspects and feeding them fake documents and information.Advertisement“The U.S. Justice Department indicted Huawei Technologies in 2019, accusing the world’s largest communications equipment manufacturer and some of its executives of violating U.S. sanctions on Iran and conspiring to obstruct justice related to the investigation — prompting furious condemnations from both the company and the country,” Devlin, Perry and Ellen write. “The new charges suggest that the Chinese government went to great lengths to try to defeat the U.S. case against the company, assigning alleged Chinese intelligence officers to obtain information about witnesses and evidence. Huawei has long insisted it operates independently of the Chinese government.”A Huawei representative didn’t respond to a request for comment.Inside the industryAdvertisementWorkforce reportTrendingMentionsMichelle Giuda is joining the Krach Institute for Tech Diplomacy as its director. Giuda previously worked as an executive vice president at Weber Shandwick and as an assistant secretary of state in the Trump administration.DaybookGeoffrey Starks and Nathan Simington , as well as Amazon and SpaceX executives, FCC Commissionersand, as well as Amazon and SpaceX executives, speak at a New America event on satellite spectrum today at 11:45 a.m.Alan F. Estevez , the undersecretary of commerce for industry and security, discusses new semiconductor export controls at an , the undersecretary of commerce for industry and security, discusses new semiconductor export controls at an event hosted by the Center for a New American Security on Thursday at 10 a.m.Dave Limp the company’s satellite internet technology at a Washington Post Live event on Thursday at 10:30 a.m. Amazon senior vice president discusses the company’s satellite internet technology at a Washington Post Live event on Thursday at 10:30 a.m.Before you log offGoing into Monday with the same enthusiasm as Tim Cook pic.twitter.com/pB3N5xV8pJ — Dan - EngineMode11 (@EngineMode11) October 24, 2022That’s all for today — thank you so much for joining us! Make sure to tell others to subscribe to The Technology 202 here. Get in touch with tips, feedback or greetings on Twitter or email.GiftOutline Gift Article",0.0,0.0
106,https://www.washingtonpost.com/climate-environment/2022/10/11/rain-increasing-climate-change-us/?pwapi_token=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWJpZCI6IjQ5NzgxMjU3IiwicmVhc29uIjoiZ2lmdCIsIm5iZiI6MTY2NTUyMzA3MCwiaXNzIjoic3Vic2NyaXB0aW9ucyIsImV4cCI6MTY2NjczMjY3MCwiaWF0IjoxNjY1NTIzMDcwLCJqdGkiOiI5NmQ2Y2ZlYi00NzI4LTQ4NGItYjA1OC01NzUyYTZmOGJkMmIiLCJ1cmwiOiJodHRwczovL3d3dy53YXNoaW5ndG9ucG9zdC5jb20vY2xpbWF0ZS1lbnZpcm9ubWVudC8yMDIyLzEwLzExL3JhaW4taW5jcmVhc2luZy1jbGltYXRlLWNoYW5nZS11cy8ifQ.dNgq8ovACyzvsQj57auaVi2HD3v97xjEVkPMKhyiCHg,Study finds climate change is bringing more intense rains to U.S.,"Listen Comment on this story Comment Gift Article ShareWhen it rains, it pours. A paper published Tuesday in the journal Geophysical Research Letters finds that it’s raining harder in most of the United States. The study, written by researchers at Northwestern University, tied the results to climate change and to warmer air’s ability to hold more water. 10 steps you can take to lower your carbon footprint ArrowRight Record rain is hitting drought-stricken areas. That’s not good news. The findings echo the fundamental laws of physics and thermodynamics, as well as the evidence from decades of research, and highlight the real-time effect that humans are having on the weather and climate.The research offers confirmation of what atmospheric scientists have been warning of for years: a warmer world is, on balance, a wetter world. And as global temperatures continue to rise, an uptick in precipitation extremes is expected.Climate change is causing heavier rainsWhat the study finds is consistent with a basic tenet of atmospheric physics: For every degree Fahrenheit that air temperature rises, the atmosphere can hold 4 percent more water; this is known as the Clausius-Clapeyron relationship. Where storm clouds develop and the atmosphere is sufficiently moist, it means a warmer climate will support more intense rainfall.AdvertisementThe study reports “consistent shifts from lower to higher daily precipitation intensities, particularly in the central and eastern United States.” The authors compared rainfall over two periods — 1951 to 1980 and 1991 to 2020 — to see how patterns evolved.“When it’s raining, it’s raining more,” said Ryan Harp, the author lead author on the study, in an interview. “But what we also did was … we were able to verify some of the expectations we had based on modeling studies.”In other words, most similar studies to date had centered on projections made by forward-running computer models fed with historical data. This is among the first that, on a nationwide level, examine observed daily rainfall trends.“I think during that process we were a little surprised that this paper hasn’t been written before,” said Daniel Horton, a study co-author and a professor at Northwestern University, in an interview. “We know that precipitation should be increasing … but we just wanted to do a very straightforward paper that says, ‘Yep, we’re seeing it.’ ”AdvertisementHarp said the fact that reality matched simulations lends credence to climate models.“People should in general be trusting in climate models,” he said. “We’re constantly working to improve them to the best of our abilities.”Not necessarily more rain overall, and not everywhereIn the study, the authors examined daily data from more than 1,700 weather stations distributed in the Lower 48. Each had to have a continuous record dating back to at least 1951 to be included in the study.In the eastern United States, the researchers observed a 4.5 to 5.7 percent increase in average daily rainfall on days when it rained. That does not say there are more days with rain, or more rain overall.“That doesn’t necessarily give us the whole story,” Harp said. “There may be places where precipitation intensity is increasing but frequency is decreasing. We might not know if there’s an overall increase or decrease. That’s one thing that we’re working on.”Greg Carbin, the head of forecast operations at the National Weather Service Weather Prediction Center, who was not involved in this research, appreciated that the study touched on the “paradox of potentially fewer precipitation days with higher-intensity precipitation occurring on those days.”Carbin has noted a trend of more rain falling on fewer days in his analysis of recent precipitation.Advertisement“Overall, the area covered by the count of 1-inch rainfall days was lower than in recent years across large parts of the central and eastern U.S.,” Carbin wrote in an email. “In fact, moderate to severe drought has plagued areas of the Northeast, and extreme to exceptional drought is now expanding across part of the central U.S. Nonetheless, we have had extreme rainfall events occur in St. Louis, Dallas, eastern Kentucky, and, most recently, with Hurricane Ian in Florida.”Despite strong trends in the central and eastern United States, the authors noted that there were a few places where rainfall did not appear to be growing more intense. The paper does detail “mixed signals in the western U.S.,” but for reasons the authors are still trying to identify.“That [trend] didn’t hold true for the western U.S.,” said Harp, especially in the Pacific Northwest. He explained that changes in the overall placement of weather systems are “suppressing” any tendency for heavier precipitation in the West. A slight change in the location at which high and low pressure systems are anchored can have an enormous bearing on steering currents, and subsequently on how much precipitation falls in a given location.Changing precipitation trends poses societal challengesWith the planet continuing to warm, a continued increase in rainfall intensity can be expected. That spells concern over whether existing infrastructure can handle the downpours of the future.AdvertisementCommunities may need to turn to simulated precipitation events of the future to guide building decisions, Horton said.The past summer was a testament to the extent to which climate-supercharged downpours can wreak havoc on major metropolitan areas. During a five-week span in July and August, five 1,000-year rain events — or extremely heavy rainfall episodes that have a 0.1 percent chance of happening in any given year — occurred across the nation.“Recent years have seen some remarkable high-end precipitation events,” Carbin said.GiftOutline Gift Article",0.0,0.0
304,https://fortune.com/2022/10/18/mark-zuckerberg-meta-avatars-video-chat-zoom-fatigue/,Mark Zuckerberg has a $10 billion plan to make it impossible for remote workers to hide from their bosses,"At least digital humanoids don’t get Zoom fatigue—yet.During the Meta Connect 2022 live keynote last week, CEO Mark Zuckerberg discussed his new plans for Meta to bring avatars—uncanny digital stand-ins for human workers—to video chats.They would be customized to match a person’s exact skin tone, hairstyle, and outfit choices. According to Zuckerberg, an entirely virtual roundtable meeting would consist of you and your coworkers’ avatars chatting in something like a “third mode” between fully camera-on and camera-off.“You can still express yourself and react, but you’re not on-camera, so it’s kind of like a better camera-off mode,” he said.The social media giant invested $10 billion in building the metaverse last year, a digital space where users can interact with experiences and other people using VR technology. Zuckerberg revealed the video chat avatar feature in the key note after announcing partnerships with several companies, including one with Microsoft chairman and CEO Satya Nadella that would bring Microsoft apps to Meta Horizon Workrooms—the VR metaverse rooms where workers’ avatars meet—to create “a unified, digital office we think can make distributed work so much better.”As Intelligencer’s John Herrman points out, all of this could be a strategy to diversify Meta’s business—but it could also be a play at acknowledging execs’ challenges with remote work and trying to rectify them. The opportunity for a “better camera-off mode” just might be an answered prayer for the bosses unhappy with the remote workers who tend to join meetings with their web cameras off.Is seeing still believing?Proximity bias, which describes bosses tending to prefer workers they can see in person, has long been proven. It also may explain why managers who are used to commandeering a physical office would be thrilled if they could see their workers—even if that required them to wear an elaborate headset that costs as much as a Peloton.A 20,000-person survey by Microsoft itself found that bosses are still regularly questioning their remote employees’ productivity levels. Some have even taken draconian measures to ensure that their ideal level of productivity is met. Per August research from the New York Times, eight out of the 10 largest private employers in the U.S. track productivity metrics, including active online time, incidence of keyboard pauses, how long it takes to write an email, and even individual keystrokes.Zuckerberg’s enthusiasm about metaverse meetings, and the support from a tech sector heavyweight like Nadella, may speak to exactly this kind of “productivity paranoia.”But some experts are wary of a full-scale pivot to the metaverse. “We would have to carefully attend to the physical implications of headsets,” Roshni Raveendhran, assistant professor at the University of Virginia’s Darden School of Business, told Fortune last year. “Like if it harms our eyesight or implicates our brain functions; we don’t know any of these things now, and we won’t know until there’s more of a continual usage pattern. We need to pay attention to some of those before we go into full-scale adoption.”The metaverse is unlikely to be as all-encompassing as Zuckerberg hopes, says Cathy Hackl, a futurist and metaverse expert. For instance, meetings that hinge on deeper bonding or team building, such as new hire orientations or holiday parties, are still best done in person. “Your company can’t treat you to a cocktail virtually,” she told Fortune.And with even the most advanced VR devices, Hackl added, she hits her limit around the 45-minute mark. “I don’t think I could wear a headset for a six-hour video call.”",0.0,0.0
74,https://www.nationalgeographic.co.uk/science-and-technology/2022/10/many-scientists-see-fusion-as-the-future-of-energy-and-theyre-betting-big,Many scientists see fusion as the future of energy â and they're betting big.,"Even with massive investment, there are very high hurdles still to overcome: technical challenges such as fuel performance and reactor maintenance; political challenges, too, although the Americans, the Europeans, the Russians, the Chinese, the Japanese and the Australians have all warmed to the idea.As have Britons. In October 2021, the Department for Business, Energy & Industrial Strategy published its strategy on nuclear fusion. This form of energy, it notes, will be abundant, efficient, carbon-free, safe, and will produce radioactive waste much shorter-lived than that of current nuclear power stations.Arthur Turrell is a former plasma physicist at Imperial College London, and author of a 2021 book, The Star Builders: Nuclear Fusion & the Race to Power the Planet. He says that “controlling fusion to produce energy is the biggest technological challenge we’ve ever taken on as a species”. He explains how fusion reactors, or “star machines”, are indescribably complex, with tens of millions of individual parts.The science bitSo just how does nuclear fusion work? It is the fusing of light nuclei to form a heavier nucleus, at the same time releasing huge amounts of energy. It’s what happens in the middle of stars like our Sun, providing the power that drives the universe. Crucially, it’s the opposite of nuclear fission, the process used in nuclear power stations whereby huge amounts of energy are released when nuclei are split apart to form smaller nuclei.The Sun notwithstanding, humans are currently experimenting with two main methods of fusion. JET, for example, uses what’s known as magnetic confinement fusion: two isotopes of hydrogen – deuterium and tritium – are heated to temperatures up to 150 million degrees Celsius, becoming an electrically-charged gas called plasma, which is confined in the doughnut-shaped tokamak, and controlled with strong magnetic fields. The deuterium and tritium fuses together to produce helium and high-speed neutrons, releasing vast amounts of energy in the process – 10 million times more energy per kg of fuel than that released by burning fossil fuels. As Turrell neatly explains, the mass of deuterium-tritium fuel equivalent to an Olympic swimming pool of water would contain more energy than the entire planet uses in a year.",0.0,0.0
203,https://www.businessinsider.com/evs-nasa-charged-electric-car-5-minutes-tech-2022-10,Electric vehicles could be charged within 5 minutes thanks to tech developed by NASA for use in space,"A cooling system developed by NASA for electronics in space could be used to help charge electric cars.The system could, in theory, allow electric cars to be charged in just five minutes, NASA said.The heat-transfer system can cool cables carrying high currents, potentially allowing super-fast charging without the risk of overheating.Sign up for our newsletter for the latest tech news and scoops — delivered daily to your inbox. Loading Something is loading. Thanks for signing up! Access your favorite topics in a personalized feed while you're on the go. download the app Email address By clicking ‘Sign up’, you agree to receive marketing emails from Insider as well as other partner offers and accept our Terms of Service and Privacy PolicyResearchers have found that NASA technology developed for use on the International Space Station could also be used to charge electric vehicles at a much faster rate than in currently possible.The complex cooling technique, which has been developed to help certain electrical systems in space maintain proper temperatures, can deliver almost five times the current of other electric vehicle chargers currently on the market, NASA said in a blog post.Higher electrical currents generate more heat, meaning the more current flowing, the higher likelihood of components overheating.NASA's complex heat transfer system, known as ""subcooled flow boiling,"" can cool cables carrying high charges, potentially allowing for a faster flow of electricity without the risk of components overheating, according to the blog post.In the blog, NASA said the system had been developed to help deliver ""nuclear fission power systems for missions to the Moon, Mars, and beyond; vapor compression heat pumps to support Lunar and Martian habitats; and systems to provide thermal control and advanced life support onboard spacecraft.""Current charging time for EVs range from less than 20 minutes at some public fast charging stations to days or hours when using at-home chargers.NASA claims the new heat transfer system could reduce the charging time at charging stations to just five minutes.NASA said in a blog post: ""Application of this new technology resulted in unprecedented reduction of the time required to charge a vehicle and may remove one of the key barriers to worldwide adoption of electric vehicles.""The US government has been ramping up investment in electric car charging to meet its target of installing 500,000 electric-car chargers across the country by 2030.Slow charging and unreliable charging stations have been an issue for some EV owners.",0.0,0.0
21,https://www.japantimes.co.jp/news/2022/10/04/world/politics-diplomacy-world/us-limits-tech-to-chinese/,U.S. plans new limits on tech sent to Chinese firms,"The administration of U.S. President Joe Biden is expected to announce new measures to restrict Chinese companies from getting access to technologies that enable high-performance computing, according to several people familiar with the matter, the latest in a series of moves aimed at hobbling Beijing’s ambitions to craft next-generation weapons and automate large-scale surveillance systems.The measures, which could be announced as soon as this week, would be some of the most significant steps taken by the Biden administration to cut off China’s access to advanced semiconductor technology. They would build on a Trump-era rule that struck a blow to Chinese telecom giant Huawei by prohibiting companies around the world from sending it products made with the use of American technology, machinery or software.",0.0,0.0
4,https://www.engadget.com/zipline-drone-delivery-medicine-utah-114733625.html,Zipline drones will deliver medicine to communities in Utah,"Zipline has teamed up with a healthcare provider servicing the Intermountain Region in the US to deliver medicine to customers using its drones. The company has started doing drone deliveries to select Intermountain Healthcare patients in the Salt Lake Valley area. For now, it can only do drops for local communities within several miles of its distribution center. Zipline intends to add more centers over the next five years, though, so it can eventually expand beyond Salt Lake Valley and deliver medicine throughout Utah.As TechCrunch notes, Zipline has long been deploying drones for delivery in Africa, and it wasn't until the pandemic that it started doing drops in the US. In 2020, it teamed up with Novant Health to ferry personal protective gear and other types of medical equipment to frontline healthcare workers tending to COVID-19 patients in North Carolina. Later that year, it signed a deal with Walmart to deliver health and wellness supplies to customers near the retailer's headquarters in northwest Arkansas.In June this year, the FAA authorized Zipline to conduct long range on-demand commercial drone deliveries in the US. The company said that the certification it received from the agency allows it to significantly expand its services in the country. That means we'll see it expand its covered areas with current partners and perhaps see it sign agreements with more partner companies in the future.Turn on browser notifications to receive breaking news alerts from Engadget You can disable notifications at any time in your settings menu. Not now Turned on Turn onIntermountain Healthcare patients in the Salt Lake Valley area can now sign up for Zipline deliveries. The company will then evaluate their eligibility based on their location, their yard size — its target delivery area must be at least two parking spaces big — and their surrounding airspace. Zipline's drones are six-foot gliders with a wingspan that's 10 feet long. These drones fly 300 to 400 feet above the ground, though they drop down to an altitude of around 60 to 80 feet to deliver packages outfitted with a parachute.Bijal Mehta, head of global fulfillment operations at Zipline, said in a statement:",0.0,0.0
592,https://techcrunch.com/2020/02/09/hannah-seal-interview/,Index Fundâs portfolio is driving long-overdue innovation in femcare,"Index Fund’s portfolio is driving long-overdue innovation in femcare 'It’s a category that’s been underserved for a long time,' says principal Hannah SealU.K. startup Daye is rethinking female intimate care from a woman’s perspective, starting with a tampon infused with cannabidiol that tackles period pain.It’s also quietly demolishing the retrograde approach to “femcare” product design that not only peddles stale and sexist stereotypes, but also can harm women’s bodies.Those perfumed sanitary pads stinking out the supermarket shelf? Whomever came up with that idea has obviously never experienced thrush or bacterial vaginosis nor spoken to a health professional who could have told them vaginal infections can be triggered by perfumed products.The missing link: There are few people with a vagina in positions leading product strategy. And that’s the disruptive opportunity female-led femcare businesses like Daye are closing in on.The Index Ventures-backed startup is shaking up a tired category by selling the flip-side: thoughtfully designed products for period care that do no harm and take aim at actual problems women have, starting with dysmenorrhea (otherwise known as menstrual cramps). The overarching strand is building community to help women better understand what’s going on with their bodies and reinforce shifting product expectations in the process.We chatted with Index principal Hannah Seal about the fund’s investment in Daye and to get her thoughts more broadly on a new generation of female-focused startups that are driving long-overdue innovation.The interview has been edited for length and clarity.",0.0,0.0
22,https://www.inverse.com/science/nasa-ufo-uap-study-team-members,NASA announces its unidentified aerial phenomena research team to examine mysterious sightings,"A 16-person team — including an astronaut, a space-treaty drafter, a boxer, and several astrobiologists — will soon begin its review of unexplained aerial phenomena (UAP) for NASA.The space agency announced Friday the members of the team, who will labor over the course of nine months starting on Monday to analyze unclassified data on UAPs, peculiar sightings of objects behaving unlike anything we’re familiar with. But until the full report is released to the public in mid-2023, NASA says everything will be kept a secret.UAPs get their classification due to their puzzling behavior in the sky, which doesn’t fit into the known behavior of aircraft or known natural phenomena. NASA will unpack the data to come up with a way to study the unknown.NASA says their work will “lay the groundwork” for future UAP studies. This first phase is a brainstorm, to see how observations that civilian government entities and commercial data have gathered could be analyzed. And then, they’ll look at how future data can be collected.NASA will hold a public meeting after the report is released to discuss the study’s findings, an event that curious onlookers might want to earmark.The space agency says officials are excited to see what the team uncovers. “NASA is going in with an open mind,” the space agency writes in a Frequently Asked Questions webpage devoted to UAPs. “And we expect to find that explanations will apply to some events and different explanations will apply to others. We will not underestimate what the natural world contains, and we believe there is a lot to learn.”Is it aliens? The short answer is, NASA doesn’t know. The space agency chooses to highlight its search for extraterrestrial life when it publishes new information about the new UAP study. But agency officials have also been candid about where the data stands. They explicitly stated back in June that, “there is no evidence UAPs are extra-terrestrial in origin.”Meet the UAP teamDaniel Evans, the assistant deputy associate administrator for research at NASA’s Science Mission Directorate, orchestrated the study.The 16-member team includes:",0.0,0.0
201,https://arstechnica.com/gadgets/2022/09/stadia-controllers-could-become-e-waste-unless-google-issues-bluetooth-update/,Stadia controllers could become e-waste unless Google issues Bluetooth update,"Google's Stadia game-streaming service will die a nearly inevitable death early next year. Google is refunding players the cost of all their hardware and game purchases. But, so far, Google is also leaving Stadia players with controllers that, while once costing $70, will soon do less than a $20 Bluetooth gamepad.Stadia's controllers were custom-made to connect directly to the Internet, reducing lag and allowing for instant firmware updates and (sometimes painful) connections to smart TVs. There's Bluetooth inside the Stadia controller, but it's only used when you're setting up Stadia, either with a TV, a computer with the Chrome browser, or a Chromecast Ultra.The Google Store's page for the Stadia controller states in a footnote: ""Product contains Bluetooth Classic radio. No Bluetooth Classic functionality is enabled at this time. Bluetooth Classic may be implemented at a later date."" (Bluetooth Classic is a more traditional version of Bluetooth than modern low-energy or mesh versions.)That potential later date can't get much later for fans of the Stadia controller. Many cite the controller's hand feel and claim it as their favorite. They'd like to see Google unlock Bluetooth to make their favorite something more than a USB-only controller and avoid a lot of plastic and circuit board trash.""Now if you'd just enable Bluetooth on the controller, we could help the environment by not letting them become electronic waste,"" writes Roadrunner571 on one of many controller-related threads on the r/Stadia subreddit. ""They created trash and they at least owe it to me to do their best within reason to prevent millions of otherwise perfectly good controllers from filling landfills,"" another wrote.Many have called for Google, if they're not going to push a firmware update themselves to unlock the functionality, to open up access to the devices themselves, so the community can do it for them. That's often a tricky scenario for large companies relying on a series of sub-contracted manufacturers to produce hardware. Some have suggested that the full refunds give Google more leeway to ignore the limited function of their devices post-shutdown.AdvertisementYou can still plug the Stadia controller into the USB port on your Smart TV, computer, or gaming console and use it as a controller through a standard HID (Human Interface Device) connection. How-To Geek reports that it's working well on PCs and with Android devices but not great on Xbox or Playstation consoles. At least one Github project reportedly improves the Stadia controller's Windows function (as an Xbox controller). One intrepid Stadia fan, Parth Shah, had already cobbled together a ""Stadia Wireless"" Python hack to get the Stadia controller working ""wirelessly"": connected to a phone, then that phone connecting to a Windows PC over Wi-Fi, emulating a standard Xbox controller.Yet Shah is also active in the Stadia subreddit, asking for his creation to be made obsolete: ""Not having to go through all this trouble would be so amazing. Hopefully [G]oogle does something about it.""There's some precedent to pushing new firmware to old business ideas. Valve, makers of the Steam PC gaming store and assorted hardware connected to it, enabled Bluetooth Low-Energy on Steam Controllers just before its Steam Box and Steam Link hardware ambitions fizzled out. Valve had something else in mind for them, namely its Steam Link software on other platforms. But Valve made Steam Controllers viable for lots of other platforms and prevented them from ending up in, at best, e-waste sorting facilities.E-waste from abandoned hardware is an area where Google, along with many other large tech companies, is far more quiet than it is about carbon emissions, water, or even food waste. The company's pledge to create ""A circular Google"" states that the company believes that by ""incorporating circularity into our designs from inception, things created today can become the resources of tomorrow and enable reuse, repair, and recovery.""In this case, it seems like circularity, in the form of a standard Bluetooth controller, is sitting inside Stadia controllers. The reuse and recovery would be much appreciated by customers.",0.0,0.0
322,https://www.msn.com/en-us/news/us/facebook-workers-are-reportedly-under-duress-as-meta-stock-craters/ar-AA13uDlp,Facebook workers are reportedly under duress as Meta stock craters,"© Olivier Douliery, AFP Via Getty Images In this file photo illustration taken on March 24, 2020, a Facebook logo is displayed on a smartphone in Arlington, Virginia.Workers at the Bay Area-based tech behemoth Meta, the owners of Facebook, Instagram and the struggling Meta Quest VR devices, are reportedly feeling the pinch as the company's stock falters dramatically.According to a Business Insider report from Wednesday, Facebook workers are feeling heightened pressure to overperform or get sacked.The publication, speaking with multiple anonymous Facebook employees, alleges that a new mandate has been implemented: Workers must “put in 200% effort” within three months — or quit.The report added that even high achievers in the company are not immune to layoffs.This detail dovetails with a recent open letter by prominent shareholder Brad Gerstner, who called for a cutback in Meta funding and a 20% cutback in staff costs.“Like many other companies in a zero rate world — Meta has drifted into the land of excess — too many people, too many ideas, too little urgency,” Gerstner wrote in a Medium post Monday.A Meta spokesperson disputed the specifics of the Business Insider report in a statement to SFGATE, but referenced Zuckerberg’s last earnings call in which he discussed plans to “steadily reduce headcount growth over the next year.”“This is a period that demands more intensity, and I expect us to get more done with fewer resources,” Zuckerberg said at the time. “We're currently going through the process of increasing the goals for many of our efforts. Previously challenging periods have been transformational for our company and helped us develop our next generation of leaders. I expect this period to be no different.”Meta stock cratered by nearly 25% at the end of the day Thursday, the lowest price it’s been since 2016, CNBC reported. (The share cost has risen marginally as of Friday morning, but remains below the $100 mark.) The decline comes after Facebook reported a decline in profit and revenue year over year.Hear of anything going on at Meta or at another Bay Area tech company? Contact Joshua Bote securely on Signal at 707-742-3756.",0.0,0.0
3,https://www.eurekalert.org/news-releases/958880,Strange new phase of matter created in quantum computer acts like it has two time dimensions,"By subjecting a quantum computer’s qubits to quasi-rhythmic laser pulses based on the Fibonacci sequence, physicists demonstrated a way of storing quantum information that is less prone to errorsBy shining a laser pulse sequence inspired by the Fibonacci numbers at atoms inside a quantum computer, physicists have created a remarkable, never-before-seen phase of matter. The phase has the benefits of two time dimensions despite there still being only one singular flow of time, the physicists report July 20 in Nature.This mind-bending property offers a sought-after benefit: Information stored in the phase is far more protected against errors than with alternative setups currently used in quantum computers. As a result, the information can exist without getting garbled for much longer, an important milestone for making quantum computing viable, says study lead author Philipp Dumitrescu.The approach’s use of an “extra” time dimension “is a completely different way of thinking about phases of matter,” says Dumitrescu, who worked on the project as a research fellow at the Flatiron Institute’s Center for Computational Quantum Physics in New York City. “I’ve been working on these theory ideas for over five years, and seeing them come actually to be realized in experiments is exciting.”Dumitrescu spearheaded the study’s theoretical component with Andrew Potter of the University of British Columbia in Vancouver, Romain Vasseur of the University of Massachusetts, Amherst, and Ajesh Kumar of the University of Texas at Austin. The experiments were carried out on a quantum computer at Quantinuum in Broomfield, Colorado, by a team led by Brian Neyenhuis.The workhorses of the team’s quantum computer are 10 atomic ions of an element called ytterbium. Each ion is individually held and controlled by electric fields produced by an ion trap, and can be manipulated or measured using laser pulses.Each of those atomic ions serves as what scientists dub a quantum bit, or ‘qubit.’ Whereas traditional computers quantify information in bits (each representing a 0 or a 1), the qubits used by quantum computers leverage the strangeness of quantum mechanics to store even more information. Just as Schrödinger’s cat is both dead and alive in its box, a qubit can be a 0, a 1 or a mashup — or ‘superposition’ — of both. That extra information density and the way qubits interact with one another promise to allow quantum computers to tackle computational problems far beyond the reach of conventional computers.There’s a big problem, though: Just as peeking in Schrödinger’s box seals the cat’s fate, so does interacting with a qubit. And that interaction doesn’t even have to be deliberate. “Even if you keep all the atoms under tight control, they can lose their quantumness by talking to their environment, heating up or interacting with things in ways you didn’t plan,” Dumitrescu says. “In practice, experimental devices have many sources of error that can degrade coherence after just a few laser pulses.”The challenge, therefore, is to make qubits more robust. To do that, physicists can use ‘symmetries,’ essentially properties that hold up to change. (A snowflake, for instance, has rotational symmetry because it looks the same when rotated by 60 degrees.) One method is adding time symmetry by blasting the atoms with rhythmic laser pulses. This approach helps, but Dumitrescu and his collaborators wondered if they could go further. So instead of just one time symmetry, they aimed to add two by using ordered but non-repeating laser pulses.The best way to understand their approach is by considering something else ordered yet non-repeating: ‘quasicrystals.’ A typical crystal has a regular, repeating structure, like the hexagons in a honeycomb. A quasicrystal still has order, but its patterns never repeat. (Penrose tiling is one example of this.) Even more mind-boggling is that quasicrystals are crystals from higher dimensions projected, or squished down, into lower dimensions. Those higher dimensions can even be beyond physical space’s three dimensions: A 2-D Penrose tiling, for instance, is a projected slice of a 5-D lattice.For the qubits, Dumitrescu, Vasseur and Potter proposed in 2018 the creation of a quasicrystal in time rather than space. Whereas a periodic laser pulse would alternate (A, B, A, B, A, B, etc.), the researchers created a quasi-periodic laser-pulse regimen based on the Fibonacci sequence. In such a sequence, each part of the sequence is the sum of the two previous parts (A, AB, ABA, ABAAB, ABAABABA, etc.). This arrangement, just like a quasicrystal, is ordered without repeating. And, akin to a quasicrystal, it’s a 2D pattern squashed into a single dimension. That dimensional flattening theoretically results in two time symmetries instead of just one: The system essentially gets a bonus symmetry from a nonexistent extra time dimension.Actual quantum computers are incredibly complex experimental systems, though, so whether the benefits promised by the theory would endure in real-world qubits remained unproven.Using Quantinuum’s quantum computer, the experientialists put the theory to the test. They pulsed laser light at the computer’s qubits both periodically and using the sequence based on the Fibonacci numbers. The focus was on the qubits at either end of the 10-atom lineup; that’s where the researchers expected to see the new phase of matter experiencing two time symmetries at once. In the periodic test, the edge qubits stayed quantum for around 1.5 seconds — already an impressive length given that the qubits were interacting strongly with one another. With the quasi-periodic pattern, the qubits stayed quantum for the entire length of the experiment, about 5.5 seconds. That’s because the extra time symmetry provided more protection, Dumitrescu says.“With this quasi-periodic sequence, there’s a complicated evolution that cancels out all the errors that live on the edge,” he says. “Because of that, the edge stays quantum-mechanically coherent much, much longer than you’d expect.”Though the findings demonstrate that the new phase of matter can act as long-term quantum information storage, the researchers still need to functionally integrate the phase with the computational side of quantum computing. “We have this direct, tantalizing application, but we need to find a way to hook it into the calculations,” Dumitrescu says. “That’s an open problem we’re working on.”ABOUT THE FLATIRON INSTITUTEThe Flatiron Institute is the research division of the Simons Foundation. The institute's mission is to advance scientific research through computational methods, including data analysis, theory, modeling and simulation. The institute's Center for Computational Quantum Physics aims to develop the concepts, theories, algorithms and codes needed to solve the quantum many-body problem and to use the solutions to predict the behavior of materials and molecules of scientific and technological interest.",0.0,0.0
43,https://techcrunch.com/2022/07/13/xfuel-hopes-to-sail-past-biofuels-troubled-past-with-modular-reactor-design/,XFuel hopes to sail past biofuelsâ troubled past with modular reactor design,"Biofuels are the sirens of renewable energy, luring startups with enchanting promises of enormous markets, from aviation to trucking and shipping. Companies just can’t help throwing themselves at the problem, and more than a few have been dashed to pieces in the process.One new startup, though, hopes it’s Ulysses in this tale, able to sail past the rocky shores that have sunk more than a few of its predecessors.XFuel is pinning its hopes on a modular refinery design that it says can produce replacement fuels for marine shipping and diesel vehicles with a carbon footprint that’s up to 85% lower now and possibly carbon-neutral in the future.Today, the Dublin-based startup announced an €8.2 million investment round led by AENU, a new German VC firm, and joined by Union Square Ventures and HAX/SOSV.XFuel is currently making marine- and diesel-grade fuels and developing aviation fuels.“It is a direct replacement for the fossil counterparts,” co-founder and CEO Nicholas Ball said. “The focus here was to develop a technology to be able to produce fuel at a comparable or lower price point than fossil fuels. We went down this R&D path for a number of years, a lot of trial- and-error-type work.”The result, he said, is a demonstration plant in Spain that “proves out the technology that we have and the modularity that we’re trying to encompass here.”The heart of XFuel’s work revolves around what the company calls mechanical catalytic conversion, which takes plant material and uses heat, chemical reactants and friction to help break it down. (Ball, when pressed, wouldn’t be more specific than that.)",0.0,0.0
321,https://www.nytimes.com/2022/10/26/technology/meta-facebook-q3-earnings.html,Metaâs Profit Slides by More Than 50 Percent as Challenges Mount,"A year ago, Mark Zuckerberg changed Facebook’s name to Meta and said he was going all in on the immersive digital world of the so-called metaverse.Since then, Meta has plowed billions of dollars into, and restructured itself around, the emerging technology — just as the global economy has slowed, inflation has soared and investors have begun paying more attention to costs.The combination has been nothing short of disastrous. This year, Meta’s earnings have been hit hard by its spending on the metaverse and its slowing growth in social networking and digital advertising. In July, the Silicon Valley company posted its first sales decline as a public company. Its stock has plunged more than 60 percent this year.On Wednesday, Meta continued that trajectory and indicated that the decline would not end anytime soon. It said it would be “making significant changes across the board to operate more efficiently,” including by shrinking some teams and by hiring only in its areas of highest priority.",0.0,0.0
2,https://www.eurekalert.org/news-releases/965575,Being lonely and unhappy accelerates aging more than smoking,"Deep Longevity bridges the gap between the concepts of biological and psychological aging. According to the new aging clock, vulnerable mental health has a stronger effect on the pace of aging compared to a number of health conditions and smokingMolecular damage accumulates and contributes to the development of aging-related frailty and serious diseases. In some people these molecular processes are more intense than in others, a condition commonly referred to as accelerated aging.Fortunately, the increased pace of aging may be detected before its disastrous consequences manifest by using digital models of aging (aging clocks). Such models can also be used to derive anti-aging therapies on individual and population levels.According to the latest article published in Aging-US , any anti-aging therapy needs to focus on one’s mental health as much as on one’s physical health. An international collaboration led by Deep Longevity with US and Chinese scientists have measured the effects of being lonely, having restless sleep, or feeling unhappy on the pace of aging and found it to be significant.The article features a new aging clock trained and verified with blood and biometric data of 11,914 Chinese adults. This is the first aging clock to be trained exclusively on a Chinese cohort of such volume.Aging acceleration was detected in people with a history of stroke, liver and lung diseases, smokers, and most interestingly, people in a vulnerable mental state. In fact, feeling hopeless, unhappy, and lonely was shown to increase one’s biological age more than smoking. Other factors linked to aging acceleration include being single and living in a rural area (due to the low availability of medical services).The authors of the article conclude that the psychological aspect of aging should not be neglected either in research or in practical anti-aging applications. According to Manuel Faria from Stanford University:“Mental and psychosocial states are some of the most robust predictors of health outcomes — and quality of life — yet they have largely been omitted from modern healthcare”.Alex Zhavoronkov, the CEO of Insilico Medicine, points out that the study provides a course of action to“slow down or even reverse psychological aging on a national scale.Earlier this year, Deep Longevity released an AI-guided mental health web service FuturSelf.AI that is based on a preceding publication in Aging-US. The service offers a free psychological assessment that is processed by an AI and provides a comprehensive report on a user’s psychological age as well as current and future mental well-being. Deepankar Nayak, the CEO of Deep longevity affirms,""FuturSelf.AI, in combination with the study of older Chinese adults, positions Deep Longevity at the forefront of biogerontological research"".About Deep LongevityDeep Longevity developed the Longevity as a Service (LaaS)© solution to integrate multiple deep biomarkers of aging dubbed “deep aging clocks” to provide a universal multifactorial measure of human biological age. Deep Longevity is owned by Hong Kong Stock Exchange listed Endurance Longevity (SEHK:0575.HK).",0.0,0.0
42,https://techcrunch.com/2022/07/18/united-arab-emirates-launches-820m-fund-to-boost-domestic-space-economy/,United Arab Emirates launches $820M fund to boost domestic space economy,"The United Arab Emirates will pour more than $800 million into space initiatives through a massive new fund, with the first investment going toward the establishment of a remote sensing satellite constellation.That constellation, called “Sirb” (the Arabic word for a flock of birds), will use synthetic aperture radar technology to capture high-resolution images. The country listed border control, oil spill detection and ship detection and tracking among the practical uses for the satellites. The UAE aims to launch the first satellite in three years, with the entire satellite program to last around six years. It did not specify the total amount it plans to invest in the constellation.The 3 billion AED ($820 million) National Space Fund, announced Monday, is the latest signal that the country is looking to the space sector to help diversify its oil-dependent economy. As of 2020, oil exports made up nearly 30% of total gross domestic product. However, the UAE’s Ministry of Economy counts space among its “promising economic sectors,” and its space program has undertaken a number of major programs in the past five years.The UAE established an astronaut program in 2017; one of its two astronauts will fly to the International Space Station in 2023 as part of a long-duration mission with Axiom Space. That astronaut, Hazza Al Mansoori, was the first person from the Emirates to go to space in a 2019 mission to the ISS.KhalifaSat, the first satellite that was entirely designed and manufactured in the Emirates, was launched to orbit in 2018. Since, the UAE sent an orbiter to Mars in 2020, announced plans to send a 22-pound rover to the moon with Japanese startup ispace and said it would send a probe to the asteroid belt between Mars and Jupiter, with the aim of ultimately landing on an asteroid in the early 2030s.The National Space Fund will “actively encourage partnerships between international and local enterprises,” according to a statement. The country will also seek solicitation from local and international companies for the Sirb satellite constellation.",0.0,0.0
97,https://techcrunch.com/2022/06/22/zap-energy-nets-160m-series-c-to-advance-its-lightning-in-a-bottle-fusion-tech/,Zap Energy nets $160M Series C to advance its lightning-in-a-bottle fusion tech,"Fusion startupFusion startupFusion powerFusion powerStill, clever new approaches to contain scorching hot plasma — which burns at more than 100 million degrees Celsius — have brought fusion power tantalizingly close to reality. Investors are flocking to the field, hopeful that advances wrought by continued research and increasingly sophisticated computer simulations will finally help fusion pull away from its long string of failures.Still, clever new approaches to contain scorching hot plasma — which burns at more than 100 million degrees Celsius — have brought fusion power tantalizingly close to reality. Investors are flocking to the field, hopeful that advances wrought by continued research and increasingly sophisticated computer simulations will finally help fusion pull away from its long string of failures.Zap Energy’s oversubscribed Series C was led by Lowercarbon Capital. New investors include Breakthrough Energy Ventures, Shell Ventures, DCVC and Valor Equity Partners. Existing investors Addition, Energy Impact Partners and Chevron Technology Ventures also contributed to the round. The startup’s core technology was spun out of research performed at the University of Washington and Lawrence Livermore National Laboratory.Zap Energy’s oversubscribed Series C was led by Lowercarbon Capital. New investors include Breakthrough Energy Ventures, Shell Ventures, DCVC and Valor Equity Partners. Existing investors Addition, Energy Impact Partners and Chevron Technology Ventures also contributed to the round. The startup’s core technology was spun out of research performed at the University of Washington and Lawrence Livermore National Laboratory.Generally speaking, fusion power generates electricity by fusing hydrogen isotopes (either deuterium or tritium) into helium. The process releases neutrons, which are then captured to generate heat and spin a turbine. Atomic nuclei don’t like to fuse, so to coax them close enough for fusion to happen, nuclear scientists use extreme pressure and heat, creating a fourth state of matter known as plasma.Generally speaking, fusion power generates electricity by fusing hydrogen isotopes (either deuterium or tritium) into helium. The process releases neutrons, which are then captured to generate heat and spin a turbine. Atomic nuclei don’t like to fuse, so to coax them close enough for fusion to happen, nuclear scientists use extreme pressure and heat, creating a fourth state of matter known as plasma.",0.0,0.0
515,https://www.gq-magazine.co.uk/lifestyle/article/weight-loss-drugs-tirzepatide/amp,Is the world ready for extremely effective weight-loss drugs?,"Earlier this summer, Forrest Smith got some promising news. The Denver-based petroleum engineer, who works for the National Park Service, had read reports on a new diabetes medication called tirzepatide. Clinical trials had confirmed a potent side effect: Tirzepatide users could shed up to 20 percent of their body weight. Smith told me he spent his childhood cast as “the fat kid in school,” and his adulthood locked in a cycle of losing pounds and regaining them. Though he is not diabetic, he was aware that some doctors were prescribing the drug for weight loss and, feeling like he had nothing to lose, sought one out for treatment. He took his first weekly injection in July, and says it was like “a switch was flipped overnight.” Food cravings disappeared. When watching skinny friends eat, he used to wonder, “How do you not eat that entire plate of cookies in front of you?” That all changed. “One cookie? Totally doable.”View moreHe now weighs 236 pounds, 24 pounds down from when he began the medication. Smith’s spouse and parents were so impressed with his progress that they decided to seek out tirzepatide, too. His young children have noticed that running around their garden now tires them out before their father. Since his first shot, Smith has been reaching deeper into his closet for clothes that will fit. “Hopefully,” he said, “I don't find parachute pants—I don’t have to go that far back.”Tirzepatide (marketed by Eli Lilly and Company as Mounjaro) first became available to the American public in May of 2022, when it was approved by the United States Food and Drug Administration (FDA) as a diabetes treatment. And while FDA approval for using the drug specifically for weight loss appears imminent, doctors have the authority to deviate from FDA mandates when prescribing drugs, and some have been writing scripts to treat obesity at their own discretion. “I’ve been very excited about these medicines,” said Dr. Melanie Jay, director of NYU Langone’s Comprehensive Program on Obesity. “[Obesity] has always been something that's under-treated.” It might be the trickle that precedes a torrent—tirzepatide is just one in a class of new extremely effective weight loss drugs that threaten to upend the way we think about and treat obesity.Many people are under the misconception that their weight can be completely controlled by diet and exerciseThat class of drugs is called incretins. Initially created to spur insulin production in diabetic patients, incretins often left participants in drug trials with two notable side effects: satiety and delayed gastric emptying. In other words, recipients feel full quicker, while food itself moves from stomach to intestine more slowly, which makes you feel even more full. The combination of those effects caused patients to eat less and consistently lose weight.To understand why these drugs could be so revolutionary, you need to understand how obesity works—which is often different from the way it’s talked about. Many people are under the misconception that their weight can be completely controlled by diet and exercise. (Look no further than the 18 seasons of The Biggest Loser for evidence.) But researchers and doctors are more inclined to think of the condition as just that: a chronic health condition. “Our brains regulate our appetite, and they regulate our metabolism,” said Jay. For the obese, those regulations are set to retain weight. A healthy lifestyle can help prevent obesity, but when a person who’s already overweight goes on a diet, their bodies increase appetite and decrease metabolism. The weight returns. (Exercise doesn’t seem to matter much at all.) These patients—a huge proportion of Americans—often aren’t well-served by the medical establishment. And as Matt Yglesias recently pointed out for Grid, the body-positivity movement has advocated for people to seek health at any size—an understandable reaction, but one that can obscure the real health costs of obesity.The effective treatment options for obesity that already exist are under-used. Bariatric surgery, for example, can be an effective way to address extra weight. But surgery is seen as a drastic option, and Americans tend to think poorly of weight loss surgery. Without a comorbidity like diabetes, a prospective candidate typically needs a BMI of at least 40 to undergo the surgery—and only a small sliver of those who qualify get the procedure. That’s one reason why obesity experts see so much promise in the new drugs.But there are big hurdles to widespread adoption, and not just questions of cost and approval that every drug faces on its way to the public. Weight loss drugs have a checkered past. “If you look back in the history of obesity, drugs that have been approved have then been taken off the market,” says Dr. Spencer Nadolsky, a physician who runs the obesity program for telehealth provider Weekend Health. Dangerous amphetamines were used as appetite suppressants, and more recent drugs, like Fen-Phen, a weight loss drug widely used in the 1990s, caused heart problems, leading to an FDA ban. Safer weight loss drugs began to reappear in the 2000s, but their efficacy was often mild.Incretins, on the other hand, are only continuing to get more effective. The newest of these medications cause around 20 percent weight loss, within the same range that bariatric surgery achieves. And while common side effects include nausea and other gastrointestinal distress, it's a much less disruptive medical intervention than surgery.One obesity expert at Harvard Medical School, Dr. Fatima Stanford, told me that some patients have reacted so strongly to one incretin, semaglutide, that they’ve avoided surgery completely. “They went from severe obesity with diabetes to no diabetes and no severe obesity—into a healthy weight range,” she said. “It’s effortless for them—we’re changing the way their brains see weight.” This has major quality of life implications. “When you have higher levels of obesity,” said Jay, “losing 15 or 20% of your body weight is huge, right? It's huge for resolving comorbidities and preventing diabetes, and all sorts of things.”One Washington woman in her 50s named Suzy, who asked to only be identified by her first name, has lost 26 pounds since starting tirzepitide. She has three siblings and two parents with type two diabetes. With the drug, she thinks she can avoid that disease. Another woman, Rachel McLaughlin, who started an oral incretin in 2021, said weight loss gave her the confidence to join an art class. “I don’t look like I’m carrying the weight of the world around,” she said.But remarkable advances in medical technology don’t mean much if they’re impossible to access. McLaughlin faced that setback when she lost her job earlier this year. Losing health insurance increased the cost of her prescription from $25 (£22) to more than $2,000 (£1,772) per month. Off the medication, she regained 15 of the 25 pounds she’d lost. Progress only resumed once she found a new job in June that restored her coverage.Like other diabetes medications, incretins are meant to be taken indefinitely. Dr. Mike Albert, co-founder of Accomplish Health, a telehealth company specializing in obesity, said the biggest influences over what he prescribes are cost and coverage. “That’s the limiter,” he said. “If a medicine is not covered on a health plan, or under the benefits of a health plan, or if it is cost prohibitive, it doesn't matter how good I think it will do for this person.”Medicare, which heavily influences how private insurance charts its own plans, doesn’t cover anti-obesity medications. (In an unfortunate twist, Medicare’s policy on obesity meds came in partial response to the Fen-Phen scandal.) A bill sitting in Congress called the Treat and Reduce Obesity Act would change that, but its fate remains unclear.Changing how both the public and health care system views obesity won't happen overnight—after all, it was only in 2013 that the American Medical Association acknowledged obesity as a chronic illness.“Most primary care doctors, unfortunately, still suffer from an obesity stigma and bias,” said Nadolsky. If you cornered a doctor at a dinner party, Stanford said, they’d likely be able to tell you how to treat an esoteric condition like Behcet’s disease. “Then if you ask them about obesity, which affects almost half the population, they would look like, I don't know what to do.”This all means that widespread adoption of incretins for weight loss still faces significant barriers. There is also the thorny (and still mostly theoretical) question of whether these drugs are appropriate for people who simply want to lose a few pounds. But for patients currently experiencing obesity and metabolic dysfunction, the possibilities a prescription brings are already too great to ignore. Suzy told me that she and her husband are planning to travel through Europe in retirement—unthinkable until she began a tirzepatide regimen. McLaughlin has travel plans too, but she's focusing on the beginning of the trip. “I cannot wait to get on a plane,” she said, “and take a seat comfortably.”",0.0,0.0
289,https://www.thenationalnews.com/travel/news/2022/08/23/worlds-first-floating-pod-homes-launched-in-panama-starting-at-295000/,"Worldâs first floating pod homes launched in Panama starting at $295,000","Panama will be home to the world's first community of floating SeaPods, with the inaugural pod now in the water at Linton Bay Marina in Colon.Ocean Builders, a company specialising in innovative marine technology, has officially launched what it says are the first floating eco-restorative pod homes in the world.Perched three metres above sea level on the Caribbean coast of Panama, the futuristic units are designed to accommodate two people and are on sale now, with prices ranging from $295,000 to $1.5 million.By December, the first overnight guests will be able to bed down in the pods, and 100 fully-owned units will be ready for full-time residents by summer next year.A second batch of more than 1,000 of the pods will go into production next year.Designed by Dutch architect Koen Olthuis, the futuristic SeaPods are geared toward climate-conscious travellers who want to live on the water, but don’t want to give up the luxuries of modern living.Futuristic living on the water from $295,000Master bedrooms come with epic views over the ocean. Photo: Ocean BuildersWith minimalist decor, curved walls and an ultra-sleek design, the SeaPod flagship model looks like something from The Jetsons. It is spread over 77 square metres of space that's split across three levels.There's a master bedroom with epic views, a living room and kitchen, a bathroom and an outdoor patio. Wraparound panoramic windows give residents 360-degree unobstructed ocean views.Wooden teak flooring, colour-changing lights and wireless charging stations are available in each SeaPod, which also comes with automated black-out blinds and sliding panel windows.Entirely customisable, there's the option to add climbing walls, greenhouses, skylights, hot tubs and patio gardens.Cutting-edge technology is at the heart of Panama's newest waterfront destination, with each pod using software to control lighting, internal air temperature, water pressure and more.Guests wear a smart ring that can be used to control technology settings, as well as being used to unlock doors, open windows and turn on music and mood lighting. Wireless charging stations are built into several of the pod's surfaces so that chargers and wires for phones become a thing of the past.Daily drone delivery and new marine habitatsDaily essentials such as groceries and medicine are flown in by drones that have been designed to easily withstand open ocean conditions. Self-driving boats remove rubbish, compost and recycling and, when they're not on duty, work to clean up the surrounding ocean waters by expelling trash to help mitigate human impact on the ocean even beyond the community.The SeaPods are designed so that each one can function as a new habitat for marine life. Photo: Ocean BuildersSustainability is a key focus for Ocean Builders and pods are designed to be respectful of their surrounding environment.The pods have been designed to become marine habitats for fish and other creatures, and artificial intelligence cameras will monitor what goes on beneath the waves. Marine detection technology is available to alert pod residents when dolphins, whales or their other favourite sea creatures are nearby.Ocean Builders officially launched three models on Monday. They include the original SeaPod, the GreenPod for land living and the EcoPod, a more affordable option of each version.The single-level SeaPod Eco is slightly smaller than the flagship version and laid out on a single floor, but includes the same principles, technology options and customisable design features.12 futuristic cities being built around the world, from Saudi Arabia to China — in pictures",0.0,0.0
212,https://reneweconomy.com.au/huge-new-nickel-mine-aims-for-100-pct-renewables-with-worlds-biggest-renewable-micro-grid/,Australiaâs huge new nickel mine will host worldâs biggest renewable micro-grid,"The massive $1.7 billion West Musgrave nickel and copper project – given the green light by Australian mining company Oz Minerals late last week – will be a groundbreaking project for the sheer scale and influence of the renewable energy resources it proposes to harness.Oz Minerals aims to reach 100 per cent renewable power at the remote mine – located in Western Australia near the borders with South Australia and the Northern Territory – and will start off by providing more than 80 per cent of its power needs from what will be the world’s biggest renewable energy micro-grid.Modelling done so far indicates an optimal mix of around 60MW of solar and 90MW of wind, along with a sizeable battery – although the specifications of the battery have yet to be finalised.Oz Minerals believes this configuration will allow the mine and its processing plant to run on “diesel off” or “renewables only” for extended periods.The size of the battery will likely be decided by the extent to which the company can tailor the operators of the mine and processing plant to when the wind is blowing and the sun is shining, and how much of excess output can afford to be spilled.See this story for more information on that: Mopping up spilled energy: Mining giant looks to take next step to 100% renewablesLargest renewable micro grid in worldAll this will make it one of the largest operations in the world running on wind and solar only, and its “game changing” operations will be highly informative for the operators of Australia’s national grid which intend to follow the same path over the next decade.The recognition that wind and solar can play such a significant role even – or perhaps especially – in such a remote location has been one of the decisive factors helping OZ Minerals commit to one of the world’s lowest cost and lowest emission operations.The cost is important, and so are the emissions, given the Oz Minerals intends to “ride the global electrification wave” and target the surging demand for nickel and copper for electric vehicles, along with the boom in wind, solar and storage in the grid.The cost of powering such plants with diesel – or gas via a new pipeline – would have been prohibitive. And by focusing on renewables and solar, Oz Minerals has absolute clarity on its electricity costs for the life of the mine.The West Musgrave transport fleet will initially be powered by fossil fuels, but the company intends to switch to electrify the haul truck fleet at the first opportunity, likely to be the first engine change-out.It hopes to increase the penetration of renewables to reach net zero scope 1 emissions well before 2038, and expects technology advancements will help it make the leap from 80 per cent to full renewables, most likely in the areas of storage.Low cost and low emissionsOz Minerals has actually been looking at the renewables options for West Musgrave for many years – we first wrote about it in 2018 – because it knew then that powering the mine with fossil fuels wasn’t a viable option.It has long recognised that at such a remote location a big share of renewables was the key to helping it deliver one of the world’s lower cost and lowest emissions copper and nickel mining projects.The fact that it will supply a low emissions supply of nickel and copper will be important for the electric vehicle markets that it intends to tap into, because EV makes also want to ensure their supply chains are low carbon too.Oz Minerals is currently seeking bids from vendors before finalising the best mix of wind, solar, battery and diesel, and will then sign a long term power purchase agreement with an option to buy the energy component outright at a later date.The mine is being built on the land of the Ngaanyatjarra people.",0.0,0.0
67,https://techcrunch.com/2022/10/12/2422480/,Carbon accounting platform acquired by Sage as climate tech heats up,"Spherics, a U.K.-based carbon accounting platform for SMEs to understand and reduce their environmental impact, has been acquired by accounting giant Sage. Terms of the deal were not disclosed but it’s understood Spherics had raised £1.25 million in equity financing from angel investors and £300,000 in grants.Spherics was a smaller startup playing in a similar space to larger ones, which include Normative, Plan A, Klimametrix.global, Persefoni and Planetly.com (other carbon accounting players, like Watershed and Climatiq, operate more like consultants).Sage previously stated it plans to support SMEs to get to net zero, and this acquisition appears to be part of their strategy.Spherics automates the process of calculating emissions by ingesting data from a company’s accounting software and matching transactions to gauge an estimate of their carbon footprint. It can also apply carbon emission factors to procurement categories (such as delivery, accommodation, electricity and travel).“We know that SMBs care about the impact they have on the environment, and our research shows that they want to work with suppliers and partners that can help them understand and address it,” said Amaya Souarez, EVP Cloud Operations, Sage, in a statement. “By combining Spherics’ innovative software with Sage’s digital network, we are connecting businesses with their customer and supplier emissions data, enabling easy and collaborative climate action across value chains which helps to reduce carbon.”George Sandilands, CEO and co-founder of Spherics, added: “Our vision and mission align very much with Sage’s core values, and we are excited to embark on this new journey to help SMBs knock down barriers to a more sustainable future. Global emissions are still rising fast, and we need immediate and meaningful climate action across the world.”Headquartered in Bristol, United Kingdom, Spherics is the second Bristol startup to be acquired by Sage in the last year, after Brightpearl was picked up in 2021.Bristol seems to be making a habit of climate tech, also producing Ecologi Zero, real-time carbon footprinting software for businesses.",0.0,0.0
298,https://interestingengineering.com/innovation/startup-3d-print-homes-recyclable-plastics,This startup 3D prints tiny homes from recyclable plastics,"""The construction sector is the largest global consumer of raw materials, responsible for approximately 11 percent of the world's total carbon emissions. Our responsibility to our customers and future generations is to use the most sustainable practices imaginable,"" said Ross Maguire, the CEO of Azure, in April.Azure also unveiled what it called the world's first 3D printed ""backyard studio"" made with recycled plastic materials in the same month.The plastic 3D printed studios and accessory dwelling units (ADUs) - meaning legal and regulatory terms for a secondary house or apartment that shares the building lot of a larger, primary home - are now available for preorder as the startup prepares to ramp up its production line in the Culver City neighborhood of Los Angeles.Azure uses recyclable plastics to build homes. AzureFaster, cheaper, and sustainable homes with 3D printingAzure sticks up for building homes 70 percent faster and 30 percent cheaper than ""traditional home construction methods."" As Business Insider says, most 3D home builders use a form of mixed or pure concrete to build a home. However, Azure is ""saying goodbye"" to this by using sustainable materials.Azure's printing materials consist of the waterproof plastic polymer generally found in plastic bottles and packaging food, according to the startup.""Our supply chain should never be short in our lifetime,"" told Ross Maguire to Business Insider.""We have created production efficiencies not only by capitalizing on the advances in 3D printing but by creating a design and process that is completed in only 20 hours. When compared with conventional construction, we produce the entire structural skeleton, the exterior sheathing, the water control barrier, the exterior finish, the passageways for utilities, and the grounding for interior finishes, in a fraction of the time and cost. By revolutionizing a new age of the home building with our sustainable, automated, and exact production processes, we see a very, very exciting future ahead,"" further added Maguire in April to describe the startup's goal.",0.0,0.0
278,https://techcrunch.com/2015/08/17/new-stretchy-electronics-will-help-us-stay-healthy-and-safe/,New Stretchy Electronics Will Help Us Stay Healthy And Safe,"Researchers at the Air Force Research Laboratory at Wright-Patterson Air Force Base are working on a new form of electronics encased in a stretchy, bendable casing that allows you to wrap leads around body parts and even sense strain and stress in buildings, airplanes, and other vehicles. The product of the Department of Defense’s Flexible Hybrid Electronics Manufacturing Innovation Institute, the material can be used in any situation where flexibility and high pressure are the norm.“Basically, we are using a hybrid technology that mixes traditional electronics with flexible, high-performance electronics and new 3-D printing technologies,” said Benjamin J. Leever, Ph.D. “In some cases, we incorporate ‘inks,’ which are based on metals, polymers and organic materials, to tie the system together electronically. With our technology, we can take a razor-thin silicon integrated circuit, a few hundred nanometers thick, and place it on a flexible, bendable or even foldable, plastic-like substrate material.”The team is using liquid gallium alloys injected into the substrate to carry electricity. Because the alloys are never exposed to air you efficiently prevent oxidation. The material can then be “integrated into complex curved surfaces, such as an airplane’s wing, or even a person’s skin.” The team also sees some value in the material for weapons. For example, a slice of this material connected to a bomb could survive the initial impact with a target to control the final payload detonation. In short, it acts as a tough skin and sensor for highly sensitive situations.",0.0,0.0
394,https://arstechnica.com/science/2022/10/a-bold-effort-to-cure-hiv-using-crispr/,A bold effort to cure HIVâusing Crispr,"In July, an HIV-positive man became the first volunteer in a clinical trial aimed at using Crispr gene editing to snip the AIDS-causing virus out of his cells. For an hour, he was hooked up to an IV bag that pumped the experimental treatment directly into his bloodstream. The one-time infusion is designed to carry the gene-editing tools to the man’s infected cells to clear the virus.Later this month, the volunteer will stop taking the antiretroviral drugs he’s been on to keep the virus at undetectable levels. Then, investigators will wait 12 weeks to see if the virus rebounds. If not, they’ll consider the experiment a success. “What we’re trying to do is return the cell to a near-normal state,” says Daniel Dornbusch, CEO of Excision BioTherapeutics, the San Francisco-based biotech company that’s running the trial.The HIV virus attacks immune cells in the body called CD4 cells and hijacks their machinery to make copies of itself. But some HIV-infected cells can go dormant—sometimes for years—and not actively produce new virus copies. These so-called reservoirs are a major barrier to curing HIV.Advertisement“HIV is a tough foe to fight because it’s able to insert itself into our own DNA, and it’s also able to become silent and reactivate at different points in a person’s life,” says Jonathan Li, a physician at Brigham and Women’s Hospital and HIV researcher at Harvard University who’s not involved with the Crispr trial. Figuring out how to target these reservoirs—and doing it without harming vital CD4 cells—has proven challenging, Li says.While antiretroviral drugs can halt viral replication and clear the virus from the blood, they can’t reach these reservoirs, so people have to take medication every day for the rest of their lives. But Excision BioTherapeutics is hoping that Crispr will remove HIV for good.Crispr is being used in several other studies to treat a handful of conditions that arise from genetic mutations. In those cases, scientists are using Crispr to edit peoples’ own cells. But for the HIV trial, Excision researchers are turning the gene-editing tool against the virus. The Crispr infusion contains gene-editing molecules that target two regions in the HIV genome important for viral replication. The virus can only reproduce if it’s fully intact, so Crispr disrupts that process by cutting out chunks of the genome.In 2019, researchers at Temple University and the University of Nebraska found that using Crispr to delete those regions eliminated HIV from the genomes of rats and mice. A year later, the Temple group also showed that the approach safely removed viral DNA from macaques with SIV, the monkey version of HIV.",0.0,0.0
455,https://techcrunch.com/2022/06/10/meet-felix-williams-a-vc-who-started-his-own-firm-at-the-age-of-19/,"Why Felix Williams, who started a VC firm at 19, believes his youth gives him an advantage as an investor","Felix Williams is the founder and managing director ofFelix Williams is the founder and managing director ofTechCrunch sat down with Williams to learn more about how he got into venture capital, and his plans for the future.TechCrunch sat down with Williams to learn more about how he got into venture capital, and his plans for the future.When did you first become interested in venture capital? How did you break into it?When did you first become interested in venture capital? How did you break into it?While growing up, I had no idea what venture capital was. The concept made sense; who wouldn’t want to be invested in ‘Google’ in the early days, but the idea of an industry that did precisely that was foreign to me until about 16 years old. At the time, there was a fund in St. Louis, iSelect Fund, that was growing rapidly and needed some help doing Excel/database work. I’d have to say that performing that grunt work was the best thing that has happened to me in my professional life. In a few weeks, I was engulfed in the venture and startup worlds. Reading about activity in the ecosystem became my dopamine hit, and I was hooked. I felt like the luckiest teenager in the world, having gotten the opportunity to watch some of the best and brightest people I had ever seen try and solve the problems we are afflicted with, the problems we see on the news every day. The notion of work that I felt in my previous job at a national tutoring chain fell away and was replaced with a sense of purpose.While growing up, I had no idea what venture capital was. The concept made sense; who wouldn’t want to be invested in ‘Google’ in the early days, but the idea of an industry that did precisely that was foreign to me until about 16 years old. At the time, there was a fund in St. Louis, iSelect Fund, that was growing rapidly and needed some help doing Excel/database work. I’d have to say that performing that grunt work was the best thing that has happened to me in my professional life. In a few weeks, I was engulfed in the venture and startup worlds. Reading about activity in the ecosystem became my dopamine hit, and I was hooked. I felt like the luckiest teenager in the world, having gotten the opportunity to watch some of the best and brightest people I had ever seen try and solve the problems we are afflicted with, the problems we see on the news every day. The notion of work that I felt in my previous job at a national tutoring chain fell away and was replaced with a sense of purpose.When did you start your venture firm? What challenges did you face? Did you find it difficult to be taken seriously because of your age at the time? How old were you exactly?When did you start your venture firm? What challenges did you face? Did you find it difficult to be taken seriously because of your age at the time? How old were you exactly?Lagomaj was born a week or two before my 19th birthday. At the time, our path forward wasn’t always clear. For example, I was mistaken for an intern in multiple meetings and generally not taken too seriously at networking or industry events. It wasn’t unusual for founders to take calls mid-pitch or check their messages when it was my turn to ask questions. I learned quickly that the best way to go about working was to build a rapport with someone via email or phone before a face-to-face meeting. Referrals and testimonials went a long way in establishing credibility with people outside my growing network, but that network is what kept me going. I was inspired by the people in my life. There is something very special about working with individuals who devote their lives to working on huge problems. Passion drives the best innovators that we’ve ever known, and there were times where founders and I were able to share a common passion, and those deals have turned out to be some of my favorite ones to have been involved with. As we’ve started building a more robust reputation, my age has become less of an obstacle and more of an advantage as some of my viewpoints are often different from the typical GP.Lagomaj was born a week or two before my 19th birthday. At the time, our path forward wasn’t always clear. For example, I was mistaken for an intern in multiple meetings and generally not taken too seriously at networking or industry events. It wasn’t unusual for founders to take calls mid-pitch or check their messages when it was my turn to ask questions. I learned quickly that the best way to go about working was to build a rapport with someone via email or phone before a face-to-face meeting. Referrals and testimonials went a long way in establishing credibility with people outside my growing network, but that network is what kept me going. I was inspired by the people in my life. There is something very special about working with individuals who devote their lives to working on huge problems. Passion drives the best innovators that we’ve ever known, and there were times where founders and I were able to share a common passion, and those deals have turned out to be some of my favorite ones to have been involved with. As we’ve started building a more robust reputation, my age has become less of an obstacle and more of an advantage as some of my viewpoints are often different from the typical GP.What is your firm’s investment thesis? How much have you raised? What are some of your portfolio companies?What is your firm’s investment thesis? How much have you raised? What are some of your portfolio companies?While we don’t disclose how much we’ve deployed or how much has been committed to the fund, I can say that we have done more than 45 deals with check sizes ranging anywhere from a few hundred thousand to $5 million, most of the time landing somewhere in the middle. In 2021, we invested more than we did in 2017-2020 combined. We currently have a presence in St. Louis, Austin and Southern California, and spend time looking nationally for primarily B2B deals involving early-stage companies. Our fund is especially keen on aligning incentives with the entrepreneurs we work with through a multi-decade investing horizon, participation through multiple rounds, and our willingness to do deals outside of a normal-priced round. For example, we completed a cutting-edge research and development facility with one of our portfolio companies that is seeking to transform how we produce and think about food. That deal is quite different from what most VC funds will take on, but we believed it to be critical to the advancement of a better food system, and we pursued it. Unlike some other funds, we do not consider ourselves an Impact or ESG fund. Our mission is to find passionate people doing extraordinary things for the world we live in, and when you do that, you output ESG gains. I am proud to say that most companies in the portfolio are working towards at least one UN sustainable development goal.While we don’t disclose how much we’ve deployed or how much has been committed to the fund, I can say that we have done more than 45 deals with check sizes ranging anywhere from a few hundred thousand to $5 million, most of the time landing somewhere in the middle. In 2021, we invested more than we did in 2017-2020 combined. We currently have a presence in St. Louis, Austin and Southern California, and spend time looking nationally for primarily B2B deals involving early-stage companies. Our fund is especially keen on aligning incentives with the entrepreneurs we work with through a multi-decade investing horizon, participation through multiple rounds, and our willingness to do deals outside of a normal-priced round. For example, we completed a cutting-edge research and development facility with one of our portfolio companies that is seeking to transform how we produce and think about food. That deal is quite different from what most VC funds will take on, but we believed it to be critical to the advancement of a better food system, and we pursued it. Unlike some other funds, we do not consider ourselves an Impact or ESG fund. Our mission is to find passionate people doing extraordinary things for the world we live in, and when you do that, you output ESG gains. I am proud to say that most companies in the portfolio are working towards at least one UN sustainable development goal.An early win we had was with Agrible and itsAn early win we had was with Agrible and itsWhy did you open an office in Austin?Why did you open an office in Austin?We think that Austin complements our presence in St. Louis well. Both cities have a growing tech scene that is not yet saturated with VC firms, and each has different focuses at the core of their startup ecosystems. In St. Louis, we see an exceptionally robust hard science market, especially bioscience, while in Austin, the focus and growth that we have seen has been more software-centric. Austin too, has many macro trends going for it, such as its desirability for young professionals, a culture that facilitates growth and a considerably strong talent pool. The city has been tremendously welcoming, and we are grateful to be part of its story.We think that Austin complements our presence in St. Louis well. Both cities have a growing tech scene that is not yet saturated with VC firms, and each has different focuses at the core of their startup ecosystems. In St. Louis, we see an exceptionally robust hard science market, especially bioscience, while in Austin, the focus and growth that we have seen has been more software-centric. Austin too, has many macro trends going for it, such as its desirability for young professionals, a culture that facilitates growth and a considerably strong talent pool. The city has been tremendously welcoming, and we are grateful to be part of its story.What are your long-term goals/plans?What are your long-term goals/plans?Over the next few years, our top priority is to build an engine that can invest at scale using data and software to augment the human decision-making process. Although we’ve been operating for a few years now, I am not shy in telling people we are still in the development stages. Our processes and thesis will continue to evolve as we bring in new team members with much more experience than I have. We’re building capabilities on both the ventures and support sides for post-investment portfolio company guidance. In the next two years, like many of our portfolio companies, we plan to forgo profitability and invest heavily in the infrastructure that will position us well in the decades to come. Every day, we refine our offering to investors and portfolio companies. Every day, we will continue that process to ensure that when we go out for our next big fundraising round down the road, we will be poised to do well. It is our opinion that venture as it stands now won’t last forever, and we want to be positioned well for when that paradigm shift starts to manifest itself.Over the next few years, our top priority is to build an engine that can invest at scale using data and software to augment the human decision-making process. Although we’ve been operating for a few years now, I am not shy in telling people we are still in the development stages. Our processes and thesis will continue to evolve as we bring in new team members with much more experience than I have. We’re building capabilities on both the ventures and support sides for post-investment portfolio company guidance. In the next two years, like many of our portfolio companies, we plan to forgo profitability and invest heavily in the infrastructure that will position us well in the decades to come. Every day, we refine our offering to investors and portfolio companies. Every day, we will continue that process to ensure that when we go out for our next big fundraising round down the road, we will be poised to do well. It is our opinion that venture as it stands now won’t last forever, and we want to be positioned well for when that paradigm shift starts to manifest itself.Although 2022 has certainly been interesting as allocators re-evaluate their portfolios, our conviction in particular technology and trends has never been higher. We’re ecstatic about continuing to invest in companies and partnerships at the confluence of innovation and market adoption.Although 2022 has certainly been interesting as allocators re-evaluate their portfolios, our conviction in particular technology and trends has never been higher. We’re ecstatic about continuing to invest in companies and partnerships at the confluence of innovation and market adoption.",0.0,0.0
303,https://www.theregister.com/2022/11/02/windows_11_statcounter/,Windows 11 runs on fewer than 1 in 6 PCs,"Much of the Windows world has yet to adopt Microsoft's latest desktop operating system more than a year after it launched, according to figures for October collated by Statcounter.Just 15.44 percent of PCs across the globe have installed Windows 11, meaning it gained 1.83 percentage points in a month. This compares to the 71.29 percent running Windows 10, which fell marginally from 71.88 percent in September.Windows 7 is still hanging on with a tenuous grip, in third place with 9.61 percent, Windows 8.1 in fourth with 2.45 percent, plain old Windows 8 with 0.69 percent, and bless its heart, Windows XP with 0.39 percent because of your extended family.In total, Windows has almost 76 percent of the global desktop OS market followed by OS X with 15.7 percent and Linux with 2.6 percent.Android comprised 42.37 percent of total operating system market share, with Windows trailing on 30.11 percent, iOS on 17.6 percent, OS X on 6.24 percent, and Linux on 1.04 percent.Statcounter is a web analytics service with tracking code installed on 1.5 million websites, recording billions of page views for each site. AdDuplex collates stats from Microsoft Store apps that contain the AdDuplex SDK (estimated to be 5,000 apps) and it claimed that Windows 11 had 23 percent market share in June.Microsoft releases activation data to PC markers but this is not made public.It almost didn't happen...Windows 11 launched on October 5, 2021. It is the OS most never thought would happen after Microsoft said some six years earlier: ""With Windows 10, the experience will evolve and get even better over time. We'll deliver new features when they're ready, not waiting for the next major release. We think of Windows as a Service.""One reason for the new release was improved security and reliability, Microsoft said, including hardware root of trust via Trusted Platform Module (TPM) 2.0, Secure Boot, hypervisor-protected code integrity, and hardware-enforced stack protection.The release also managed to alienate a bunch of folk due to its hardware requirements. Microsoft decided that Windows 11 would not install on devices that lack a recent TPM-equipped CPU, and while there is a workaround it's an imperfect solution.According to Lansweeper data, some 42.76 percent of 27 million PCs it tested across 60,000 organizations failed the CPU test, and it said this was forcing users who didn't want to upgrade hardware to stick with Windows 10.Most corporate enterprises have yet to migrate to Windows 11 – typically they wait for 18 months after an OS has launched before upgrading business computers. The entire PC ecosystem will be waiting with bated breath to see if that happens next year or whether businesses will want to sweat assets for longer in a nod to uncertain economic times. ®",0.0,0.0
361,https://techcrunch.com/2022/02/09/scopio-aims-to-turn-hematology-into-remote-work-with-50m-c-round/,Scopio aims to turn hematology into remote work with $50M C round,"Today, if a hematologist wanted to dive into the exact organization and structure of your blood cells, they’d probably need a microscope in a lab. Scopio, an Israel-based startup that just closed a $50 million Series C round, argues that soon, a lot of that work could be done with nothing more than a laptop.Founded in 2015, Scopio is an imaging company looking to re-imagine a common blood test called a peripheral blood smear. In essence, that’s a test where a doctor, usually looking to understand an anomaly in a blood cell count, literally takes a look at your blood cells. That process involves placing a smear of blood onto a slide, and examining the shape, size and structure of certain cells using a well-trained eye.Scopio has developed a scanner, called Scopio100x, capable of imaging that whole blood sample, while maintaining the ability to achieve 100x magnification. The result is a zoomable, digital image that CEO and founder Itai Hayut argues will allow peripheral blood smears to be done remotely, and bring down the costs of these procedures in the first place. Once samples are scanned in the lab, they could be reviewed by hematologists working from anywhere.You can zoom around in one of the images here.“We’ve seen lines of people in hematology labs leaning over microscopes, in some cases, using a manual clicker to count cells,” Hayut told TechCrunch. “We thought this is just a perfect example of how computer vision tools can assist the experts, and get better results much quicker.”Peripheral smear blood tests are part of a battery of different assessments that can be used to identify blood diseases. But these days, they’re not the first-line option, in most cases.If your doctor is concerned you might have a blood-based disease they might first order a complete blood count. Those tests are done almost entirely autonomously: an analyzer will count out different levels of blood cells types in your body, and give the doctor a rough idea of how much of each type of cell is present.If those tests present anomalies, a doctor might want to see the samples for themselves. In that case, they’ll perform a peripheral blood test to examine cell size, structure and look for indicators for a specific disease.There has been evidence that the peripheral blood smear landscape has some big pain points. For instance, some papers argue, the manual review of samples doesn’t often add much to doctors’ diagnostic dataset. One paper published in 2020 in Diagnostic Pathology, for example, found that just 23% of 515 peripheral blood smears ordered across three medical centers added clinical value.That paper doesn’t necessarily mean the technique itself is extraneous; the authors do add that efforts to make the process more efficient are probably warranted.Plenty of other papers confirm that the peripheral blood smear isn’t likely to fall by the wayside. Some 15% of analyzer tests are still referred to hematologists for a blood smear to confirm findings. And, on a less scientific note, some researchers see the ability to divine diagnoses from blood cells as something of an art.In short, it seems like we’re still going to have to manually look at blood cells to confirm diagnoses for the time being. And other companies have already looked to develop imaging tools that can make that manual review faster, and more automated. For example, two major companies in this space already are Cellavision and Sysmex, systems which are responsible for most of the peer-reviewed studies in this space, per a 2019 review paper.In some ways, the fact that this tech already exists works in Scopio’s favor, because research already suggests that cell-imaging systems have benefits to offer, and scientists are already familiar with them. Namely, these systems allow for remote review (though about 10-20% of samples still need in-person confirmation), reduce eyestrain, can lower labor costs, make it easy to archive and retrieve blood films and make good teaching tools.Hayut argues that Scopio can represent the next generation of this technology because the company appears to have found a niche within that world: The existing imaging tech doesn’t capture the entire slide.To attain greater magnification, the breadth of the image is compromised. Think about what it’s like to zoom in on something using a camera lens: the field of view gets smaller. In this case, that means only portions of the slide are scanned and displayed, said Hayut. Independently published papers have confirmed this idea.“Scopio is the first company in the world that managed to break the trade-off between field of view and resolution,” Hayut said. In short, they’ve managed to capture the whole slide and still achieve up to 100x magnification, in line with what’s needed to perform a peripheral blood smear.The ability to scan the entire slide leads to the second half of Scopio’s pitch: that “two orders of magnitude” more visualized and digitized cells means that more applications can be developed around them. In essence, Hayut said this will allow new algorithms to learn more from the peripheral blood smear in the first place.Scopio, like several of the other major players in this space, has been investing in getting certain clinical decision-making algorithms FDA approved. (Think of this like support software that helps a hematologist distinguish between cell types.)In October 2020, the FDA approved a clinical support system from Scopio that classifies cells, and allows a hematologist to review those automatic classifications, through the 510(k) new device pathway. (It was granted approval through this pathway because the classification process was substantially similar to an equivalent already on the market.)The company has also recently completed a clinical study on an application intended to assist technicians with review of bone marrow aspirate — samples usually used to scan for conditions like leukemia, multiple myeloma or anemia. The data on that study has yet to be published, but the company plans to file for FDA approval of another clinical decision-support system targeted at bone marrow aspirate analysis in March.As for the Series C funds, the company has a singular focus: commercial delivery. The company plans to expand the commercial team in Europe and the U.S., and attempt to make inroads into clinical labs (Scopio’s core client).This Series C round brings Scopio’s total funding to $85 million. The round was led by OurCrowd, and an unnamed strategic investor. It includes new investors Mizrahi-Tefahot Bank Invest, Ilex Medical and existing investors Olive Tree Ventures and Aurum Ventures.",0.0,0.0
531,https://www.mdpi.com/2072-6643/14/20/4294/htm,Dietary Fats and Cardio-Metabolic Outcomes in a Cohort of Italian Adults,"Dietary fats may also have an effect on inflammation, which has a central role in the onset of many chronic pathologies. The first mechanism by which fats can affect inflammatory status is promotion of the translocation of microbial endotoxins, especially lipopolysaccharide (LPS), from the gut into the bloodstream [ 15 ]. LPS is a toxic cell-wall component of all our gut microbiome Gram-negative bacteria. The signaling of LPS is mediated through TLR4 receptors and leads to the stimulation of NF-kB, which in turn determines the secretions of many proinflammatory cytokines, such as IL-1, TNF-α, IL-6 and IL-8. SFAs seem to greatly stimulate inflammatory response because they are also structural components of LPS.Although dietary SFAs are generally considered harmful to global health, these recent findings are quite controversial [ 9 ]. A possible explanation for these controversial results may derive from the type of SFA consumed in the diet. The absorption of short-chain fatty acids (SCFAs, two to six carbons) and medium-chain fatty acids (MCFAs, 8 to 12 carbons) occurs directly via portal circulation, while long-chain fatty acids (LCFAs, 14 to 20 or more carbons) are packaged into micelles and circulate via lymphatic-forming chylomicrons. While meat products are typically rich in LCFAs (i.e., palmitic and stearic acids), SCFAs (i.e., propionic acid and butyric acid) are produced when dietary fiber is fermented in the colon and are naturally present in milk and whole dairy products [ 10 ]. Scientific evidence from observational studies shows that higher intake of dairy products [ 11 ] and whole grains (rich in fiber) [ 12 ] are associated with a lower risk of CVD, while higher consumption of meat (red or processed) [ 13 ] is associated with higher risk. The evidence further suggests that the effects of SFA on lipid markers depend on the number of carbon atoms in the chain; a higher intake of lauric acid increases HDL cholesterol and reduces the TC to HDL ratio, while stearic, myristic and palmitic acids may raise LDL cholesterol [ 14 ].Although calorie excess is the major determinant of weight gain, dietary fats have also been blamed for being the culprit in the dramatic increase in obesity and its associated diseases over the past half century. Over recent decades, dietary fat consumption has been discouraged but, in spite of the reduction in total daily individual fat intake by 10% and the increase in consumption of low-fat food, obesity rates are dramatically growing [ 5 ]. Furthermore, indistinctly cutting total fat intake from the diet inevitably leads to an increase in the consumption of highly processed grains and simple sugars while lowering the intake of liposoluble vitamins and unsaturated fats, especially from nuts, vegetable oils and fatty fish, which are particularly valuable for health [ 6 ].Noncommunicable diseases (NCDs), such as cardio-metabolic disorders and cancer, are currently the main causes of global mortality, representing 71% of all deaths in the world [ 1 ]. Recent evidence shows that the major risk factor for these conditions is chronic subclinical low-grade inflammation [ 2 ], which is usually determined by physical inactivity, tobacco, pollution, sleep alterations, dysbiosis, and infections [ 3 ]. Among the triggers for inflammation, poor diet and excessive weight also play important roles [ 4 ]. The growth in the volume and number of adipocytes due to an excessive caloric intake leads to an increase in monocyte adhesion and recruitment to adipose tissue. Macrophages in adipocytes show many pro-inflammatory receptors, such as tumor necrosis factor receptors (TNFRs), Toll-like receptors (TLRs) and interleukin-1 receptor (IL-1R), as well as high activation of the nuclear factor-kB (NF-kB) transcription factors for pro-inflammatory cytokines [ 4 ]. Moreover, a condition of chronic low-grade inflammation may impair insulin sensitivity; insulin resistance worsens the inflammatory state, increasing abdominal obesity, intrahepatic fat stocking, vascular inflammation and endothelial dysfunction, which leads to an increase in cardiovascular risk [ 3 ].Continuous variables are expressed as means and standard deviations (SDs), while categorical variables are expressed as frequencies of occurrence and percentages. Individuals were grouped by quartiles of total fat intake and distributions of background characteristics were compared between groups. Differences were tested with the chi-squared test for categorical variables, ANOVA for continuous variables distributed normally and the Kruskall–Wallis test for variables distributed non-normally. Energy-adjusted and multivariate logistic regression models were used to test the association between fat consumption and cardio-metabolic outcomes; the multivariate model adjusted for all other background characteristics (physical activity, educational status, occupational status, smoking status, alcohol consumption, menopausal status) was performed to test whether the observed associations were independent from the aforementioned variables. All reported p-values were based on two-sided tests and compared to a significance level of 5%. SPSS 17 (SPSS Inc., Chicago, IL, USA) software was used for all the statistical calculations.The nutritional assessment was conducted using two food frequency questionnaires (FFQs; a long and a short version) previously validated for the inhabitants of Sicily, south Italy [ 21 22 ]. The determination of the food ingested, the calories introduced and, especially, macro- and micro-nutrient intake were achieved through comparison with the food composition tables of the Research Center for Foods and Nutrition. The mean daily intake of each food was calculated in g or ml by considering the portion sizes provided in the FFQs and then converted to 24 h intake. Then, the content of total and specific fatty acids in each food was searched in the food composition tables of the Research Center for Foods and Nutrition and an estimation of their daily intake was calculated by multiplying the content of total and individual fatty acid molecules by the daily consumption of each food.Anthropometric measurements were obtained following standard protocols [ 20 ]. Individuals were grouped according to body mass index (BMI) cut-offs as under/normal weight (BMI < 25 kg/m), overweight (from BMI 25 to 29.9 kg/m) and obese (BMI ≥ 30 kg/m). Arterial blood pressure was measured in sitting position and after at least 5 min of rest at the end of the physical examination. Due to the possibility of differences in blood pressure measurement, the measurements were taken three times from the right arm, relaxed and well-supported by a table, with an angle of 45° from the trunk. The mean of the last two measurements was considered for inclusion in the database. Patients were considered hypertensive when average systolic/diastolic blood pressure levels were equal to or more than 140/90 mmHg, in accordance with the European Society of Cardiology (ESC)/European Society of Hypertension (ESH) guidelines, or when participants had been previously diagnosed with hypertension. Patients were considered dyslipidemic or diabetic if diagnosed by a physician with hypercholesterolemia/hypertriglyceridemia or diabetes, respectively. Previous diagnosis of diseases was collected from the medical records of the referred general practitioner.Data were collected with a presence-assisted interview through tablet computers. All subjects were supplied with a paper copy of the questionnaire in order to see each response option. However, the final answers were recorded instantly by the interviewer. The demographic information, such as age at recruitment, gender, highest educational level achieved, occupation (the most relevant job during the year before the investigation) or last occupation before retirement and marital status, were collected. Occupational status was classified as: (i) unemployed, (ii) low (unskilled workers), (iii) medium (partially skilled workers) and (iv) high (skilled workers). Educational status was categorized as: (i) low (primary/secondary), (ii) medium (high school) and (iii) high (university). The International Physical Activity Questionnaire (IPAQ) was used to examine motor activity [ 19 ], and it included a panel of questionnaires (five domains) investigating the time spent being physically active in the last week. In accordance with the IPAQ, physical activity level was classified as: (i) low, (ii) moderate and (iii) high. Smoking status was categorized as: (i) non-smoker, (ii) ex-smoker and (iii) current smoker, and alcohol consumption was classified as: (i) none, (ii) moderate drinker (0.1–12 g/d) and (iii) regular drinker (>12 g/d).The Mediterranean Healthy Eating, Aging and Lifestyle (MEAL) study is an observational study aimed at examining the relationship between lifestyle and dietary habits in the Mediterranean region and NCDs. The original cohort included a sample of 2044 randomized adults (≥18 years old) from the main districts of Catania, a city in the south of Italy. The recruitment and data collection were carried out between 2014 and 2015. Details of the project protocol are published elsewhere. All subjects involved in the study were advised about the objective of the project and provided written informed consent. All the study methods were carried out following the Declaration of Helsinki (1989). The study protocol was examined and accepted by the relevant ethical committee.The association between total and classes of dietary fats and metabolic outcomes is shown in Table 2 . Multivariate-adjusted analysis revealed a significant inverse association between total dietary fats and hypertension (for Q4, odds ratio (OR) = 0.57, 95% CI: 0.35, 0.91). Moreover, individuals reporting moderate consumption of total fats were less likely to have diabetes (for Q3, 0.27, 95% CI: 0.12, 0.61). Among single classes of dietary fats, individuals in the highest quartile of SFA intake were less likely to have hypertension (OR = 0.55, 95% CI: 0.34, 0.89). Moreover, subjects reporting moderate intake of MUFA were less likely to have hypertension and diabetes (OR = 0.61, 95% CI: 0.42, 0.88 and OR = 0.47, 95% CI: 0.22, 0.97, respectively). No associations were found between PUFA and any of the investigated outcomes.4. DiscussionIn the current study, we investigated the relationship between dietary fat subtype intake and cardio-metabolic risk factors in a cohort of Mediterranean adults. Interestingly, total SFA consumption was not detrimentally associated with any cardio-metabolic outcomes; conversely, individuals who had higher intake of total SFA were less likely to have hypertension and those who specifically consumed more SCSFA–MCSFA were less likely to have dyslipidemia and diabetes. Although SFAs have been assumed to be the main nutritional risk factor for cardio-metabolic diseases, recent studies have provided new controversial and interesting evidence suggesting that the SFA–CVD relationship may not be as strong as initially thought. A recent systematic review by the Cochrane group reported that a reduction in the intake of SFAs induced a 17% lowering of the risk of cardiovascular disease and that the beneficial effects increase when SFAs are replaced with PUFAs or starchy food [ 23 ]. However, cutting SFAs had a null effect on the other CVD end-points investigated and, furthermore, the putative adverse effect of SFAs on CVD events became non-significant when the analysis included only clinical trials that had successfully reduced SFA intake while removing those that were not successful [ 24 ]. The Prospective Urban Rural Epidemiological (PURE) study [ 25 ] conducted on 135,000 subjects without CVD demonstrated that increased consumption of total fats was linked with lower mortality and had a null association with CVD. Moreover, subjects in the highest quintile of SFA intake had a lower risk of stroke. Furthermore, a recent dose–response meta-analysis of cohort studies [ 8 ] highlighted that total fat, SFA, MUFA, and PUFA intake were not associated with CVD risk. Moreover, a meta-analysis of epidemiological studies conducted by SiriTarino [ 26 ] found no evidence that SFAs are associated with an increased risk of CHD. In addition, De Souza [ 27 ] and colleagues found no association between SFA intake and all-cause mortality, CHD, CHD mortality, ischemic stroke or type-2 diabetes among healthy subjects. A possible explanation for these controversial results on cardio-metabolic health may be the chain length of the fatty acids mainly consumed in diets [ 28 ]. SCFA may have a favorable impact on metabolism through activation of G protein-coupled receptors in endocrine and colon epithelial cells that, in turn, release anorectic hormones, such as glucagon-like peptide 1 (GLP) and peptide YY (PYY), which may contribute to reducing food intake and protecting individuals against obesity and diabetes, as shown in our results. Specifically, butyric acid (4:0) may have a beneficial effect on cardiovascular risk via inhibition of the NF-kB pathway and pro-inflammatory cytokines [ 29 ]. MCSFAs, such as caproic acid (6:0) and caprylic acid (8:0), have been shown in a cellular model to reduce the activity of fatty acid synthase (FAS), a primary enzyme of de novo lipogenesis that may contribute to the development of obesity and non-alcoholic fatty liver disease (NAFLD) [ 30 ]. Moreover, MCSFA may prevent endotoxic lipopolysaccharide (LPS)-mediated inflammation and lesions, which are linked to metabolic syndrome [ 31 ]. Caprylic acid (C8:0) and capric acid (C10:0) may reduce intestinal bile acid reabsorption with a simultaneous increase in excretion, which, in turn, lower TC and LDL-C [ 32 ].In our cohort, myristic acid (14:0) intake was not associated with dyslipidemia and diabetes, while we found a positive association with hypertension. Although this molecule has been reported to play a role in post-translational protein changes and pathways that regulate several metabolic processes [ 33 ], data from the literature on its actual effect on metabolic health are not univocal: some studies reported potential beneficial effects from increasing HDL-C, such as reducing triglycerides levels, improving long-chain omega-3 levels in plasma phospholipids [ 34 ] and obesity-associated insulin resistance [ 35 ] and increasing LDL-C and apoB levels [ 36 ]. Among LCSFAs, in our study, stearic acid (18:0) was associated with a lower risk of diabetes and hypertension. Palmitic acid (16:0) and stearic acid (18:0) have been shown to increase cardiovascular risk through worsening of the lipid profile and alteration of inflammatory response [ 37 38 ], although the effects of stearic acid are less widely agreed on [ 39 ]. Moreover, stearic acid undergoes conversion to MUFA oleic acid (18:1) through the hepatic enzyme stearoyl–CoA–desaturase, which may in part explain the extensive detrimental effects.n -3 and n -6 PUFAs could have contrasting roles in human health. Indeed, n -6 PUFAs, such as linoleic acid (LA, 18:2), were thought to have pro-inflammatory effects because they can be converted into arachidonic acid (AA, 20:4) with consequent production of pro-inflammatory eicosanoids and, at the same time, reduce the conversion of n -3 PUFA alpha-linolenic acid (ALA, 18:3) into eicosapentaenoic acid (EPA, 20:5) and/or docosahexaenoic acid (DHA, 22:6) by competing for the same enzymes [ n -6 PUFAs, but not n -3 PUFAs, may improve homeostasis model assessment—insulin resistance (HOMA-IR), lowering insulin in healthy subjects [ Despite the new nutritional scenario regarding the role of dietary fat in cardio-metabolic health, the American Heart Association recently remarked on the importance of limiting SFA and substituting it with PUFA to reduce cardiovascular risk [ 40 ]. The American Dietary Guidelines Advisory Committee showed strong evidence that replacing SFAs with PUFAs reduces the risk of CHD events and CVD mortality, but there is a paucity of evidence to establish whether this substitution affects the risk of stroke or heart failure [ 41 ]. Data from previous epidemiological studies [ 42 ] and clinical trials [ 43 ] have shown that replacing SFA with PUFA and MUFA reduces the risk of combined CVD events, mainly lowering LDL-C and reducing inflammation. However, a recent umbrella review showed that replacing SFA with PUFA does not convincingly reduce cardiovascular events or mortality, probably due to the original invalidity of the diet–heart hypothesis and numerous research biases [ 44 ]. In our study, neither total PUFA intake nor the individual PUFAs were associated with dyslipidemia. PUFAs have always been generally considered “healthy” fats. They are implicated in vascular function, cell membranes, the nervous system and inflammation, being precursors of eicosanoids and beneficial lipid mediators, such as resolvins, docosatrienes and protectins. Previous evidence suggested that-3 and-6 PUFAs could have contrasting roles in human health. Indeed,-6 PUFAs, such as linoleic acid (LA, 18:2), were thought to have pro-inflammatory effects because they can be converted into arachidonic acid (AA, 20:4) with consequent production of pro-inflammatory eicosanoids and, at the same time, reduce the conversion of-3 PUFA alpha-linolenic acid (ALA, 18:3) into eicosapentaenoic acid (EPA, 20:5) and/or docosahexaenoic acid (DHA, 22:6) by competing for the same enzymes [ 45 ]. This hypothesis has lost its strength based on the latest results from clinical studies on humans demonstrating that LA intake has little influence on conversion into AA, while, conversely, it may be converted into nitrosylated LA and 13-hydroxyoctadecadienoic acid, which show anti-inflammatory effects [ 46 ]. Interestingly, in our study, subjects reporting a higher intake of LA were less likely to be hypertensive in a linear way. The blood pressure-lowering effects of LA are probably due to changes in vasodilator prostaglandin metabolism [ 47 ]. Moreover, we found that the intake of EPA and DHA was inversely associated with hypertension. A recent dose–response meta-analysis showed that EPA and DHA may reduce the risk of CHD by lowering high blood pressure among people already diagnosed with hypertension [ 48 ]. These fatty acids may exert cardioprotective effects, mainly by reducing ventricular fibrillation, heart rate and platelet aggregation through various mechanisms, including improved synthesis of eicosanoids [ 49 50 ] and inhibition of the NF-kB pathway by acting on PPAR-gamma and certain G-protein-coupled receptors in macrophages and adipocytes, thus reducing the production of inflammatory cytokines [ 51 ]. Finally, PUFA may also influence the risk of type-2 diabetes by reducing insulin resistance, activating PPAR-alpha and suppressing sterol regulatory binding protein-1c (SREBP-1c) [ 52 ]. A recent meta-analysis of RCTs showed that substituting SFAs with PUFAs improved glycemia and insulin resistance [ 53 ]. However, in line with our results, not all subtypes of PUFA appear to have the same effects on type-2 diabetes risk. The latest data show that-6 PUFAs, but not-3 PUFAs, may improve homeostasis model assessment—insulin resistance (HOMA-IR), lowering insulin in healthy subjects [ 54 ]. Moreover, a recent study reported that high levels of LA, but not AR, are associated with a lower risk of becoming diabetic [ 55 ]. In our study, only subjects with the highest intake of LA were less likely to have diabetes while the association with other PUFA was null.In addition to PUFAs, MUFAs have also been considered for replacing dietary SFAs, as highlighted by the latest American dietary guidelines, although evidence is weak. Although substitution of SFAs with MUFAs has been associated with a decrease in metabolic syndrome [ 56 ], findings from a meta-analysis of observational studies showed null results on risk of CVD [ 8 42 ]. Our results showed that individuals with higher intake of oleic acid (18:1) were less likely to have hypertension and diabetes, while no association was found for dyslipidemia. Typical sources of MUFAs in the Mediterranean region are nuts, which have been demonstrated to have potential benefits for metabolic disorders [ 57 ]. MUFAs may have anti-inflammatory and antioxidant properties, lowering endoplasmic reticulum stress, inhibiting NF-kB transcription factor and acting through AMP-activated protein kinase (AMPK) phosphorylation, and may also reduce the polarization of M1 macrophages to M2 macrophages [ 51 ]. However, recent published studies report a beneficial effect of extra virgin olive oil and, probably, its polyphenols rather than the simple intake of MUFAs [ 58 ]. When MUFAs were isocalorically replaced with a non-lipidic component, such as carbohydrates, observed effects on blood lipids were rather small or negligible, and a recent review even highlighted the potentially negative effects of olive oil and oleic acid if introduced in large quantities [ 59 ]. These findings are in line with those of our study concerning gadoleic acid (20:1), a long-chain MUFA that appeared to be detrimentally associated with each investigated outcome in our study. The Ludwigshafen Risk and Cardiovascular Health Study showed an inverse association of gadoleic acid with LDL-C, HDL-C and eGFR but direct correlations with markers of inflammation and endothelial activation, as well as heart failure [ 60 ]. In contrast, a randomized controlled trial found that the supplementation of LCMUFAs (gadoleic acid and cetoleic acid) improved endothelial function by lowering trimethylamine-N-oxide levels, IL-6 and TNF-α, possibly due to improved gut microbiota profile [ 61 ]. The debate on the effects of LCMUFAs (more than 18 carbons) remains inconclusive as research is still scarce.The results of the current study should be considered in light of several limitations. First, the observational nature of this investigation did not make it possible to define a causal relation between variables but only an association. The cross-sectional design of the study may have limited the interpretation of the results, as they may have suffered from revere causation. Moreover, although we performed multivariate-adjusted logistic regression analyses, residual vulnerability to type-1 errors still exists and should be taken into account. Another limitation concerns the dietary assessment method: although there is a univocal and perfect approach to collecting dietary data (with integrated use of multiple 24 h recalls and dietary diaries being highly desirable), FFQs are known to potentially under- or overestimate food intake due to recall bias, portion size miscalculation and social desirability bias. Finally, cases were confirmed by medical visit, but potential undiagnosed patients may have led to inclusion of false-negative cases in the study sample. These findings require further investigation in studies that are better designed, more controlled and use a prospective approach.",0.0,0.0
554,https://thehill.com/policy/energy-environment/3669504-supreme-court-to-hear-case-that-could-have-massive-impact-on-us-water-quality/,Supreme Court to hear case that could have massive impact on US water quality,"The Supreme Court on Monday will hear arguments of a case between Idaho landowners and the Environmental Protection Agency (EPA), a dispute that could redefine the scope of the country’s clean water regulations.The first case of the justices’ new term, landing just ahead of the Clean Water Act’s 50th anniversary, will feature arguments about wetlands and when they can or cannot be regulated by the federal government.Although technical in nature, the legal dispute could have broad implications for the country’s water quality if the 6-3 conservative majority court uses the case to narrow the EPA’s regulatory reach.“If that’s what the Supreme Court should decide, we’re basically rolling back the clock 50 years,” said Rep. Peter DeFazio (D-Ore.), who chairs a House panel on water resources and the environment. “That would remove 50 percent of our critical wetlands, and 70 percent of our rivers and streams from federal protection.”The case began in 2007 when Michael and Chantell Sackett were told they needed a federal permit to build a home on land they owned because it contained wetlands, prompting the Sacketts to sue.A federal court, siding with the U.S. government, ruled that the wetlands on the Sacketts’ property contained a “significant nexus” with other regulated waters, meaning the couple would need authorization to build there.The Sacketts are now urging the Supreme Court to discard the “significant nexus” threshold. Instead, their petition favors a separate test from former Justice Antonin Scalia that called for the waters to have a “continuous surface water connection” — a higher threshold that would apply to fewer wetlands.The stakes of this case, however, go far beyond one property dispute. It attracted briefs from environmental groups, which argue that it would hamper the government’s ability to keep people safe from pollution, as well as industries like farming, mining, construction and oil and gas, which support the deregulatory effort.“This is a very, very, big deal for the Clean Water Act. It will determine, likely, whether the Clean Water Act can protect half of the water bodies in the country, and if it can’t, meeting the water quality goals of the law that we all count on will be virtually impossible,” said Jon Devine, who leads the Natural Resources Defense Council’s federal water policy team.The case appears to mirror regulatory differences between the Trump administration’s efforts to limit regulations to just wetlands with continuous surface water connections to other regulated waters, and the Obama administration’s regulations, which applied the significant nexus test.A total of 51 percent of the country’s wetlands would not be protected under the Trump-era rule,The Biden administrationAnd while the Sacketts’ petition to the court appears to be in support of the continuous surface water test,They say that a wetland should be “inseparably bound up” with another regulated water and also subject to Congress’s authority over interstate waters.Damien Schiff, a lawyer representing the Sacketts said that abiding by the Clean Water Act can be significantly burdensome, both in the application process itself and in the requirements to mitigate environmental damage.“Whenever the Clean Water Act applies, it does add a significant financial burden, not just because there is a lot of costs involved in the application process … but also just simply the cost of compensatory mitigation,” said Schiff, a senior attorney at the Pacific Legal Foundation.He said that the Army Corps of Engineers “might very well issue a permit, but typically not only is the permit issued for a much smaller project than was originally requested but it’s always accompanied by a pretty significant compensatory mitigation obligation and that can run into the hundreds of thousands if not millions of dollars.”A looser test would be expected to apply to fewer wetlands, allowing individuals and corporations to act there without EPA oversight.Under the current system, many polluters are also not necessarily blocked from carrying out activities in regulated waters.Instead, they may need to either apply for a permit that contains stipulations that they follow environmental safeguards, or follow existing stipulations in a “general permit” that gives a blanket waiver to certain activities.But environmentalists say that while pollution still occurs when permits are in place, the stipulations they offer are important for averting the worst damages.“This case is not about prohibiting construction or development, it’s about what safeguards are in place when someone does so,” Devine said.Environmentalists say that this pollution may end up in America’s drinking water and also harm fish that people catch for consumption. And while many public water systems are treated to prevent pollution, some people get their water from private wells, which may not get the same level of treatment.“Drinking water does have standards, but that doesn’t mean that all those standards are perfect and the pollution that comes in through those sources means more cost of treatment. It means that people who live on wells or in areas where the water treatment systems aren’t as big or fancy or as expensive are going to suffer,” said Sam Sankar, senior vice president of programs at Earthjustice.Sankar said his organization has 18 tribes as clients, and many of them will face “direct impacts.”The court began its work Monday after an epochal term in which the six Republican-appointed justices advanced an aggressive conservative legal agenda.The case will be the first that is heard by Ketanji Brown Jackson in her tenure as a Supreme Court justice.Although overshadowed by the court’s overruling of Roe v. Wade, last term saw the court vote 6-3 to pare back federal agency power in West Virginia v. EPA, a case thatCourt watchers believe the conservative majority court will continue its rightward trajectory this term.“There’s no reason to think this coming term, or any term in the foreseeable future, will be any different,” Irv Gornstein, executive director of Georgetown Law’s Supreme Court Institute said recently. “On things that matter most, get ready for a lot of 6-3s.”",0.0,0.0
245,https://techcrunch.com/2022/07/14/gridtential-thinks-the-og-renewable-battery-chemistry-is-ripe-for-disruption/,Gridtential thinks the OG renewable battery chemistry is ripe for disruption,"Lithium-ion batteries are one of the driving forces behind the transition away from fossil fuels, but the rechargeable battery that started it all — lead-acid — has received very little attention.Invented over 160 years ago, lead-acid batteries have been upgraded a few times, but today’s cells are largely unchanged from those sold in the ’70s and ’80s. Gridtential, a Santa Clara-based startup, is betting there’s plenty of room for improvement. It’s developed a silicon plate that can replace up to 35% of the lead in a traditional battery while improving its charging rate fivefold and quadrupling its lifespan.Gridtential today announced partnerships with two players in the lead-acid market, Hammond Group, which makes battery materials and additives, and Wirtz Manufacturing, which makes equipment to deposit battery material on a substrate.",0.0,0.0
538,https://www.zdnet.com/article/nasa-develops-a-tiny-high-powered-laser-to-find-water-on-the-moon/,"NASA's new tiny, high-powered laser could find water on the Moon","Image: NASA/Michael GiuntoPrevious technologies have allowed NASA to confirm that there are small amounts of hydration across the Moon. However, these technologies have not been able to identify where it came from, how much water there is or even if it is, in fact, water. Now, utilizing Goddard technology, engineer Dr. Berhanu Bulcha has developed an instrument to definitively locate and identify water sources on the Moon, according to a NASA post.""Other missions found hydration on the Moon, but that could indicate hydroxyl or water. If it's water, where did it come from? Is it indigenous to the formation of the Moon, or did it arrive later by comet impacts? How much water is there? We need to answer these questions because water is critical for survival and can be used to make fuel for further exploration,"" said Dr. Bulcha.SEE: NASA enters contract for computing processor that will change space explorationNASA prioritizes identifying water and other resources because it is crucial to exploring the Moon and other objects in the solar system.Dr. Bulcha said that an instrument known as a heterodyne spectrometer could zoom in on particular frequencies to locate and identify the hydration on the Moon. A stable, high-power terahertz laser that is needed for the spectrometer was prototyped in collaboration with Longwave Photonics through NASA's Small Business Innovation Research (SBIR) program.""The problem with existing laser technology is that no materials have the right properties to produce a terahertz wave,"" said Dr. Bulcha.SEE: NASA is blazing an inspirational trail. We need to make sure everyone can follow itHydrogen-containing compounds such as water emit photons in the terahertz frequency range, says NASA. However, traditional lasers fall short in the portion of the spectrum known as the terahertz gap. In order to fill the gap, Dr. Bulch's team is developing quantum cascade lasers.To bypass issues with the quantum cascade laser beams spreading out in a large angle, the team, using innovative technology supported by Goddard's Internal Research and Development (IRAD) funding, integrated the laser on a waveguide with a thin optical antenna to tighten the beam.Dr. Bulch hopes to have a flight-ready laser for NASA's Artemis program. However, the use of this laser can go far beyond the Artemis mission. ""It could also power a handheld device for use by future explorers on the Moon, Mars, and beyond,"" said NASA.",0.0,0.0
541,https://thehill.com/opinion/technology/3647216-china-has-returned-helium-3-from-the-moon-opening-door-to-future-technology/,"China has returned helium-3 from the moon, opening door to future technology","The Chinese Chang’e 5 mission hasThe crystal mineral was exceedingly tiny, about one-tenth the size of a human hair. The new mineral is of immense interest to lunar geologists. The helium-3 that it contains has the potential to change the world.Scientists have known the lunar surface contains deposits of helium-3 since the Apollo program. The main advantage of helium-3 fusion over fusion using tritium and deuterium, isotopes of hydrogen, is that it doesn’t create radioactive neutrons. Its main disadvantage is that achieving a controlled fusion reaction with helium-3 is far more difficult than using more conventional fuels.According to NASAChina, perhaps in partnership with Russia, still plans crewed lunar landings sometime in the 2030s.In the meantime, NASA’s twice delayed Artemis 1 missionTwo robotic space missions,NASA still plans to send Artemis 2 and a crew of four astronauts, one of them from Canada, around the moon in 2024. The next year (or perhaps the year following), Artemis 3 will land the first astronauts on the lunar surface since the mission of Apollo 17 in 1972.Many reasons exist for returning to the moon:Of course, the problem remains of getting the technology of helium-3 fusion working. Helium-3 fusion may not become a reality before the middle of this century because of the technological obstacles involved. Some changes in American space and energy policy might hasten the advent of helium-3 fusion, however.The United States should start testing mining operations on the moon’s surface, particularly extracting helium-3 from lunar soil. Then helium-3 could be transported to Earth and provided to research laboratories so they can continue research and development of what promises to be a solution to both energy scarcity and climate change.The country that controls the source of energy that keeps technological civilization running will control the Earth. If China becomes that country, considering its human rights record and imperial foreign policy, history will take a dark turn. Therefore, the United States and the countries that have signed the Artemis Accords must acquire control of lunar helium-3 and develop the technology to use it as a source of fusion energy. Thus, the Artemis program will ensure the continuance of prosperity and human freedom on the Earth.Mark R. Whittington is the author of space exploration studies “",0.0,0.0
546,https://www.space.com/dart-asteroid-mission-on-track-for-impact,"DART asteroid-smashing mission 'on track for an impact' Monday, NASA says","NASA is just days away from slamming a spacecraft into an asteroid 7 million miles (11 million kilometers) from Earth.The agency's long-awaited Double Asteroid Redirection Test ( DART ) mission will impact with the asteroid moonlet Dimorphos on Monday (Sept. 26), if all goes according to plan. The DART mission launched on Nov. 23, 2021 on top of a SpaceX Falcon 9 rocket and is now hurtling through deep space toward the binary near-Earth asteroid (65803) Didymos and its moonlet Dimorphos.The mission, which is managed by the John Hopkins University Applied Physics Laboratory (JHUAPL), is humanity's first attempt to determine if we could alter the course of an asteroid, a feat that might one day be required to save human civilization. While changing the orbit of an asteroid 7 million miles away sounds daunting, DART team members from NASA and JHUAPL said during a media briefing on Thursday (Sept. 22) that they are confident that the years of planning that have gone into the mission will lead to success.Related: NASA's DART asteroid-impact mission will be a key test of planetary defenseTraveling at speeds of 4.1 miles per second (6.6 km/s), or 14,760 mph (23,760 kph), the DART spacecraft will impact the 560-foot-wide (170 meters) Dimorphos, a moonlet that orbits the other member of its binary system, the 2,600-foot-wide (780 m) asteroid Didymos.Doing so, NASA believes, will shift Dimorphos' orbital period enough to alter its gravitational effects on the larger Didymos, changing the trajectory of the pair.DART will crash into Dimorphos, causing a change to the moonlet's orbit. (Image credit: NASA/Johns Hopkins APL)Katherine Calvin, chief scientist and senior climate advisor at NASA, said that while DART will be a key test of this ""kinetic impactor"" planetary defense strategy, the mission will also produce valuable science that will allow astronomers to peer back into the deep history of the solar system.""We're looking at asteroids to make sure that we don't find ourselves in their path. We also study asteroids to learn more about the formation and history of our solar system. Every time we see an asteroid, we're catching a glimpse of a fossil of the early solar system,"" Calvin said.""These remnants capture a time when planets like Earth were forming,"" she added. ""Asteroids and other small bodies also delivered water, other ingredients of life to Earth as it was maturing. We're studying these to learn more about the history of our solar system.""Lindley Johnson, planetary defense officer at NASA, said that DART marks a turning point in the history of the human species.""This is an exciting time, not only for the agency, but for space history and the history of humankind,"" Johnson said during Thursday's briefing. ""It's quite frankly the first time that we are able to demonstrate that we have not only the knowledge of the hazards posed by these asteroids and comets that are left over from the formation of the solar system, but also have the technology that we could deflect one from a course inbound to impact the Earth. So this demonstration is extremely important to our future.""That sentiment was echoed by Tom Statler, a DART program scientist at NASA. ""The first test is a test of our ability to build an autonomously guided spacecraft that will actually achieve the kinetic impact on the asteroid. The second test is a test of how the actual asteroid responds to the kinetic impact,"" Statler said. ""Because, at the end of the day, the real question is: How effectively did we move the asteroid, and can this technique of kinetic impact be used in the future if we ever needed to?""Read more: DART asteroid mission: NASA's first planetary defense spacecraftThe asteroid Didymos and its moonlet Dimorphos are shown in a composite image taken by DART's DRACO instrument on July 27, 2022. (Image credit: NASA JPL DART Navigation Team)The outcome of the DART mission on Monday (Sept. 26) will certainly help answer that question, and many of the DART team members shared their confidence in the mission during the briefing. Edward Reynolds, DART project manager at JHUAPL, said the spacecraft is ready to smash itself to pieces on the surface of Dimorphos when the time comes.""What we can say at this point is that all subsystems on the spacecraft are green, they're healthy, they're performing very well. We have plenty of propellant and we have plenty of power,"" Reynolds said. ""We've been doing a bunch of rehearsals, and some of the rehearsals are very nominal.""""At this point, I can say that the team is ready,"" Reynolds added. ""The ground systems are ready, and the spacecraft is healthy and on track for an impact on Monday.""Engineers on the DART team are watching the spacecraft's trajectory carefully over the coming days leading up to the impact, which should occur at 7:14 p.m. EDT (2314 GMT) on Monday (Sept. 26). Elena Adams, DART mission systems engineer at JHUAPL, said that the team is still making sure the impactor spacecraft is on course.""Over the next couple of days, we're actually still performing some trajectory correction maneuvers to make sure that we are on the right path to hit the asteroid,"" Adams said. ""We rehearsed a lot. But as we go through the cruise phase, we update parameters in the spacecraft to make sure that we can actually hit the asteroid. And so in the last couple of days, we'll update those parameters; we'll do checks like streaming images back to Earth.""""So in the next few days, we'll take more images of the Didymos system, we'll do trajectory correction maneuvers, and then at 24 hours prior to impact, it's all hands on deck,"" she added.Adams said the team has 21 contingencies in place in case DART's Small-body Maneuvering Autonomous Real Time Navigation (Smart Nav) system determines that the spacecraft is off course. ""We've planned for all the things, and we're ready to intervene. And we have been rehearsing this for quite some time.""NASA's Double Asteroid Redirection Test, or DART, is moved into a shipping container for its trip to the Vandenberg Space Force Base in California for a launch on Nov. 24, 2021. (Image credit: NASA/Johns Hopkins APL/Ed Whitman)The 21st contingency the team has planned for is DART's survival. In the event that DART misses Dimorphos, Adams says the team will immediately begin processing the data the spacecraft collected and plan for a possible impact with other objects.""We're going to sit down back into our seats and we're going to start preserving all the data on board if it misses. And we'll have time with our Deep Space Network right afterwards to be able to actually get all that data down,"" Adams said. ""And then we'll start conserving propellant and we'll start looking for [other] objects to come back to.""In response to a question from Space.com concerning any flight testing the team has conducted, Adams mentioned a recent set of images the DART spacecraft's DRACO camera took of Jupiter and its four big Galilean moons . The DART team captured the images in order to ""fool"" the DART spacecraft's SMART Nav system so that its tracking capabilities could be tested.""We actually watched Europa exit from behind Jupiter. And we fooled our Smart Nav that Jupiter was Didymos and Europa was Dimorphos, and we actually watched the separation happen,"" Adams said.That's important, she added, ""because in the last four hours during our terminal phase, when the spacecraft is completely autonomous, we're going to watch Dimorphos emerge from behind Didymos. So, we already trained the system to do this in flight. So we're looking forward to it. I think we can do it.""Statler reiterated that confidence, adding that, while this type of mission was once the stuff of fantasy, the DART team believes we now have the tools and the knowledge to carry out a successful planetary defense mission.""We're moving an asteroid. We are changing the motion of a natural celestial body in space,"" Statler said. ""Humanity has never done that before. And this is the stuff of science fiction books, and really corny episodes of 'Star Trek' from when I was a kid. And now it's real. And that's kind of astonishing that we are actually doing that and what that bodes for the future: What we can do, as well as our discussions of what humanity should do.""It opens up an amazing frontier,"" he added. ""It's very exciting.""",0.0,0.0
438,https://www.theverge.com/2022/10/24/23420502/video-game-kid-brain-function-fmri,Kids who play video games score higher on brain function tests,"Kids who play video games have better memory and better control over their motor skills than kids who don’t, according to a new study looking at adolescent brain function.Video games might not be responsible for those differences — the study can’t say what the causes are — but the findings add to a bigger body of work showing gamers have better performance on some tests of brain function. That lends support to efforts to develop games that can treat cognitive problems.“This study adds to our growing understanding of the associations between playing video games and brain development,” said Nora Volkow, director of the National Institute on Drug Abuse, in a statement.The study used data from the Adolescent Brain Cognitive Development (ABCD) study, which launched in 2018 and is tracking brain development in thousands of children in the United States as they grow into adulthood. Participants periodically go through a battery of assessments, including brain imaging, cognitive tasks, mental health screenings, physical health exams, and other tests.To study video games and cognition, the research team on this new study pulled from the first set of assessments in the ABCD study. It included data on 2,217 children who were nine and 10 years old. The ABCD study asked participants how many hours of video games they played on a typical weekday or weekend day. The research team divided the group into video gamers (kids who played at least 21 hours per week) and non-video gamers (kids who played no video games per week). Kids who only played occasionally weren’t included in the study. Then, the research team looked at the kids’ performance on tests that measure attention, impulse control, and memory.The video gamers did better on the tests, the study found. They also had differences in brain activity patterns from the non-gamers — they had more activity in brain regions involved with attention and memory when they were performing the tests. Notably, there were no differences between the two groups on measures of mental health (more evidence rebutting widespread concerns that video games are bad for emotional well-being).This study adds to a large body of work showing differences in the brains of gamers compared with non-gamers and hinting that gamers have an edge on certain types of brain function. Companies are trying to leverage those differences to develop video games that treat cognitive conditions. Akili Interactive, for example, has a prescription video game to treat ADHD, and DeepWell Digital Therapeutics wants to find the therapeutic value in existing games.But despite all that work, it’s still not clear why there are differences between gamers and non-gamers in this age group. It could be that video games cause the improvements in cognition. It could also be that people who already have better attention for tasks like the ones in this study are more drawn to video games. There are many different types of video games, as well — this new study, for example, didn’t ask what games the gamers played.",0.0,0.0
273,https://techcrunch.com/2020/06/15/cmu-demonstrates-nanoscale-technology-that-causes-plants-to-absorb-nutrients-with-nearly-100-efficiency/,CMU demonstrates nanoscale technology that causes plants to absorb nutrients with nearly 100% efficiency,"Spraying plants with fertilizers and pesticides is typically a highly lossy affair — as little as 1% of the substances currently used in industrial and food production farming is actually taken up by the plant, while the rest leaches off into the soil. A new technology demonstrated for the first time by Carnegie Mellon University’s Greg Lowry and his team reverses that — causing a plant to absorb molecules with up to 99% efficiency, meaning only 1% is wasted.There are efficiency improvements, and then there are technology demonstrations that could completely upend current methods of doing things — like this one. Lowry’s research, which has been demonstrated as outlined in a peer-review publication now available in Nanoscale Communications, makes use of nanoparticles to coat molecular substances that you would want to be absorbed by a plant. These could include nutrients designed to optimize growth and crop yields, for instance, or pesticides that could protect them from destructive bugs and infestations.We covered this work last year, when it was still just at the pre-demonstration stage — now, Lowry’s team has shown that you can indeed engineer nanoparticles specifically to target pores on the surface of a leaf. Essentially, it’s like custom-creating Lego blocks for receptors on the leaf’s surface and then tying the nutrients you want to deliver to those custom Lego blocks for a perfect fit.This demonstration bears out the team’s hypothesis, which sets the stage for potential further development and, eventually, commercial application. The biggest potential commercial use of this technology could be in pesticides, as it’s estimated that as much as 40% of potential crop yield is still lost to plant disease that’s preventable with effective use of pesticides that can block them from entering through pores on leaves. They could also improve absorption of plant food and fertilizer designed to stimulate growth, and potentially these two uses could be combined into a single “dose” of nanoparticles that can do double duty, with great potential to increase plant and crop output.",0.0,0.0
529,https://www.nature.com/articles/s41380-022-01812-3,Insulin modulates emotional behavior through a serotonin-dependent mechanism,"Anderson RJ, Freedland KE, Clouse RE, Lustman PJ. The prevalence of comorbid depression in adults with diabetes: a meta-analysis. Diabetes Care. 2001;24:1069–78.Lee JH, Park SK, Ryoo JH, Oh CM, Mansur RB, Alfonsi JE, et al. The association between insulin resistance and depression in the Korean general population. J Affect Disord. 2017;208:553–9.Kan C, Silva N, Golden SH, Rajala U, Timonen M, Stahl D, et al. A systematic review and meta-analysis of the association between depression and insulin resistance. Diabetes Care. 2013;36:480–9.Phillips CM, Perry IJ. Depressive symptoms, anxiety, and well-being among metabolic health obese subtypes. Psychoneuroendocrinology 2015;62:47–53.Dutheil S, Ota KT, Wohleb ES, Rasmussen K, Duman RS. High-fat diet induced anxiety and anhedonia: impact on brain homeostasis and inflammation. Neuropsychopharmacology 2016;41:1874–87.Zemdegs J, Quesseveur G, Jarriault D, Pénicaud L, Fioramonti X, Guiard BP. High-fat diet-induced metabolic disorders impairs 5-HT function and anxiety-like behavior in mice. Br J Pharm. 2016;173:2095–110.Zemdegs J, Martin H, Pintana H, Bullich S, Manta S, Marqués MA, et al. Metformin promotes anxiolytic and antidepressant-like responses in insulin-resistant mice by decreasing circulating branched-chain amino acids. J Neurosci. 2019;39:5935–48.Hassan AM, Mancano G, Kashofer K, Fröhlich EE, Matak A, Mayerhofer R, et al. High-fat diet induces depression-like behaviour in mice associated with changes in microbiome, neuropeptide Y, and brain metabolome. Nutr Neurosci. 2019;22:877–93.Papazoglou IK, Jean A, Gertler A, Taouis M, Vacher CM. Hippocampal GSK3β as a molecular link between obesity and depression. Mol Neurobiol. 2015;52:363–74.Martin H, Bullich S, Guiard BP, Fioramonti X. The impact of insulin on the serotonergic system and consequences on diabetes-associated mood disorders. J Neuroendocrinol. 2021;33:e12928.Kleinridders A, Cai W, Cappellucci L, Ghazarian A, Collins WR, Vienberg SG, et al. Insulin resistance in brain alters dopamine turnover and causes behavioral disorders. Proc Natl Acad Sci. 2015;112:3463–8.Guiard BP, El Mansari M, Blier P. Prospect of a dopamine contribution in the next generation of antidepressant drugs: the triple reuptake inhibitors. Curr Drug Targets. 2009;10:1069–84.Labouèbe G, Liu S, Dias C, Zou H, Wong JCY, Karunakaran S, et al. Insulin induces long-term depression of VTA dopamine neurons via an endocannabinoid-mediated mechanism. Nat Neurosci. 2013;16:300–8.Könner AC, Hess S, Tovar S, Mesaros A, Sánchez-Lasheras C, Evers N, et al. Role for insulin signaling in catecholaminergic neurons in control of energy homeostasis. Cell Metab. 2011;13:720–8.Evans MC, Kumar NS, Inglis MA, Anderson GM. Leptin and insulin do not exert redundant control of metabolic or emotive function via dopamine neurons. Horm Behav. 2018;106:93–104.Yohn CN, Gergues MM, Samuels BA. The role of 5-HT receptors in depression. Mol Brain. 2017;10:28.Kiyasova V, Fernandez SP, Laine J, Stankovski L, Muzerelle A, Doly S, et al. A genetically defined morphologically and functionally unique subset of 5-HT neurons in the mouse raphe nuclei. J Neurosci J Soc Neurosci. 2011;31:2756–68.Hanson LR, Fine JM, Svitak AL, Faltesek KA, Intranasal administration of CNS therapeutics to awake mice. J Vis Exp. 2013;74:4440.Dhuria SV, Hanson LR, Frey WH. Intranasal delivery to the central nervous system: mechanisms and experimental considerations. J Pharm Sci. 2010;99:1654–73.Fan LW, Carter K, Bhatt A, Pang Y. Rapid transport of insulin to the brain following intranasal administration in rats. Neural Regen Res. 2019;14:1046–51.Dellu-Hagedorn F, Fitoussi A, De Deurwaerdère P. Correlative analysis of dopaminergic and serotonergic metabolism across the brain to study monoaminergic function and interaction. J Neurosci Methods. 2017;280:54–63.Puginier E, Bharatiya R, Chagraoui A, Manem J, Cho YH, Garret M, et al. Early neurochemical modifications of monoaminergic systems in the R6/1 mouse model of Huntington’s disease. Neurochem Int. 2019;128:186–95.Rainer Q, Nguyen HT, Quesseveur G, Gardier AM, David DJ, Guiard BP. Functional status of somatodendritic serotonin 1A autoreceptor after long-term treatment with fluoxetine in a mouse model of anxiety/depression based on repeated corticosterone administration. Mol Pharm. 2012;81:106–12.Qesseveur G, Petit AC, Nguyen HT, Dahan L, Colle R, Rotenberg S, et al. Genetic dysfunction of serotonin 2A receptor hampers response to antidepressant drugs: A translational approach. Neuropharmacology 2016;105:142–53.Guiard BP, Przybylski C, Guilloux JP, Seif I, Froger N, De Felipe C, et al. Blockade of substance P (neurokinin 1) receptors enhances extracellular serotonin when combined with a selective serotonin reuptake inhibitor: an in vivo microdialysis study in mice. J Neurochem. 2004;89:54–63.Ferreira de Sá DS, Römer S, Brückner AH, Issler T, Hauck A, Michael T. Effects of intranasal insulin as an enhancer of fear extinction: a randomized, double-blind, placebo-controlled experimental study. Neuropsychopharmacol Publ Am Coll Neuropsychopharmacol. 2020;45:753–60.Marks DR, Tucker K, Cavallin MA, Mast TG, Fadool DA. Awake intranasal insulin delivery modifies protein complexes and alters memory, anxiety, and olfactory behaviors. J Neurosci. 2009;29:6734–51.Schmid V, Kullmann S, Gfrörer W, Hund V, Hallschmid M, Lipp HP, et al. Safety of intranasal human insulin: A review. Diabetes Obes Metab. 2018;20:1563–77.Papazoglou I, Berthou F, Vicaire N, Rouch C, Markaki EM, Bailbe D, et al. Hypothalamic serotonin–insulin signaling cross-talk and alterations in a type 2 diabetic model. Mol Cell Endocrinol. 2012;350:136–44.Portal B, Delcourte S, Rovera R, Lejards C, Bullich S, Malnou CE, et al. Genetic and pharmacological inactivation of astroglial connexin 43 differentially influences the acute response of antidepressant and anxiolytic drugs. Acta Physiol Oxf Engl. 2020;229:e13440.MacKenzie RG, Trulson ME. Effects of insulin and streptozotocin-induced diabetes on brain tryptophan and serotonin metabolism in rats. J Neurochem. 1978;30:205–11.Orosco M, Nicolaidis S. Insulin and glucose-induced changes in feeding and medial hypothalamic monoamines revealed by microdialysis in rats. Brain Res Bull. 1994;33:289–97.Martín-Cora FJ, Fornal CA, Metzler CW, Jacobs BL. Insulin-induced hypoglycemia decreases single-unit activity of serotonergic medullary raphe neurons in freely moving cats: relationship to sympathetic and motor output: Medullary 5-HT neuronal responses to glucoregulatory challenges. Eur J Neurosci. 2002;16:722–34.Chaput Y, de Montigny C, Blier P. Effects of a selective 5-HT reuptake blocker, citalopram, on the sensitivity of 5-HT autoreceptors: electrophysiological studies in the rat brain. Naunyn Schmiedebergs Arch Pharm. 1986;333:342–8.Czachura JF, Rasmussen K. Effects of acute and chronic administration of fluoxetine on the activity of serotonergic neurons in the dorsal raphe nucleus of the rat. Naunyn Schmiedebergs Arch Pharm. 2000;362:266–75.Bosker FJ, Klompmakers A, Westenberg HGM. Postsynaptic 5-HT1A receptors mediate 5-hydroxytryptamine release in the amygdala through a feedback to the caudal linear raphe. Eur J Pharm. 1997;333:147–57.Martín-Ruiz R, Ugedo L. Electrophysiological evidence for postsynaptic 5-HT(1A) receptor control of dorsal raphe 5-HT neurones. Neuropharmacology 2001;41:72–8.Hajós M, Richards CD, Székely AD, Sharp T. An electrophysiological and neuroanatomical study of the medial prefrontal cortical projection to the midbrain raphe nuclei in the rat. Neuroscience 1998;87:95–108.Craven R, Grahame-Smith D, Newberry N. WAY-100635 and GR127935: effects on 5-hydroxytryptamine-containing neurones. Eur J Pharm. 1994;271:R1–3.Fletcher A, Forster EA, Bill DJ, Brown G, Cliffe IA, Hartley JE, et al. Electrophysiological, biochemical, neurohormonal and behavioural studies with WAY-100635, a potent, selective and silent 5-HT1A receptor antagonist. Behav Brain Res. 1996;73:337–53.Johnson DA, Gartside SE, Ingram CD. 5-HT1A receptor-mediated autoinhibition does not function at physiological firing rates: evidence from in vitro electrophysiological studies in the rat dorsal raphe nucleus. Neuropharmacology 2002;43:959–65.Deryabina IB, Andrianov VV, Muranova LN, Bogodvid TK, Gainutdinov KL, Effects of thryptophan hydroxylase blockade by P-Chlorophenylalanine on contextual memory reconsolidation after training of different intensity. Int J Mol Sci. 2020;21:2087.Johnson PL, Molosh A, Fitz SD, Arendt D, Deehan GA, Federici LM, et al. Pharmacological depletion of serotonin in the basolateral amygdala complex reduces anxiety and disrupts fear conditioning. Pharm Biochem Behav. 2015;138:174–9.Engin E, Smith KS, Gao Y, Nagy D, Foster RA, Tsvetkov E, et al. Modulation of anxiety and fear via distinct intrahippocampal circuits. eLife 2016;5:e14120.Wagle M, Zarei M, Lovett-Barron M, Poston KT, Xu J, Ramey V, et al. Brain-wide perception of the emotional valence of light is regulated by distinct hypothalamic neurons. Mol Psychiatry. 2022;1–17. Online ahead of print.Insel T, Cuthbert B, Garvey M, Heinssen R, Pine DS, Quinn K, et al. Research domain criteria (RDoC): toward a new classification framework for research on mental disorders. Am J Psychiatry. 2010;167:748–51.Sharma S, Fulton S. Diet-induced obesity promotes depressive-like behaviour that is associated with neural adaptations in brain reward circuitry. Int J Obes. 2013;37:382.Liu Z, Patil IY, Jiang T, Sancheti H, Walsh JP, Stiles BL, et al. High-fat diet induces hepatic insulin resistance and impairment of synaptic plasticity. PloS One. 2015;10:e0128274.Kothari V, Luo Y, Tornabene T, O’Neill AM, Greene MW, Geetha T, et al. High-fat diet induces brain insulin resistance and cognitive impairment in mice. Biochim Biophys Acta Mol Basis Dis. 2017;1863:499–508.Trivedi MH, Rush AJ, Wisniewski SR, Nierenberg AA, Warden D, Ritz L, et al. Evaluation of outcomes with citalopram for depression using measurement-based care in STAR*D: Implications for clinical practice. Am J Psychiatry. 2006;163:28–40.Blier P, Ward H. Toward optimal treatments for major depression. CNS Spectr. 2002;7:148–50. 153–4",0.0,0.0
158,https://step.ukaea.uk,Spherical Tokamak for Energy Production,"Spherical Tokamak for Energy ProductionSTEP is a UKAEA programme that will demonstrate the ability to generate net electricity from fusion. It will also determine how the plant will be maintained through its operational life and prove the potential for the plant to produce its own fuel.The first phase of the programme is to produce a concept design by 2024. It will be a spherical tokamak, connected to the National Grid and producing net energy, although it is not expected to be a commercially operating plant at this stage.",0.0,0.0
88,https://www.theguardian.com/world/2022/oct/27/megalopolis-how-coastal-west-africa-will-shape-the-coming-century?CMP=longread_email,Megalopolis: how coastal west Africa will shape the coming century,"It has long been said that no one knows with any certainty the population of Lagos, Nigeria. When I spent time there a decade ago, the United Nations conservatively put the number at 11.5 million, but other estimates ranged as high as 18 million. The one thing everyone agreed was that Lagos was growing very fast. The population was already 40 times bigger than it had been in 1960, when Nigeria gained independence. One local demographer told me that 5,000 people were migrating to Lagos every day, mostly from the Nigerian countryside. Since then, the city has continued to swell. By 2035, the UN projects that Lagos will be home to 24.5 million people.What is happening in Lagos is happening across the continent. Today, Africa has 1.4 billion people. By the middle of the century, experts such as Edward Paice, author of Youthquake: Why Africa’s Demography Should Matter to the World, believe that this number will have almost doubled. By the end of this century, the UN projects that Africa, which had less than one-tenth of the world’s population in 1950, will be home to 3.9 billion people, or 40% of humanity.These are staggering numbers, but they do not tell the full story. We need to zoom in closer. It is in cities where most of this astounding demographic growth will occur. Once we begin to think along these lines, what is at stake becomes even clearer. Much western commentary on Africa’s population growth has been alarmist and somewhat parochial, focusing on what this means for migration to Europe. The question of how African nations manage the fastest urbanisation in human history will certainly affect how many millions of its people seek to stay or leave. A recent continental survey by a South African foundation, for example, found that 73% of young Nigerians expressed an interest in emigrating within the next three years. But given its scale, this is a story with far larger implications than population movements alone, shaping everything from global economic prosperity to the future of the African nation state and the prospects for limiting climate crisis.There is one place above all that should been seen as the centre of this urban transformation. It is a stretch of coastal west Africa that begins in the west with Abidjan, the economic capital of Ivory Coast, and extends 600 miles east – passing through the countries of Ghana, Togo and Benin – before finally arriving at Lagos. Recently, this has come to be seen by many experts as the world’s most rapidly urbanising region, a “megalopolis” in the making – that is, a large and densely clustered group of metropolitan centres. When its population surpassed 10 million people in the 1950s, the New York metropolitan area became the anchor of one of the first urban zones to be described this way – a region of almost continuous dense habitation that stretches 400 miles from Washington DC to Boston. Other regions, such as Japan’s Tokyo-Osaka corridor, soon gained the same distinction, and were later joined by other gigantic clusters in India, China and Europe.But the Abidjan-Lagos stretch now stands to become the granddaddy of them all. In just over a decade from now, its major cities will contain 40 million people. Abidjan, with 8.3 million people, will be almost as large as New York City is today. The story of the region’s small cities is equally dramatic. They are either becoming major urban centres in their own right, or – as with places like Oyo in Nigeria, Takoradi in Ghana, and Bingerville in Ivory Coast – they are gradually being absorbed by bigger cities. Meanwhile, newborn cities are popping into existence in settings that were all but barren a generation ago. When one includes these sorts of places, the projected population for this coastal zone will reach 51 million people by 2035, roughly as many people as the north-eastern corridor of the US counted when it first came to be considered a megalopolis.But unlike that American super-region, whose population long ago plateaued, this part of west Africa will keep growing. By 2100, the Lagos-Abidjan stretch is projected to be the largest zone of continuous, dense habitation on earth, with something in the order of half a billion people.“I have worked in China and in India, and that is where most of the attention on cities has been until fairly recently, but Africa is unquestionably the continent that will drive the future of urbanisation. And it is that strip along the coast of west Africa where the biggest changes are coming,” said Daniel Hoornweg, a scholar of urbanisation at Ontario Tech University. “If it can develop efficiently, the region will become more than the sum of its parts – and the parts themselves are quite big. But if it develops badly, a tremendous amount of economic potential will be lost, and in the worst of cases, all hell could break loose.”The first time I travelled along this stretch of coast was in the late 1970s, on a long road trip to Nigeria from Ivory Coast, where my family then lived. My father, who ran a 20-country healthcare training programme for the World Health Organization, had a meeting to attend in Lagos, and he decided to invite my brothers and me along for the ride. At the time I was a first-year college student in the US, but it was the summer holidays, and I was excited to jump aboard a clattering old-school grey Land Rover for the trip.He followed a route traced out on a well-worn, foldable Michelin map. It did not take long to discover that many of the routes marked on the map in red – supposedly signifying national or international highways – were little more than two-lane asphalt roads, some of which had long ago been chewed to oblivion by heavy trucking traffic, or eroded by years of seasonal rains. The secondary or tertiary roads, traced more faintly in yellow and white, signalled far greater challenges: jarring dirt paths that were more like trails than highways. These would leave our bodies aching and caked with dust. For long stretches, the west African countryside was so empty that we had to carry our own fuel in jerry cans.One unfortunate artefact of this region’s imperial history is that, while the British and French built roads and railways to transport agricultural commodities and minerals from the hinterlands of their colonies to modern ports – where they could be shipped home for great profit – in their intense imperial rivalry, they did little to connect their respective possessions. But by 1992, when I took another long drive along this coast, a stretch of highway had been built on either side of the frontier between Ivory Coast and Ghana circumventing a coastal lagoon, and relegating the old picturesque but chancy border-crossing ferry to quaint memory. Back then, few could have imagined the full scope of the changes coming to this stretch of coast – though, in retrospect, some of the signs were already clear.Downtown Lagos, Nigeria. Photograph: peeterv/Getty Images/iStockphotoAs late as 1980, Lagos had still seemed like a series of modest towns barely stitched together by its highways and bridges. By the early 90s, though, it had exploded in size, and was already choking on itself. It had become notorious for some of the world’s worst traffic jams, known locally as go-slows. Abidjan, the region’s second-largest city, had also begun to morph. Its suburbs were expanding, thrusting toward the border with Ghana to the east. The other national and economic capitals of this region – Accra in Ghana, Lomé in Togo and Cotonou in Benin – were likewise starting to mushroom.But it was on more recent trips, in the 2010s, that I saw the urban revolution transforming west Africa coming into full view. By then, Ivory Coast had laid down a true highway all the way from Abidjan to its border with Ghana. Abidjan had gobbled up early colonial capitals like Bingerville and the postcard-pretty but long-stagnant beach town of Grand-Bassam, turning them into dormitory communities. The roadside scenery during a drive from border to border along the Ghanaian coast bore no resemblance to the lightly peopled landscapes of earlier decades. Towns and cities were strung together one after another along nearly the entire route. For long stretches, one scarcely ever left an urban environment.As always in this region, Lagos is where the most dramatic changes are visible. As it swells, the city is shooting thick urban tendrils west toward the border with Benin – the slender, francophone nation of 12 million people next door – rendering much of that country’s economy a satellite not so much of Nigeria, but of Lagos itself. (If Lagos state were an independent country, its economy would rank as the fourth-biggest in Africa.)Led by Lagos, as coastal west Africa’s urbanisation gathers pace, and populations and regional commerce begin to surge across old imperial borders, the lives of tens of millions of people along the coastal corridor are changing in ways that neither colonial designs nor six decades of independent government seem to have remotely anticipated.Earlier this year, I returned to the coast, this time not for one long road trip, but for a series of shorter forays by car in Ghana, Togo and Benin. Everywhere I went, the speed and scale of the historic transformations under way were evident. In Ghana, I visited a place I had encountered on previous trips, Takoradi, and its conjoined twin, the railroad town of Sekondi. In 1980, the two towns together counted 197,000 people. This year, their population surpassed a threshold that only 14 American cities have ever reached: 1 million people, a more than five-fold increase in little more than a generation.On the July morning I returned to Takoradi, it was the Islamic holiday of Eid al-Adha, or Tabaski, and the narrow downtown streets were packed with young celebrants from the local Muslim minority, all dressed colourfully in flowing laced robes. When the centre of Takoradi was built, more than a century ago, the city was Ghana’s lone port. It was here that Kwame Nkrumah famously returned by ship from England in 1947, emerging from obscurity to lead his country, then a British colony known as the Gold Coast, to independence 10 years later. In their fading pastel and dreary grey tones, the verandaed buildings of the old downtown looked like the set of a period drama. Just beyond here, though, the antiquated scene gave way to an enormous construction site, where a highway flyover was rising above dusty streets. Once complete, it will allow traffic to bypass the old, outgrown centre in favour of the much larger modern periphery, where most of the city’s people now live.Overpass construction in Sekondi-Takoradi. Photograph: Howard W FrenchAt Takoradi’s western edge, I stopped at a new shopping mall where, on the shelves of a busy supermarket, I found South African wines, Swiss chocolates, cellophane packs of the same brand of fresh blueberries I eat every day in New York, and – an even more surefire sign of disposable income – expensive canned dog food. There were also Portuguese and Chinese restaurants, a beauty salon, mobile phone shops and a bridal gown dealer doing brisk business.It is not immediately obvious where the income necessary to sustain this kind of commercial strip comes from. Some surely derives from work in the offshore oil business based nearby, some from a recently expanded regional port, some from a combination of old-line cocoa farming and new jobs in tech. And this points to the reality of what makes this megaregion so distinctive from earlier ones. Since at least the 18th century, as the writings of Hegel and Hume show, Africa has been widely regarded in the west as if it existed outside the flow of history – scarcely a participant in the global present, and even less relevant to the future. This has never been true, but those who cling on to such misapprehensions would do well to visit this stretch of coastline. In Lagos, Accra, Abidjan, or even in much smaller places like Takoradi, meanwhile, globalised enclaves with strong links to the rich world jostle with expanses of ragged urbanity, half hopefully striving, half congealed in poverty.On another morning, I drove from the heart of Ghana’s capital, Accra, to the city of Kasoa, less than 20 miles away. Kasoa is sometimes touted as one of the fastest-growing conurbations on the continent. When I made my first trips along this coast in the 70s, it was little more than a shambling collection of rural roadside traders’ stalls. In 1984, Kasoa had 3,000 people. Scarcely a decade ago, its population was just shy of 70,000. Now it is home to roughly half a million people, equal to Edinburgh or Tucson.The view from an overpass above Kasoa on the coastal highway is a reminder that cities throughout Africa have tended to sprawl outwards, rather than upward. There is little high-rise housing here, and few tall buildings of any kind. From up high, Kasoa has a rough-hewn, unfinished look. The newborn city lurches outward from the highway junction in all directions, its roads jammed with traffic. For many experts, this is a problematic feature of much of west Africa’s urbanisation: it is almost entirely unplanned.Kasoa’s streets are frenzied with jumbles of wooden stalls and incessant trading of all kinds. In the dusty byways beyond the highway, young people were everywhere: hawking sachets of cold water, running after cars to sell mobile phone credits and cheap plastic toys, crying out the prices of sweet, puffy bread or plantain chips from beneath beach umbrellas on street corners.Most noticeable of all were the schoolchildren walking the streets in their uniforms and backpacks. By 2050, about 40% of all the people under 18 in the world will be African, a proportion that will reach half by century’s end. On the streets of Kasoa, statistics like these come to life. Everywhere there were billboards for daycare centres, kindergartens and “international schools”. The only real competition for school ads came from church ads, which offer promises of success in this world as much as in the next.Most of the people who fill the streets of places like Kasoa are recent arrivals from the countryside, and live in ramshackle cinderblock dwellings. Julius Ackatiah, a 55-year-old, recently set himself up in business here after many years in Italy, where he had already realised the African dream of emigration, legally acquiring a new nationality in a rich European country. I met him as he peered out from the unfussy sidestreet storefront where he sells secondhand housewares he has shipped from Italy.Why had he chosen Kasoa, I asked him? Accra has recently become overbuilt and too expensive, Ackatiah said, but Kasoa was on the rise. “There are lots of people here, and they are trying to set up new homes for themselves and make new lives in this town. That makes for good business.” As Ackatiah spoke on the stairs of his shop, he was engulfed by his used-goods stock in trade: cheap plastic chairs, living room couches and tables, computer monitors and household appliances, small and large, from refrigerators and microwaves to laundry irons.One of the biggest challenges for Africa’s emerging megaregions remains its weak transport networks. In 2018, more than 40 nations agreed to create the African Continental Free Trade Area, an arrangement that economists say could boost African GDP by $450bn by 2035, mostly thanks to increased intra-African commerce. Since then, another 10 countries have joined, including Nigeria, making for a truly continent-wide agreement. “At its crux, outside the World Trade Organization, it is the biggest region of free trade in the world,” said Astrid Haas, a Ugandan independent economist based in Kampala. “What it is intended to do is unlock the benefits on the continental scale for African countries to be able to trade with each other; to eliminate both tariff and non-tariff barriers.”But realising its full potential will require much more intense cooperation between neighbours, and especially on improving physical infrastructure. Algiers and Cairo remain the only African cities with underground commuter lines. (In recent years, inspired citizen designers have carefully sketched out potential subway networks for cities such as Kigali and Port Harcourt, but these remain hopeful ideas for now.) Abidjan and Lagos are building surface light urban rail systems, but both are small-scale and behind schedule. Meanwhile, the lack of decent roads continues to hold this region back. The four-lane highway between Accra and Kasoa aside, almost the entire 600-mile stretch of coast consists of an undivided two-lane road that passes slowly through small towns and villages. Drivers sometimes find themselves having to dodge daring pedestrians and errant animals.Then there are the predatory police and soldiers who stop drivers in order to extort money under the pretext of traffic safety checks or the fight against crime. Last summer, on the outskirts of Takoradi, I was waved down by a portly, peanut-chewing police officer who asked, as if it was the most normal thing in the world: “What have you brought for me?” West African travellers face holdups like this, smiling or not, on a daily basis. On a trip in Ghana in the 90s, when I travelled 340 miles from the northern town of Bolgatanga to the central city of Kumasi, I counted 72 roadblocks. If anything, international borders in the region have long been even worse hotspots for this kind of predation.A development proposal in Accra, Ghana. Photograph: Howard W FrenchYet there is some reason for optimism. In May, the African Development Bank announced it had raised $15.6bn to fund the construction of a new coastal highway from Lagos to Abidjan. “We are talking about something like the road between Baltimore and New York – a toll road,” said Lydie Ehouman, a transportation economist at the bank, who told me the target for completion of the highway, which will be four to six lanes wide throughout, is 2026. “It will be free-flowing, with a chip in your licence plate so you don’t need to stop at toll gates. It will be a modern highway.” Economists at the African Development Bank argue that the West African Highway, as the new road will be called, will increase cross-border trade among the participating countries by 36%.“If people are confident in the availability of reliable, rapid transportation, other things will begin to change dramatically, too,” said Hoornweg, the Ontario Tech professor. “Property values will rise sharply along the major transportation axes, and that will encourage people to build upward, with highrises, rather than building out with more and more sprawl. The cities will also become much more efficient and environmentally friendly, and that makes their development more sustainable.”On the ground today, a vision like this isn’t so easily conjured. It’s true that in Lagos a collection of impressive modern highrises is slowly taking shape. And in downtown Accra, a dazzling new real estate scheme – high-end apartment towers, office buildings, fancy shopping plazas, luxury hotels – is planned for the waterfront. But such projects are catering to the needs of the already wealthy, and not to the growing millions of people in the region who will soon urgently need housing. Here, the contrast with China, where huge clusters of residential high-rises ring every large city, could not be more striking. Rather than avatars of the future, in fact, the easiest thing to conclude from projects like these is that the region’s governments are setting their sights far too low to address the sweeping demographic and social changes on their way. This may even be true about the coastal highway system.“The best thing that could happen to west Africa would be if someone could convince these countries to seriously consider the experience of Asia,” said Alain Bertaud, a senior fellow at the Marron Institute at New York University. As a former World Bank official who specialises in urbanisation, Bertaud advised China about developing one of the world’s most successful megaregions, in the Pearl River delta. “Density itself does not create prosperity,” Bertaud told me. “You will have to have lots more transportation, including new rail lines, new roads that link the coastal highway to the hinterlands and to small cities, where the cheaper land is.” He pointed out that this requires a lot of building across national borders, which is not easy in any part of the world. “In India, we have seen that even building a corridor that crosses several states within the same country is difficult. In Africa they will need much better coordination.”Haas, the Ugandan economist, agreed. “Africa faces a need for $20-25 billion annually in infrastructure investment, plus $20bn more each year for housing. Trying to convey the scale here is very hard. We are talking about ballooning numbers, and people need to be shocked into action.”Toward the end of my trip, I took a three-hour drive from Accra to the border with Togo. As we drove, Accra soon gave way to a grimy industrial zone that stretched for miles. From here all the way to the border, about 120 miles, the landscape was filled with peri-urban sprawl, its most distinctive feature being the ubiquitous roadside schools where children played sports or milled about.At the border, as soon as I climbed out of my car I was surrounded by touts eager to sell me taxi rides, exchange currency for me or help expedite my visa and vaccination checks. I proceeded alone, expecting complications, but was pleasantly surprised at how straightforward the procedures were on both sides of the border. My first question to the driver I hired on the Togolese side was how far it was to the capital, Lomé. He laughed. “You’re already in Lomé,” he said. “In 15 minutes, you will be at your hotel.”The next day, a Sunday, I drove 30 minutes east from Lomé to a small town with Royce Wells, a 30-year-old American IT professional who wanted to inspect the progress on a beachside house he is building. Togo is an unusually narrow country – wedged between Ghana and Benin, it runs about 430 miles north to south, but has only 31 miles of coastline. For this reason, local elites and foreign investors alike have long dreamed of building it into a kind of entrepot trading state that profits from various kinds of arbitrage, from sharp currency fluctuations in Nigeria and Ghana to varying levels of corruption and political risk among its neighbours.The Togo-Ghana border as seen from Lomé. Photograph: Joerg Boethling/AlamyTogo maintains a democratic facade through regular elections, but has been tightly controlled by one family since 1963. In contrast to Nigeria, though, the electricity works, the internet is fast, and everyday life is not plagued by insecurity. With its commercial future in mind, Togo has built a port with capacity much larger than its domestic needs, and also produces cement, steel and other industrial and consumer goods for its larger neighbours. On this basis, Wells sees the country as a good bet, and hopes to make money building hotels there. “The places that learn how to create the right tax incentives and legal protections [for investors] will basically be able to arbitrage on Lagos and its dysfunction,” he told me.Others are much more sceptical that this vision will ever be realised. After all, it relies on canny decision-making at the top of government. Bright Simons, a prominent Ghanaian political analyst and entrepreneur, called this five-nation megaregion “one of the most administratively broken landscapes on the planet”. Its governments are “unbelievably un-strategic”, he said. “I am always puzzled by the enthusiasm of elites for creating chambers of commerce with Mexico, or some other distant country, rather than with their own neighbours.”Here, the needs of west Africa’s booming population collide with the stubborn realities of the nation state, and specifically with contrasting colonial histories. Ivory Coast, Benin and Togo are former French colonies, and Nigeria and Ghana were colonised by Britain. This has left different official languages in place, whether English or French, as well as a currency in the French-speaking states, the CFA franc, that is a relic of colonisation – it was once tied to the French franc and is now attached to the euro. Perhaps the most important imperial legacy, though, is the insular national elites who, because of colonial history and the near-checkerboard way the countries alternate between English and French, pay scarce heed to each other. A Nigerian I met in Accra, for example, told me: “It wasn’t until I started spending time in Ghana recently that I realised Ghana isn’t our neighbour. Benin sits next to us, followed by Togo.”Cotonou, the economic capital of Benin (separate from but very close to its national capital, Porto-Novo), lies 20 miles from the border of Nigeria, and 76 miles from Lagos, but there is no immediate sense of the behemoth next door. The city of 700,000 (on its way to 5 million by 2100) clusters around a small and tidy administrative centre, complete with a modernist presidential palace built largely in glass, whose large size belies the diminutive nature of Benin itself, the corridor’s second-smallest state. With its low-rise buildings and heavy scooter traffic, much of Cotonou feels scarcely different from a big town or village. Whether Benin likes it or not, Lagos’s accelerating expansion seems destined to one day swamp this place.When I asked a longtime acquaintance, a successful businessman from Benin, whether people in his country, including its leaders, sustain close relations with Nigeria, the answer was no. “The elite here still flatters itself with talk about being the Latin Quarter of the region, due to our French chauvinism,” he said, referring to the pre-independence era when France made Benin a regional centre of colonial education. “Our leaders are very poor at thinking ahead … If you tell the president he has nice shoes, he’ll be swimming in happiness. With Nigeria next door, what we should have done long ago is make English a compulsory second language in school, but no one has ever thought of that.”This kind of pessimism, built upon a scornful assessment of governance at the national level in west Africa, is widespread. “We are going to need to have a functioning Ghanaian state, functioning states in Benin and Togo, and at least a minimally functional Nigerian government all at the same time in order to make this hugely urbanised future livable,” said E Gyimah-Boadi, the 70-year-old co-founder and former CEO of the Ghana Center for Democratic Development, a thinktank.“Part of me wants to believe that the youth of west Africa can be their own saviours, and that it is not because of the failures of my generation that they are necessarily doomed. The nation state has been a huge curse. It worked very well for some of us, but we have left very little behind for the young. Basically, we have cheated them.”Follow the Long Read on Twitter at @gdnlongread, listen to our podcasts here and sign up to the long read weekly email here.",0.0,0.0
152,https://arstechnica.com/tech-policy/2022/10/company-that-makes-rent-setting-software-for-landlords-sued-for-collusion/,Company that makes rent-setting software for landlords sued for collusion,"Front page layoutSite themeProPublica is a Pulitzer Prize-winning investigative newsroom. Sign up forRenters filed a lawsuitThe lawsuit was filed days afterThe proposed class-action lawsuit was filed in US District Court in San Diego.In an email, a RealPage representative said that the company “strongly denies the allegations and will vigorously defend against the lawsuit.” She declined to comment further, saying the company does not comment on pending litigation.The nine property managers named in the lawsuit did not respond immediately to a request for comment.They included some of the nation’s largest landlords, such as Greystar, Lincoln Property Company, Equity Residential, Mid-America Apartment Communities, and FPI Management—which together manage hundreds of thousands of apartments.Four of the five renters named in the suit were Greystar tenants. A fifth rented from Security Properties. Their apartments were located in San Diego, San Francisco, and two Washington state cities, Redmond and Everett.The lawsuit accused the property managers and RealPage of forming “a cartel to artificially inflate the price of and artificially decrease the supply and output of multifamily residential real estate leases from competitive levels.”RealPage’s software uses an algorithm to churn through a trove of data each night to suggest daily prices for available rental units. The software uses not only information about the apartment being priced and the property where it is located, but also private data on what nearby competitors are charging in rents. The software considers actual rents paid to those rivals—not just what they are advertising, the company told ProPublica.Join the Ars Orbital Transmission mailing list to get weekly updates delivered to your inbox.CNMN Collection",0.0,0.0
429,https://www.psypost.org/2022/10/victims-of-childhood-abuse-are-biologically-older-than-their-peers-in-midlife-study-indicates-64085,"Victims of childhood abuse are biologically older than their peers in midlife, study indicates","New research has found that individuals who suffer physical or sexual abuse in childhood age faster than their non-abused peers. Published in the journal Psychoneuroendocrinology, the researchers obtained participants aged 32-49 years and, using blood tests, found evidence to support the hypothesis that childhood trauma can shorten the lifespan.Interested in the consequences of childhood trauma, Gloria Graf and colleagues sought to investigate if evidence of childhood abuse could be seen in the biomarkers of aging. Previous research has already discovered that individuals abused in childhood experience more health problems as they age. If this is so, Graf and colleagues hypothesized it could be due to faster biological aging. As biological age increases, so does vulnerability to disease.To determine if those abused in childhood are aging faster than their non-abused peers, the researchers found 357 test subjects from a pool of individuals who had experienced court-documented childhood neglect and physical or sexual abuse. The study also included 200 control subjects who were matched with test subjects based on childhood economic and demographic similarities.Two blood tests were used to assess the biological aging of both the experimental and control subjects. The first is known as the Klemera-Doubal method Biological Age (KDM BA). Results of a KDM BA test can identify at what age certain biological markers would be seen as typical. For example, a KDM BA result of 53 for someone who is 49 indicates the individual is aging faster than their years. The second test, PhenoAge, measures mortality risk, and those with high mortality risk should have high biological age.The results of the KDM BA test indicated that those abused in childhood are more likely to have biological markers that indicate they are older than their actual age. Within the abused group, women aged faster than men, and minority sub-groups aged slower than Caucasians.The PhenoAge test did not reveal statistically significant results. The researchers hypothesized this could be because of the age of the subjects. Regardless of abuse and faster aging, those in both groups were not yet old enough to demonstrate large differences in mortality risk.Graf and colleagues report that these results are large enough to consider the necessity of follow-up care throughout the lifespan for victims of childhood abuse. If preventative care was provided to support physical and mental health long after childhood, it might be possible to decrease disease and increase length of life.The researchers acknowledge the limitations of their work. First, science is still developing the standard methodology for identifying how fast or slow someone is aging. The methods chosen are well-researched and respected but are not yet considered ‘standard.’ Second, subjects in the experimental group are those who experienced abuse significant enough to make it into the judicial system. Those in the control group may have also experienced undocumented abuse. This unknown factor could have had consequences for their results.Despite the acknowledged limitations, the researchers found their results meaningful, stating: “In sum, our results contribute support for the hypothesis that childhood maltreatment disrupts healthy aging processes.”The findings are also in line with other research, which has indicated that individuals exposed to adverse childhood experiences – such as neglect, witnessing intimate partner violence, and parental death — tend to be biologically older than their counterparts.The study, “Biological aging in maltreated children followed up into middle adulthood”, was authored by Gloria Graf, X. Li, D. Kwan, Daniel Belskey, and Cathy Widom.",0.0,0.0
476,https://techcrunch.com/2022/10/07/convective-capitals-35-million-answer-to-the-increasing-threat-of-wildfires/,Convective Capitalâs $35 million answer to the increasing threat of wildfires,"Wildfires have become an ever-increasing threat as houses are built closer together and the growing impacts of climate change wreak havoc on natural landscapes. Entrepreneurs, in response, have started to develop tech meant to minimize the scale and damage of these natural disasters. Convective Capital is a new VC firm looking to back them.Bill Clerico, the former co-founder and CEO of fintech WePay, launched the firm this year and has since raised $35 million for a first fund to back early-stage startups creating tech that can help detect and contain wildfires. The fund plans to invest in roughly 15 companies by writing seven-figure checks.While some of these startups could fall under the umbrella of climate tech, Clerico said focusing on wildfire solutions fits more into the climate resilience category. He thinks the distinction makes it a more straightforward investment opportunity because increasing wildfires are already a problem today as opposed to climate tech meant to prevent or minimize future problems.The thesis turned out to be a polarizing one to pitch as some investors understood the need immediately while others thought focusing on wildfire could prove to be too niche.“It made fundraising easier in that there were people who had witnessed the economic opportunity first hand, and understood the impacts of fire there,” Clerico said. “Or they had experienced it personally in various ways…or folks didn’t.”Clerico left WePay after a decade to pursue angel investing and become a volunteer fire fighter. While spending time at his home in Mendocino, California, he saw the impacts of the growing wildfire crisis as one of the natural disasters closed down the road to his house and he found himself struggling to get home insurance.“Just watching wildfires become the really big crisis that it is, and having a real vested interest in the outdoors, led me down this path,” Clerico said. “I started thinking about how technology could be a solution.”Clerico had made about 50 angel investments and admitted he was bored at the thought of hearing another fintech pitch. He started backing fire tech companies and began to specialize in the category. He decided to raise a fund so he could invest in the sector at scale.He estimated that there are currently 200 startups focused on this area, claiming that Convective Capital has probably talked to all of them. These startups are tackling different areas of the wildfire crisis ranging from Pano, a startup that uses camera systems and AI to help emergency response teams detect fires earlier, to Rain Industries, a company that creates autonomous drones to help put out fires.“What was missing though is that community coming together and acknowledging that fire tech is thing,” Clerico said. “It doesn’t exist as a category like fintech exists. Part of what we want to do as a firm is bring awareness to that category and really just help these founders get to know each other.”Maxwell Brodie, the co-founder and CEO of Rain Industries, told TechCrunch that while most likely everyone in California has been impacted by wildfires, it’s nice to see that someone like Clerico is actually trying to do something about it. He hopes that his involvement can help draw more builders and investors into the category.“All larger pools of resources [and capital] seek out where new emerging growth is going to come from,” Brodie said. “What [Clerico] is doing with Convective Capital is proving that there is a new emerging area of growth and everyone should be paying attention to that, especially late-stage investors.”While Clerico doesn’t believe that any sectors can really be recession proof, he thinks firetech is an area that isn’t really tied to broader market conditions. And while many of the companies he backs aren’t preventing the wildfires from starting, he hopes they can help mitigate some of the damage.“To leverage the power of startups to have a positive impact is a really inspiring challenge,” he said. “And one of the reasons why myself and my partners have gone after this.”",0.0,0.0
254,https://nypost.com/2022/10/26/terrifying-video-shows-chinese-robot-attack-dog-with-machine-gun-dropped-by-drone/,Terrifying video shows Chinese robot attack dog with machine gun dropped by drone,"A Chinese military contractor created a video showing off its terrifying new military technology, revealing a robot attack dog that can be dropped off by a drone.The video that was initially released on the verified Weibo account of “Kestrel Defense Blood-Wing,” a page affiliated with a Chinese defense contractor, shows a drone hovering over a building and then dropping off a robot on the roof. After the drone flies away, the robot gets up on four legs and then begins to scan for targets around the building with what appears to be some sort of automatic weapons attached to its back.According to a report from WarZone, the weapon mounted on the robot dog is possibly a Chinese QBB-97 light machine gun, which is capable of firing 650 rounds per minute at an effective range of 400 meters.A description of the robot posted by Kestrel Defense Blood-Wing and automatically translated to English boasts that the weapon can easily “launch a surprise attack.”“War dogs descending from the sky, air assault, Red Wing Forward heavy-duty drones deliver combat robot dogs, which can be directly inserted into the weak link behind the enemy to launch a surprise attack or can be placed on the roof of the enemy to occupy the commanding heights to suppress firepower. And ground troops [can] conduct a three-dimensional pincer attack on the enemy in the building,” the description reads.Video shows a drone hovering over a building and then dropping off a robot on the roof. Blood-WingPrevious 1 of 4 Next The weapon mounted on the robot dog is possibly a Chinese QBB-97 light machine gun. The robot gets up on four legs and then begins to scan for targets around the building. Red Wing Forward heavy-duty drones deliver combat robot dogs. The machine is capable of firing 650 rounds per minute at an effective range of 400 meters.The Chinese technology and other similar weapons have so far been designed to be operated by a human at the controls, though military analysts fear that systems in which robots designed to operate autonomously are in development and could soon be deployed on battlefields.Autonomous weapons systems would be particularly deadly for opposing forces, with the military that develops them being able to drop them deep behind enemy lines into areas that had previously been too difficult to reach or too dangerous to deploy human soldiers.",0.0,0.0
312,https://9to5mac.com/2022/10/27/apple-cant-make-enough-iphone-14-pros/,Tim Cook says Apple canât yet make enough iPhone 14 Pros to meet demand,"Apple’s fiscal Q4 earnings are out and while the company saw another record for revenue, there were some slight misses on expectations. CEO Tim Cook shared more details on what challenges the company is seeing like trying to keep up with iPhone 14 Pro demand.Speaking with CNBC’s Steve Kovach, Cook shared more on the situation with iPhone supply and demand:“We’re constrained right now on the 14 Pro and Pro Max and have been from the day we launched…and so obviously we’re chasing supply there and trying to get as much supply as we can to solve the demand.”That lines up with previous reports we’ve seen:Apple slightly missed expectations on Q4 iPhone revenue. But an important detail to remember is there was only just over a week of iPhone 14 and 14 Pro sales included in the period. Even so, Apple was able to grow YoY iPhone revenue by almost 10% and overall revenue for the quarter was up 8%.Cook said another major factor for its Q4 performance was the foreign exchange rates:“The foreign exchange headwinds were over 600 basis points for the quarter,” Cook told CNBC’s Steve Kovach. “So it was significant. We would have grown in double digits without the foreign exchange headwinds.”On the whole, Cook was proud of the company’s performance noting it “countered the industry trends on the phone if you look at third party estimates…”Read more on Apple’s Q4 results:FTC: We use income earning auto affiliate links. More.Check out 9to5Mac on YouTube for more Apple news:",0.0,0.0
228,https://techxplore.com/news/2022-10-australia-intercontinental-power-grid.html,Australia backs plan for intercontinental power grid,"Australia's Prime Minister Anthony Albanese (R) shakes hands with Singapore's Prime Minister Lee Hsien Loong during their meeting at Parliament House in Canberra on October 18, 2022.Australia touted a world-first project Tuesday that could help make the country a ""renewable energy superpower"" by shifting huge volumes of solar electricity under the sea to Singapore.Singapore Prime Minister Lee Hsien Loong met Australian counterpart Anthony Albanese in Canberra to ink a new green energy deal between the two countries.Albanese said the pact showed a ""collective resolve"" to slash greenhouse gas emissions through an ambitious energy project.He name-checked clean energy start-up Sun Cable, which wants to build a high-voltage transmission line capable of shifting huge volumes of solar power from the deserts of northern Australia to tropical Singapore.Sun Cable has said that, if successful, it would be the world's first intercontinental power grid.""If this project can be made to work—and I believe it can be—you will see the world's largest solar farm,"" Albanese told reporters.""The prospect of Sun Cable is just one part of what I talk about when I say Australia can be a renewable energy superpower for the world.""Lee said the green economy deal was the ""first such agreement of its kind"".""We hope that it will be a pathfinder for other countries simply to co-operate with one another to deal with what is a global problem.""Australia is one of the world's largest coal and gas exporters and has been frequently criticised on the global stage for its failure to make meaningful reductions in carbon emissions.Coal still plays a key role in domestic electricity production.© 2022 AFP",0.0,0.0
565,https://www.transportenvironment.org/discover/carmakers-lifetime-emissions-50-higher-than-reported/,Carmakersâ global emissions 50% higher than reported,"Carmakers’ global emissions are on average 50% higher than what they report with Hyundai-Kia and BMW underreporting emissions by as much as 115% and 80% respectively, a new Transport & Environment (T&E) report shows. With obligatory scope 3 (lifetime) emissions disclosure set to be introduced in 2023, asset managers with exposure to carbon intensive carmakers face a ‘ticking carbon bomb’, says T&E.In 2023, the EU will introduce a requirement that financial institutions disclose their scope 3 emissions (indirect emissions)[1]. The new requirement will hit asset managers with exposure to carmakers hard. Unlike manufacturers of furniture or mobile phones, the vast majority (98%) of a car company’s emissions come under scope 3 – primarily the use of the cars [2].But, as T&E’s analysis shows, carmakers’ already high scope 3 emissions are likely far larger than officially reported.Luca Bonaccorsi, director of sustainable finance at T&E, said: “For green investing to be effective, we need accurate data. Carmakers are trying to pull the wool over investors eyes by underreporting the lifetime emissions of their cars. This makes a mockery of carmakers’ green claims.”Carmakers base their total reported emissions on a number of factors such as the average size of the vehicles, where the cars are driven and the lifespan of vehicles. Carmakers on the whole have used selective data to reach a lower figure. Toyota, for example, bases the lifetime average emissions of its vehicles on a scarcely believable 100,000 kilometres.This makes car companies, from an investment perspective, almost as carbon intensive as the oil industry. At today’s prices, €1 million invested in an average of oil giants Exxon Mobil, BP and Shell finances around 5,000 tonnes of CO2 equivalent (CO2e). The same amount finances more than 4,500 tCO2e in the car sector[3]. In some cases the carbon intensity of carmakers is significantly higher: nearly 10,000 tonnes if invested in Renault-Nissan-Mitsubishi and 7,000 tonnes for Honda according to carmakers’ reporting [4].Luca Bonaccorsi added: “According to official disclosures, a euro invested in a car company finances virtually the same amount of carbon as a euro in an oil company. This should be a wake up call for the financial industry. Asset managers wanting to avoid a ticking carbon bomb will have to start ditching carmakers that continue to sell polluting cars.”By the end of 2022, Morningstar, a US-based financial firm, estimates that some 50% of all new financial products sold will be environmental, social and governance (ESG) based. However, ESG ratings fail to capture the companies’ true climate impact. Despite CO2 emissions being the most important environmental indicators, they represent less than 1% of the ESG rating for S&P and MSCI, two of the world’s leading ESG indexes. T&E calls on the EU to regulate and harmonise the methodology for ESG ratings to ensure consistent and transparent reporting of data.ENDSNotes to editor[1] Car companies’ true carbon intensity will be revealed in 2023 thanks to mandatory Scope 3 disclosure (both in the Sustainable Finance Disclosure Regulation and in the Corporate Sustainability Reporting Directive).[2] Greenhouse gas emissions are categorised into three groups (Scopes) by the most widely-used international accounting tool, the Greenhouse Gas (GHG) Protocol. Scope 1 covers direct emissions from owned or controlled sources. Scope 2 covers indirect emissions from the generation of purchased electricity, steam, heating and cooling consumed by the reporting company. Scope 3 includes all other indirect emissions that occur in a company’s value chain.[3] This is based on the official scope 3 disclosures of carmakers and oil companies, not T&E’s estimates. Oil companies are likely also significantly underreporting their scope 3 emissions. However, we have no evidence to believe that the under-reporting is higher in any specific sector. On the contrary, in another analysis, evidence suggests the error must be rather homogeneous across sectors and is somewhat filtered out by the use of ratios.[4] The chart does not compare companies’ total emissions but the amount of emissions equivalent to a specific financial investment. This ratio is influenced by the appetite of the market for a specific company, so the higher the evaluation of the company, the lower the carbon intensity ratio. A company’s evaluation is affected by a large number of variables.",0.0,0.0
82,https://www.theverge.com/2022/11/1/23435516/tumblr-porn-ban-modified-nudity-allowed-sexually-explicit-depictions-banned,Tumblr will now allow nudity but not explicit sex,"Tumblr has made an update it hinted at in September, changing its rules to allow nudity — but not sexually explicit images — on the platform.The company updated its community guidelines earlier today, laying out a set of rules that stops short of its earlier permissive attitude toward sexuality but that formally allows a wider range of imagery. “We now welcome a broader range of expression, creativity, and art on Tumblr, including content depicting the human form (yes, that includes the naked human form). So, even if your creations contain nudity, mature subject matter, or sexual themes, you can now share them on Tumblr using the appropriate Community Label,” the post says. “Visual depictions of sexually explicit acts remain off-limits on Tumblr.”A help center post and the community guidelines offer a little more detail. They say that “text, images, and videos that contain nudity, offensive language, sexual themes, or mature subject matter” is allowed on Tumblr, but “visual depictions of sexually explicit acts (or content with an overt focus on genitalia)” aren’t. There’s an exception for “historically significant art that you may find in a mainstream museum and which depicts sex acts — such as from India’s Śuṅga Empire,” although it must be labeled with a mature content or “sexual themes” tag so that users can filter it from their dashboards.“Nudity and other kinds of adult material are generally welcome. We’re not here to judge your art, we just ask that you add a Community Label to your mature content so that people can choose to filter it out of their Dashboard if they prefer,” say the community guidelines. However, users can’t post links or ads to “adult-oriented affiliate networks,” they can’t advertise “escort or erotic services,” and they can’t post content that “promotes pedophilia,” including “sexually suggestive” content with images of children.",0.0,0.0
30,https://www.ft.com/content/c08642f5-3aa3-447b-9028-c1c84b8e10fe,Airbus climbs past Boeing in single-aisle market share,"Airbus and Boeing have competed neck and neck for five decades in one of the world’s great commercial rivalries. But, as the contest resumes in earnest in the wake of the pandemic, the old order has changed. Airbus now has a wide lead in the single-aisle market — the hottest area of aviation — leaving Boeing to grapple with how to bridge the gap.The European company has grabbed new orders and market share with its popular A320 family of narrow-body jets, which predominantly serve shorter-haul destinations, to which travel has rebounded faster, compared with long-haul flights.Latest figures to the end of June show that Airbus had close to 17,000 orders of its A320 and A220 aircraft, and has so far delivered just over 10,600. The A320 is now the bestselling aircraft ever, overtaking US-based Boeing’s 737 jet.Recent fleet data from aviation consultancy Cirium showed Airbus’s A320 family with a “firm order backlog” market share of 59 per cent compared with Boeing’s 737 family of jets.The bestseller within the A320 family is its largest model, the A321neo, which is also offered with extra fuel tanks in long-range and extra-long range variants. Some airlines — such as America’s JetBlue — now use these for long-haul flights that were traditionally flown by more expensive wide-body jets.Airbus’s market share is only likely to grow as the group moves ahead with aggressive plans to lift output of the jets to 75 a month by 2025, despite industry-wide concerns about constraints in the supply chain. Production had reached a record 60 a month in 2019 before dropping to 40 a month when Covid hit.Some analysts have questioned when Boeing will be able to regain some of that lost market share, as the company has continued to deal with fallout from the grounding of its 737 Max 8 after two fatal crashes within five months.Production problems have prevented customer deliveries of Boeing’s wide-body 787 aircraft © Richard Ellis/AlamyGlobal regulators have since cleared the jet to fly again after Boeing implemented software and design changes and the plane is notching up new orders.Another challenge looming, however, is the recertification of the shorter 737 Max 7 and longer 737 Max 10 variants. Boeing is racing to complete those processes before the end of the year to avoid having to develop a new flight deck under rules introduced by US Congress following the Max crashes.I have a lot of time for Dave Calhoun . . . but he’s not in Seattle and the problems in Boeing lie in SeattleBoeing has also suffered production issues that have prevented customer deliveries of its wide-body 787 aircraft. In addition, development of its 777X aircraft has been delayed, while problems on a number of big defence contracts have only added to the challenges.Union representatives, meanwhile, have criticised the company’s decision to move its global headquarters from Chicago to Washington, DC — seen as taking it further away from its spiritual home, the commercial aircraft factories of Seattle, and adding to persistent questions over the quality of its engineering.Repeated delays on the commercial side have frustrated some of Boeing’s largest customers, including Ryanair. The low-cost carrier’s chief executive, Michael O’Leary, has said sweeping changes are needed to Boeing’s senior management led by chief executive Dave Calhoun.In a recent interview, O’Leary told the Financial Times that the US aviation group has “lost huge market share and existing customers are being lost to Airbus, which is why I don’t understand why they sit there and do nothing”.“I have a lot of time for Dave Calhoun . . . but he’s not in Seattle and the problems in Boeing lie in Seattle,” he said.But others, including Lufthansa chief executive Carsten Spohr, have continued to back the US company. Boeing has insisted that things have changed since the Max accidents. It is also ramping up the hiring of engineers as it works with the US aviation regulator to certify its upcoming 777X aircraft.Boeing’s chief executive Dave Calhoun has sought to resist discussion on market share © Christopher Goodney/BloombergHowever, in a further blow, Boeing last month lost out to Airbus on a $37bn order from China’s three big state airlines. They chose 290 A320neo jets — the biggest order by Chinese airlines since the start of the pandemic. The country is a crucial market for both Airbus and Boeing and the orders come at a time of rising political tensions between the US and China.Calhoun has previously cited uncertainty over orders from China as one of the three main risks facing the company, along with securely boosting production of the Max and resolving issues around the 787. China was the first country to ground the Max and, although its aviation regulator last year approved its return to service, Chinese carriers have not started flying the plane commercially again.The multibillion-dollar question facing Boeing, therefore, is how to recover its lead against Airbus, at the same time as China’s first self-developed aircraft — Comac’s narrow-body C919 — is finally nearing completion.Boeing abandoned a plan for a new midsize aeroplane — a twin-aisle aircraft that would have sat between the 737 Max and the larger 787 — and it remains unclear what its next step will be. Its balance sheet also remains constrained, with some $45bn of net debt.$45bn Net debt on Boeing balance sheetThe company needs to “launch an answer to the A321neo,” says Kevin Michaels, managing director of Michigan-based AeroDynamic Advisory. “Can they afford it? I think they can. Their balance sheet isn’t great but you’ve got to invest in your core business to stay around in the long run.”“The other problem they face is knowing what to do — if you do press the button, how do you do that plane? The world is about to change massively but no one yet knows what that technology will be and you could end up spending $20bn on something that will be immediately obsolete,” says Nick Cunningham, analyst at research firm Agency Partners in London, who believes the company needs to raise equity to fund a new programme.But Calhoun has recently played down any concerns about the company’s market share position vis-à-vis Airbus. “At this moment in time, it’s less important,” he told an investor conference in June. Boeing, he added, had to concentrate on getting planes back in the air.“We have to stay focused on doing that incredibly well. One aeroplane at a time. If I jump to a market share discussion immediately and say, ‘Let’s get above 50 and let’s do it next year’, what happens? The whole system gets crammed down in every way.”He also indicated at the same conference that the company might not launch anything new for at least another couple of years. He does not believe that the performance improvement to justify an all new aircraft currently exists.Boeing, he said, was sure it had the ability to compete. “I’m confident, my sales team is confident,” said Calhoun. “Our customers express confidence to me, so why would I rush? No good reason.”Additional reporting by Philip Georgiadis",0.0,0.0
16,https://www.eurekalert.org/news-releases/968551,Conservative state policies generally associated with higher mortality,"Making policies fully liberal in all U.S. states could have saved hundreds of thousands of lives in recent yearsState policies in eight different policy domains, including gun safety, labor and tobacco, are associated with U.S. working-age mortality, according to a new study published this week in the open-access journal PLOS ONE by Jennifer Karas Montez of Syracuse University, US, and colleagues. They note that more conservative state policies were generally associated with higher mortality.Americans die younger than people in most other high-income countries and within the United States life expectancy differs markedly across geographic areas. In 2019, it ranged from 74.4 years in Mississippi to 80.9 years in Hawaii.In the new work, the researchers used data from the 1999-2019 National Vital Statistics System to calculate state-level age-adjusted mortality rates for deaths from all causes and from cardiovascular disease (CVD), alcohol, suicide and drug poisoning among adults ages 25 to 64. They merged that data with annual state-level data on eight policy domains, where each state’s policies were scored on a 0-to-1 conservative-to-liberal continuum.The analysis revealed that more liberal policies on the environment, gun safety, labor, economic taxes and tobacco taxes were associated with lower mortality in each state. However, for marijuana, more conservative policies were associated with lower mortality. Particularly strong associations were found between gun safety policies and suicide mortality among men; between labor policies and alcohol-induced mortality; and between economic and tobacco tax policies and cardiovascular disease mortality. Simulations suggested that changing all policies in all states to a fully liberal orientation could have saved 171,030 lives in 2019, while changing them to a fully conservative orientation may have cost 217,635 lives.The authors conclude that the emergence of more conservative state policies in several domains and shifts in the share of the population living in states with these policies provide a partial explanation for the high and rising mortality among working-age Americans and the overall mortality disadvantage of the US compared to other high-income countries.The authors add: “U.S. state policies in recent decades may have contributed to the high and rising mortality rates of working-age adults. Changing state policies could prevent thousands of deaths every year from cardiovascular disease, suicide, alcohol, and drug poisoning.”#####In your coverage please use this URL to provide access to the freely available article in PLOS ONE: https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0275466Citation: Montez JK, Mehri N, Monnat SM, Beckfield J, Chapman D, Grumbach JM, et al. (2022) U.S. state policy contexts and mortality of working-age adults. PLoS ONE 17(10): e0275466. https://doi.org/10.1371/journal.pone.0275466Author Countries: USAFunding: This article was supported by a grant from the National Institute on Aging to JKM (grant R01AG05581). www.nih.nia.gov. The funder had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.",0.0,0.0
71,https://techcrunch.com/2022/09/13/latams-gen-t-is-working-to-enrich-biotech-with-brazilian-genomic-data/,LatAmâs Gen-t is working to enrich biotech with Brazilian genomic data,"Improving the diversity of global genomic data could hasten medical breakthroughs — and that’s the goal of Gen-t, a Brazilian startup working to infuse biotech with genetic data from the country’s population.For Lygia da Veiga Pereira, founder of the company, she said it’s more than just building a company, it’s about advancing science and medical technology.“The field keeps saying that we need diversity, but most of the diversity in the world is in countries with [the] least developed health systems,” said Pereira in an interview with TechCrunch. “Lack of diversity became sort of the mantra for the field, and I saw an opportunity, because if Brazil had anything to contribute, it would be with our diversity.”Today, less than 1% of genomic data is collected from people of Latin American and Hispanic origin; 87% comes from people of European descent. With so much data coming from a European background, this population gains earlier benefits from precision medicine.Without diversifying that data, Pereira said it can’t lead to greater medical advancements.“When you study a population with an ancestry different than European, the chances to make novel discoveries of genes associated with different phenotypes is increased, just because it’s uncharted territory,” she said.Gent-t has a partnership with Dr. Consulta, a network of medical centers in São Paulo and Rio de Janeiro, to recruit participants for its initiative. Currently, the company has efforts across four clinics in São Paulo and over 200 active participants, despite being fairly new, with its soft launch back in June. Patients must give informed consent before any testing is done.Gen-t is looking to have over 200,000 participants and maintain contact with each of them across a five-year period, if not longer. Currently the company is looking for participants 45 years of age or older.Assuming the company reaches its enterprising goal of 200,000 participants, the notion of making genomic data more inclusive is ambitious. Companies like 54gene and Nucleus Genomics are also fighting this uphill battle.In addition to private efforts, the Pan American Health Organization has been conducting genomic and health research within Latin America. But recent efforts within the PAHO have been focused on the COVID-19 pandemic.Gen-t has been able to garner support and raised 10 million Brazilian Real ($2 million USD) in a pre-seed funding round led by Eduardo Mufarej, with participation from Armínio Fraga, Daniel Gold from QVT Financial LP and Roivant Sciences.This round’s funds will go toward building out the startup’s technical teams and beginning clinical research.The road to more diverse genomic data may be a long one, but Pereira hopes this initiative will inspire others to find ways of contributing.“We’re working on building a model to also make the platform available to academia … because the more people doing research on the genetics of our population, the better it is for the population and for science in general,” she said.",0.0,0.0
17,https://www.cambridge.org/core/journals/journal-of-public-policy/article/hidden-homeownership-welfare-state-an-international-longterm-perspective-on-the-tax-treatment-of-homeowners/6B29E4D84EEB28E9BEAC308ABAD3211B,The hidden homeownership welfare state: an international long-term perspective on the tax treatment of homeowners,"Tax treatment of the owner-occupied housing Most countries foster homeownership in one way or another. Traditionally, homeownership policies are rather found in the manifestos of conservative parties and are particularly pronounced in Anglophone countries (Schelkle Reference Schelkle2012). In German-speaking countries, by contrast, Social Democrats in particular were rather skeptical about homeownership subsidies and either introduced it quite late in their party manifestos or did not consider it as a central objective of their housing policy (Kohl Reference Kohl2020). The political parties that propose homeownership subsidies not only for reasons of housing provision but also for reasons of fostering equality, secure wealth and stable democracies (Arundel and Ronald Reference Arundel and Ronald2021). This translated into a number of different subsidy schemes. On the one hand, homeownership can be promoted through direct subsidies. In countries with a tradition of “socialised homeownership” such as Iceland or Ireland, future homeowners have been eligible to subsidised loans or government transfers (Sveinsson Reference Sveinsson2000). In Germany, for example, these are housing construction bonuses (Wohnungsbauprämie) and family housing grants (Baukindergeld) (Kohlhase Reference Kohlhase2011). On the other hand, homeownership can be stimulated through the taxation system. In this study, we will focus on this second element of subsidy policies. In the literature, the following four types of instruments are mainly considered: taxes on imputed rent, interest relief on mortgage repayments, capital gains tax on housing, and the VAT on new dwellings (Haffner Reference Haffner1992; van Weesep and van Velzen Reference van Weesep and van Velzen1995; MacLennan et al. Reference MacLennan, Muellbauer and Stephens1998; Stephens Reference Stephens2003; Wolswijk Reference Wolswijk2009; Figari et al. Reference Figari, Paulus, Sutherland, Tsakloglou, Verbist and Zantomio2012). Below, we introduce each tax and exemptions in turn. Footnote 1 Imputed rent tax Taxes on imputed rent must be paid by the owner for the dwelling he occupies. This is justified by the fact that homeowners, unlike renters, do not pay any rent and therefore have an additional source of income. Especially, if at the same time the mortgage interest can be deducted from the income tax (see below), a bias in favour of homeowners emerges. The tax on imputed rent is aimed at restoring tax neutrality. In order to evaluate the amount of unpaid rent, fiscal authorities estimate a monetary use value of owner-occupied dwelling. The tax is expected to reduce the formation of homeownership. On the other hand, since the use value of housing can be considered as an additional income, the failure to collect such a tax would mean an unequal treatment of other types of income and, hence, a stimulation of the homeownership. The collection of this tax is often complicated, because the use value is difficult to assess correctly. Moreover, the absence of a tax on imputed rent represents a subsidy, which does not discriminate between the newly built and existing housing. Thus, everyone occupying one’s own dwelling can benefit from it. Tax deductibility of mortgage payments The possibility to deduct mortgage interests goes often hand in hand with the tax on imputed rents. It follows from the logic that the cost incurred to obtain an additional income (nonpayment of rent) must be deductible. In some countries, the possibility of mortgage interest relief exists even in the absence of an imputed rent tax. The interest deductibility makes the purchase of a home more attractive. However, this can generate the risk of speculative price bubbles. Capital gains tax This tax is imposed in cases when the owner makes profits resulting from the positive difference between the selling price of a dwelling and its purchasing price, provided that this difference cannot be entirely related to the improvements made to the dwelling. The capital gains tax tends to make the purchase of housing less attractive. One of the disadvantages of homeownership compared to renting is its reduced flexibility and mobility. Typically, it takes more time to sell an owner-occupied home than to terminate a rental contract. The absence of a capital gains tax could compensate for such a disadvantage and eventually make it more attractive for renters to become homeowners. On the other hand, it could create incentives for speculating with housing, since the absence of the capital gains tax for housing would make it more attractive than other assets (e.g., shares), which are subject to such a tax. This could stimulate the formation of speculative house price bubbles and, hence, make it more difficult for the low- and middle-income households to purchase homes. Therefore, the capital gains tax on housing is sometimes conceived as a speculation tax from which the owners, who really occupy their dwellings, are exempted. Being a speculative tax, the capital gains tax imposes as a rule a minimum holding period. It means that the real estate must be kept by the owner for a certain time period until it is exempted from the taxation. Table A5 reports different exemptions from the capital gains tax for each country. The capital gains tax is assumed to be applicable regardless of the holding period, save for the cases, where the owner-occupier is explicitly exempted from the tax. VAT on the new dwellings The VAT on newly built dwellings is added to the purchasing price of a dwelling offered for sale. As a result, housing becomes more expensive and less attractive to buy. At the same time, exactly as in the case of the imputed rent tax, the VAT for new dwellings allows treating housing similar to other goods, which are subject to VAT. Hence, the absence of the VAT on housing can be considered as a subsidy. Unlike the absence of the tax on imputed rent, the absence of the VAT stimulates the construction of new dwellings.Quantification of taxation attractiveness and tenure neutrality In order to assess the impact of these forms of housing taxation, they have to be measured in numeric terms. The coding of regulations is a difficult task, since it has to strike a balance between capturing the essence of legal acts and producing interpretable and objective indices. Surely, the regulations are very complex and trying to mimic them in a detailed way would make their quantification infeasible. Therefore, certain simplifying assumptions must be made in order to render the task tractable. We therefore only account for the existence of taxes not for their rates or application sphere. Leximetric approach to taxation policies Here, we apply the methodology, which is known as leximetrics, used since at least the early 1990s to measure the intensity of governmental regulations. Leximetrics is employed in a large variety of areas of economics, such as labour markets, finance, shareholder protection, and housing. Footnote 2 There are already several studies examining homeownership taxation (e.g. Wolswijk Reference Wolswijk2009; Figari et al. Reference Figari, Paulus, Sutherland, Tsakloglou, Verbist and Zantomio2012). However, none of them intends to quantify the regulations. The first researcher to quantify the housing ownership policies was Atterhög (Reference Atterhög2005). Based on expert surveys conducted in 18 countries, he built six indices (direct grants for buying, other subsidies, mortgage deduction, grant tax deduction, low property tax, and homeownership allowances) covering the period between 1970 and 2000 at decade frequency. His indices vary between 0 (no support) and 5 (very generous support). Thus, our databases partly overlap (countries, periods, and policies). However, our data have annual frequency, are based on regulation and not expert opinion, and cover a much longer period. In addition, our database and that of Atterhög share only one common policy index – the mortgage deduction. Barrios et al. (Reference Barrios, Denis, Ivaskaite-Tamosiune, Reut and Vazquez Torres2019), on the other hand, consider five homeownership policy indicators (transfer taxes, recurrent property taxes, capital gains taxes, imputed rent taxation, and mortgage interest deduction) to show the distortions for households decisions by computing the cost of owner-occupied housing. Their policy indicators are similar to the ones that we use in this study, except for their additional implicit recurrent property taxes. Another difference is that they measure transfer and capital gains taxation in absolute terms rather than as a dummy variable. Their sample comprises 28 EU countries between 1995 and 2017. While these approaches examine the existence or magnitude of housing taxation policies, Seelkopf et al. (Reference Seelkopf, Bubek, Eihmanis, Ganderson, Limberg, Mnaili, Zuluaga and Genschel2021) take another dimension of taxation policies into account, which is the year of introduction of the corresponding tax. They achieve this by constructing a new data set containing the year and mode of introduction of six key modern taxes (personal income tax, corporate income tax, social security contributions, inheritance tax, general sales tax, and VAT) in 220 countries between 1750 and 2018. While this is a useful database for the introduction of general tax codes, it is not specific enough for the subdomain of housing and homeownership. Our approach In this study, we follow the approach suggested by Kholodilin (Reference Kholodilin2020), who measures the intensity of rental market regulations worldwide over a long period. First, we conduct an overview of the relevant legislation pieces in order to extract information concerning the tax treatment of owner-occupied dwellings. Footnote 3 Second, for each of the four taxation types discussed above, a binary index is constructed that equals one, if regulation is more favourable with respect to homeowners, and zero, otherwise: (1) $${I_{jt}} = \left\{ {\matrix{ {1,\quad {\rm{if}}\;{\rm{taxation}}\;{\rm{of}}\;{\rm{type}}\;j\;{\rm{is}}\;{\rm{favorable}}\;{\rm{to}}\;{\rm{homeowners}}\;{\rm{in}}\;{\rm{period}}{\mkern 1mu} {\mkern 1mu} t} \hfill \\ {0,\quad {\rm{otherwise}}} \hfill } } \right.$$ Thus, the binary indices for the imputed rent tax, capital gains tax, and VAT are equal to 1, when homeowners are not subject to these taxes, while the binary index for interest deductibility is equal to 1, when such an option is provided to homeowners. When a regulation exists (such as capital gains taxation), but subject to major exemptions (e.g. tax exemptions for certain holding periods), we consider the regulation to not be in place (cf. Table A5 in Supplementary material for a detailed list of exemptions). The resulting binary indices are plotted in Figures 1, 2, 3, and 4 as shaded areas. Each horizontal bar corresponds to an individual country. The darker shades of grey correspond to regulations that are more beneficial for homeowners. Yellow colour denotes missing observations. In addition and to reduce descriptive complexity, we compute a composite homeowneship taxation attractiveness index as a simple average of binary variables: (2) $$HOT{A_t} = {1 \over J}\sum\limits_{j = 1}^J {{I_{jt}}} $$ where $J = 4$ is the number of individual binary taxation indices. Hence, the index can vary between 0 and 1. The higher its values, the more favourable the housing taxation for homeowners. The indices of homeownership tax attractiveness cover 37 countries in total which reflects our attempt to cover the economically most important OECD and a dozen of non-OECD countries, where data were available and accessible. Figure 5 shows their geographical distribution in 2020. Again, the shades of grey depict the degree of attractiveness of taxation, while yellow denotes countries for which no such information is available. The composite indices for individual countries are displayed in Figure 6. Finally, we also compute the degree of neutrality of homeownership taxation with respect to the housing tenure. If the tax treatment is more favourable towards homeowners, then ceteris paribus it can create an additional incentive for people to choose owning over renting. The taxation neutrality is defined through the following two cases: either the imputed rent tax is absent and mortgage payments are not deductible or the imputed rent tax is levied and mortgage deductions are allowed. (3) $$TN{I_t} = {{I\,_t^{\rm imputed\ rent\ tax} + I\, _t^{\rm mortgage\ deductibility} - 1} \over 2}$$ Thus, the value of this index corresponding to the taxation neutrality will be equal 0. When it is below zero, taxation is biased towards renters, while when it is positive, it is biased towards homeowners.",0.0,0.0
411,https://www.eurekalert.org/news-releases/967153,Survey finds more than 40% of Americans misled others about having COVID-19 and use of precautions,"Four of 10 Americans surveyed report that they were often less than truthful about whether they had COVID-19 and/or didn’t comply with many of the disease’s preventive measures during the height of the pandemic, according to a new nationwide study led in part by University of Utah Health scientists. The most common reasons were wanting to feel normal and exercise personal freedom.The study, which appears in the Oct. 10, 2022, issue of JAMA Network Open, raises concerns about how reluctance to accurately report health status and adherence to masking, social distancing, and other public health measures could potentially lengthen the current COVID-19 pandemic or promote the spread of other infectious diseases in the future, according to Angela Fagerlin, Ph.D., senior author of the study and chair of the Department of Population Health Sciences at U of U Health.“COVID-19 safety measures can certainly be burdensome, but they work,” says Andrea Gurmankin Levy, Ph.D., a professor of social sciences at Middlesex Community College in Connecticut. As co-lead author of the study, she worked in collaboration with Fagerlin and other scientists at U of U Heath as well as researchers elsewhere in the United States.“When people are dishonest about their COVID-19 status or what precautions they are taking, it can increase the spread of disease in their community.” Levy says. “For some people, particularly before we had COVID vaccines, that can mean death.”The researchers decided to assess how truthful Americans were being about their COVID-19 disease status and/or compliance with COVID-19 preventive measures after they noticed several media stories about people who were dishonest about their vaccination status, Fagerlin says.In the survey, conducted in December 2021, more than 1,700 people from across the country were asked to reveal whether they had ever misrepresented their COVID-19 status, vaccination status, or told others that they were following public health measures when they actually weren’t. The sample size is far larger and asked about a broader range of behaviors than previous studies on this topic, according to Fagerlin, who is also a research scientist at the Veteran Affairs Salt Lake City Healthcare System.Screening questions allowed the health service researchers and psychologists who designed the study to evenly divide the participants: one-third who had had COVID-19, one-third who had not had COVID-19 and were vaccinated, and one-third who had not had COVID-19 and were unvaccinated.Based on a list of nine behaviors, 721 respondents (42%) reported that they had misrepresented COVID-19 status or failed to follow public health recommendations. Some of the most common incidents were:Breaking quarantine rulesTelling someone they were with, or were about to see, that they were taking more COVID-19 precautions than they actually wereNot mentioning that they might have had, or knew that they had, COVID-19 when entering a doctor’s officeTelling someone they were vaccinated when they weren’tSaying they weren’t vaccinated when they actually wereAll age groups younger than 60 years and those who had a greater distrust of science were more likely to engage in misrepresentation and/or misrepresentation than others. About 60% of respondents said that they had sought a doctor’s advice for COVID-19 prevention or treatment.However, the researchers found no association between COVID-19 misrepresentation and political beliefs, political party affiliation, or religion.“Some individuals may think if they fib about their COVID-19 status once or twice, it’s not a big deal,” Fagerlin says. “But if, as our study suggests, nearly half of us are doing it, that’s a significant problem that contributes to prolonging the pandemic.”Among the reasons respondents gave for misrepresentation were:I didn’t think COVID-19 was real, or it was no big dealIt’s no one else’s businessI didn’t feel sickI was following the advice of a celebrity or other public figureI couldn’t miss work to stay homeAmong the study’s limitations, the researchers could not determine if respondents honestly answered survey questions, opening the possibility that their findings underestimated how commonly people misrepresented their health status.“This study goes a long way toward showing us what concerns people have about the public health measures implemented in response to the pandemic and how likely they are to be honest in the face of a global crisis,” says Alistair Thorpe, Ph.D., co-first author and a post-doctoral researcher in the Department of Population Health Sciences at U of U Health. “Knowing that will help us better prepare for the next wave of worldwide illness.”https://www.youtube.com/watch?v=8AbyzG9GYd8###In addition to Fagerlin and Thorpe, University of Utah Health researchers Holly Shoemaker, Frank A. Drews, Jorie M. Butler, and Vanessa Stevens contributed to this study. Other participating institutions include Middlesex Community College in Middletown, Connecticut; University of Colorado School of Medicine, Aurora; Veterans Affairs Denver Center for Innovation; University of Iowa School of Medicine, Iowa City; Salt Lake City VA Informatics Decision-Enhancement and Analytic Sciences (IDEAS) Center for Innovation; VA Salt Lake City Health Care System; and the American Heart Association.The study, “Misrepresentation and Nonadherence Regarding COVID-19 Public Health Measures,” appears in the Oct. 10, 2022, issue of JAMA Network Open. It was supported by the Jon M. Huntsman Presidential Endowment and an American Heart Association Children’s Strategically Focused Research Network Fellowship.",0.0,0.0
138,https://www.smithsonianmag.com/science-nature/new-technologies-are-helping-paleontologists-track-the-history-of-squishy-cephalopods-180980565/,"What New Tech Is Revealing About Squishy, Prehistoric Cephalopods","Finding and studying fossils of Earth’s squishiest prehistoric creatures is a difficult task. The fossil record often tells the history of life through hard tissues. Bones, teeth, shells and other mineralized, durable parts of living things have a far better chance of being preserved as fossils than the softer tissues like muscle and internal organs. That’s a huge challenge for all paleontologists, but especially experts on ancient cephalopods—the fossil relatives of today’s nautilus, squid, cuttlefish and octopus that live from the shore to the dark depths. Mollusks have soft bodies that often decayed away before getting a chance to become fossils, leaving experts only with shells or beaks from what was once a complete animal. Yet the cephalopod fossil record is full of surprises, and experts have become ever more inventive in finding ways to visualize creatures that have been extinct for millions of years.One of the latest surprises comes from an ancient relative of today’s vampire squid, a fossil relative called Vampyronassa. Vampyronassa was originally described twenty years ago. At the time, experts had to rely on what they could see with the naked eye. Paleontologists saw one of the cephalopod’s eyes and its sucker-lined arms, but much of its anatomy was obscured by the encasing rock. The outer details allowed researchers to categorize this strange cephalopod as a distant relative of the “vampire squid” that floats through the ocean depths today, but little more could be said of the animal’s biology. It seemed reasonable to assume that the fossil species lived much like it’s modern-day counterpart.But advances in visualization technology and greater availability of micro CT scans allowed paleontologists to take a new look at the fossil. Especially when soft-bodied animals are preserved as fossils, there are often hidden aspects of their anatomy that can only be seen by looking beneath the surface of the fossil. “We chose to reanalyze these specimens as we now have access to non-destructive, powerful X-ray based imaging techniques that allow us to observe previously unseen internal structures,” says Sorbonne University paleontologist Alison Rowe, the lead author of a recent Scientific Reportsstudy redescribing the fossil.Being able to look inside the fossil yielded unexpected results that couldn’t been seen just from the outside. Micro CT scans revealed parts of the gills, stomach, esophagus and other internal organs of this creature, the closest experts could hope to get to seeing this animal alive. “We were able to determine that the sucker attachment of Vampyronassa is the same type seen only in modern Vampyroteuthis,” Rowe says, though the shape of those suckers look like those of octopus. The shape of the suckers and the way they are anchored to the arms of Vampyronassa is a combination never seen before, what Rowe says “provides a small window on the diversity of character combinations that occurred in the Jurassic that are now lost.”Looking closely did more than answer some anatomical questions, however. Today’s Vampyroteuthis has sometimes been called a living fossil, the assumption being that these cephalopods found a cozy home in deep, oxygen-poor waters and stayed there in a cozy niche, eating detritus that falls from above, since the Jurassic. But the new study of Vampyronassahas revealed something different. The arms and internal anatomy of the fossil cephalopod indicate that it was an active predator that pursued prey closer to the surface. Vampyronassa zipped around to hunt and nab prey with its sucker-lined arms, with its later relatives retiring to a deep sea existence sometime after 33 million years ago.The fossil of Vampyronassa was a rare case. Fossils of cephalopods like ancient octopus and squid, which had very few hard parts, are difficult to find. Cephalopods such as the coil-shelled ammonoids are much more common, sometimes found in vast beds of empty shells. Such fossils have often been used to tell time in the fossil record as the evolution and extinction of ammonoid species was so rapid that particular species are often associated with particular rock layers–find an ammonoid and you can get a pretty good idea of where you are in the fossil record. Until recently, it seemed that the shells couldn’t tell us very much about how these animals lived. But paleontologists are an inventive bunch, and technological advances have allowed them to get closer to understanding how the beautiful and prolific ammonoid made a living during the deep past.Case in point, paleontologists didn’t really know what ammonoids ate. The cephalopods were clearly an important part of ancient food webs from 66 to 450 million years ago, and were even fodder from marine reptiles like mosasaurs given some Cretaceous ammonoid shells are found with bite marks on them, but paleontologists were missing what ammonoids themselves ate. Only in 2011 did paleontologist Isabelle Kruta and colleagues announce that they were able to use high-powered X-rays to detect plankton inside the mouth of one particular ammonoid that was a little better preserved than others. Ammonoids fed on microscopic organisms floating in the water column. This became a critical realization. The last ammonoids went extinct about 100,000 years after the impact that wiped out the non-avian dinosaurs, during a time when oceans were struggling to rebuild their food webs from the bottom up. If ammonoids ate plankton, but also produced offspring that were so small they were part of the ocean’s plankton, the poor cephalopods may have practically cannibalized themselves into oblivion.Prior to those final years, though, ammonoids came in a variety of shapes and sizes, up to species with shells the size of a Mini Cooper. How did these creatures swim, and why did evolution seem to favor some shapes over others? Scientists have turned to ammonoid robots to help answer those questions.True ammonoids haven’t swum in the seas for about 66 million years, but their shells, at least, have been put through their paces in a college swimming pool. Starting with high-definition scans of ammonoid shells, University of Utah paleontologist David Peterman created three dimensional models of ammonoid shells that he then turned into swimming robots. These models mimic the swimming behavior of the extinct species, allowing experts to get a better idea of how these animals actually moved in the water. “Thanks to computation advances and 3-D prints,” Peterman says, “we were able to explore paleoecological and biomechanical questions with unprecedented levels of detail.” Scientists combined engineering and even video game software with scans of fossils tens of millions of years old, ancient and modern coming together to let ammonoids swim once again.The tests in the pool have helped resolve some longstanding questions about these animals. Some prehistoric, shelled cephalopods have cone-shaped shells rather than whorls. Did these cephalopods swim in a horizontal position, vertical or crawl along the sea floor as in old museum dioramas? No one really knew. But the biomechanical tests revealed that these shells did best in a vertical position, meaning the cone-shelled cephalopods didn’t so much jet around in search of food but bobbed with the currents as they snagged what they could with their sucker-lined arms.Frustrating as it might be that we lack as much detail on the soft tissues of prehistoric squid relatives as we might like, Peterman says, being able to scan, visualize and even replicate parts of these ancient creatures is telling us more than ever before. “These animals tell the remarkable story of how seafloor-dwelling critters evolved into living, jet-propelled submarines,” Peterman says, “leaving behind an unparalleled treasure trove of information.”",0.0,0.0
514,https://theveganherald.com/2022/10/study-plant-based-diets-improve-maternal-fetal-outcomes-in-ckd-pregnancies/,Study: Plant-Based Diets Improve Maternal-Fetal Outcomes in CKD Pregnancies,"Plant-based, moderately protein-restricted diets in pregnancy in patients with chronic kidney disease are associated with a lower risk of preterm delivery and small-for-gestational-age babies.This is according to a new study published in the journal Nutrients and epublished by the National Institute of Health.“Reducing protein intake in patients with chronic kidney disease (CKD) limits glomerular stress induced by hyperfiltration and can prevent the progression of kidney disease; data in pregnancy are limited”, states the study. “The aim of this study is to analyze the results obtained in CKD patients who followed a plant-based moderately protein-restricted diet during pregnancy in comparison with a propensity-score-matched cohort of CKD pregnancies on unrestricted diets.”A total of 52 CKD pregnancies followed up with a protein-restricted plant-based diet (Torino, Italy) were matched with a propensity score based on kidney function and proteinuria with CKD pregnancies with unrestricted protein intake (Cagliari Italy).“Outcomes included preterm (<37 weeks) and very preterm (<34 weeks) delivery and giving birth to a small-for-gestational-age baby”, states the study. “The median age in our cohort was 34 years, 63.46% of women were primiparous, and the median body mass index (BMI) was 23.15 kg/m2 with 13.46% of obese subjects.”No statistical differences were found between women on a plant-based diet and women who were not in terms of age, parity, BMI, obesity, CKD stage, timing of referral, or cause of CKD. No differences were found between the two groups regarding the week of delivery. However, “the combined negative outcome (birth before 37 completed gestational weeks or birth-weight centile <10) occurred less frequently in women following the diet than in women in the control group (61.54% versus 80.77%; p = 0.03).”The lower risk “was confirmed in a multivariable analysis adjusted for renal function and proteinuria (OR: 0.260 [Q1:0.093-Q3:0.724]; p = 0.010), in which the increase in proteinuria from the first to the last check-up before delivery was lower in patients on plant-based diets (median from 0.80 to 1.87 g/24 h; p: ns) than in controls (0.63 to 2.39 g/24 h p < 0.0001).”The study concludes by stating that “plant-based, moderately protein-restricted diets in pregnancy in patients with CKD are associated with a lower risk of preterm delivery and small-for-gestational-age babies; the effect may be mediated by better stabilization of proteinuria.”Below is the study’s abstract.Reducing protein intake in patients with chronic kidney disease (CKD) limits glomerular stress induced by hyperfiltration and can prevent the progression of kidney disease; data in pregnancy are limited. The aim of this study is to analyze the results obtained in CKD patients who followed a plant-based moderately protein-restricted diet during pregnancy in comparison with a propensity-score-matched cohort of CKD pregnancies on unrestricted diets. A total of 52 CKD pregnancies followed up with a protein-restricted plant-based diet (Torino, Italy) were matched with a propensity score based on kidney function and proteinuria with CKD pregnancies with unrestricted protein intake (Cagliari Italy). Outcomes included preterm (<37 weeks) and very preterm (<34 weeks) delivery and giving birth to a small-for-gestational-age baby. The median age in our cohort was 34 years, 63.46% of women were primiparous, and the median body mass index (BMI) was 23.15 kg/m2 with 13.46% of obese subjects. No statistical differences were found between women on a plant-based diet and women who were not in terms of age, parity, BMI, obesity, CKD stage, timing of referral, or cause of CKD. No differences were found between the two groups regarding the week of delivery. However, the combined negative outcome (birth before 37 completed gestational weeks or birth-weight centile <10) occurred less frequently in women following the diet than in women in the control group (61.54% versus 80.77%; p = 0.03). The lower risk was confirmed in a multivariable analysis adjusted for renal function and proteinuria (OR: 0.260 [Q1:0.093-Q3:0.724]; p = 0.010), in which the increase in proteinuria from the first to the last check-up before delivery was lower in patients on plant-based diets (median from 0.80 to 1.87 g/24 h; p: ns) than in controls (0.63 to 2.39 g/24 h p < 0.0001). Plant-based, moderately protein-restricted diets in pregnancy in patients with CKD are associated with a lower risk of preterm delivery and small-for-gestational-age babies; the effect may be mediated by better stabilization of proteinuria.",0.0,0.0
47,https://techcrunch.com/2021/02/17/astra-hires-longtime-apple-veteran-benjamin-lyon-as-chief-engineer/,Astra hires longtime Apple veteran Benjamin Lyon as chief engineer,"New space startup Astra, which is currently focused on commercial rockets, but which plans to eventually build satellites, too, has hired one of Apple’s key engineering leaders to head its own engineering efforts. Benjamin Lyon spent more than two decades at Apple, where he worked on everything from the iPhone to input devices and sensor hardware to special projects: the department at Apple working on autonomous vehicle technology.“When I’ve looked at what to do next at Apple, it has always been this combination of ‘What is the most impactful thing that I can do for humanity?’ — the iPhone was very much one of these,” Lyon told me in an interview. “Phones were awful [at the time], and if we could fundamentally come up with a new interface, that would completely change how people interact with devices.”Creating a mobile device with an interface that was “completely flexible and completely customizable to the application” was what seemed so transformative to Lyon about the iPhone, and he sees a direct parallel in the work that Astra is doing to lower the barrier of access to space through cheap, scalable and highly efficient rocketry.“Astra to me feels very, very much like redefining what it means for a phone to be smart,” Lyon said. “I think the Astra vision is this magical combination of fundamentally taking the rocket science out of space. How do you do that? Well, you better have a great foundation of a team, and a great foundation of core technologies that you can bring together in order to make a compelling series of products.”Foundations are the key ingredient according not only to Lyon, but also to Astra co-founder and CEO Chris Kemp, who explained why an experienced Apple engineer made the most sense to him to lead a rocket startup’s engineering efforts.“We did not want anyone from aerospace — I’ll just say that out of the gate,” Kemp told me. “Aerospace has not figured out how to build rockets at scale, or do anything profitably — ever. So I found no inspiration from anyone I talked to who had anything to do with any of the other space-related companies. We do feel that there are people that are at SpaceX and Blue Origin who are really good at what they do. But in terms of the culture that we’re trying to establish at Astra, if you look back at Apple, and the things that Benjamin worked on there over many decades, he really took on not only designing the thing, but also designing the thing that makes the thing, which was more important than the thing itself.”Kemp’s alluding to Apple’s lauded ability to work very closely with suppliers and move fundamental component engineering in-house, crafting unique designs for things like the system-on-a-chip that now powers everything from the iPhone to Macs. Apple often designs the processes involved in making those fundamental components, and then helps its suppliers stand up the factories required to build those to its exacting specifications. Astra’s approach to the space industry centers around a similar approach, with a focus on optimizing the output of its Alameda-based rocket factory, and iterating its products quickly to match the needs of the market while keeping pricing accessible.And Astra’s definition of “iteration” matches up much more closely with the one used by Silicon Valley than that typically espoused by legacy aerospace companies — going further still in questioning the industry’s fundamentals than even watershed space tech innovators like SpaceX, which in many ways still adheres to accepted rocket industry methods.“You don’t do the iPhone X at iPhone 1 — you start with the iPhone 1 and you work your way to the iPhone X,” Lyon told me. “You’re going to see that with Astra as well, there’s going to be this amazing evolution, but it’s going to be tech company-rate evolution, as opposed to an ‘every 20 years’ evolution.”That sentiment lines up with Astra and Kemp’s approach to date: The company reached space for the first time late last year, with a rocket that was the second of three planned launches in a rapid iteration cycle designed to achieve that milestone. After the first of these launches (Rocket 3.1 if you’re keeping track) failed to make space last September, Astra quickly went back to the drawing board and tweaked the design to come back for its successful attempt in December (Rocket 3.2) — an extremely fast turnaround for an aerospace company by any measure. The company is now focused on its Rocket 3.3 launch, which should only require software changes to achieve a successful orbit, and put it on track to begin delivering commercial payloads for paying customers.Astra’s rocket is tiny compared to the mammoth Starship that SpaceX is currently developing, but that’s part of the appeal that drew Lyon to the startup in the first place. He says the goal of “design[ing] a rocket to match the application,” rather than simply “design[ing] a rocket to end all rockets” makes vastly more sense to serve the bourgeoning market.“And that’s just the beginning,” he added. “Then you’ll take the next step, which is if you look at the technology that’s in a satellite, and a bunch of the smart technology that’s in a rocket, there’s a tremendous amount of duplication there. So, get rid of the duplication — design the rocket and the satellite together as one system.”Eventually, that means contemplating not only launch and satellite as a single challenge, but also managing “the entire experience of getting to space and managing a constellation” as “a single design problem,” according to Lyon, which is the level of ambition at Astra that he views as on par with that of Steve Jobs at Apple at the outset of the iPhone project.Ultimately, Astra hopes to be able to provide aspiring space technology companies with everything they need so that the actual space component of their business is fully handled. The idea is that startups and innovators can then focus on bringing new models and sensing technologies to Astra, worrying only about payload — leaving launch, integration and eventually constellation management to the experts. It’s not unlike what the App Store unlocked for the software industry, Lyon said.“We’re trying to do something that’s never been done before in aerospace, which is to really scale the production of rockets, and also focus on the overall economics of the business,” Kemp explained about additional advantages of having Lyon on board. “As we become a public company, in particular, we have very aggressive EBITDA targets, and very aggressive production targets, much the same way Apple does. We also want to have a new rocket every year, just like [the iPhone] and so to some degree, we found every aspect of Benjamin’s ethos aligned with our values, and the culture that we’re creating here at Astra of relentless, constant innovation and iteration.”",0.0,0.0
256,https://www.engadget.com/smart-buoys-protect-whales-211616043.html,Smart buoy 'hears' the sea to protect whales against ship collisions,"Whales face numerous threats from humans, not the least of which are ship collisions — the World Sustainability Organization estimates 18,000 to 25,000 animals die each year. There may be a technological way to minimize those deaths, however. Reuters reports Chile's government and the MERI Foundation have deployed the first smart buoy from the Blue Boat Initiative, an effort to both safeguard whales and track undersea ecosystems. The device, floating in the Gulf of Corcovado 684 miles away from Chile, alerts ships to nearby blue, humpback, right and sei whales to help avoid incidents.The technology uses oceanographic sensors and AI-powered Listening to the Deep Ocean Environment (LIDO) software to determine a waterborne mammal's type and location. It also checks the ocean's health by monitoring oxygen levels, temperature and other criteria. That extra data could help study climate change and its impact on sea life.The Blue Boat Initiative currently aims to install six or more buoys to protect whales across the gulf. In the long term, though, project members hope to blanket the whales' complete migratory route between Antarctica and the equator. This could reduce collisions across the creatures' entire habitat, not to mention better inform government decisions about conservation and the environment.The technology may be as important for humans as for the whales. On top of their roles in delicately balanced ecosystems, whales both help capture CO2 and redistribute heat through ocean currents. The more these animals are allowed to flourish, the better the ocean is at limiting global warming and its harmful effects.",0.0,0.0
176,https://noctua.at/en/noctua-confirms-am5-heatsink-compatibility-and-announces-free-of-charge-upgrades-for-low-profile-coolers-and-older-heatsink-models,Noctua confirms AM5 heatsink compatibility and announces free-of-charge upgrades for low-profile coolers and older heatsink models,"says Roland Mossig (Noctua CEO).AM5 (LGA1718) is AMD’s upcoming socket for its next-generation Ryzen 7000 (Zen 4) series processors. In short, all Noctua coolers and mounting-kits that support AM4 are upwards compatible with socket AM5, except the NH-L9a-AM4 and the NM-AM4-L9aL9i.All Noctua AM4 mountings except the ones of the NH-L9a-AM4 and the NM-AM4-L9aL9i attach to the threads of the standard AM4 stock backplate. Since these backplate threads and their pattern are identical on AM4 and AM5, our AM4 mountings that attach to the standard AMD backplate also support AM5.This means that all SE-AM4 models as well as all Noctua multi-socket coolers purchased since 01/2019 already support socket AM5. Multi-socket coolers purchased before this date that have already been upgraded to AM4 using the NM-AM4 or NM-AM4-UxS kits also require no further upgrades. Older multi-socket coolers that have been purchased before 2019 and have not yet been upgraded to AM4 can be made compatible with AM5 using these upgrade kits. For easier identification, the NM-AM4 or NM-AM4-UxS kits will be renamed to NM-AM5/4-MP83 (for coolers with 83mm mounting pitch) and NM-AM5/4-MP78 (for coolers with 78mm mounting pitch).The socket compatibility overview in the Noctua Compatibility Centre (NCC) allows customers to see at a glance which Noctua CPU cooler models support socket AM5 out of the box or via mounting upgrade kits and which upgrade kit is required for which cooler model. The AM5 motherboard compatibility list is currently being built up and will be expanded over the coming weeks so that customers can verify that their cooler is fully compatible with their new AM5 motherboard.For ordering the mounting-kits free of charge via Noctua’s website, a proof of purchase of both an eligible Noctua CPU cooler and either an AM5/4 CPU or an AM5/4 motherboard will be required. Depending on the country, express shipping options may be available but will be subject to service charges. Alternatively, customers who need the kits urgently will be able to purchase them on Amazon for a suggested service charge of EUR/USD 7.90.explains Roland Mossig (Noctua CEO).The NH-L9a-AM4 and the NM-AM4-L9aL9i are not compatible with AM5 because they require replacing the standard AMD backplate with a custom one, which isn’t possible on AM5. Therefore, Noctua has announced the new NM-AM5-L9aL9i mounting-kit that will allow the NH-L9a, NH-L9a-AM4 and NH-L9i heatsinks to be upgraded to AM5. The NH-L9i-17xx cannot be used because it has been tailored to the different height specifications of the LGA17xx platform. Like the other mounting-kits, the NM-AM5-L9aL9i will be available free of charge via Noctua.at (from end of October). A new version of the NH-L9a cooler that already includes AM5 mounting hardware is planned for Q1 2023.Designed in Austria, Noctua’s premium cooling components are internationally renowned for their superb quietness, exceptional performance and thoroughgoing quality. Having received more than 6000 awards and recommendations from leading hardware websites and magazines, Noctua’s fans and heatsinks are serving hundreds of thousands of satisfied customers around the globe.",0.0,0.0
117,https://www.oxfam.org/en/press-releases/85-worlds-population-will-live-grip-stringent-austerity-measures-next-year,85% of the world's population will live in the grip of stringent austerity measures by next year,"Despite millions of people being pushed into hunger and poverty, 143 countries — including 94 developing nations — are implementing policy measures that undermine governments’ capacity to provide healthcare, education and social protection.A new report titled “End Austerity: A global report on budget cuts and harmful social reforms” shows that 85 percent of the world’s population will live in the grip of austerity measures by 2023. This trend is likely to continue until at least 2025, when 75 percent of the global population (129 countries) could still be living under these conditions.Austerity measures include scaling down social protection programs for women, children, the elderly and other vulnerable people, leaving only a small safety net for a fraction of the poorest. They also include cutting or capping the wages and number of teachers and healthcare workers, eliminating subsidies, privatizing or commercializing public services such as energy, water and public transportation, and reducing pensions and workers’ rights.Civil society organizations from across the world are launching the #EndAusterity campaign today to fight back against the wave of austerity that is sweeping across the world, supercharging inequality and compounding the effects of the cost-of-living crisis and climate breakdown.Isabel Ortiz, Director of the Global Social Justice Program at the Initiative for Policy Dialogue, said: “Decisions on budget cuts affect the lives of millions of people and should not be taken behind closed doors by a few technocrats at a Ministry of Finance, with the support of the IMF. Policies must instead be agreed transparently in a national social dialogue, negotiating with trade unions, employer federations and civil society organizations. Austerity cuts are not inevitable; in fact our report presents nine financing alternatives that are available, even to the poorest countries.”Additional analysis published today by the Financial Transparency Coalition and its partners shows that one-third less COVID-19 recovery money was spent last year compared to 2020, falling from 3.9 percent of GDP to 2.5 percent of GDP.The report “Recovery at a Crossroads: How Countries Spent COVID-19 Funds” also found that only 37 percent of COVID-19 recovery funds in 21 developing countries were invested in social protection. Meanwhile, 38 percent of these funds went to big corporations — this does not take into account tax waivers, corporate loans, and credit lines where they are not accounted for in the budgets. Smaller businesses got 20 percent of recovery funds, and informal workers 4 percent. Women have been particularly affected, since despite being hard hit by the pandemic, they only received half as much support as men.Matti Kohonen, director of the Financial Transparency Coalition, said: “Despite the cost-of-living crisis, governments in developing countries, often with their hands tied by international financial institutions, are putting big corporations ahead of the people. Nearly 40 percent of COVID-19 recovery funds went to big companies, meaning that those most impacted by the pandemic have been left behind. We should promote a people-centered recovery with progressive tax policies instead of cutting social protection and support for the most vulnerable.”Civil society organizations will kick off the #EndAusterity campaign on 28 September with a series of virtual events that will run through 30 September. These events will bring together high-profile academics and civil society activists to discuss alternatives to austerity. Alternatives include taxing corporate excess profits, eliminating illicit financial flows, canceling and restructuring sovereign debt, and increasing coverage of social security and employer’s contributions, as well as issuing new IMF Special Drawing Rights targeted to developing countries.“In the worst of times, austerity is the worst possible choice. It should not even be on the agenda. Austerity is designed to dismantle public healthcare and education and labor regulations. It enriches the wealthy and big corporations at the expense of the rest of us. Choosing austerity over many other ways to reduce deficits or even boost budget revenues, like taxing wealth and windfall profits, is not only economically disastrous — it’s deadly,” said Nabil Abdo, Oxfam International’s Senior Policy Advisor.",0.0,0.0
23,https://www.independent.co.uk/tech/solar-panel-world-record-window-b2211057.html,Record-breaking transparent solar panels pave way for electricity-generating windows,"For free real time breaking news alerts sent straight to your inbox sign up to our breaking news emails Sign up to our free breaking news emails Please enter a valid email address Please enter a valid email address SIGN UP I would like to be emailed about offers, events and updates from The Independent. Read our privacy notice Thanks for signing up to theBreaking News email {{ #verifyErrors }}{{ message }}{{ /verifyErrors }}{{ ^verifyErrors }}Something went wrong. Please try again later{{ /verifyErrors }}Scientists have achieved a new efficiency record for dye-sensitized solar cells (DSCs), opening up new commercial possibilities for transparent solar panels.A team from École Polytechnique Fédérale de Lausanne in Switzerland made the breakthrough using specially designed photosensitizer dye molecules that when combined are capable of harvesting light from across the entire visible light spectrum.The transparent properties of DSCs make them suitable for use in windows, greenhouses and glass facades, the researchers said, as well as in the screens of portable electronic devices.They are also flexible, relatively low-cost and can be made using conventional roll-printing techniques. Theoretically, the price/performance ratio is also good enough to allow them to compete with fossil fuel electrical generation.The first commercial applications are already being realised, with dye-sensitized solar windows installed in the SwissTech Convention Center, however their capacity for generating electricity has so far been restricted by their lack of efficiency compared to traditional solar cells.The latest development pushes the power conversion efficiency to between 28.4-30.2 per cent, while still maintaining long-term operational stability over 500 hours of testing.“Our findings pave the way for facile access to high performance DSCs and offer promising prospects for applications as power supply and battery replacement for low-power electronic devices that use ambient light as their energy source,” wrote the authors of a study detailing the technology.The study, titled ‘Hydroxamic acid preadsorption raises efficiency of cosensitized solar cells’, was published in the scientific journal Nature on Wednesday.",0.0,0.0
64,https://techcrunch.com/2022/11/04/how-to-land-investors-who-fund-game-changing-companies/,How to land investors who fund game-changing companies,"A lot of problems worth solving aren’t ones that you can solve in a year or two or even 10.For founders and investors alike, such long timelines can seem daunting. But for Gene Berdichevsky, co-founder and CEO of battery tech startup Sila, hard tech problems are also some of the most tantalizing.“It’s always a good time to be a hard tech startup,” Berdichevsky said at TechCrunch Disrupt. “One of the reasons is that the world doesn’t change just because it should. It changes because someone goes after something insanely hard and actually succeeds at it.”Such hard.tech startups run the gamut from advanced batteries like those made by Sila to nuclear fusion, quantum computing, automation and robotics. Any tech that has the potential for such broad impact also has a massive potential market, and that means a certain class of investors are willing to be in it for the long haul.“Hire people to do the technical stuff. Keep an eye on it, but then go learn the other pieces.” Gene Berdichevsky, co-founder and CEO, Sila“We look for real step-change, game-changing technologies that are going to benefit everyone and we think that will drive a huge [total addressable market],” said Milo Werner, a general partner at The Engine.When Berdichevsky founded Sila, he believed his company’s technology, a silicon-based anode that promises to improve lithium-ion battery energy density by 20%–40%, would be a significant enough advance that it would have no problem finding a market.What he didn’t expect was how long it would take. When Sila’s first product debuted inside the Whoop 4.0 wearable last year, the path to market had been twice as long as Berdichevsky had expected.",0.0,0.0
91,https://www.theguardian.com/food/2022/sep/18/leading-the-whey-the-synthetic-milk-startups-shaking-up-the-dairy-industry,Leading the whey: the synthetic milk startups shaking up the dairy industry,"In 1931, Winston Churchill predicted the rise of animal-free food. Then an opposition MP in his wilderness years, Churchill wrote an essay that imagined life in 50 years’ time. “Synthetic food will, of course, be used in the future,” he wrote.The artificial stuff would “be practically indistinguishable from the natural products, and any changes will be so gradual as to escape observation,” Churchill wrote. “Microbes, which at present convert the nitrogen of the air into proteins by which animals live, will be fostered and made to work under controlled conditions just as yeast is now.”Though several decades later than envisaged, Churchill’s prediction has been borne out by the development of lab-grown meat and, more recently, animal-free dairy products.Synthetic milk has emerged as a new potential alternative to cow’s milk, one that – unlike plant-based oat, nut and soy milks – purports to replicate its taste, appearance and mouthfeel. Described by experts as the future of milk, it has been touted as an environmentally friendly option that may shake up the dairy industry – and leave small-scale farmers in the lurch.“Lab-grown milk is considered the next food frontier,” says Dr Diana Bogueva, of Curtin University’s Sustainability Policy Institute, citing the growing popularity of dairy alternatives. Compared with dairy production, synthetic milk is likely to have a smaller carbon footprint and cause less pollution, and obviously eliminates animal welfare concerns, she says.The industry is expanding rapidly. In the US, cow-free dairy proteins produced by the firm Perfect Day are now widely used in products including ice-cream, cream cheese, chocolate and protein powders. Another American startup, New Culture, is commercialising a synthetic milk-based mozzarella, while the Israeli firm Remilk has set up a giant facility in Denmark to produce cheese, yoghurt and ice-cream.It will be some time before cow-free milk arrives in Australian supermarkets, but startups such as All G Foods and the CSIRO spin-off company Eden Brew are racing to bring products to market within the next two years.Yeast of EdenChemically, milk is mostly water – about 87%, to be precise. Milk solids comprise the rest: fats, proteins, sugars – primarily lactose – and minerals. By Australian law, at least 3.2% of the liquid in full-cream milk must be fat and another 3% protein.Most synthetic dairy companies are focusing on producing milk proteins using a process known as precision fermentation. It involves genetically programming yeast or other microorganisms using synthetic DNA to produce a specific protein. Jim Fader, the co-founder of Eden Brew, compares the process to beer brewing.“We use yeast to make a protein to make a drink. They use yeast to make alcohol to make a drink,” he says.There are at least 20 proteins in cow’s milk, about 80% of which are casein proteins, found in the curds; the rest are whey proteins, perhaps most familiar as a component of powdered protein shakes.Aggregates of casein, known as micelles, give milk its characteristic appearance and heat stability.“The micelle plays a fundamental role in many parts of milk,” Fader says. “For example, when it binds with calcium, it makes the milk look white. If you want to froth your milk and put it in your cappuccino, the ability for the milk to withstand that heat and the bubbles to be able to form … is also down to the micelle.”Synthetic milk technology is ‘less about trying to displace cows everywhere from dairy’ but ‘augmenting supply’, Jim Fader says. Photograph: ReutersEden Brew is producing six proteins that are most abundant in milk. Once brewed, these will be purified and dried.A key investor in the firm is the New South Wales dairy cooperative Norco, which will be responsible for rehydrating and blending the proteins. At this stage, other components such as minerals and coconut-based fat will be added. The end product will be lactose-free, with a small quantity of table sugar used to approximate the sweetness of cow’s milk.Fader says the firm will launch an ice-cream – simpler than milk because it can be made with just two proteins – around December next year. Milk will follow, likely in August 2024.All G Foods is focusing its efforts on whey proteins. The firm’s plant-based meat products are already served in commercial burger chains and sold in some supermarkets.The company’s chief scientific officer, Jared Raynes, says the ultimate goal is to produce yoghurts, cheese and fresh milk. But the firm’s focus for now is on beta-lactoglobulin, the main protein in whey.“We are going to be applying for regulatory approval with our protein powder,” he says.Parallels with synthetic fabricsMilena Bojovic, who is completing a PhD at Macquarie University, says while the promise of cow-free fresh milk has been widely trumpeted, the impact of synthetic dairy is likely to be greater on products such as milk powder.“Fresh milk consumption is on the decline,” she says and consumers may be wary of drinking a synthetic version of a natural product. She points out that traditional dairy production is also “very much technologically mitigated, from conception to the birth of calves to the milking process”.“If synthetic milk really takes off, the biggest disruption I think will be if it can be powdered and used in the ingredients space … as an additive like milk solids, which is in a lot of processed foods,” Bojovic says. “I don’t think most consumers are questioning where the milk solids in their KitKat came from.”“If and possibly when that happens, that will be one of the major disruptions for dairy industries that are producing exclusively for export in the form of powdered milk.”Bojovic, who has analysed global dairy trends as part of her research, is concerned that technological advances may leave farmers behind. Large dairy players such as Norco and Fonterra, a New Zealand multinational cooperative, have begun to invest in synthetic protein production.“Small-scale operations are really going to struggle in the context of global dairy consolidation,” she says. “There’s more pressure on farmers to innovate and also to invest in technology to make sure that they’re at the standard that bigger corporates are at.”Bojovic sees parallels with the rise of synthetic fabrics. “When synthetic fibres hit the market, that decimated the wool industry in a lot of regions,” she says. “It’s not the first time that farmers have been faced with the threat of synthetics, but they’ve adapted, they’ve innovated.”Melissa Cameron, Dairy Australia’s human health and nutrition policy manager, says it is yet to be seen how consumers will respond to a synthetic product. She points to statistics suggesting that 58% of Australian households exclusively buy fresh and long-life cow’s milk.“People are not abandoning dairy,” she says. “The commercialisation of synthetic proteins and products to a scale that makes these products available widely to consumers is yet quite a while off. As our populations grow around the world, synthetic products will deliver complementary protein and products. There will be room for all.”Dairy demand worldwide grew by 36% between 2007 and 2017 and is expected to keep rising as the world’s population increases and per-capita consumption grows.Fader says the technology that companies such as Eden Brew are developing is “less about trying to displace cows everywhere from dairy”. Rather, “it’s about augmenting the current supply because demand is forecast to go up by so much”.",0.0,0.0
55,https://www.bbc.com/news/science-environment-63407459?at_medium=RSS&at_campaign=KARANGA,Climate change: UN warns key warming threshold slipping from sight,"The report also finds that a raft of new policies in countries like the US, Japan, Korea and the EU will likely see clean energy investments of around $2 trillion by 2030, a rise of more than 50% from today.",0.0,0.0
505,https://techcrunch.com/2019/06/24/scientists-discover-a-new-way-to-provide-plants-the-nutrients-they-need-to-thrive/,Scientists discover a new way to provide plants the nutrients they need to thrive,"Researchers at Carnegie Mellon University have discovered a new method for delivering key nutrients to plant roots – without having to ensure they’re present in the soil where the plants are growing.The landmark study greatly increases the efficiency of surface delivery of nutrients and pesticides to plants. Currently, when crops are sprayed with stuff that’s supposed to help them grow faster or better, the vast majority of that (up to 95 percent, according to CMU’s engineering blog) will just end up either as concentrated deposits in the surrounding soil, or dissolving into ground water. In both cases, accumulation over time can have negative knock-on effects, in addition to being terribly inefficient at their primary task.This method, described by researchers in detail in a new academic paper, would manage to improve efficiency to nearly 100% absorption of nutrients and pesticides delivered as nanoparticles (particles smaller than 50 nanometers across – a human hair is about 75,000 nanometers wide, for context) sprayed onto the leaves of plants, which then make their way through the plant’s internal vascular system all the way down into the root system.Using this method, agricultural professionals could also greatly improve delivery of plant antibiotics, making it easier and more cost-effective to treat plant diseases affecting crop yields. It would be cheaper to delivery all nutrients and pesticides, too, because the big bump in efficiency of uptake by the plants means you can use much less of anything you want to deliver to achieve your desired effect.This research could have huge impact in terms of addressing growing global food supply needs while making the most existing agricultural land footprint and decreasing the need for potentially damaging expansion of the same.",0.0,0.0
362,https://techcrunch.com/2022/10/19/labby-product-launch/,Labby wants to make milk healthier and cows happier with better sensors,"For most dairy farmers, milk flowing from their cows is tested by a traveling technician once per month. But in a world where bovine mastitis can appear from one day to the next, it is udderly ridiculous to test milk flowing from cows once per month. Today at TechCrunch Startup Battlefield, Labby offered a different solution, with an inline optical sensor that can test cows every time they are milked. For now, the product detects potential issues early, but over time, the company believes it can start predicting issues before they occur.The company’s product is called MilKey and comes in two variants: a hand-held product that can be used anywhere, or an inline product that can be hooked into the milking machines, which enables daily farmers to test continuously.The main difference between the two products is also their strengths. The handheld device can be used by any technician out in the (literal) field; you select the cow you’re testing on a smartphone app, and the test results show up with the right animal. That’s great when a cow is wandering about or if you have suspicions about a particular animal having an illness. The inline device is fully automatic and works over Wi-Fi. For this device, the results need to be assigned to the right cow manually, but it makes it feasible to test every cow, every milking.Labby tells TechCrunch that the device takes spectral measurements of milk samples and uploads them to the cloud. From there, the company uses machine-learning models to take spectral readings as inputs. It can estimate the content of the milk, broken down into fats, proteins and somatic cell counts. Once the measurements are taken and assigned to an animal, the farmers can use an app or any web browser to see the full testing history of any animal, to ensure they are going a-bovine and beyond in terms of milk production.“Animal health records are like human records; they give critical indications about animal health and feed efficiency. It turns out that milk is the best biomarker for everything. Currently, the industry only tests once a month for each animal. We think this is a systemic failure for the farmers and for the animals,” says Julia Somerdin, CEO and founder of Labby, in an interview with TechCrunch. “One complication for animal health is mastitis. It one of the most common yet expensive diseases, and it can change from day to day. So when they do 30-day testing, the test will tell you everything is fine, but the next day the animal could develop a case, which can be subclinical with no symptoms. So for farmers, between testing days, they have no idea how the animal is doing.”You may be wondering “who cares,” but dairy farming is a hell of an industry. There are 9 million cows across 40,000 farms in the U.S. Worldwide, there are 250 million cows across 115 million farms; it all adds up.“With our solution, we can provide on-farm real-time testing to help provide the farmer with daily, weekly and monthly health records,” says Somerdin. “Animal health is the critical indicator that’s missing from today’s industry practices.”From the numbers and the impact, you’ll be unsurprised that there are big sums of money involved. The best milk gets farmers the best price, which means that milk quality is directly linked to revenue, the Labby team tells me. The benefit is two-fold: Healthier cows need less veterinary attention, and higher-quality milk nets the milk producers more money per gallon of milk delivered.“We can insert Labby in the value chain. Dairy is a very input-intensive industry so we have all kinds of suppliers that help farmers produce more and better milk, and then the dairy farmers sell their milk to dairy processors. With our service, the big battle, besides the money-saving aspect, is we create all this real-time data,” says Somerdin. “Animal genetics companies can use that data, helping them refine their algorithms. We can also bridge the gap between dairy producers and veterinarians, enabling telehealth for cows.”Apart from the fact that when I hear “telehealth for cows,” I giggle at the thought of a cow staring into a Zoom screen and talking about its feelings and its four upset stomachs, it’s easy to understand how Labby adds significant value and the ability to be an early warning system for animal health.“The most important thing is that you don’t need a technician to sample the milk anymore. The cleaning can also be integrated with the current system,” says Somerdin, explaining how the company has designed a set-it-and-forget-it approach to continuous testing.Labby was part of Techstars, and raised a total of $1.3 million from them and a number of other investors, including MIT Media lab’s E14 fund.The company officially started selling its products in early October, and has only just started shipping its products to customers. In the short term, it’s a hardware+SaaS business, but after that, it’s time to start milking the data itself for wisdom.“Our business model has three revenue streams. For the dairy farmers, they pay once for the hardware equipment, then monthly for us to provide the testing in the cloud. The farmer pays per cow per day,” says Somerdin. “In addition, we’re looking at data. We believe we are generating significant value for the industry, such as for genetic companies. We will have a data licensing fee, but we will wait to offer that until we have half a million cows on the platform.”Over time, the company hopes to be able to use big data to catch a glimpse of the future, too.“The data will help us develop a reliable benchmark for each animal,” says Somerdin, and suggests that deviations from the benchmark could tell you something about what’s going on for the cows, health-wise. “Based on that, we can look at pattern recognition for disease onset among the herd. We could also predict patterns for milk production, which currently relies only on historical data, which limits their accuracy.”All in all, the company seems eager to (milk)shake up the industry, and bring all the farmers to the yard. And they’re like, it’s better than yours. They will teach you, but they’ll have to charge.",0.0,0.0
405, cytochrome c, or citrate synthase was found with 0.5 mM LiCl treatment (n = 3 per group). C, cytochrome c oxidase subunit IV (COXIV),0.0,0.0
276,https://gizmodo.com/human-composting-green-burial-california-1849558091,Human Composting Now Legal in California,"In a few years , people in California will have a new choice for what to do with their loved ones’ bodies after death: put them in their garden.This weekend, Gov. Gavin Newsom signed a bill into law that makes human composting legal in the state beginning in 2027. The bill, AB-351, makes California the fifth state to allow human composting since it was first legalized in Washington in 2019 (Oregon, Colorado, and Vermont are the other places where you can make yourself into mulch).“AB 351 will provide an additional option for California residents that is more environmentally-friendly and gives them another choice for burial,” Assemblymember Cristina Garcia, who sponsored the bill, said in a release. “With climate change and sea-level rise as very real threats to our environment, this is an alternative method of final disposition that won’t contribute emissions into our atmosphere.”AdvertisementHuman beings cause more than enough trouble while we’re alive, but the practices we’ve developed to handle our bodies after death are also pretty bad for the environment. Burying a dead body takes about three gallons of embalming liquid per corpse—stuff like formaldehyde, methanol, and ethanol—and about 5.3 million gallons total gets buried with bodies each year. Meanwhile, cremation creates more than 500 pounds (227 kilograms) of carbon dioxide from the burning process of just one body, and the burning itself uses up the energy equivalent of two tanks of gasoline. In the U.S., cremation creates roughly 360,000 metric tons of carbon dioxide each year.It’s a no-brainer, then, to think of greener alternatives. The most common process for human composting—and the one laid out in the new California law—is called natural organic reduction, which involves leaving the body in a container with some wood chips and other organic matter for about a month to let bacteria do its work. The resulting mulch (yep, it’s human body mulch) is then allowed to cure for a few more weeks before being turned over to the family. E ach body can produce about a cubic yard of soil, or around one pickup truckbeds’ worth. According to Garcia’s release, this process will save about a metric ton of CO2 per body.Seattle-based company Recompose, which is mentioned in Garcia’s press release, was the first officially licensed human composting service to open in the U.S. after Washington state legalized the practice. In the release, Recompose’s founder, Katrina Spade, who invented the natural organic reduction process and was a key part of the legalization drive in Washington, said the company hopes to expand its services to California soon.",0.0,0.0
240,https://electrek.co/2022/10/04/renewables-global-electricity/,Renewables met 100% of the rise in global electricity demand in the first half of 2022,"Renewables met all of the rise in global electricity demand in the first half of 2022, preventing any growth in coal and gas generation, according to a new report published by London-based energy think tank Ember.The rise in wind and solar generation met over 75% of the demand growth in the first half of 2022, while hydro met the remainder, preventing a possible 4% increase in fossil-fuel generation and avoiding $40 billion in fuel costs and 230 Mt CO2 in emissions.Malgorzata Wiatros-Motyka, senior analyst at Ember, said:Wind and solar are proving themselves during the energy crisis. The first step to ending the grip of expensive and polluting fossil fuels is to build enough clean power to meet the world’s growing appetite for electricity.The report analyzes electricity data from 75 countries representing 90% of global electricity demand. It compares the first six months of 2022 to the first half of 2021 to show how the electricity transition has progressed.The report finds that global electricity demand grew by 389 terawatt hours (TWh) in the first half of 2022. Renewables – wind, solar, and hydro – increased by 416 TWh, slightly exceeding the rise in electricity demand.Wind and solar alone rose by 300 TWh, which was equal to 77% of the rise in global electricity demand. In China, the rise in wind and solar generation alone met 92% of its electricity demand rise. In the United States it was 81%, and in India it was 23%.Rise in fossil-fuel generation unchangedAs a result of the growth in renewables, fossil-fuel generation was almost unchanged (+5 TWh, +0.1%). Coal fell by 36 TWh (-1%) and gas by 1 TWh (-0.05%). This offset a slight rise in other fossil fuels (mainly oil) of 42 TWh. Consequently, global CO2 power sector emissions were unchanged in the first half of 2022 compared to the same period last year, despite the rise in electricity demand.Coal in the EU rose 15% only to cover a temporary shortfall in nuclear and hydro generation. Coal in India rose 10% because of a sharp rebound in electricity demand from lows early last year when the pandemic struck hardest. Globally, these rises were offset by coal-power falls of 3% in China and 7% in the United States.The growth in wind and solar prevented a 4% rise in fossil fuel electricity generation worldwide. In China, the growth in wind and solar enabled fossil fuel power to fall by 3%. Without this growth, fossil fuels would have risen by 1%. In India, fossil fuel power rose by 9%, but it would have been 12% without growth in wind and solar. In the United States, it slowed down the rise in fossil fuel power from 7% to just 1%. In the EU, fossil fuel power rose by 6%, but it would have been 16% without growth in wind and solar.Despite the halt in fossil-fuel generation in the first half of 2022, coal and gas generation increased in July and August. It leaves open the possibility that power sector emissions in 2022 may yet rise, following last year’s all-time high.Further, a new report from San Francisco-based NGO Global Energy Monitor found that approximately 89.6 gigawatts (GW) of gas plants in development globally, totaling 5,070 million metric tons of CO2e lifetime emissions if built, are coal-to-gas conversions or replacements.These conversions are proceeding despite data showing that gas projects are increasingly uncompetitive with renewables and are just as bad, if not worse, for the environment than coal.Wiatros-Motyka said:We can’t be sure if we’ve reached peak coal and gas in the power sector. Global power sector emissions are still pushing all-time highs when they need to be falling very quickly. And the same fossil fuels pushing us into a climate crisis are also causing the global energy crisis. We have a solution: Wind and solar are homegrown and cheap, and are already cutting both bills and emissions fast.Read more: Siemens Gamesa launches recyclable onshore wind turbine bladesUnderstandSolar is a free service that links you to top-rated solar installers in your region for personalized solar estimates. Tesla now offers price matching, so it’s important to shop for the best quotes. Click here to learn more and get your quotes. — *ad.",0.0,0.0
344,https://9to5mac.com/2022/10/25/apple-watch-blood-oxygen-study/,Study finds Apple Watch blood oxygen sensor is as reliable as âmedical-grade deviceâ,"A new validation study published this month puts the blood oxygen feature of the Apple Watch to the test. According to the results of the study, the Apple Watch Series 6 is able to “reliably detect states of reduced blood oxygen saturation” in comparison to medical-grade pulse oximeters. Here’s how the study came to determine this…How reliable is the Apple Watch’s blood oxygen sensor?As spotted by MyHealthyApple, the study was published this month in the Digital Health open access journal. The objective of the study was to investigate “how a commercially available smartwatch that measures peripheral blood oxygen saturation (SpO 2 ) can detect hypoxemia compared to a medical-grade pulse oximeter.”For the study, researchers recruited 24 healthy participants. Each person wore an Apple Watch Series 6 on their left wrist and a pulse oximeter sensor on their left middle finger (the Masimo Radical-7).The participants breathed via a breathing circuit with a three-way non-rebreathing valve in three phases. First, in the 2-minute initial stabilization phase, the participants inhaled the ambient air. Then in the 5-minute desaturation phase, the participants breathed the oxygen-reduced gas mixture (12% O 2 ), which temporarily reduced their blood oxygen saturation. In the final stabilization phase, the participants inhaled the ambient air again until SpO 2 returned to normal values. Measurements of SpO 2 were taken from the smartwatch and the pulse oximeter simultaneously in 30-s intervals.The study resulted in 642 individual pairs of blood oxygen measurements:The differences in individual measurements between the smartwatch and oximeter within 6% SpO 2 can be expected for SpO 2 readings 90%-100% and up to 8% for SpO 2 readings less than 90%.As such, the researchers conclude:The bias in SpO 2 between the smartwatch and the oximeter was 0.0% for all the data points. The bias for SpO 2 less than 90% was 1.2%. The differences in individual measurements between the smartwatch and oximeter within 6% SpO 2 can be expected for SpO 2 readings 90%–100% and up to 8% for SpO 2 readings less than 90%.Apple first added blood oxygen measurement support to the Apple Watch Series 6. It’s also a feature on the newest Apple Watch Series 7, Apple Watch Series 8, and Apple Watch Ultra. Apple has been hesitant to promote the feature with any actual medical claims, and the company hasn’t advertised any significant improvements to the technology since it first debuted on the Series 6 in 2020.You can read the complete study right here on the SAGE Journals website.FTC: We use income earning auto affiliate links. More.Check out 9to5Mac on YouTube for more Apple news:",0.0,0.0
333,https://www.businessinsider.com/meta-accuses-apple-undercutting-businesses-app-store-policy-change-2022-10,"Meta is mad about Apple's latest policy change, accusing the company of trying to 'grow their own business while undercutting others'","Apple's updated App Store rules give it 30% of in-app purchases for social media post ""boosts.""The rule essentially allows Apple to tax some advertising in apps like Facebook and Instagram.A Meta spokesperson told Insider that Apple's move undercuts other businesses and helps itself.Sign up for our newsletter for the latest tech news and scoops — delivered daily to your inbox. Loading Something is loading. Thanks for signing up! Access your favorite topics in a personalized feed while you're on the go. download the app Email address By clicking ‘Sign up’, you agree to receive marketing emails from Insider as well as other partner offers and accept our Terms of Service and Privacy PolicyMeta is not happy with Apple's latest update to its App Store guidelines around in-app purchases.The updated rule requires iOS app developers to use Apple's system of in-app purchases for post ""boosts"" — advertisements that show up in the same app they're purchased on — in social media apps. That means Apple gets 30% of the in-app purchases in Meta-owned apps like Facebook or Instagram when people use the app to pay to boost their posts and profiles to a wider audience.""Apple continues to evolve its policies to grow their own business while undercutting others in the digital economy,"" a Meta spokesperson told Insider in a statement. ""Apple previously said it didn't take a share of developer advertising revenue, and now apparently changed its mind. We remain committed to offering small businesses simple ways to run ads and grow their businesses on our apps.""During the Epic v. Apple trial last May, Phil Schiller, who is responsible for leading the App Store, testified that Apple never took cuts of iOS developer's advertising revenue.An Apple spokesperson told Insider that, ""for many years,"" the guidelines for the App Store ""have been clear that the sale of digital goods and services within an app must use In-App Purchase.""Boosting is a digital service, the spokesperson said, so it requires in-app purchase.""This has always been the case and there are many examples of apps that do it successfully,"" the spokesperson said.Twitter and TikTok are other apps who use in-app purchase for boosts.The Verge's Alex Heath reported earlier this week that, based on his conversations with employees at Meta, the App Store update isn't anticipated to have too big of an impact on Meta's revenue, but ""there is concern about the precedent set and that Apple will eventually require the same rule for Meta's standalone ads manager app.""Eric Seufert, an ad industry analyst, told Heath that people who buy boosts in their social media apps are going to be more affected by the updated App Store policies because they will have to pay more for the same reach they had before.In Meta's earning call on Wednesday, Meta CEO Mark Zuckerberg acknowledged some of Apple's recent changes, including its latest App Store policy language around boosted posts, saying they are ""obviously big risks"" that Meta ""see as issues.""Zuckerberg also talked about competition and ""ads challenges,"" that he said are ""especially coming from Apple.""Meta experienced a 4% revenue decline in the third quarter of this year, continuing a string of disappointing quarterly earnings. On an analyst call, it told investors the company plans to continue spending even more next year, despite losing money while Zuckerberg continues his quest to build the metaverse.",0.0,0.0
443,https://www.eurekalert.org/news-releases/968159,"In stressful jobs, depression risk rises with hours worked, study in new doctors finds","In “emulated” clinical trial, longer work weeks were strongly linked to larger rise in depression symptoms, pushing some first-year resident physicians into moderate or severe depression rangeThe more hours someone works each week in a stressful job, the more their risk of depression rises, a study in new doctors finds.Working 90 or more hours a week was associated with changes in depression symptom scores three times larger than the change in depression symptoms among those working 40 to 45 hours a week.What’s more, a higher percentage of those who worked a large number of hours had scores high enough to qualify for a diagnosis of moderate to severe depression -- serious enough to warrant treatment – compared with those working fewer hours.The research team, based at the University of Michigan, used advanced statistical methods to emulate a randomized clinical trial, accounting for many other factors in the doctors’ personal and professional lives.They found a “dose response” effect between hours worked and depression symptoms, with an average symptom increase of 1.8 points on a standard scale for those working 40 to 45 hours, ranging up to 5.2 points for those working more than 90 hours. They conclude that, among all the stressors affecting physicians, working a large number of hours is a major contributor to depression.Writing in the New England Journal of Medicine, the team from Michigan Medicine, U-M’s academic medical center, report their findings from studying 11 years’ worth of data on more than 17,000 first-year medical residents. The recently graduated doctors were in training at hundreds of hospitals across the United States.The data come from the Intern Health Study, based at the Michigan Neuroscience Institute and the Eisenberg Family Depression Center. Each year, the study recruits new medical school graduates to take part in a year of tracking of their depressive symptoms, work hours, sleep and more while they complete the first year of residency, also called the intern year.The impact of high numbers of work hoursThis study comes as major national organizations, such as the National Academy of Medicine and the Association of American Medical Colleges, grapple with how to address the high rates of depression among physicians, physicians-in-training and other health care professionals. Though the interns in the study reported a wide range of previous-week work hours, the most common work hour levels were between 65 to 80 hours per week.The Accreditation Council for Graduate Medical Education, which sets national standards for residency programs, currently sets an 80-hour limit on residents’ work weeks, but that can be averaged over four weeks and there are possible exceptions. ACGME also limits the length of a single shift and the number of days in a row that residents can work. Studies have shown mixed results about the impact these limits have had on resident wellness and patient safety risks.The authors say their findings point to a clear need to further reduce the number of hours residents work each week on average.“This analysis suggests strongly that reducing the average number of work hours would make a difference in the degree to which interns’ depressive symptoms increase over time, and reduce the number who develop diagnosable depression,” says Amy Bohnert, Ph.D., the study’s senior author and a professor at the U-M Medical School. “The key thing is to have people work fewer hours; you can more effectively deal with the stresses or frustrations of your job when you have more time to recover.”Yu Fang, M.S.E., the study’s lead author and a research specialist at the Michigan Neuroscience Institute, notes that the number of hours is important, but so are the training opportunities that come from time spent in hospitals and clinics. “It is important to use the time spent at work for supervised learning opportunities, and not low-value clinical service tasks,” she says.A population ripe for studyThe new study uses a design called an emulated clinical trial, which simulates a randomized clinical trial in situations where conducting a real randomized trial is not feasible. Because nearly all interns nationwide start at about the same time of year and are subject to varying work schedules set by their programs, studying people going through this stage of medical training is ideal for emulating a clinical trial.This opportunity is what led Intern Health Study founder Srijan Sen, M.D., Ph.D. to launch the research project in the first place: New physicians entering the most stressful year of their careers make a perfect group in which to study the role of many factors in the risk or onset of depression.The authors suggest that studies parallel to this work on physicians should be conducted in other high-stress and high-work-hour jobs. “We would expect that the negative effect of long work hours on physician mental health would be present in other professions,” says Sen.The average age of the doctors in the study was 27, and just over half were women. One in five were training in surgical disciplines, and 18% were from racial or ethnic groups traditionally underrepresented in the medical profession.Less than 1 in 20 met the criteria for moderate to severe depression at the start of intern year. In all, 46% had a stressful life event such as a family death or birth, or getting married, during their intern year, and 37% said they had been involved in at least one medical error during the year.In analyzing the results, the researchers adjusted for gender, neuroticism, pre-internship history of depression, early family environment, age, year they began internship, marital status, whether they had children, and stressful life events and medical errors during the intern year.Make a difference for today’s residents“National initiatives on clinician well-being have put increasing emphasis on the complex set of factors that affect clinician well-being, including the electronic health record, regulatory burden, resilience, workplace violence and culture,” says Sen, the director of the EFDC and the Eisenberg Professor of Depression and Neurosciences. “I think this emphasis has inadvertently led to the feeling that the problem is infinitely complicated and making real progress is hopeless. This paper demonstrates how big of an impact that the single factor of work hours has on clinician depression and well-being.”Sen is part of National Academy of Medicine’s Working Group on Navigating the Impacts of COVID-19 on Clinician Well-Being, part of a larger effort that recently issued a National Plan for Health Workforce Well-Being.Bohnert notes that residency directors running training programs for new doctors could reduce work hours by prioritizing efforts that increase efficiency and decreases unnecessary work.Fang also notes that the data from U.S. residents may apply to junior doctors, as they’re called, in other nations. The Intern Health Study now enrolls interns in China and Kenya as well.Supported by the National Institute of Mental Health (MH101459)Work Hours and Depression in U.S. First-Year PhysiciansN Engl J Med 2022; 387:1522-1524DOI: 10.1056/NEJMc2210365http://www.nejm.org/doi/full/10.1056/NEJMc2210365",0.0,0.0
287,https://techcrunch.com/2020/04/24/replacing-plastic-with-plant-pulp-for-sustainable-packaging-attracts-a-billionaire-backer/,Replacing plastic with plant pulp for sustainable packaging attracts a billionaire backer,"In a small suburb of Melbourne, two entrepreneurs are developing a technology that could mean big changes for the packaging industry.Stuart Gordon and Mark Appleford are the co-founders of Varden, a company that has developed a process to take the waste material from sugarcane and convert it into a paper-like packaging product with the functional attributes of plastic.Their technology managed to grab the attention of — and $2.2 million in funding from — Horizons Ventures, the venture capital fund managing the money of Li Ka-shing, one of the world’s wealthiest men.It’s an opportune time to launch a novel packaging technology, as the European Union has already instituted a ban on single-use plastic items, which will go into effect in 2021. Taking their lead, companies like Nestlé and Walmart have pledged to use only sustainable packaging for products beginning in 2025.The environmental toll that packaging takes on the earth’s habitats is already a concern for many, and the urgency to find a solution is only mounting with consumers and businesses actually producing more waste in the rush to change consumer behavior and socially distance as a result of the COVID-19 global pandemic.“I like technologies that focus on carbon reductions,” said Chris Liu, Horizons Ventures’ representative in Australia.A longtime tech and product executive who had stints at Intel and Fjord, a digital design studio, Liu relocated to Australia recently and has actually taken himself off the grid.Living in Western Australia, the climate emergency was brought directly to the top of Liu’s mind when the wildfires, which raged through the country, came within two kilometers of his new home.For Mark Appleford, it wasn’t so much the fires as it was the garbage that kept washing up on the shores of his beloved beaches.Over beers at a barbecue he began talking to his eventual co-founder, Stuart Gordon, about the environmental problem they’d solve if they had the ability to change things. They settled on plastics.Working in Appleford’s laundry room they started developing the technology that would become Varden. That early laundry room-work in 2015 led to a small seed round and the company’s long slog to get an initial product in the hands of test customers.Finagling some time with the New Zealand manufacturer Fisher and Paykel, the two co-founders put together an early prototype of their coffee pods made from sugarcane bagasse, a waste byproduct of the sugar feedstock.“We worked backwards through customers to supply chain, which led us to material selection, which was something that would allow us to create a product that people understood,” said Gordon.The production process has evolved to fit inside a 40-foot container that holds the firm’s machine, which takes agricultural waste and converts that waste into packaging.Instead of using rollers like a paper mill, Varden’s technology uses a thermoform to mold the plant waste into a product that has the same properties as plastic.It removes a complicated step that’s been essential to the current crop of bioplastics, which use bacteria to convert plant waste into plastic substitutes that are then sold to the industry.“It looks like paper… you can tear it in half and it sounds like paper when you rip it, and you can throw it in the bin,” said Appleford.Gordon said that the company’s containers are outperforming commodity based plastics. And the first target for replacement, the founders said, is coffee capsules.“We went for coffee because it’s the hardest,” said Appleford.It’s also a huge market, according to the company. Varden estimates there are more than 20 billion coffee pods consumed every year.With the new money, Varden will begin manufacturing at scale to meet initial demand from pilot customers and is hoping to expand its product line to include medical blister packs in addition to the coffee pods.“A pilot plant on the products we’re looking at is a pilot plant that can generate 20 million units a year,” said Gordon.Both men are hoping that their product — and others like it — can usher in a generation of new sustainable packaging materials that are better for the environment at every stage of their life cycle.“The next generation of packaging will be better… there are plant-based flexibles for your salads, for your potato chips… [But] the next generation of molded packaging is us… bioplastic will ultimately go.”",0.0,0.0
435,https://news.ki.se/heres-how-the-brain-works-when-we-choose-to-help-someone-in-danger,Hereâs how the brain works when we choose to help someone in danger,"“Our findings indicate that the brain’s defence system plays a greater role in helping behaviour than was previously thought. These results contradict the conventional wisdom that we need to suppress our own fear system in order to help others who are in danger”, says Andreas Olsson, professor at the Department of Clinical Neuroscience, Karolinska Institutet and the study's last author.The capacity for empathy for the distress of others has long been considered the driving force of helping. But when we decide to help someone who is in danger, we have to consider not only the other person’s distress but the risk we pose to ourselves by helping – for example, by rushing into a burning building to save someone or helping someone who fell on a train track.Measured brain activityStudies in other animals suggest that the brain’s defence systems are important for helping others, but very little is known about these processes in humans. Researchers from Karolinska Institutet have now investigated this in more detail.The study included 49 healthy volunteers who were asked to decide whether they wanted to help another, unknown person avoid the discomfort of a mild electric shock. But if they decided to help the person, there was a risk that they might receive a shock themselves. The unknown person was visible to the participant on a screen. During the task, the activity in the participants’ brains was imaged with an fMRI scanner.The participants were also told how soon the shock would be delivered, so that the researchers could measure their reactions relative to the proximity of the threat.An evolutionarily ancient region of the brain",0.0,0.0
507,https://norml.org/news/2022/10/20/survey-ibd-patients-report-fewer-er-visits-following-initiation-of-medical-cannabis/,Survey: IBD Patients Report Fewer ER Visits Following Initiation of Medical Cannabis,"Bronx, NY: Patients with inflammatory bowel disease (IBD) report symptom mitigation and fewer emergency room visits following the use of cannabis products, according to data published in the Journal of Clinical Gastroenterology.Investigators affiliated with the Albert Einstein College of Medicine in New York City surveyed a cohort of 236 IBD patients registered in the state’s medical cannabis access program.Respondents “reported fewer emergency room visits in the 12 months after versus before MC [medical cannabis] use and less impact of symptoms on daily life.” Subjects in the study were most likely to consume THC-dominant products via vaporization. Minor adverse effects, specifically drowsiness, were reported among a minority (4.2 percent) of subjects.Authors concluded: “MC users with IBD perceive symptom benefits and report decreased emergency room visits without serious adverse effects. Further studies are needed to confirm these results with objective measures of healthcare utilization and disease activity.”Observational trials have previously documented that cannabis use is associated with “decreased inpatient health care utilization” in patients with irritable bowel syndrome and with fewer disease-related hospitalizations in patients with Crohn’s. In a randomized placebo-controlled trial involving 21 patients with refractory Chron’s disease, nearly half achieved disease remission following their use of herbal cannabis.Full text of the study, “Medical cannabis use patterns and adverse effects in inflammatory bowel disease,” appears in the Journal of Clinical Gastroenterology. Additional information on cannabis and IBD is available from NORML.Share this: TwitterFacebookLike this: Like Loading...",0.0,0.0
110,https://www.vice.com/en/article/g5vwzq/the-pacific-ocean-is-shrinking-amasia-supercontinent,"The Pacific Ocean Is Shrinking and Will Form a New Supercontinent, Scientists Say","The Pacific Ocean is shrinking. Every year, it gets about an inch smaller as the tectonic plates that the Americas sit on are pushed westward. Now, thanks to calculations by a supercomputer, scientists say that a new “supercontinent” will eventually emerge due to this process: Amasia.The current world map, with its recognizable pattern of continents and oceans, is just one snapshot of our planet in time. Earth has tried on all kinds of continental configurations over its 4.5-billion-year lifespan, including periods where almost all of Earth’s land consolidates into one giant supercontinent.AdvertisementWe currently live in the broken remains of the supercontinent Pangaea, which formed 335 million years ago and disintegrated during the rise of the dinosaurs. The existence of even older supercontinents, such as Rodinia and Columbia (Nuna), suggest that Earth is locked into a “supercontinent cycle” that sees the formation and destruction of these immense landmasses on a rough timeline of 600 million years. The cycle raises the question of what kind of new supercontinent might emerge millions of years from now, prompting scientists to propose future landmasses with names like Novopangaea, Aurica, and Amasia.To shed light on this mystery, researchers led by Chuan Huang, a geophysicist at Curtin University in Australia, simulated the future of Earth with a supercomputer. The results suggest that a new supercontinent, Amasia, will form when the Pacific Ocean shrinks into nothingness some 200 million years from now, causing North America to slam into Asia, according to a recent study published in National Science Review.The future emergence of Amasia, a portmanteau of America and Asia, has been discussed by scientists for more than a decade, but there is debate over whether this supercontinent would form “inside in,” a process known as introversion, or “outside in,” which is called extroversion. Introversion involves the closure of younger post-Pangaea oceans, such as the Indian or Atlantic, whereas extroversion indicates the closure of the Pacific Ocean, which is the oldest ocean on Earth and is shrinking at a rate of about one inch per year.Advertisement“Earth's known supercontinents are believed to have formed in vastly different ways, with two endmembers being introversion and extroversion,” said Huang and his colleagues in the study. “The former involves the closure of the internal oceans formed during the break-up of the previous supercontinent, whereas the latter involves the closure of the previous external superocean.”“With our modelling results, we speculate if the next supercontinent will likely assemble through the closure of the Pacific Ocean,” which would be extroversion, “or the Indo-Atlantic oceans,” which would be introversion, the team added.As Huang and his colleagues ran their supercomputer simulations, they noticed the strength of the lithosphere, the stiff top layer of Earth that encompasses the crust and surface, is an overlooked variable in the emergence of the next supercontinent. The oceanic lithosphere has been weakening over time as a result of Earth’s slow cooling, a shift that clearly predicts the rise of Amasia from extroversion, or the closure of the Pacific Ocean.Sign up for Motherboard’s daily newsletter for a regular dose of our original reporting, plus behind-the-scenes content about our biggest stories.“Our results show that the yield strength of the oceanic lithosphere plays a critical role in determining the assembly path of a supercontinent,” the researchers said. “We found that high oceanic lithospheric strength leads to introversion assembly, whereas lower strength leads to extroversion assembly.”“This predicts that the next supercontinent Amasia could only be assembled through the closure of the Pacific Ocean,” the team concluded.In this way, the new study offers a glimpse of our planet some 200 to 300 million years from now, when an enormous landmass could unite over the ashes of the long-lived Pacific Ocean. It’s a reminder that humanity has existed for a mere split-second in geological time, and that our planet in the deep past and far future may as well be an alien world.""Earth as we know it will be drastically different when Amasia forms,” said Zheng-Xiang Li, a professor at Curtin’s Earth Dynamics Research Group who co-authored the study, in a statement. “The sea level is expected to be lower, and the vast interior of the supercontinent will be very arid with high daily temperature ranges.""",0.0,0.0
277,https://techcrunch.com/2022/06/27/uks-magical-mushroom-company-uses-mycelium-to-replace-plastic-packaging/,UKâs Magical Mushroom Company uses mycelium to replace plastic packaging,"Global plastic waste has more than doubled, and 40% of that waste comes from packaging. Luckily there is no shortage of sustainable packaging startups in Europe. Just take a look: Circleback (Germany), Recup (Germany), Sourceful (U.K.), one • five (Germany), Shellworks (U.K.), Woola (Estonia), Papkot (France), Biotic (Israel), FunCell (France) and Traceless (Germany).The latest to join the ranks is Magical Mushroom Company (MMC). It’s now raised a £3 million seed round led by Ecovative Design LLC with participation by Dale Vince, founder of Ecotricity (a green energy company in the U.K.); Robert Del Naja (activist); and Marcus Watson, co-founder of Adoreum Partners, who brought 30 other investors.The investment will be used to fund the opening of its first raw material production plant.MMC’s solution is a direct replacement for plastic-based packaging such as polystyrene and cardboard. It does this by combining agricultural waste with mycelium — the root structure of a mushroom. The result, claims the company, is biodegradable (in 45 days), durable and comparable in price to traditional packaging derived from fossil fuels like polystyrene.Launched in 2019, MMC’s clients include Raymarine, BA Components, Castrads, Ffern, Selfridges, Lush, Seedlip and ID Watch, among many others.Paul Gilligan, CEO and founder at Magical Mushroom Company, said in a statement: “We have just eight years to meet the UN’s Sustainable Development Goals and businesses have a crucial role to play – but they need viable and cost-effective solutions that significantly reduce the carbon footprint across their entire supply chain. We’re proud to be creating value from waste and unlocking the potential of mycelium.”",0.0,0.0
169,https://electrek.co/2022/09/23/second-largest-us-electric-school-bus-fleet-just-crossed-500k-miles/,"The second largest electric school bus fleet in the US just crossed 500,000 service miles","The school year is beginning, so the buses will be out in full force. However, you may notice a significant difference this year as emission-free electric school buses roll out across the United States. One of the nation’s leading school bus manufacturers, Thomas Built Buses, just achieved a major milestone with help from its Virginia-based dealer Sonny Merryman — Saf-T-Liner C2 Jouley electric school buses have now driven more than 500,000 miles.Electric school buses are designed for a cleaner, sustainable future. Not only do they produce zero emissions, but they are also more efficient, can cost less to maintain, and have abilities their gas-powered counterparts lack.450,000 yellow school buses across the United States travel over 4.3 billion miles each year, according to information from the US Department of Transportations National Highway Traffic Safety Administration (NHTSA).More importantly, toxic emissions from traditional school buses can harm students, bus drivers, and the communities they drive in.Although the EPA has introduced stricter standards, it’s not enough as many school buses still emit harmful diesel exhaust. With federal funding more accessible than ever for electric school buses, making the transition makes sense.As of June 2022, 38 states had adopted electric school buses thanks to several initiatives such as the $5 billion Clean School Bus program.Meanwhile, states like Virginia are taking the initiative to provide funding and accelerate the transition. For example, in 2019, Virginia’s Governor Ralph Northam and Dominion Energy announced an initiative to provide 13,000 electric school buses by the end of 2030.Through programs like these, Virginia has grown to become the country’s second-largest electric bus fleet, currently operating 64 Thomas Built electric school buses. In a significant milestone, the electric school buses have now traveled over 500,000 miles, with more buses expected to be delivered as the school year progresses.Growth of electric school buses in Virginia Source: Sonny MerrymanThomas Built Buses achieves 500,000 electric miles in VirginiaThe first electric school bus to roll out in the state of Virginia was Thomas Built Buses’ Saf-T-Liner C2 Jouley in November 2020.One C2 Jouley electric bus can transport 81 students with up to 138 miles of range and a 226 kWh standard battery capacity.Virginia now has 64 electric buses in total. The first 50 were purchased and deployed through the Dominion Energy program, and the remaining 14 were bought using funds from the American Power electric school bus program.The 500,000 miles driven include several different terrains (city, rural, and hills) and distances from less than 20 miles to more than 90 miles. Although the electric buses have primarily been used for regular school routes, a few have made their way to field trips, band competitions, and more.By using electric buses for these trips, 447.7 short tons of greenhouse gases were avoided, according to the AFLEET tool.Through the experience so far, Thomas Built Buses dealer Sonny Merryman and its customers have learned a few critical takeaways that can help others deploy electric buses safely and efficiently:Properly train drivers and technicians for a smooth transition.Consider assigning a partner or team to help with the deployment.Perhaps, most importantly, the electric buses have withstood various operational tests, and drivers who have switched to the electric Jouley school buses have loved them so far, according to the school bus dealer.Electrek’s TakeFirst things first, congratulations to Thomas Built Buses and Sonny Merryman on the huge milestone. Electric school buses protect students and communities from harmful emissions while saving school districts money on fuel and maintenance in the long run.At the same time, I think there is a major takeaway from this case study. State funding works, and electric buses are the future. Virginia is proving it. California has proved it. State leaders need to get on board to speed up the transition. There are no excuses now.",0.0,0.0
104,https://www.wired.com/story/drought-destroying-ancient-ruins/,Climate Change Is Burying Archaeological Sites Under Tons of Sand,"The Nizari garrison at Gird Castle resisted the Mongol horde of Hulagu Khan for 17 years before surrendering in December 1270. The fortress rose 300 meters above the surrounding plains of present-day eastern Iran, with three rings of fortifications enclosing its base. But dwindling supplies and an outbreak of cholera forced the defenders to abandon their posts after one of the longest sieges in medieval history.Content This content can also be viewed on the site it originates from.Eight hundred years later, the remaining fortifications at Gird Castle face the onslaught of a new invader: sand. For the past three months, Bijan Rouhani, an archaeologist at the University of Oxford, has been monitoring about 700 sites in Iran’s Sistan region using satellite imagery. His comparison of US intelligence photos taken in 1977 and Google Earth’s most recent images of the area shows the advance of vast dunes that now almost bury the fortress at Gird.This summer, drought has revealed a number of previously hidden archaeological sites as low water levels have allowed archaeologists to access historic ruins in Spain, Iraq, and China. But just as climate change giveth, so it taketh away: Rising heat is damaging some ancient sites and spurring desertification that is burying others, Gird Castle among them. It is a growing problem with few proven solutions.“We can see many other sites from the Bronze Age to the Islamic periods in the area, as well as ancient rivers and canals,” says Rouhani. “Most of these sites are now buried under sand and impacted by the 120-day sand wind every year.”The ancient city of Zahedan Kohneh has suffered the same fate as Gird Castle. It was Sistan’s capital when Gird fell to the Mongols and was once one of the largest cities in Iran—today it is draped in a growing garment of sand. Archaeologists monitoring sites in other regions, countries, and continents report similar stories. Ahmed Mutasim Abdalla Mahmoud, a researcher specializing in sand movement at the University of Nottingham, says sand poses the biggest threat to Sudan’s Nubian pyramids, built around 4,500 years ago. He warns that the 200 pyramids at El Kurru, Jebel Barkal, and Meroe on the Nile River could soon disappear beneath sand.“The threat has been exacerbated by climate change, which has made the land more arid and sandstorms more frequent,” he writes on the Conversation. “Moving sands can engulf entire houses in rural Sudan, and cover fields, irrigation canals, and riverbanks.”",0.0,0.0
11,https://www.cnet.com/google-amp/news/nasas-webb-space-telescope-is-so-good-we-might-need-improved-planetary-models/,"NASA's Webb Space Telescope Is So Good, We Might Need Improved Planetary Models","This telescope is producing impeccable results, but do our models match its excellence?It has become exceedingly clear, over the past few months, that NASA's James Webb Space Telescope does exactly what it set out to do. Just as its creators had hoped, the multibillion-dollar machine is flawlessly ""unfolding the universe"" by revealing cosmic light we cannot see with our own eyes -- and its excellent results make even the most unlikely of stargazers feel alive.Because of this gold-plated telescope, Twitter went wild one day over a bleary red dot. For 48 hours, people worldwide were gawking at a galaxy born shortly after the birth of time itself. It would appear that, thanks to the technological prowess of the JWST, humanity stands united over stardust.Get the CNET Now newsletter Spice up your small talk with the latest tech news, products and reviews. Delivered on weekdays. Yes, I also want to receive the CNET Insider newsletter, keeping me up to date with all things CNET. Subscribe By signing up, you agree to our Terms of Use and acknowledge the data practices in our Privacy Policy. You may unsubscribe at any time. Thanks for signing up! Personalize my inbox An error occurred. Please check your email and try againBut here's the thing.Amid personal awe, scientists from the Massachusetts Institute of Technology warn that we ought to consider one crucial scientific consequence of having a superhero telescope.If the JWST is like a zero-to-100 'scope upgrade, they wonder, is it possible our science models need a zero-to-100 reboot, too? Are the datasets scientists have been using for decades unable to match the device's power and therefore falling short in revealing what it's trying to tell us?""The data we will be getting from the JWST will be incredible, but ... our insights will be limited if our models don't match it in quality,"" Clara Sousa-Silva, a quantum astrochemist at the Center for Astrophysics, Harvard & Smithsonian, told CNET.And, according to a new study of which she's a co-author, published Thursday in the journal Nature Astronomy, the answer is yes.More specifically, this paper suggests some of the light-parsing tools scientists normally use to understand exoplanet atmospheres aren't totally equipped to deal with the JWST's exceptional light data. In the long run, such a hindrance may impact the most massive JWST quest of all: the hunt for extraterrestrial life.""Currently, the model we use to decrypt spectral information is not up to par with the precision and quality of data we have from the James Webb telescope,"" Prajwal Niraula, graduate student at MIT's department of Earth, atmospheric and planetary sciences and co-author of the study, said in a statement. ""We need to up our game.""NASAHere's one way to think about the conundrum.Imagine pairing the newest, most powerful Xbox console with the very first iteration of a TV. (Yes, I know the extreme hypothetical nature of my scenario). The Xbox would be trying to give the TV awesome high-resolution, colorful, beautiful graphics to show us -- but the TV wouldn't have the capacity to compute any of it.I wouldn't be surprised if the TV straight up exploded. But the point is you wouldn't know what the Xbox is trying to provide for you, unless you get an equally high-res TV.Similarly, in the vein of exoplanet discoveries, scientists feed a bunch of deep-space light, or photon, data into models that test for ""opacity."" Opacity measures how easily photons pass through a material and differs depending on things like light wavelength, material temperature and pressure.This means every such interaction leaves behind a telltale signature of what the photon's properties are, and therefore, when it comes to exoplanets, what kind of chemical atmosphere those photons passed through to get to the light detector. That's how scientists sort of reverse-calculate, from light data, what an exoplanet's atmosphere is composed of.In this case, the detector liaison lies on the James Webb Space Telescope -- but in the team's new study, after putting the most commonly used opacity model to the test, the researchers saw JWST light data hitting what they call an ""accuracy wall.""The model wasn't sensitive enough to parse stuff like whether a planet has an atmospheric temperature of 300 or 600 Kelvin, the researchers say, or whether a certain gas takes up 5% or 25% of the atmosphere. Such a difference is not only statistically significant, but per Niraula, also ""matters in order for us to constrain planetary formation mechanisms and reliably identify biosignatures.""That is, evidence of alien life.""We need to work on our interpretive tools,"" Sousa-Silva said, ""so that we don't find ourselves seeing something amazing through JWST but not knowing how to interpret it.""T. Treu/GLASS-JWST/NASA/CSA/ESA/STScIFurther, the team also found its models kind of disguising its uncertain readings. A few adjustments can easily paper over uncertainty, deeming results a good fit when they're incorrect.""We found that there are enough parameters to tweak, even with a wrong model, to still get a good fit, meaning you wouldn't know that your model is wrong and what it's telling you is wrong,"" Julien de Wit, assistant professor at MIT's EAPS and study co-author, said in a statement.Going forward, the team urges opacity models be improved to accommodate our spectacular JWST revelations – especially calling for crossover studies between astronomy and spectroscopy.""There is so much that could be done if we knew perfectly how light and matter interact,"" Niraula says. ""We know that well enough around the Earth's conditions, but as soon as we move to different types of atmospheres, things change, and that's a lot of data, with increasing quality, that we risk misinterpreting.""De Wit compares the current opacity model to the ancient language translation tool the Rosetta Stone, explaining that so far, this Rosetta Stone has been doing OK, such as with the Hubble Space Telescope.""But now that we're going to the next level with Webb's precision,"" the researcher said, ""our translation process will prevent us from catching important subtleties, such as those making the difference between a planet being habitable or not.""As Sousa-Silva puts it, ""it's a call to improve our models, so that we will not miss the subtleties of data.""",0.0,0.0
388,https://english.elpais.com/science-tech/2022-10-31/gut-dwelling-bacterium-singled-out-as-the-possible-cause-of-colorectal-cancer.html,Gut-dwelling bacterium singled out as the possible cause of colorectal cancer,"A microbe that is common in the human intestine is suspected of playing a major role in the development of colorectal cancer, the second deadliest and third most common kind in the world, with two million diagnosed cases and one million deaths a year.A team of scientists from Yale University recently discovered in a group of volunteers that some strains of the bacterium Morganella morganii produce molecules called indolimines that are toxic for human DNA. In the laboratory, the researchers proved that these substances cause tumors in mice. The finding was published in the journal Science on October 28.A human being has more bacterial cells (38 trillion) than human cells (30 trillion). However, defecation can reverse the proportion in favor of human cells. Through this act, in which a third of the microbes in the colon is expelled, the person ceases to be numerically bacterial and becomes fully human. Most of these microorganisms are harmless, or even beneficial, but some can cause illness, explains Noah Palm, lead author of the study, and it is possible that the indolimines have an effect on colorectal cancer. However, much more work will be needed to prove that they are indeed the cause.More information Scientists transplant human neurons into rats and modify their behaviorThe lifetime risk of colorectal cancer is 1 in 23 in men and 1 in 25 in women, according to data from European tumor registries. The usual risk factors are age, smoking, alcohol consumption, obesity and a diet low in fruit and high in processed meats. Having an inflammatory bowel disease, such as ulcerative colitis or Crohn’s disease, increases the risk as well.Palm’s team developed a new technique that allows for the simultaneous study of a hundred types of microbes and their products. The researchers detected the (previously unknown) indolimines in strains of Morganella morganii in people with inflammatory diseases. However, even though there is a larger amount of this bacterium in patients with inflammatory bowel disease or colorectal cancer, it is also present in seemingly healthy people. Even the epithelial cells of the intestines of healthy individuals show some mutations that can be caused by toxins from these communities of microorganisms, such as indolimines, explains Palm.Morganella morganii, which measures one thousandth of a millimeter, is commonly found in water, soil and the intestines of mammals. It is usually a benign microbe, but it is also associated with urinary tract infections.Spanish biotechnologist Cayetano Pleguezuelos and his colleagues at the Hubrecht Institute in the Netherlands were the first to show the direct connection between the bacteria that live in the human digestive system and the genetic alterations that cause the development of cancer. The researchers saw that a specific strain of Escherichia coli produces a toxic molecule called colibactin which damages the DNA of human cells. This was confirmed in miniature versions of intestinal tissue generated in the laboratory. Their discovery was published in the journal Nature on February 27, 2020, while the human race had its attention on another microorganism: a coronavirus that was spreading around the world from China.Pleguezuelos applauds the new work, but suggests prudence. “Our intestinal microbiota is very complex, with many different species of bacteria, and among them there are mutualistic relationships, symbiosis, negative competition… and there are many other parameters. Bacteria can produce these toxic compounds in humans but, for some reason, they may not be able to reach the epithelial cells of the intestine and damage the DNA. These factors are not seen in experiments with mice,” he warns.The Spanish researcher believes that the new Yale University technique “opens the door to evaluating a large number of bacteria and their ability to damage DNA.” A person that weighs 70 kilos has about 46 kilos of human cells, according to a study carried out by a team from the Weizmann Institute of Science in Rehovot, Israel. The heaviest ones are muscle and fat cells. The 38 trillion bacteria only weigh about 200 grams, but they make up an extremely complex universe. “Their ability to carry out different enzymatic reactions is immense. And we don’t know most things,” says Pleguezuelos.The Spanish biotechnologist explains that every agent that damages human DNA causes a specific pattern of mutations called a mutational signature. Pleguezuelos and his colleagues identified the mutational signature of the harmful strains of the Escherichia coli and found this characteristic trace in more than 5% of the colorectal cancer patients that were analyzed, compared to 0.1% detected in other types of tumors. Of course, that figure must be taken with a grain of salt – pending further studies in other populations – but it gives an idea of the magnitude of the problem: 5% of the two million annual cases means 100,000 colorectal cancer patients with the mutational signature of these harmful strains of Escherichia coli.Doctor Palm points out that most cases of colorectal cancer occur in people who have no family history. Therefore, environmental factors, including the microbiome, play a key role in most colorectal cancer cases. However, he explains, it is still impossible to calculate the relative importance of the microbiome against other environmental factors.Although currently there are no specific treatments to prevent DNA damage induced by the microbiome, treatments could be developed to neutralize, or even eliminate, these toxin-producing microbes.",0.0,0.0
488,https://www.cnbc.com/2022/10/24/beyond-meats-steak-substitute-coming-to-grocery-stores.html,Beyond Meat is rolling out its steak substitute in grocery stores,"Beyond Meat is launching a steak substitute in grocery stores on Monday.The new product will roll out nationwide at more than 5,000 Kroger and Walmart stores, as well as Albertsons , Ahold Delhaize , Jewel-Osco, Sprouts and other local grocers.The announcement concludes a rocky month for the maker of meat alternatives. Beyond ousted Chief Operating Officer Doug Ramsey after he was arrested for allegedly biting another man's nose. The company also announced plans to cut 19% of its workforce, or roughly 200 employees, as well as the departure of its chief financial officer and the elimination of the chief growth officer role.Amid the chaos, Beyond and Yum Brands' Taco Bell started testing meatless carne asada using its Beyond Steak product at restaurants in Dayton, Ohio.The Beyond Steak that will be sold in grocery stores comes packaged in bite-sized pieces. It uses faba bean protein as its base and contains 21 grams of protein per serving, according to the company. It also has lower saturated fat content than beef steak and contains no cholesterol. The 10-ounce package will retail for $7.99.Historically, product launches have boosted Beyond's sales, driving new and returning customers to try the item. That would be welcome news for the company, which has seen its sales slide and investors lose hope in its long-term growth prospects.In the second quarter, Beyond reported U.S. grocery sales rose just 2.2% while restaurant revenue was off 2.4%. This year, shares of the company have lost 80% of their value, shrinking its market value to $821 million. At its record high in July 2019, Beyond was valued at $13.4 billion.",0.0,0.0
534,https://www.reuters.com/lifestyle/science/nasas-asteroid-deflecting-dart-spacecraft-nears-planned-impact-with-its-target-2022-09-26/,NASA's DART spacecraft hits target asteroid in first planetary defense test,"Sept 26 (Reuters) - NASA's DART spacecraft successfully slammed into a distant asteroid at hypersonic speed on Monday in the world's first test of a planetary defense system, designed to prevent a potential doomsday meteorite collision with Earth.Humanity's first attempt to alter the motion of an asteroid or any celestial body played out in a NASA webcast from the mission operations center outside Washington, D.C., 10 months after DART was launched.The livestream showed images taken by DART's camera as the cube-shaped ""impactor"" vehicle, no bigger than a vending machine with two rectangular solar arrays, streaked into the asteroid Dimorphos, about the size of a football stadium, at 7:14 p.m. EDT (2314 GMT) some 6.8 million miles (11 million km) from Earth.The $330 million mission, some seven years in development, was devised to determine if a spacecraft is capable of changing the trajectory of an asteroid through sheer kinetic force, nudging it off course just enough to keep Earth out of harm's way.Whether the experiment succeeded beyond accomplishing its intended impact will not be known until further ground-based telescope observations of the asteroid next month. But NASA officials hailed the immediate outcome of Monday's test, saying the spacecraft achieved its purpose.""NASA works for the benefit of humanity, so for us it’s the ultimate fulfillment of our mission to do something like this - a technology demonstration that, who knows, some day could save our home,"" NASA Deputy Administrator Pam Melroy, a retired astronaut, said minutes after the impact.DART, launched by a SpaceX rocket in November 2021, made most of its voyage under the guidance of NASA's flight directors, with control handed over to an autonomous on-board navigation system in the final hours of the journey.Monday evening's bullseye impact was monitored in near real time from the mission operations center at the Johns Hopkins University Applied Physics Laboratory in Laurel, Maryland.Cheers erupted from the control room as second-by-second images of the target asteroid, captured by DART's onboard camera, grew larger and ultimately filled the TV screen of NASA's live webcast just before the signal was lost, confirming the spacecraft had crashed into Dimorphos.DART's celestial target was an oblong asteroid ""moonlet"" about 560 feet (170 meters) in diameter that orbits a parent asteroid five times larger called Didymos as part of a binary pair with the same name, the Greek word for twin.Neither object presents any actual threat to Earth, and NASA scientists said their DART test could not create a new hazard by mistake.Dimorphos and Didymos are both tiny compared with the cataclysmic Chicxulub asteroid that struck Earth some 66 million years ago, wiping out about three-quarters of the world's plant and animal species including the dinosaurs.[1/4] The last complete image of asteroid moonlet Dimorphos, taken by the DRACO imager on NASA's DART mission 12 kilometers from the asteroid and 2 seconds before impact, showing a patch of the asteroid that is 31 meters across, released September 26, 2022. NASA/Johns Hopkins APL/Handout via REUTERS 1 2 3 4Smaller asteroids are far more common and present a greater theoretical concern in the near term, making the Didymos pair suitable test subjects for their size, according to NASA scientists and planetary defense experts. A Dimorphos-sized asteroid, while not capable of posing a planet-wide threat, could level a major city with a direct hit.Also, the two asteroids' relative proximity to Earth and dual configuration make them ideal for the first proof-of-concept mission of DART, short for Double Asteroid Redirection Test.ROBOTIC SUICIDE MISSIONThe mission represented a rare instance in which a NASA spacecraft had to crash to succeed. DART flew directly into Dimorphos at 15,000 miles per hour (24,000 kph), creating the force scientists hope will be enough to shift its orbital track closer to the parent asteroid.APL engineers said the spacecraft was presumably smashed to bits and left a small impact crater in the boulder-strewn surface of the asteroid.The DART team said it expects to shorten the orbital path of Dimorphos by 10 minutes but would consider at least 73 seconds a success, proving the exercise as a viable technique to deflect an asteroid on a collision course with Earth - if one were ever discovered.A nudge to an asteroid millions of miles away years in advance could be sufficient to safely reroute it.Earlier calculations of the starting location and orbital period of Dimorphos were made during a six-day observation period in July and will be compared with post-impact measurements made in October to determine whether the asteroid budged and by how much.Monday's test also was observed by a camera mounted on a briefcase-sized mini-spacecraft released from DART days in advance, as well as by ground-based observatories and the Hubble and Webb space telescopes, but images from those were not immediately available.DART is the latest of several NASA missions in recent years to explore and interact with asteroids, primordial rocky remnants from the solar system's formation more than 4.5 billion years ago.Last year, NASA launched a probe on a voyage to the Trojan asteroid clusters orbiting near Jupiter, while the grab-and-go spacecraft OSIRIS-REx is on its way back to Earth with a sample collected in October 2020 from the asteroid Bennu.The Dimorphos moonlet is one of the smallest astronomical objects to receive a permanent name and is one of 27,500 known near-Earth asteroids of all sizes tracked by NASA. Although none are known to pose a foreseeable hazard to humankind, NASA estimates that many more asteroids remain undetected in the near-Earth vicinity.(This story corrects name in paragraph 6 to Pam from Palm)Reporting by Steve Gorman in Los Angeles; Additional reporting by Joey Roulette in Los Angeles; Editing by Sandra Maler and Stephen CoatesOur Standards: The Thomson Reuters Trust Principles.",0.0,0.0
390,https://www.technologynetworks.com/cancer-research/news/new-report-shows-decline-in-us-cancer-deaths-continues-367025,New Report Shows Decline in US Cancer Deaths Continues,"The latest Annual Report to the Nation on the Status of Cancer has provided an update on the most recent statistics and trends in cancer cases and deaths in the United States. This year’s report, published in Cancer, also places focus on pancreatic cancer.Knowledge in the fight against cancerCancer is one of the leading causes of death worldwide. It is expected that the number of new cancer cases globally will grow to 27.5 million, with 16.3 million cancer deaths, by 2040. Breast, lung, colon and prostate cancers are the four most common cancers worldwide, accounting for approximately 40% of all new cases collectively.In the US, annual reports on the statistical trends in cancer cases have been published since 1998 as part of a collaboration between the Centers for Disease Control and Prevention (CDC), the American Cancer Society, the National Cancer Institute (NCI) and the North American Association of Central Cancer Registries (NAACCR).These reports examine a plethora of data, analyzing trends in cancer incidence, mortality and survival by cancer type, sex, age and racial/ethnic groups.The current report combined information about race and ethnicity to create five mutually exclusive groups: non‐Hispanic White (White), non‐Hispanic Black (Black), non‐Hispanic American Indian/Alaska Native (AI/AN), non‐Hispanic Asian/Pacific Islander (API) and Hispanic (of any race).Additionally, data for the various groups analyzed in the current report were collected at time points ranging from 2001–2019 – therefore, it is important to note that all data were collected before the COVID-19 pandemic.Cancer incidence ratesOverall incidence rates per 100,000 individuals were 497 for males and 431 for females from 2014–2018.API and Black males had the lowest and highest incidence rates among men, respectively, and API and AI/AN females also had the lowest and highest rates respectively for women.However, incidence varied across 18 of the most common cancer types included in this report:For males – incidence rates for three of these cancers increased (including pancreas and kidney), seven were stable (including prostate) and eight decreased (including lung and larynx).For females – incidence rates of seven cancers increased (including melanoma, liver and breast), four cancers were stable (including uterine) and seven decreased (including thyroid and ovary).Additionally, for breast cancer – the most common cancer among adolescents and young adults (15–39 years of age) – the incidence rate increased by 1.0% per year on average between 2010 and 2018.Mortality ratesCombining data from males and females showed that the decline in overall death rates from cancer steepened from 2001 to 2019, decreasing by 2.1% per year. Similar trends in overall death rates were also observed in each of the racial/ethnic groups analyzed in the report.Data from adolescents and young adults showed a decrease in death rates by 3% per year between 2001 and 2005, however, this rate of decline slowed to around 0.9% per year thereafter.Racial and ethnic disparitiesThe report also highlighted racial and ethnic disparities, in both the incidence rates (2014–2018) and death rates (2015–2019) across many cancer types, as summarized in the table below.Type of cancer Incidence and death rates Bladder cancer In White, Black, ApI and Hispanic males, incidence of bladder cancer decreased. Incidence increased among AI/ AN males. Uterine cancer Incidence rates remained stable in White females but increased in every other racial/ethnic group. Lung, breast and colon cancer Incidence rates decreased for females in all racial/ethnic groups. For AI/ AN females, death rates for breast cancer increased but remained stable for colon cancer. Breast cancer death rates remained stable among API females. Prostate cancer Death rates decreased for API, AI/AN and Hispanic males. Rates remained stable for Black and White males.Lisa C. Richardson MD, director of the CDC’s Division of Cancer Prevention and Control, elaborated on these findings in a press release: “Factors such as race, ethnicity and socioeconomic status should not play a role in people’s ability to be healthy or determine how long they live. [The] CDC works with its public health partners – within and outside the government – to address these disparities and advance health equity through a range of key initiatives, including programs, research and policy initiatives. We know that we can meet this challenge together and create an America where people are free of cancer.”A special focus on pancreatic cancerThe pancreas is an organ located behind the stomach which produces enzymes that help digest food, as well as hormones like insulin and glucagon that regulate our blood sugar levels.Cancer of the pancreas is commonly diagnosed once it is already in its advanced stages – early pancreatic cancers often have vague symptoms or even none at all. For these reasons, the combined five-year survival rate for pancreatic cancer is just 5–10%.In the current report, the researchers explain that diagnoses of pancreatic cancer account for around 3% of new cancer cases – however, it also accounts for 8% of cancer deaths.Nevertheless, the report also highlights significant steps forward for the survival rates of certain types of pancreatic cancer. Between 2001 and 2017, one-year relative survival for patients with neuroendocrine tumors increased from 65.9% to 84.2%, and there was also an increase from 24% to 36.7% for patients with adenocarcinomas.“Pancreatic cancer incidence and survival reflect both the underlying risk of disease as well as the difficulty of diagnosing pancreatic cancer at a treatable stage,” said Betsy A. Kohler, M.P.H, NAACCR executive director. “As advancements in screening technology and effective treatments for early-stage disease become available, we are hopeful for greater improvements in pancreatic cancer survival, which historically has been a particularly lethal cancer type.”",0.0,0.0
272,https://techcrunch.com/2013/06/26/bendlay-3d-is-a-bendable-printing-filament-that-you-can-use-to-make-clear-flexible-straps-and-bands/,"BENDLAY 3D Is A Bendable Printing Filament That You Can Use To Make Clear, Flexible Straps And Bands","BENDLAY 3D Is A Bendable Printing Filament That You Can Use To Make Clear, Flexible Straps And Bands[youtube=http://www.youtube.com/watch?feature=player_embedded&v=VtYbYr19GVg]Kai Parthy is a German engineer who creates odd printing filaments for 3D printers. His previous projects, LayWoo-d3 and Laybrick, are two non-warping plastics that offer wood and brick-like consistencies when extruded. Oddly, LayWoo-d3 actually smells like wood when printed.Now he’s created a bendable printing filament called BENDLAY that is 91% transparent and remains “bendable” after printing.One of the problems with ABS plastic is that it can split and warp as it is formed and it isn’t quite food safe. It is also very brittle and will “whiten” when bent, resulting in a messy final object. This filament is made of stretchy Butadiene, a form of synthetic rubber. It is foodsafe and can be used for clear bottles and containers and works well for flexible straps.While ABS can be used to create flexible items like bracelets, this material will truly bend without breaking, allowing for hinges and other mechanical parts to be built into other, stiffer parts.It costs $42 a roll, which is about right for a pound or so of 3mm filament, and comes on 750 gram rolls. It should work with almost any extruder-based device but, sadly, doesn’t smell like fresh rubber.via 3DPrintingIndustry",0.0,0.0
305,https://www.cnbc.com/2022/10/27/meta-is-no-longer-one-of-the-20-biggest-us-companies.html,Facebook used to be a Big Tech giant â now Meta isn't even in the top 20 most valuable U.S. companies,"Sixteen months after Facebook crossed $1 trillion in market cap, joining an exclusive club consisting of Apple , Microsoft , Alphabet and Amazon , its parent company Meta is worth less than Home Depot and barely more than Pfizer and Coca-Cola .Far from Facebook's Big Tech days, Meta is no longer among the 20 most valuable U.S. companies after the stock sank 23% on Thursday. The company has shed 70% of its value this year and 74% since the stock peaked in September 2021, totaling over $730 billion in market cap lost. It's trading at its lowest since early 2016, when Barack Obama was still president.The stunning collapse of Meta's share price is reminiscent of the dot-com bust days, but far bigger in terms of value erased from a single company. The slide began late last year as signs of a sputtering economy started to emerge, and accelerated in early 2022 after the company said Apple's privacy change to iOS would result in a $10 billion revenue hit this year.Founder and CEO Mark Zuckerberg has been unable to stop the bleeding and only seems to be making matters worse. Since changing the company name to Meta a year ago Friday, Zuckerberg has said its future is the metaverse, a virtual universe of work, play and education. But investors just see it as a multibillion-dollar money pit, while the core advertising business shrinks — Facebook is forecasting a third consecutive drop in revenue for the fourth quarter.",0.0,0.0
306,https://www.cnet.com/tech/services-and-software/study-shows-30-of-people-are-redoing-google-searches/,"Almost 30% of People Redo or Refine Google Searches, Study Says","Almost 30% of people are having to redo their Google searches, either by refining or extending queries, according to research published earlier this month by SEMRush, an online marketing software company.SEMRush took data from 20,000 anonymous users who made 455,368 unique searches. It then looked at how long it took them to make a subsequent action. For over 70% of users, it took less than 15 seconds to make a secondary click, meaning they most likely found the website or answer they were looking for. Almost 30% of users, however, were refining, redoing or extending their searches in some way, suggesting that for some, answers weren't effectively percolating to the top.This 30% number comes from 9.7% of users who engaged in a ""Google Click,"" meaning they clicked on images or something in a carousel after making a query. For these people, they may have actually found what they were looking for. Another 17.9% of users made modifications to ""Google Keyword,"" or ways to modify their original query. This totals to 27.6%, which was then rounded up by SEMRush.Satisfaction wasn't something measured in this study, just click behaviors after making a Google Search. It's possible a person could have been happy with an initial result and might have wanted to rephrase to investigate further.Keyword changes happened more often on mobile, at 29.3% versus 17.9% on desktop, SEMRush found. It suggests people in need of quick information might be looking for answers on Google rather than clicking through to a website. Since the study didn't survey users about their experience, it's impossible to say exactly why someone on mobile is more often redoing or refining their searches. Typos on a small screen could be a culprit.On desktop, the study also found that 25.6% of results were ""zero clicks."" This means a person didn't click on a link after making a query. It could mean they refined their search, or that they found the answer they were looking for without clicking on a link to a website. The latter could spell trouble for the billions of sites that rely on traffic to bring in ad sales -- while less clicks is better for people looking for quick answers, it's detrimental to the many news and information sites creating that content.""Google Search sends billions of clicks to websites every day, and we've sent more traffic to the open web every year since Google was first created,"" said Danny Sullivan, Google's public liaison for Search. ""It's not unusual that people conduct a search without knowing exactly what they are looking for, then refine that search after seeing results and our refinement options (like related searches) to ultimately find what they need.""Complaints over Search's faltering reliability continue to come up in online discussions and articles. From Reddit threads to pieces in The Atlantic, people say they're fighting a battle against websites trying to game Google's search engine optimization and the company's own system of filtering results. Search also remains Google's most valuable product, with it controlling over 92% of online search market share, helping the company drive ad revenue.Some users say they're now using short-form video platform TikTok to find the answers they're looking for instead of Google. It might be why Google is integrating more TikTok-like features in Search and why it spent $100 million to buy an AI avatar startup.Alphabet, Google's parent company, reported $69 billion in revenue this past quarter, with $39.5 billion coming from ""Google Search and Other."" Even then, Google's earnings came short of analyst estimates.",0.0,0.0
310,https://arstechnica.com/tech-policy/2022/10/metas-value-plunges-more-than-65-billion-amid-falling-sales-rising-costs/,"Metaâs value plunges more than $65 billion amid falling sales, rising costs","Investors wiped more than $65 billion from Meta’s market capitalization on Wednesday after the Facebook owner reported another quarter of declining revenues and failed to convince investors that big bets on the metaverse and artificial intelligence were paying off.Shares in Meta dropped 19 percent in after-hours trading as the world’s largest social media platform joined other Big Tech groups in warning that an economic slowdown was hammering its advertising businesses as brands spend less on marketing.On top of the wider macroeconomic woes, Meta faces a confluence of challenges, including rising competition for its Instagram platform from rivals such as short-form video app TikTok and difficulties in targeting and measuring advertising because of Apple’s privacy policy changes.The company said it expected revenue in the current quarter to be in the range of $30 billion to $32.5 billion, compared with analysts’ expectations of $32.2 billion.Net income in the third quarter fell 52 percent to $4.4 billion, below consensus estimates for $5 billion, according to S&P Capital IQ. Meanwhile, revenues fell 4 percent to $27.71 billion, the slowest pace of growth since going public in 2012, after a 1 percent decline last quarter. That was slightly better than analysts’ estimates for a 5 percent drop.Mark Zuckerberg, Meta founder and chief executive, warned the company faced “near-term challenges on revenue” but said “the fundamentals are there for a return to stronger revenue growth.”On a call with analysts, he doubled down on his biggest bets including developing a short-form video format to rival TikTok, business messaging, and the metaverse. He tried to reassure investors that investments in these areas would pay off in the long term.“I appreciate the patience and I think that those who are patient and invest with us will end up being rewarded,” he said, arguing that the company was doing “leading work” on the metaverse that would be “of historical importance.”AdvertisementMeta’s disappointing earnings came amid a broader sell-off of Big Tech stocks. Shares of Google parent Alphabet fell more than 9 percent on Wednesday after it reported an unexpectedly severe slowdown in its core search ads business, while Snap’s stock plunged last week after it posted its slowest pace of growth since going public in 2017.Meta, which expanded headcount rapidly during the pandemic, has faced investor scrutiny for spending heavily on Zuckerberg’s vision of building a digital avatar-filled world known as the metaverse. Like other virtual and augmented reality projects Meta is working on, this is not expected to generate returns for many years.Revenues from Reality Labs, its metaverse unit, nearly halved in the third quarter to $285 million, while losses were $3.7 billion compared with $2.6 billion a year ago. The company said it expected operating losses in the unit to “grow significantly year-over-year” in 2023.“Meta is on shaky legs when it comes to the current state of its business,” said Debra Aho Williamson, an analyst at Insider Intelligence. “Zuckerberg’s decision to focus his company on the future promise of the metaverse took his attention away from the unfortunate realities of today.”The company estimated 2022 total expenses would be in the range of $85 billion to $87 billion, narrowing from its prior outlook of $85 billion to $88 billion. However, it anticipated 2023 expenses in the range of $96 billion to $101 billion despite recently seeking to cut costs and freeze most hiring.The company said it was “making significant changes across the board to operate more efficiently” and had “increased scrutiny on all areas of operating expenses.”But it warned “these moves… will take time to play out” and that some attempts to find savings, like shrinking its office space as more employees work from home, would result in “incremental costs in the near term.”Zuckerberg told analysts that investment in its artificial intelligence capabilities contributed to a surge in capital expenditure but that the technology would help boost views of its short-form video format.Analysts also raised concerns about mounting expenses. “Summing up how investors are feeling right now is that there are just too many experimental bets versus proven bets on the core,” said Brent Thill, an analyst at Jefferies.© 2022 The Financial Times Ltd. All rights reserved. Not to be redistributed, copied, or modified in any way.",0.0,0.0
311,https://www.express.co.uk/life-style/science-technology/1687324/WhatsApp-down-chat-app-offline-cant-send-messages,WhatsApp down: Chat app hit by second huge outage in the space of a few days,"We use your sign-up to provide content in ways you've consented to and to improve our understanding of you. This may include adverts from us and 3rd parties based on our understanding. You can unsubscribe at any time. More infoUPDATE FOUR - Friday 10pm: The issues which affected WhatsApp and other Meta apps earlier today have now been resolved.Speaking to Express.co.uk, a spokesperson said: ""Earlier today, a configuration change caused some people to have trouble accessing our products. We fixed the issue as quickly as possible for everyone who was impacted, and we apologise for any inconvenience.""According to independent outage monitor Down Detector, Meta's apps were experiencing issues for around an hour before problems were fixed.UPDATE THREE - Friday: WhatsApp has been hit with its second major outage in the space of a few days, with the hugely popular chat app going down on a Friday evening in the UK.Independent outage monitor Down Detector recorded a huge spike in WhatsApp down reports tonight, which began surging in around 8.30pm UK time.At the time of writing Down Detector has registered a peak of almost 10,000 reports of WhatsApp down.The second WhatsApp outage of this week coincided with reported problems with Meta's other apps - Messenger, Instagram and Facebook.WhatsApp is the world's most popular chat app and is used by over two billion people worldwide each month.UPDATE TWO - Tuesday 10am: WhatsApp is finally coming back online after almost two hours of issues. Most users should now start seeing their chats being sent and received via the popular platform. It's unclear what has caused the problems but things seem to be working again.ORGINAL STORY: If you're trying and failing to send a WhatsApp message this morning you are not alone. The hugely popular service, which boasts over 2 billion users worldwide, has been hit by some serious gremlins which have left thousands of fans unable to use the platform or speak to friends and family. When trying to chat, many are simply seeing the clock icon on their messages which means they haven't been sent.",0.0,0.0
170,https://techcrunch.com/2016/10/07/poland-builds-a-solar-powered-bike-path-that-glows-a-ghostly-blue/,Poland builds a solar-powered bike path that glows a ghostly blue,"Poland can do some cool stuff. To wit: this cool bike path in a town called Pruszków. The path is made of a light-emitting material that charges in the sun and can glow for up to 10 hours in the dark, bathing cyclists in a calming blue glow.The company that made it, TPA sp. z o.o is an engineering firm focused on future tech. They expect this sort of road to be useful in larger projects – highways, say – but for now they’re limiting it to bike paths until they can test the material in the wild. They said that this type of path may be installed in Warsaw soon and that it can glow in multiple colors.The lane uses luminophores – chemicals that “ingest” light – to keep the bike path nicely lit at night. They chose blue to “match the Mazurian landscape” where lakes abound. You can read a bit more at Gazeta Wyborcza if your Polish isn’t too rusty or you can just bask in the cold beauty of a glowing bike lane in deepest Poland.",0.0,0.0
46,https://techcrunch.com/2021/08/16/brainq-raises-40m-to-transform-stroke-patient-rehabilitation-with-its-home-therapy-device/,BrainQ raises $40M to transform stroke patient rehabilitation with its home therapy device,"If you injure your elbow, surgery can help. If you lose a leg, prostheses are available. But problems within the brain are more difficult to treat, and for stroke victims, rehabilitation is largely left to the body’s own repair mechanisms. BrainQ aims to change that with a device that stimulates the damaged part of the brain and promotes self-repair, showing enough improvement in studies to warrant a Breakthrough Device certification from the FDA — and the company has just raised $40 million to take it to market.It should be said at the outset that doubting the efficacy of some brainwave-emitting miracle device is natural. And in fact when I spoke with BrainQ’s founder Yotam Drechsler, he reminded me of the last time we’d talked — back in 2017, at which time I “expressed strong skepticism.”No hard feelings — the tech was largely notional then, he admitted — but since that time the team has continued its work, raised some money, and what was a promising if not well-supported thesis then has turned into one backed by firsthand data and clinical outcomes. The resulting system could be the biggest improvement to stroke therapy in decades or more.Strokes can result in various obvious impairments, such as grip strength or coordination, but of course the injury is not to the hand or leg itself, it is to the networks in the brain that govern those parts. But medical science has no method for directly rebuilding those networks — the brain must do so on its own, in its own time.To aid this, regular physical therapy and brain health checkups, sometimes for years on end, are used to, in essence, make sure the brain is still working on it and that the parts of the body don’t themselves fall into disrepair.The most interesting improvements to this process in recent years have added tech into the loop to provide immediate feedback, such as that one’s balance is skewed to one side, and providing stimuli that aim to counteract that. But ultimately it’s still targeted physical therapy.Drechsler and BrainQ see the problem a little differently. It’s not simply an injury but a disturbance to the brain’s carefully cultivated homeostasis, one which it has no means to counteract. He compared a stroke not to an analogous injury but to a baby born prematurely and whose body is not up to the task of heating itself. What do you do in such a case? You don’t attempt to “fix” the body so it can operate at lower temperatures, or supercharge the heat output — you just put the kid in an incubator, and everything proceeds as it should.BrainQ’s device does something similar, making the brain operate better by changing its local environment.“We map the channels of healthy brains and non-healthy brains and compare them. Once we find these, we use a low-intensity magnetic field therapy to resonate in the brain and facilitate its endogenous recovery mechanisms,” explained Drechsler.It’s been shown in other contexts that this type of stimulation can produce improved neuroplasticity — the capability of the central nervous system to reprogram itself. By narrowly targeting stroke-affected areas, BrainQ’s device promotes neuroplasticity in them, leading to expedited recovery.But it’s not simply a matter of saying “the stroke affected the ventral half of the right occipital lobe, aim the magnets there.” The brain is a complicated system, and strokes affect networks, not just a given cubic centimeter. BrainQ has deployed machine learning and a large collection of data to better understand how to target those networks.Without diving too deeply into how the brain operates, let it suffice to say that certain networks operate locally at very specific spectral signatures or frequencies as detected by EEG readings. The left hand and left foot may occupy the same region of the motor cortex, but the hand might operate at 22 Hz, while the foot operates at 24 Hz, for example.“The question is, how do you find these signatures?” asked Drechsler. As it’s somewhat difficult to explain, I asked him to put it in his own words after we spoke:The novelty of BrainQ’s investigational treatment lies in the data-driven method we have deployed in order to inform the ELF-EMF frequency parameters. In choosing these parameters, our aim is to select frequencies that characterize motor-related neural networks in the CNS, and are related to the disability a person experiences following a stroke or other neurological trauma. To achieve this, we have analyzed a large-scale amount of healthy and non-healthy individuals’ brainwaves (electrophysiology data). Our technology uses explanatory machine learning algorithms to observe the natural spectral characteristics and derive unique therapeutic insights. These are used by BrainQ’s technology to target the recovery of impaired networks.The device they’ve created to administer the treatment is unusual. Because it’s a whole-brain magnetic field generator, it has a rather bulky cylindrical headpiece, but the rest of it fits into a sort of back brace and hip pack. That’s because, unlike the more common magnetic brain imaging tech, MRI, the fields and currents involved are extremely small.“We use very, very low intensity, about the same level as normal brain activity,” said Drechsler. “It’s not about creating an action potential or a jump in activity, it’s about creating the right conditions for the recovery mechanisms.”The results of this stimulation were borne out in a small (25 patients) but decisive study due to be reviewed and published soon (preprint abstract here). Patients given the BrainQ treatment in addition to normal therapy saw hugely improved recovery evaluations, which look at metrics like improvements to balance and strength; 92% saw major improvements over just therapy and 80% achieved what could be called recovery (though this term is inexact).Generally speaking the therapy would last for about an hour at a time, during which the patient would do various physical exercises while wearing the device, and they would need to be repeated five days a week for two months or so. The headset feeds the patient’s own patterns into BrainQ’s cloud-based service, which does the crunching and matching necessary to produce a tailored treatment pattern. It’s all run via tablet app, which can be operated by a caregiver (such as an outpatient nurse) or by using a built-in telemedicine platform.Drechsler said that this approach was poorly received early on, and not just by this reporter.“In 2017, we started to set the ground for a cloud-connected therapeutic device that can treat the patient wherever she or he is,” he said. “Back then no one was willing to even talk about treating patients outside the controlled environment of the hospital. Then in 2020 COVID came and everything changed.”He noted that during the pandemic, many of those recovering from a stroke who would normally visit the hospital for regular care were (and some remain) unable to do so. A home-based therapy with low risk and potentially great outcomes would be of enormous benefit for thousands and thousands of people currently recovering from a stroke. And importantly, he notes, it doesn’t shift resources away from existing treatment plans, just improves their outcomes. (“We don’t move anybody’s cheese.”)Here is where you would normally read something along the lines of “but it may be five years before the FDA approves it for insurance and use.” But BrainQ recently received Breakthrough Device certification, an expedited approval process that, since just the beginning of this year, also confers qualification for coverage under Medicare. This means that conceivably, BrainQ could be shipping devices very soon — though still a year or two out.Its next step, very prudently, is a larger-scale study, toward which the company intends to devote a large portion of its recent fundraise, $40 million led by Hanaco Ventures, with Dexcel Pharma and Peregrine Ventures participating.“The reason why we raised all this money is we are on the verge of a unique study with 12 sites,” Drechsler said. While he could not yet name the hospitals or research organizations they partnered with, he said they were basically the cream of the stroke rehabilitation crop and “really we couldn’t aspire for better than getting all these top sites in the same study. There’s this excitement that maybe something new is coming — in stroke recovery there has been almost no progress in the last two or three decades, and physical therapy has been the standard for two hundred years.”Without making any promises, he suggested that this line of inquiry could move medicine toward not just mitigating but reversing some disabilities, a feat the value of which can hardly be enumerated.“I was looking over my pitch decks from 2016,” Drechsler mused. “Early on as a CEO, you have big dreams. We heard a lot of skepticism early on in the process, but I was proud to see that many of those dreams have materialized.”",0.0,0.0
319,https://techcrunch.com/2022/10/31/elon-musk-vine-reboot-poll/,"Chief Twit, Elon Musk, signals interest in reviving Vine","New Twitter owner Elon Musk has signalled a potential interest in reviving Vine, the social video app Twitter gave up on six years ago.In the last few hours the self styled “Chief Twit”) has tweeted a yes/no poll to his 112.4 million followers — pithily positing: “Bring back Vine?”.The question — whether serious product idea or another Elon flight of fancy/’trollercoaster’ tweet — quickly drew millions of votes (most in favor) and thousands of responding tweets. This engagement in turn garnered a bit of additional attention from Musk who responded to some of his followers’ questions/suggestions on the social video topic.In response to a tweet from YouTuber, Mr Beast — which jokily referenced TikTok — Musk struck a serious tone, asking: “What could we do to make it better than TikTok?”He also took the time to publicly agree with another Twitter user — who had chimed in to opine that “video shouldn’t be a separate app” but should rather be “within Twitter”. That observation earned the ‘Tesla Owners Silicon Valley’ account an ‘100’ emoji reply from Musk, to signal (apparent) total approval of the idea that any Vine/video revival should be a feature inside Twitter, not a standalone product.So make of that what you will.The Vine revival poll (plus Musk’s wider engagement to the chatter it generated) could imply his attention to the topic of video is, at least, genuine — although it’s anyone’s guess whether a Vine reboot is actually being seriously considered, or what that would even mean beyond reviving a brand name if his plan would include a major feature set makeover. (Twitter’s press team did not respond to requests for comment.)It’s equally plausible Musk is doing the equivalent of throwing spaghetti at a wall and seeing which/if bits stick. Or he’s just bored in the small hours and thought he’d bounce another shower thought off-of his fanbase. And/or fancied indulging in a spot of ‘lazy web’ brainstorming outsourcing.As ever where Elon is concerned, the usual caveats apply.Still, Vine’s demise was a pretty self-defeating chapter in Twitter’s company history — so a reboot could offer Musk the chance to rewrite that particular bit of the script and claim incoming hero status with former Vine fans.Bring back Vine? — Elon Musk (@elonmusk) October 31, 2022At the time of writing, more than 2.8M votes had been cast in Musk’s poll about bringing back Vine, with a strong majority (69.4%) voting for a return — although the poll still has 14 hours left to run.Twitter acquired the short form video platform Twitter back in 2013. But, in typical clown car fashion, the company ended up squandering the opportunity to build the fledgling social video platform into a TikTok-style juggernaut, after then-CEO Jack Dorsey opted to ditch the app a few short years later.The shuttering of Vine earned Twitter the baldest of subtweets from Vine’s founder, Rus Yusupov — who had this straight-up warning to other entrepreneurs at the time: “Don’t sell your company!”Ironically enough (given it’s *Twitter* that’s now been sold), Yusupov has chipped into the Musk-initiated chatter around reviving Vine — offering up the (non-serious?) suggestion that Vine should have “69 second videos”.69 second videos — Rus (@rus) October 31, 2022While Vine launched with hyper short videos (of up to 6 seconds), the max upload length was later expanded to 140 seconds — and social video behemoth TikTok has gone way beyond that and even began letting its users upload videos of up to 10mins long earlier this year — so 69 second videos is probably just an attempt to grab Musk’s attention (with a puerile joke), not a serious product suggestion.Regardless, the interaction does indicate that Yusupov is watching what’s unfolding at Twitter with interest.And that’s relevant because this is also not his first foray into tweeting at Musk about Vine: His public timeline remains topped with an earlier tweet — from April 25 — when he posted a photo of himself with the (then) would-be Twitter owner, asking Musk a (rhetorical?) question: “Hey @elonmusk was this meeting about saving Vine? I forget… ”Public response from Musk to that tweet there came none. But the Chief Twit is king of keeping everyone else guessing over what he’s actually going to do next — so, again, you can’t read much/anything into his public silence back then. (Musk did also try to wiggle out of buying Twitter entirely prior to agreeing to closing the deal last week; ergo, there have been a fair few cycles of ups and downs even just over these past few months.)Hey ⁦@elonmusk⁩ was this meeting about saving Vine? I forget…. pic.twitter.com/FgmxIfS8Vx — Rus (@rus) April 25, 2022If Yusupov and Musk have been talking about a Vine reboot, the former’s response to another Twitter user’s question last month — when author Eli Pariser asked the Twitterverse for “the smart take on why Vine died even though it was basically TikTok” — might offer a few clues about what any discussions might have focused on.The Vine founder responded to Pariser by lamenting over not having built the right features “in time” — likely linked to another blindspot he conceded around not understanding the importance of building on trends like lip-sync video — as well as blaming the app’s demise on a failure to help creators monetize.",0.0,0.0
320,https://www.vice.com/en/article/pkgma8/police-are-using-dna-to-generate-3d-images-of-suspects-theyve-never-seen?utm_source=reddit.com,Police Are Using DNA to Generate 3D Images of Suspects They've Never Seen,"On Tuesday, the Edmonton Police Service (EPS) shared a computer generated image of a suspect they created with DNA phenotyping, which it used for the first time in hopes of identifying a suspect from a 2019 sexual assault case. Using DNA evidence from the case, a company called Parabon NanoLabs created the image of a young Black man. The composite image did not factor in the suspect’s age, BMI, or environmental factors, such as facial hair, tattoos, and scars. The EPS then released this image to the public, both on its website and on social media platforms including its Twitter, claiming it to be “a last resort after all investigative avenues have been exhausted.”AdvertisementThe EPS’s decision to produce and share this image is extremely harmful, according to privacy experts, raising questions about the racial biases in DNA phenotyping for forensic investigations and the privacy violations of DNA databases that investigators are able to search through.In response to the EPS’s tweet of the image, many privacy and criminal justice experts replied with indignation at the irresponsibility of the police department. Callie Schroeder, the Global Privacy Counsel at the Electronic Privacy Information Center, retweeted the tweet, questioning the usefulness of the image: “Even if it is a new piece of information, what are you going to do with this? Question every approximately 5'4"" black man you see? ...that is not a suggestion, absolutely do not do that.”“Broad dissemination of what is essentially a computer-generated guess can lead to mass surveillance of any Black man approximately 5'4"", both by their community and by law enforcement,” Schroeder told Motherboard. “This pool of suspects is far too broad to justify increases in surveillance or suspicion that could apply to thousands of innocent people.”The victim of the case only had a limited description of the suspect, “describing him as 5’4”, with a black toque, pants and sweater or hoodie” and “as having an accent,” making for a vague, indistinguishable profile.“Releasing one of these Parabon images to the public like the Edmonton Police did recently, is dangerous and irresponsible, especially when that image implicates a Black person and an immigrant,” Jennifer Lynch, the Surveillance Litigation Director of the Electronic Frontier Foundation told Motherboard. “People of color are already disproportionately targeted for criminal investigations, and this will not only exacerbate that problem, it could result in public vigilantism and real harm to misidentified individuals.”AdvertisementThe criminal justice and policing system is laden with racial biases. A Black person is five times more likely to be stopped by police without cause than a white person, and Black, Latinx, and people of color are more likely to be stopped, searched, and suspected of a crime even when no crime has occurred.Seeing the composite image with no context or knowledge of DNA phenotyping, can mislead people into believing that the suspect looks exactly like the DNA profile. “Many members of the public that see this generated image will be unaware that it's a digital approximation, that age, weight, hairstyle, and face shape may be very different, and that accuracy of skin/hair/eye color is approximate,” Schroeder said.In response to the criticism after the release of the image and the use of DNA phenotyping, the Edmonton Police Department shared a press release Thursday morning, in which it announced it removed the composite image from its website and social media.“While the tension I felt over this was very real, I prioritized the investigation – which in this case involved the pursuit of justice for the victim, herself a member of a racialized community, over the potential harm to the Black community. This was not an acceptable trade-off and I apologize for this,” wrote Enyinnah Okere, the chief operating officer of EPS.AdvertisementParabon NanoLabs sent Motherboard a number of case studies where DNA phenotyping alone helped solve murder and assault cases. However, the case studies do not address the larger concerns, which are a lot harder to measure—such as how many innocent people were questioned before the final suspect was arrested, and how the suspect image may have affected the public’s racial biases.According to Parabon, it has worked on hundreds of law enforcement investigations. On its site are a number of case studies, with many showing the comparison between the DNA profile and actual photo of the suspect. There are some similarities between the two photos, in that they both reflect the same race, gender, eye and hair color. Often, however, the resemblance between the generated image and the suspect ends there.“We're making predictions just from the DNA, so we have only so much information. And so when we make those predictions, it's a description and these are standing in. If the police had a witness, then they wouldn't need us,” Dr. Ellen Greytak, the director of bioinformatics and technical lead for the Snapshot division at Parabon NanoLabs, told Motherboard. “We’re providing facts, like a genetic witness, providing this information that the detectives can't get otherwise.”Advertisement“It's just the same as if the police had gotten a description from someone who, maybe you know, didn't see them up close enough to see if they had tattoos or scars, but described the person. What we find is that this can be extremely useful especially for narrowing down who it could be and eliminating people who really don't match that prediction,” Greytak said. “In these cases, by definition, they always have DNA and so we don't have to worry about the wrong person being picked up because they would always just match the DNA.”According to Greytak, the technology creates the composite image by running the suspect’s DNA through machine learning models that are built on thousands of people’s DNAs and their corresponding appearances.“The data that we have on the people with known appearances are from a variety of sources, some of them are publicly available, you can request access for them. Some of them are from studies that we've run, where we've collected that information,” Greytak said.The DNA dataset being used to create these composites raises more red flags regarding the privacy questions of DNA profiling. The “variety of sources,” include GEDmatch and FamilyTree DNA, which are open-source, free genealogy websites that give you access to millions of DNA profiles.Advertisement“People should know that if they send their DNA to a consumer-facing company, their genetic information may fall into the hands of law enforcement to be used in criminal investigations against them or their genetic relatives. None of this data is covered by federal health privacy rules in the United States,” Lynch said. ""While 23 and Me and Ancestry generally require warrants and limit the disclosure of their users’ data to law enforcement, other consumer genetic genealogy companies like GEDmatch and FamilyTree DNA provide near-wholesale law enforcement access to their databases.”Parabon NanoLabs claims that the images they generate aren’t based on race, but on their genetic ancestry. “When we talk about a person's genetic ancestry, or biogeographic ancestry, [which] is the term that we use for that, that is a continuous measure versus race, which is categorical,” Greytak said.However, researchers argue that taking familial origin into consideration while DNA profiling, as Parabon NanoLabs does, is not an objective measurement because it results in general populations being seen as more criminal than others.“Whereas the conventional use of DNA profiling was primarily aimed at the individual suspect, more recently a shift of interest in forensic genetics has taken place, in which the population and the family to whom an unknown suspect allegedly belongs, has moved center stage,” researchers led by anthropologist Amade M’charek wrote in a study titled “The Trouble With Race in Forensic Identification.” “Making inferences about the phenotype or the family relations of this unknown suspect produces suspect populations and families.”AdvertisementAfter a 2019 Buzzfeed investigation revealed that GEDmatch allowed police to upload a DNA profile to investigate an aggravated assault, the site changed its policies so that users had to opt in to law enforcement searches. Still, investigators are able to use a number of similar databases to upload suspect’s DNA and map out the suspect’s family tree until they can pinpoint the suspect’s true identity.A notorious case in which this tactic proved successful was in finding the Golden State Killer, a serial killer named Joseph James DeAngelo. After uploading his DNA to GEDmatch, investigators were able to find one of his family members who was already in the system, and trace DeAngelo down decades after he committed the crime.Many police departments have been collecting DNA from innocent people and people who commit minor crimes, such as Orange County, which has a database of more than 182,000 DNA profiles, almost all from people who faced misdemeanor charges, which include petty theft or driving with a suspended license. Several attorneys filed a lawsuit against the county, who claim that the database is against California law. The lawsuit says that handing over DNA is a “coercive bargain,” because those who hand over a DNA sample will receive lighter punishments or even a dismissed case.A similar lawsuit was filed in New York City by the Legal Aid Society, which accuses the city of operating a DNA database that violates state law and constitutional protections against unreasonable searches. These DNA databases again perpetuate the pervasive racial biases of the criminal justice system. Because people of color, especially Black and Latino people, make up 75 percent of people arrested in the past decade in NYC, the DNA database further inscribes criminality onto marginalized demographics.While race isn’t necessarily measured by DNA phenotyping, race is produced semiotically by the visual nature of DNA composite profiles and in the already biased DNA datasets, which these profiles are derived from. The usage of DNA phenotyping may have broken open a few cold cases, but we have to ask: at what cost.",0.0,0.0
50,https://techcrunch.com/2020/01/07/union-square-ventures-leads-legal-tech-startup-juros-5m-series-a/,Union Square Ventures leads legal tech startup Juroâs $5M Series A,"Juro, a UK startup that’s using machine learning tech and user-centric design to do for contracts what Typeform does for online forms, has caught the eye of Union Square Ventures. The New York-based fund leads a $5 million Series A investment that’s being announced this morning.Also participating in the Series A are existing investors Point Nine Capital, Taavet Hinrikus (co-founder of TransferWise) and Paul Forster (co-founder of Indeed). The round takes Juro’s total raised to-date to $8M, including a $2M seed which we covered back in 2018.London is turning into a bit of a hub for legal tech, per Juro CEO and co-founder Richard Mabey — who cites “strong legal services industry” and “strong engineering talent” as explainers for that.It was also, he reckons, “a bit of a draw” for Union Square Ventures — making what Juro couches as a “rare” US-to-Europe investment in legal tech in the city via the startup.“Having brand name customers in the US certainly helped. But ultimately, they look for product-led companies with strong cross-functional teams wherever they find them,” he adds.Juro’s business is focused on taking the tedium out of negotiating and drawing up contracts by making contract-building more interactive and trackable. It also handles e-signing, and follows on with contract management services, using machine learning tech to power features such as automatic contract tagging and for flagging up unusual language.All of that sums to being a “contract collaboration platform”, as Juro’s marketing puts it. Think of it like Google Docs but with baked in legal smarts. There’s also support for visual garnish like animated GIFs to spice up offer letters and engage new hires.“We have a data model underlying our editor that transforms every contract into actionable data,” says Mabey. “Juro contracts look like contracts, smell like contracts but ultimately they are written in code. And that code structures the data within them. This makes a contract manager’s life 10x easier than using an unstructured format like Word/pdf.”“Still our main competitor is MS Word,” he adds. “Our challenge is to bring lawyers (and other users of contracts) out of Word, which is a significant task. Fortunately, Word was never designed for legal workflows, so we can add lots of value through our custom-built editor.”Part of Juro’s Series A funds will be put towards beefing up its machine learning/data science capabilities, per Mabey — who says the overall plan at this point is to “double down on product”, including by tripling the size of the product team.“That means hiring more designers, data scientists and engineers — building our engineering team in the Baltics,” he tells us. “There’s so much more we are excited to do, especially on the ML/data side and the funding unlocks our ability to do this. We will also be building our commercial team (marketing, sales, cs) in London to serve the EU market and expand further into the US, where we already have some customers on the ground.”The 2016-founded startup still isn’t breaking out customer numbers but says it’s processed more than 50,000 contracts for its clients so far, noting too that those contracts have been agreed in 50+ countries. (“Everywhere from Estonia to Japan to Kazakhstan,” as Mabey puts it.)In terms of who Juro users are, it’s still mostly “mid-market tech companies” — with Mabey citing the likes of marketplaces (Deliveroo), SaaS (Envoy) and fintechs (Luno), saying it’s especially companies processing “high volumes of contracts”.Another vertical it’s recently expanded into is media, he notes.“E-signature giants have grown massively in the last few years, and some are gradually encroaching into the contract lifecycle — but again, they deal with files (pdfs mostly) rather than dynamic, browser-based documentation,” he argues, adding: “In terms of new legal tech entrants — I’m excited by Kira Systems especially, who are working on unpicking pdf contracts post-signature.”As part of the Series A, Union Square Ventures parter, John Buttrick, is joining Juro’s board.Commenting in a supporting statement, Buttrick said: “We look for founders with products equipped to change an industry. While contract management might not be new, Juro’s transformative vision for it certainly is. There’s no greater proof of the product’s ease of use than the fact that we negotiated and closed the funding round in it. We’re delighted to support Juro’s team in making their vision a reality.”",0.0,0.0
28,https://www.geekwire.com/2022/eviation-all-electric-alice-airplane-first-flight-test/,âIt was wonderfulâ: Eviationâs Alice electric airplane wins praise after its first flight test,"Eviation’s all-electric Alice airplane streaks over the runway at Moses Lake, Wash. (Eviation Photo)MOSES LAKE, Wash. — After years of on-the-ground development, Eviation’s all-electric Alice airplane quietly took to the air here this morning for its first test flight.Test pilot Steve Crane guided the nine-passenger aircraft, powered by two 640-kilowatt electric motors, through its takeoff from Grant County International Airport in Moses Lake, a facility in Eastern Washington’s high desert that’s often used for testing innovations in aviation.When the motors revved up, they sounded like electric grass trimmers. And when the plane flew overhead, the noise was more like a hum than a roar.Alice flew for eight minutes and reached a maximum altitude of 3,500 feet before landing safely back at the airport.So how was the ride? “It was wonderful,” Crane said. “It handled just like we thought it would. Very responsive, very quick to the throttle, and it came on in for a wonderful landing. I couldn’t be happier.”Crane explained that the relatively short flight was intended to be the first in a series of “baby steps” for the test program. “Today was just about the initial envelope,” he told reporters. “For future tests, we’ll expand that envelope.”After the first flight of the all-electric Alice airplane, test pilot Steve Crane shakes hands with Eviation CEO Gregory Davis while Clermont Group Chairman Richard Chandler looks on. (Eviation Photo)Arlington, Wash.-based Eviation is on a growing list of ventures that are aiming to make aviation more efficient and less expensive by taking advantage of advances in electric propulsion and battery technology.“What we have just done is made aviation history,” Gregory Davis, Eviation’s president and CEO, said after the flight. “This is about changing the way that we fly. It’s about connecting communities in a sustainable way, and we are obviously beaming with pride on this beautiful sunny day here at Moses Lake.”The Alice aircraft — whose name was inspired by the book “Alice in Wonderland” and the Jefferson Airplane song “White Rabbit” — will come in different variants for commuter, cargo and executive flights. Davis said the initial goal is to build a plane with a maximum range of 200 to 300 nautical miles. According to Eviation’s stats, Alice’s maximum useful load would be 2,500 to 2,600 pounds, and its maximum operating speed would be 260 knots (300 mph).Davis acknowledged that the design specifications and capabilities of the production version of the plane may be something of a moving target, due to Eviation’s dependence on improvements in battery technology. “It’s going to be carbon fiber, it’s going to be fly-by-wire, it’s going to be electric — so in that respect, it’s the same plane,” Davis said. “As far as the actual design of the aircraft, I think everything’s going to be evolved.”Eviation’s Alice airplane passes overhead during its first test flight. (GeekWire Photo / Alan Boyle)Eviation’s majority owner is the Clermont Group, a privately held conglomerate based in Singapore.The plane’s electric propulsion system is provided by MagniX, a Clermont corporate cousin that has its headquarters in Everett, Wash. Eviation’s partner in the flight test program is AeroTEC, which operates the Moses Lake Flight Test Center. For what it’s worth, MagniX and AeroTEC have been working together since 2020 to conduct flight tests for a Cessna Grand Caravan airplane that was converted to use MagniX’s electric motors.Alice’s inaugural flight test came more than three years after the first prototype was unveiled at the Paris Air Show. Since then, Eviation has moved its base of operations from Israel to Arlington, and has gone through a complicated executive transition that brought Davis in as CEO.The company has been putting its flight-ready prototype through more than a year of assembly and ground testing — with some setbacks along the way.If all goes according to plan, the airplane will win certification from the Federal Aviation Administration and hit the market by 2027 — which is later than the 2024 time frame that Eviation was listing a year ago.“What we’ve learned is a lot, and one of the key things that’s driving the development of our program is the advancement of battery technology, right?” Davis told GeekWire. “So we’re being, I will say, entirely honest with ourselves about what we’re going to be able to achieve. … It’s all going to be based on getting the batteries to converge to the development cycle for the aircraft.”Three years ago, Eviation said the list price for an Alice airplane would be $4 million — but today Davis declined to provide an updated price tag. “I wouldn’t rely on anything that was mentioned a few years ago,” he said.In any case, the list price for an airplane doesn’t always reflect what customers pay. Actual pricing is typically decided privately on a deal-by-deal basis, and several deals have already been announced. DHL Express ordered 12 Alice eCargo planes last year, and Massachusetts-based Cape Air ordered 75 all-electric passenger planes in April. This month, the GlobalX charter airline said it intended to order 50 passenger planes, with deliveries due to begin in 2027.More photos from the Moses Lake flight test:Photographers wait for Alice’s first flight – and watch the sunrise. (GeekWire Photo / Alan Boyle)Eviation’s Alice airplane passes by on the runway. (GeekWire Photo / Alan Boyle)Alice lifts off. (GeekWire Photo / Alan Boyle)Alice taxis toward the airport terminal after its first test flight. (GeekWire Photo / Alan Boyle)",0.0,0.0
528,https://theveganherald.com/2022/10/study-healthy-plant-based-diets-significantly-increase-sperm-density-and-motility/,Study: Healthy Plant-Based Diets âSignificantly Increase Sperm Density and Motilityâ,"Plant-based diets can “significantly increase sperm density and motility in men”, and is “related to a lower risk of sperm volume deficiency”, according to a new study published in the peer-reviewed International Journal of Fertility and Sterility.“Infertility is a major clinical problem that affects people psychologically and medically”, states the study’s abstract. “For the past 40 years, studies have linked nearly 50% of childlessness to male infertility. It is worth noting that unlike other factors contributing to infertility, diet is a tunable factor and can be applied in counseling infertile men. ”The goal of this study “was to determine the relationship between plant diet index (PDI) and semen parameters in Iranian infertile men.”In this cross-sectional study, dietary intake was determined by a valid 168-item questionnaire (FFQ). In this study, “four dependent semen parameters, including total sperm motility (TSM), sperm concentration (SC), normal sperm morphology (NSM), and semen volume (SV) were measured.”Results of this study stated that “greater adherence to the healthful plant-based diet index (hPDI), can significantly increase sperm density and motility in men, as well as greater adherence to the PDI dietary pattern is related to a lower risk of sperm volume deficiency, and ultimately more adherence to the unhealthful plant-based diet index (uPDI), can reduce the risk of sperm motility.”Researchers conclude by stating that “In this study, for the first time, the relationship between PDI, hPDI, uPDI and male infertility was evaluated. Altogether, this study demonstrated that nutrition has an impact on semen quality and fertility of men.”Below is the full abstract for this study. You can find the study’s full text by clicking here.Background: Infertility is a major clinical problem that affects people psychologically and medically. For the past 40 years, studies have linked nearly 50% of childlessness to male infertility. It is worth noting that unlike other factors contributing to infertility, diet is a tunable factor and can be applied in counseling infertile men. The goal of this study was to determine the relationship between plant diet index (PDI) and semen parameters in Iranian infertile men. Materials and methods: In this cross-sectional study, dietary intake was determined by a valid 168-item questionnaire (FFQ). In this study, four dependent semen parameters, including total sperm motility (TSM), sperm concentration (SC), normal sperm morphology (NSM), and semen volume (SV) were measured. Results: Results of this study stated that greater adherence to the healthful plant-based diet index (hPDI), can significantly increase sperm density and motility in men, as well as greater adherence to the PDI dietary pattern is related to a lower risk of sperm volume deficiency, and ultimately more adherence to the unhealthful plant-based diet index (uPDI), can reduce the risk of sperm motility. Conclusion: In this study, for the first time, the relationship between PDI, hPDI, uPDI and male infertility was evaluated. Altogether, this study demonstrated that nutrition has an impact on semen quality and fertility of men.",0.0,0.0
323,https://globalnews.ca/news/9237190/netflix-ad-breaks/,"Goodbye binge-watching: Netflix, others, bringing back ad breaks in coming weeks","Send this page to someone via emailCanadian Netflix users will see a new membership option starting Tuesday that costs less but comes with a catch: commercial breaks inserted into their favourite shows.After years of uninterrupted binge-watches, the world’s largest streaming service is making way for a word from its sponsors. And as inflation continues to pinch consumers, the proposal of a cheaper Netflix plan may sound enticing to some.Netflix isn’t alone in believing that commercial television is back in a big way.Several free ad-supported streaming services will launch in Canada over the coming weeks, all of them built on a business model that taps into the country’s multi-billion advertising industry to finance and acquire programming.Story continues below advertisementAnalysts say together the platforms could reshape how we watch and pay for television. More viewers are complaining that streaming costs have soared near the level of their old cable bills, which has pressured each service to reconsider its business model.“Consumers are faced with more choice, more platforms and are making more deliberate decisions as to which streaming services they keep and which ones to cancel,” said Justin Krieger, senior technology and media analyst at consultancy firm RSM Canada.4:43 Disastrous week for Netflix creates concern for future of streamingOf the newcomers, Pluto TV debuts on Dec. 1 with more than 100 channels of free TV series, movies and sports that stream “live” online on a platform that mimics the experience of channel surfing, complete with the commercials.Around the same time, CBC will introduce a revamped free streaming news channel that will be available on CBC Gem and multiple other streaming platforms. A flagship program hosted by Andrew Chang of “The National” will be the main attraction, with advertisements interspersed throughout the day.Story continues below advertisementSouth of the border, Disney Plus rolls out an ad-supported option later this year with some industry observers predicting it will apply the same model in Canada soon after. The ad tier will be introduced at the price of Disney’s existing commercial-free service. Subscribers who want to eliminate the ads will have to pay a premium.Each service has its own reasons for getting into the ad business.For Netflix and Disney, one of the main drivers is growing revenues as programming costs soar and competitors lure away subscribers.Meanwhile, the free streaming services use ad revenues to fund a slate of original and licensed programming, which puts incredible pressure on Netflix to maintain its leading position with attractive new films and shows.Netflix's pitchEarlier this year, after repeatedly swearing off the possibility of ever getting into advertising, Netflix changed its tune by announcing it would launch an ad tier for subscribers in key international markets.Story continues below advertisementIn Canada, the “basic with ads” plan costs $5.99 per month _ less than the plans without ads, which start at $9.99 and peak at $20.99 a month.As a trade-off for the savings, Netflix says subscribers will be presented with an average of four to five minutes of ads per hour played before and during their TV shows and films.Video quality on the Netflix ad plan tops out at 720p, leaving full high-definition streaming at 1080p and 4K for premium subscribers. Viewers also won’t be able to download titles on their devices and not everything in the service’s library will be available.Those restrictions will sour the appeal to many Netflix devotees, suggested Carmi Levy, a technology analyst based in London, Ont.He said Canadians were sold the idea of a commercial-free Netflix a decade ago which led other entrants in the market to mimic their approach with similar models.That’s different than the United States where Peacock, Paramount Plus and HBO Max all offer less expensive ad tiers as a subscription option, while Crackle and Amazon’s Freevee are among the major players in free, ad-supported platforms.“Canadians don’t have that legacy of experience and as a result may be more resistant to the way Netflix is introducing that service,” he said.Story continues below advertisement“It’ll take time for Netflix and others to educate Canadians on the advantages of paying less for a streaming service and getting ads served up in return.”Do Canadians want ads?Kaan Yigit, a technology analyst at Solutions Research Group, said a survey conducted by his firm earlier this year found U.S. viewers have already adopted ad-supported subscription options.About 40 per cent of HBO Max subscribers signed up for its lower-priced ad tier, he said, while an average of 58 per cent of subscribers used the cheaper versions of Paramount Plus and Peacock.He estimates a modest 20 per cent of Canadian Netflix subscribers will join the ad tier over the next 12 to 18 months.However, Netflix’s initial sign-up numbers won’t be the best indicator of long-term success for the ad model, suggested Levy.Story continues below advertisementSubscribers who joined for a deal could be turned off if the ad breaks become as long as they are on network TV stations, which typically air 20 minutes of commercials per hour.“The devil is always in the details whenever a streaming provider introduces an ad-based tier,” Levy said.“What matters most is how intrusive that presentation of ads is to the overall viewing experience. And if it is intrusive in the way that consumers have long complained about traditional broadcast television ads, then this could very well be a non-starter for Netflix.”The ad agenciesUntil those intricacies play out, advertising agencies say their clients are salivating over the prospects of new placement options in the Canadian market.“What we’re seeing is a lot of initial excitement and questions around Netflix, in particular,” said Marissa Cristiano, an account director at Cossette who says she’s “exploring” ad buys on the service with some clients.Story continues below advertisement“They’ve done a really good job of creating … the type of content that brands really do want to ally with.”Cherie Hill, senior vice president of media at marketing firm Society, Etc., said she anticipates Netflix ads will be angled toward “budget-conscious” shoppers, with a strong focus on consumer staples, household items and car companies.She doesn’t anticipate much blowback from viewers, mainly because Netflix is making it an opt-in proposition.“If you’re choosing to have the commercials, it’s not going to leave a negative experience,” she said.“They’re providing an option and they’re managing expectations.”",0.0,0.0
420,https://www.psypost.org/2022/10/feeling-low-take-a-walk-down-memory-lane-study-says-nostalgia-improves-psychological-well-being-64188,Feeling low? Take a walk down memory lane. Study says nostalgia improves psychological well-being,"Nostalgia, or the good feeling one gets when thinking about the past, may not be getting the respect it deserves. A recent study in the Journal of Experimental Social Psychology concludes that the more nostalgic one is, the more authentic one feels, which has positive consequences for psychological well-being. The research team found correlational and experimental support for their hypothesis. Moreover, the effect was cross-cultural; subjects from the United States, China, and the United Kingdom were included in the study.Factors that improve psychological well-being (PWB) are studied frequently and put to good use as components of therapy or valuable life advice. However, for some factors, it is not always clear why it improves PWB. Prior studies have found that nostalgic thinking improves PWB, but why was unknown. Nicholas Kelley and colleagues set out to answer this question with a series of four studies.Their hypothesis is the feeling of authenticity, generated by nostalgic thinking that increases PWB. Understanding how behaviors or cognitions improve PWB provides opportunities to establish innovative methods to increase PWB.The first of the four studies confirmed a relationship between nostalgia, PWB, and authenticity. In these studies, authenticity was defined as “the sense that one is in alignment with one’s true self.” Psychological well-being was assessed with the Brief Inventory of Thriving (BIT).The remaining studies were experimental and demonstrated cause and effect with each step. Study two demonstrated that nostalgia increased authenticity. Study three found authenticity increased PWB, and study four found authenticity increased PWB across all well-being concepts. There were 2423 participants aged 18-78, approximately 50% were American, 33% Chinese, and 17% British.The researchers posited that psychological well-being is made up of many factors and were curious if authenticity had consequences for some or all of the factors. Their results found authenticity, induced with nostalgia, resulted in statistically significant increases in all measured components of psychological well-being (social relationships, vitality, competence, meaning of life, optimism, and subjective well-being).This was true cross-culturally, with participants from the U.S., U.K., and China producing similar results. These findings demonstrate that an enjoyable walk down memory lane can induce feelings of authenticity and thus improve total well-being.The research team acknowledges there is more research to be done. For example, does feeling authentic result in behaving authentically? Future research could include subjective measures of authenticity, or subjects could keep a diary of feelings and behaviors related to nostalgia, authenticity, and well-being as they move through their daily lives.Regardless of future research, this work is a meaningful contribution to our understanding of the benefits of authenticity. Much of the prior research has been correlational. The work of Kelley and colleagues contributes experimental data to the literature. In their words, “Thus, we showed, for the first time, that nostalgia instills a general sense of psychological thriving. Our work has implications for process models of nostalgia’s benefits.”The study, “Nostalgia confers psychological well-being by increasing authenticity” , was authored by Nicholas Kelley, William Davis, William Davis, Jianning Dang, Li Liu, Tim Wildschut and Constantine Sedikides.",0.0,0.0
478,https://techcrunch.com/2021/12/28/sectors-where-new-zealand-startups-are-poised-to-win/,Sectors where New Zealand startups are poised to win,"As a remote island nation in the middle of the South Pacific, New Zealand is experiencing the stirrings of a burgeoning startup scene. The country has historically been capital-starved, but recent investments from the government and foreign investors have significantly increased access to early-stage venture capital funding. Now, certain industries are emerging as potential areas where New Zealand can win in the tech space.Deep tech, medtech/biotech, climate tech, and crypto and blockchain are all areas that investors say they’re either actively investing in or watching for signs of scale.Note: All monetary amounts are listed in New Zealand dollars unless otherwise stipulated.Deep techNew Zealand has the right mix of deep tech-focused capital and resources, strong engineering schools and major success stories that are helping create technologically sophisticated, globally scalable startups.During the first half of this year, total investment in New Zealand’s early-stage sector increased 78% from the first half of 2020, 42% of which went directly to deep tech startups, according to PwC. Much of that funding came from New Zealand Growth Capital Partners (NZGCP), a government entity established to create a vibrant early-stage environment in New Zealand, via its Elevate fund of funds program that provides capital to New Zealand VCs investing in Series A and B rounds.Last October, Elevate allocated $20 million to a fund managed by deep tech VC firm Pacific Channel. More recently, Elevate committed $17 million to Nuance Connected Capital’s fund focused on deep tech innovations, as well as $45 million to GD1’s Fund 3, which focuses on deep tech as well as connected hardware, enterprise software and health tech.New Zealanders make really good founders. … There’s something about just growing up on a farm or, you know, playing beer float out in the lakes and rivers; New Zealand is just really resourceful. Blockchain NZ Chair Bryan VenturaThen there are groups, like Outset Ventures, formerly LevelTwo, that are geared toward helping seed and pre-seed deep tech startups get going. Outset is home to New Zealand’s only two deep tech unicorns, Rocket Lab and LanzaTech, both of which have spun out numerous other deep tech companies. Outset continues to be a resource for seed-stage startups that need not only money, but also connections to larger companies and access to workshops and labs. Just last year, Outset and Icehouse Ventures, a VC firm, partnered to raise a $12 million fund, which launched this April, for early-stage science and engineering startups. Imche Fourie, CEO of Outset, said the company has already made 17 investments from that fund.*Notable deep tech companies out of New Zealand include Foundry Lab, a startup that creates metal castings quickly and cheaply with a microwave; Soul Machines, a platform that creates lifelike digital avatars that animate autonomously, responding to interactions and interpreting facial expressions, with personalities that evolve over time; and Dennisson Technologies, a wearables company that’s developing soft exosuits that incorporate 4D material technology to actively assist people with limited mobility due to physical or neurological disability.The most Kiwi of deep tech startups, however, is Halter — a company that spun out of Rocket Lab and produces solar-powered smart cow collars that allow farmers to remotely shift and virtually fence and monitor cows in order to optimize pasture time. Founder Craig Piggott grew up on a dairy farm watching his parents struggle with the relentless work. After studying engineering at Auckland University of Technology and working at Rocket Lab, Piggott combined his experience to come up with a somewhat wacky and ambitious hardware and software play. Rocket Lab founder Peter Beck, who backed Halter, told TechCrunch he thinks it will be a globally scalable billion-dollar company.The epitome of New Zealand’s deep tech scene is its over $1.75 billion space industry. Rocket Lab, which is now a U.S.-owned company after a SPAC merger, put New Zealand on the map as a place with minimal air traffic, clear skies and favorable aerospace regulations. As a result, companies are forming that can either send payloads into space or provide services to existing space companies.Outset-backed Zenno Astronautics, for example, is developing a fuel-free satellite propulsion system that uses magnets powered by solar panels. Dawn Aerospace is working toward a remotely piloted aircraft that could take off like a normal airplane, drop a satellite payload and be back home in 15 minutes. And Astrix Autonautics, a startup founded by three Auckland University students, is being trialed by Rocket Lab to see if they can more than double the power-to-weight ratios of solar arrays used today.",0.0,0.0
334,https://abcnews.go.com/Politics/justice-department-charges-chinese-intel-officers-obstruct-probe/story?id=92000006,Justice Department charges 2 Chinese intel officers with trying to obstruct probe into Huawei,"The Department of Justice on Monday unsealed charges against two Chinese intelligence officers who allegedly worked to obstruct the DOJ's investigation of the telecommunications giant Huawei.This case is one of three that the DOJ has unsealed against 13 individuals associated with the Chinese government, 11 of which are intelligence officers, FBI Director Christopher Wray said Monday.The indictment in the obstruction case related to Huawei accuses Chinese intelligence agents Guochun He and Zheng Wang of ""attempt[ing] to direct a person they believed they recruited as an asset"" inside a U.S. government law enforcement agency ""to obtain confidential information regarding witnesses, trial evidence and potential new charges to be brought against [Huawei] for the purpose of obstructing justice.""But the ""asset"" within the U.S. government that the two agents allegedly worked with was actually acting as a double agent under the FBI's supervision, according to the DOJ.The DOJ previously unsealed an indictment in 2019 accusing Huawei in a racketeering and corruption conspiracy stemming from the company's alleged practices ""using fraud and deception to misappropriate sophisticated technology from U.S. counterparts.""At the time, the department noted that its investigation of Huawei remained ongoing. The company accused the DOJ of ""political persecution.""The new indictment lays out in great detail He and Wang's alleged attempts to interfere and obstruct the U.S. government's probe of Huawei.The two men, whom the DOJ says remain at large, allegedly paid the double agent working on behalf of the FBI some $61,000 in Bitcoin for what they believed was insider information about the investigation.In this Feb. 2, 2022, file photo, the logo of the telecommunication provider Huawei is shown. Photothek via Getty Images, FILEAt one point in October 2021, the indictment alleges, the undercover agent passed a single-page document to one of the Chinese intelligence officers that appeared to be classified as ""SECRET"" and that detailed U.S. plans to arrest two principals from Huawei living in China.He and Wang paid the undercover $41,000 just for that single page, the indictment claims.Attorney General Merrick Garland and top law enforcement officials addressed that case and others in a Monday news conference focused on China's so-called ""malign influence efforts"" and use of intelligence officers targeting the U.S.""This was an egregious attempt by [People's Republic of China] intelligence officers to shield a PRC-based company from accountability and undermine the integrity of our judicial system,"" Garland told reporters.In another case, the DOJ has charged seven individuals with allegedly forcing someone to return to China through scare tactics and harassment.""Those activities were part of the PRCs global, extra-legal effort known as 'Operation Foxhunt,'"" Garland said. ""Its purpose is to locate and bring back to China alleged fugitives who have fled to foreign countries, including the United States. The PRC has a history of targeting political dissidents and critics of the government who have sought relief and refuge in other countries.""Attorney General Merrick Garland speaks during an event at DEA headquarters, in Arlington, Va., Sept. 27, 2022. Gemunu Amarasinghe/AP, FILEIn a third case, the Justice Department alleges that for almost 10 years, four Chinese nationals attempted to target and recruit individuals to act on China's behalf through a fake think tank. They targeted a former government official and a professor at an American university.""As these cases demonstrate, the government of China sought to interfere with the rights and freedoms of individuals in the United States and to undermine our judicial system that protects those rights,"" the attorney general said. ""They did not succeed. The Justice Department will not tolerate attempts by any foreign power to undermine the rule of law upon which our democracy is based. We will continue to fiercely protect the rights guaranteed to everyone in our country. And we will defend the integrity of our institutions.""Two people accused in the harassment case have been taken into custody; the others remain at large.The DOJ officials stressed to reporters on Monday that the unsealed cases reflect accusations against China's government -- and are not a reflection of views of China as a whole or of Chinese Americans.FBI Director Wray said that the cases were not related to recent political developments in China, where President Xi Jinping's time in office was just extended.Wray said that when cases are ready to be brought, the DOJ presents them to a grand jury.",0.0,0.0
335,https://www.businessinsider.com/mark-zuckerberg-should-dial-down-metaverse-grow-facebook-instagram-whatsapp-2022-10,Mark Zuckerberg should dial down the metaverse crap and make Facebook 'Facebook' again,"Mark Zuckerberg is going all in on the metaverse, but he should re-focus on other things.The Meta CEO should prioritize growing engagement and revenue on the company's core apps.Meta reports Q3 earnings next week and analysts have called it a ""make-or-break quarter.""Sign up for our newsletter for the latest tech news and scoops — delivered daily to your inbox. Loading Something is loading. Thanks for signing up! Access your favorite topics in a personalized feed while you're on the go. download the app Email address By clicking ‘Sign up’, you agree to receive marketing emails from Insider as well as other partner offers and accept our Terms of Service and Privacy PolicyMeta, the company formerly known as Facebook, should start focusing on making Facebook Facebook again.Over the past year, CEO Mark Zuckerberg has zeroed in on his passion project: the metaverse. It's a squishy concept that can describe a number of things, but in the broadest sense it's the idea that people connect with each other through virtual worlds rather than on a traditional social network.But as I wrote recently, Meta's big pivot into the metaverse has been a disaster, with little to show for it other than a mediocre experience, increasingly expensive headsets, and its stock plunging over 60% this year.Zuckerberg should instead dial that down and prioritize bolstering his company's core apps, Facebook, Instagram, and WhatsApp, which have felt largely neglected while Meta poured $15 billion into its metaverse project.Staring down the barrel of a potential recession, Meta should be growing the engagement and revenue of those apps, which have billions of users worldwide. Meanwhile, Horizon Worlds, Meta's main metaverse app, has just 200,000 monthly active users, The Wall Street Journal recently reported.Particularly, even as Instagram has faced headwinds recently, it's still Meta's crown jewel. Keeping users happy on the app and charting a plan for it in the years to come should be the company's No. 1 priority. Meta said in its Q2 earnings that Reels was growing and accounted for 20% of the time people spend on Instagram.Instead of angering users by trying to make Instagram more of a TikTok clone, Meta should be spending its time and energy on threading the needle to monetize that usage as much as possible without turning people off.It should also be looking to do the same with WhatsApp, the most popular communications app in the world. The platform doesn't include ads, in an effort to maintain its identity as a user-friendly service first and foremost. But Meta has promised to capitalize on its popularity in other ways to drive revenue, including with paid features.Yet, instead of focusing on its proven apps, Meta is investing billions of dollars on an idea that will maybe see payoffs five or ten years down the line.If left unchecked, a bet of this magnitude risks alienating investors — and staff — while facing choppy economic waters.Zuckerberg will show us his report card later this weekMark Zuckerberg as an avatar during Connect 2022 MetaMeta reports its Q3 earnings next week, and Wall Street has already been spooked. Analyst Neil Campling called a recent metaverse presentation by Zuckerberg ""desperate"" and said ""no wonder investors are in despair.""The investment firm Bernstein called it a ""make or break quarter"" in a recent note, and said that engagement numbers will be ""critical"" for the company this quarter.""We believe that if Meta does not provide incremental information on the call suggesting that aggregate engagement across its family of apps are stable, the bear case will only get louder,"" Bernstein analysts wrote.The analysts think a turnaround is possible by year's end and into 2023 if Meta, among other things, increases the ad load on its TikTok-like video product, Reels.Meta's revenue dropped in Q2, the first time it had done so in the company's decade of being publicly traded. Zuckerberg blamed it on an ""economic downturn"" that was impacting the digital-ad business.Apple was a key part of the problem. Last year, the tech giant introduced an iOS privacy change that asked users if they wanted to opt out of being tracked across other companies' apps. Meta responded at the time saying that advertisers ""may see an overall decrease in ad performance and personalization and an increase in cost per action.""Seeking to escape a future scenario where Apple is a dominant force that can hamstring his business with a single software blow, Zuckerberg is trying to invent the next future platform.But it's rarely the incumbents who create the next big platform, which is why Zuckerberg's metaverse vision sounds like a better fit for a VC-backed startup than a companywide rallying cry.Apple has also been exploring future platforms, too, but far more quietly than Meta (its own VR headset is reportedly coming soon). But the company hasn't been punished for it by Wall Street, because it's still laser-focused on growing its core business sectors — unlike Meta.That hasn't stopped Zuckerberg from making his metaverse push a Meta vs. Apple contest, so it's clearly taking up headspace.""This is a competition of philosophies and ideas, where they believe that by doing everything themselves and tightly integrating that they build a better consumer experience,"" Zuckerberg said of Apple's strategy in an all-hands meeting this year with employees, according to The Verge.But maybe Zuckerberg should take a page out of Apple's book, prioritize the proven cash cows to keep investors happy, and relegate the metaverse stuff to the garage where moonshot projects belong.",0.0,0.0
337,https://www.businessinsider.com/snapchat-disappearing-messages-helped-teenagers-obtain-fentanyl-lawsuit-2022-10,"Snapchat's disappearing message function helped teenagers obtain fentanyl with deadly consequences, lawsuit argues","Snapchat's disappearing messages helped teenagers to obtain the drug fentanyl, a lawsuit stated.Lawyers say the feature was defective as it helped facilitate illicit sales of the drug to minors.A Snap spokesperson said several allegations in the complaint appeared to be ""wholly inaccurate.""Sign up for our newsletter for the latest tech news and scoops — delivered daily to your inbox. Loading Something is loading. Thanks for signing up! Access your favorite topics in a personalized feed while you're on the go. download the app Email address By clicking ‘Sign up’, you agree to receive marketing emails from Insider as well as other partner offers and accept our Terms of Service and Privacy PolicySnapchat's disappearing message feature helped enable the sale of fentanyl to teenagers who went on to die of overdoses, a lawsuit claimed.According to a filing in a Los Angeles court seen by Insider, parents of teens who died from Fentanyl overdoses are pursuing Snap for strict product liability over what they claim is a design defect in the social media app Snapchat.The lawsuit stated that Snapchat is marketed to minors, and that the erasing messages function encourages drug dealers to use the social media app.""The product design of Snap, most notably its disappearing message feature which is engineered to evade parental supervision and law enforcement's detection and acquisition of criminal evidence, was the direct and proximate cause of the untimely and tragic deaths and injuries at issue in this complaint,"" the filing said.A Snap spokesperson told Insider ""several allegations in the complaint appear to be wholly inaccurate,"" but did not give further details.The spokesperson said Snap used ""cutting-edge technology to proactively find and shut down drug dealers' accounts, and we block search results for drug-related terms, instead redirecting Snapchatters to resources from experts about the dangers of fentanyl.""Alexander Neville died of a Fentanyl overdose in June 2020 at the age of 14. His parents, Amy and Aaron, are part of the lawsuit.The couple said their son communicated on Snapchat with a dealer called Aj Smokxy who supplied him with fentanyl, according to subpoenaed documents, the lawsuit said. They said Alexander had become increasingly anxious during COVID-19 as his use of the app increased.""Amy went to her son's room to wake him up for an orthodontist appointment. She opened the bedroom door and found Alexander's body laying lifeless on his bedroom floor,"" the lawsuit stated.""Amy and Aaron administered CPR to their son as they waited for paramedics to arrive, but it was too late.""The lawyers argued that Alexander was only able to obtain fentanyl from the dealer through the app.""AJ Smokxy had no known connection to Alexander. They did not know each other in real life. The two would never have connected but for Snapchat,"" the lawsuit said.One of the parents' lawyers, Laura Marquez-Garrett of the Social Media Victims Law Center, previously led a lawsuit against Meta alleging Instagram caused eating disorders among children.",0.0,0.0
301,https://www.theguardian.com/technology/2022/oct/31/online-age-verification-system-could-create-honeypot-of-personal-data-and-pornography-viewing-habits-privacy-groups-warn,"Online age-verification system could create âhoneypotâ of personal data and pornography-viewing habits, privacy groups warn","In the wake of the Optus and Medibank data breaches, digital rights groups are urging the federal government to rule out requiring identification documents as part of any online age-verification system, warning it could create a honeypot of people’s personal information and pornography-viewing habits.The eSafety commissioner, Julie Inman Grant, is developing an online safety “roadmap”, outlining a way to prevent minors from accessing adult content online by ensuring host sites have verified the ages of users.The commissioner’s report was initially due to the government in December, however, the deadline has now been extended to March next year. Stakeholders were informed of the delay in reporting last week.A variety of options for age verification has been offered during the roadmap’s development, including the use of third party companies, individual sites verifying ages using ID documents or credit card checks, and internet service providers or mobile phone operators being used to check users’ ages.Digital rights groups say almost all approaches to age verification will have some level of privacy and security risk.“Following the Optus and Medibank breaches, millions of people are now acutely aware of the dangers of collecting and storing large amounts of our personal information,” Samantha Floreani, program lead at Digital Rights Watch said.“Age verification is a terrible combination of being invasive and risky, while also being ineffective for its purported purpose.“Methods that are less privacy-invasive are easily bypassed by tech-savvy kids, and those that may be more likely to work at restricting access to pornography create massive and disproportionate privacy and digital security risks.”There was the potential for a new honeypot of people’s identities and porn-viewing habits if these systems were pursued, Floreani said.“The consequences of a breach of such a system would be devastating,” she said.Sign up to Guardian Australia's Morning Mail Free daily newsletter Our Australian morning briefing email breaks down the key national and international stories of the day and why they matter Privacy Notice: Newsletters may contain info about charities, online ads, and content funded by outside parties. For more information see our Newsletters may contain info about charities, online ads, and content funded by outside parties. For more information see our Privacy Policy . We use Google reCaptcha to protect our website and the Google Privacy Policy and Terms of Service apply.Electronic Frontiers Australia chair, Justin Warren, said EFA has long warned about the privacy and security risks of such a policy.“A government that claims to be interested in evidence-based policy would listen and act on our advice. Failure to do so suggests that the motivations for increased surveillance and control are ideological,” he said.A spokesperson for the communications minister, Michelle Rowland, said the Albanese government “supports restricting Australian children from viewing online pornography” but said questions about the roadmap were best directed to the eSafety commissioner.“The eSafety commissioner is progressing a complex body of work with a wide range of divergent stakeholder views and issues including privacy and security,” the spokesperson said.A spokesperson for the eSafety commissioner said privacy and cyber security issues were important considerations in developing the roadmap and have been extensively explored as part of the consultation process.Other groups have called for an effective ban on online pornography. Anti-porn group Collective Shout called for all pornography to be treated under the same classification as child sexual abuse material or terrorism material, which would be required to be removed or blocked in Australia.Some companies have already begun implementing age-verification procedures. Google, for example, since March estimates a person’s age using information gathered on that account, such as their search history. If ultimately the company needs to see ID documents, Google has said it deletes those documents after verification.",0.0,0.0
77,https://www.tomshardware.com/news/lithograhy-tool-russia-7nm-2028,Russian University Vows to Build 7nm Chipmaking Tools,"A Russian institute is developing its own lithography scanner that could produce chips using 7nm-class fabrication technologies. The machine is under development, with the plan to build it by 2028. When it is ready, it should be more efficient than ASML's Twinscan NXT:2000i tool, whose development took over a decade.After Russia unleashed its bloody war against Ukraine on February 24, Taiwan was quick to ban shipments of advanced chips to the nation. The U.S., the U.K., and the E.U. then followed up with sanctions that effectively prohibit virtually all contract chipmakers with advanced fabs from working with Russian entities. In addition, companies like Arm cannot license their technologies to Russia-based chip designers. As a result, the Russian government rolled out a national program to develop the country's own 28nm-class fabrication technology by 2030, reverse engineer as many foreign chips as possible, and educate local talent to work on domestic chips.However, there is a problem with a 28nm-class production node by 2030. Russia's most advanced fab can produce chips using a 65nm fabrication technology. Meanwhile, American and European makers of fab tools cannot supply their equipment to Russia due to sanctions, so the country has to design and build domestic wafer production equipment if it wants to adopt a 28nm node. Essentially, what has taken companies like ASML and Applied Materials decades to develop and iterate has to be done in about eight years.Apparently, the Russian Institute of Applied Physics of the Russian Academy of Sciences intends to beat all expectations and produce a 7nm-capable lithography scanner by 2028, according to its plans published on Nizhy Novgorod Strategy Development website (via CNews).A modern lithography scanner capable of processing wafers using a 7nm-class process technology is a highly complex apparatus that involves a high-performance light source, sophisticated optics, and precise metrology, just to name a few critical parts. However, as a leading applied physics university in Russia, IAP believes that it can develop such a tool in a relatively short amount of time.The tool will be somewhat different from scanners produced by companies like ASML or Nikon. For example, IAP plans to use a >600W light source (total power, not intermediate focus power) with an 11.3nm exposure wavelength (EUV wavelength is 13.5nm), which will require considerably more sophisticated optics than exists today. Because the light source of the device will be relatively low power, it will make the tool more compact and easier to build. Yet, it also means that its production of the scanner will be considerably lower than that of modern deep ultraviolet (DUV) tools. That might not be a problem, according to IAP.When it comes to timing, IAP may be slightly too optimistic. For everything below 32nm, chipmakers use the so-called immersion lithography (which is essentially a booster to DUV tools). ASML introduced its first immersion lithography system — the Twinscan XT:1250i — in late 2003 with a plan to deliver one in Q3 2004 to produce 65nm logic chips and 70nm half-pitch DRAMs. It took the company about five years and another generation of tools to announce its 32nm-capable Twinscan NXT:1950i in late 2008, with customer deliveries starting in 2009.Then, it took the market leader some nine years to deliver its 7nm and 5nm-capable Twinscan NXT:2000i DUV tool in 2018. TSMC used less advanced tools with multi-patterning for its first-generation N7 fabrication technology, but the timing of ASML’s introductions demonstrate how hard it is to transition from 65nm to 7nm. It took ASML 14 years to go from 65nm to 7nm. Now, IAP, which does not have any experience in chip production or ties with chipmakers, intends to build a 7nm-capable machine for volume production from scratch in about six years. While the plan does not sound feasible, it looks like IAP is full of enthusiasm.""ASML, the global lithography leader, has been developing its EUV lithography system for almost 20 years and the technology has turned out to be incredibly complex,"" said Nikolai Chkhalo, Deputy Director of the Institute of Physics of Microstructures of the Russian Academy of Sciences for scientific and technological development. ""The main objective of ASML in this case was to maintain the extremely high productivity that is needed only at the world's largest factories. In Russia, no one needs such high productivity. In our work, we start from the needs and tasks faced by domestic microelectronics — and this is not so much about quantity, but about quality. First of all, we need to transit to our own fabrication processes, develop our own design standards, our own tools, engineering, materials, so our own path is inevitable here. In fact, we need to balance between simplicity and performance.""IAP plans to build a fully functional alpha scanner by 2024. This one will not have to offer high productivity or maximum resolution but will have to work and be attractive to potential investors. IAP intends to build a beta version of the scanner with higher productivity and resolution by 2026. This machine should be mass production ready, but its productivity is not expected to be at its maximum. The final iteration of the litho scanner is said to emerge in 2028. It should get a high-performance light source (hence better productivity), better metrology and overall capabilities. There is no word how many of such machines IAP and/or its production partners will be able to produce by 2028.It should be noted that fab equipment is not limited to lithography scanners. There are other types of machines performing etching, deposition, resist removal, metrology, and inspection operations that are not made in Russia. Furthermore, there is somewhat less advanced machinery like ultrapure air and water generators which also are not produced in Russia. Even if IAP RAS manages to build a lithography tool, Russia will still be a few hundred tools short of building a modern fab. Also, fabs need ultrapure raw materials produced in countries that will not supply to Russia.",0.0,0.0
377,https://techcrunch.com/2019/03/22/medtronic-defibrillators-critical-flaws/,Homeland Security warns of critical flaws in Medtronic defibrillators,"Homeland Security has issued a warning for a set of critical-rated vulnerabilities in Medtronic defibrillators that put the devices at risk of manipulation.These small cardio-defibrillators are implanted in a patient’s chest to deliver small electrical shocks to prevent irregular or dangerously fast heartbeats, which can prove fatal. Most modern devices come with wireless or radio-based technology to allow patients to monitor their conditions and their doctors to adjust settings without having to carry out an invasive surgery.But the government-issued alert warned that Medtronic’s proprietary radio communications protocol, known as Conexus, wasn’t encrypted and did not require authentication, allowing a nearby attacker with radio-intercepting hardware to modify data on an affected defibrillator.Homeland Security gave the alert a 9.3 out of 10 rating, describing it as requiring “low skill level” to exploit.It doesn’t mean that anyone with an affected defibrillator is suddenly a walking target for hackers. These devices aren’t always broadcasting a radio frequency as it would be too battery intensive. Medtronic said patients would be most at risk when patients are getting their implant checked while they’re at their doctor’s office. At all other times, the defibrillator will occasionally wake up and listen for a nearby monitoring device if it’s in range, narrowing the scope of an attack.More than 20 different Medtronic defibrillators and models are affected, the alert said, including the CareLink programmer used in doctor’s offices and the MyCareLink monitor used in patient homes.Peter Morgan, founder and principal at Clever Security, found and privately reported the bug to Medtronic in January. In an email, Morgan told TechCrunch that the bugs weren’t easy to discover, but warned of a potential risk to patients.“It is possible with this attack to cause harm to a patient, either by erasing the firmware that is giving necessary therapy to the patient’s heart, or by directly invoking shock related commands on the defibrillator,” he said. “Since this protocol is unauthenticated, the ICD cannot discern if communications its receiving are coming from a trusted Medtronic device, or an attacker.”A successful attacker could erase or reprogram the defibrillator’s firmware, and run any command on the device.Medtronic said in its own advisory that it’s not aware of any patient whose devices have been attacked, but that the company was “developing updates” to fix the vulnerabilities, but did not say when fixes would be rolled out.The Food and Drug Administration (FDA), which regulates medical devices, provided a list of the affected devices.It’s the latest example of smart medical devices taking a turn for the worst, even as spending in healthcare cybersecurity is set to become a $65 billion industry by 2021.The FDA rolled out non-binding recommendations in 2016 to advise medical device makers into practicing better cybersecurity to prevent these kinds of flaws from occurring in the first place, advising companies to “build in cybersecurity controls when they design and develop the device to assure proper device performance in the face of cyber threats.”Yet, this latest government alert marks the second time in two years Medtronic was forced to respond to security flaws in its medical devices. In October, the company finally shuttered an internet-based software update system that put its pacemaker-monitoring devices at risk.",0.0,0.0
547,https://www.theverge.com/2022/8/30/23329998/nasa-artemis-rocket-launch-second-attempt-date-time,NASA moves next Artemis I rocket launch attempt to September 3rd,"Clear your plans on Saturday: NASA says we’re going to have a rocket launch.The space agency moved the date for the next Artemis I rocket launch attempt to Saturday, September 3rd, after determining that the initial plan for Friday was going to run into bad weather.There was a 60 percent chance that the launch would have been delayed for weather on Friday, officials said during a media briefing. The two-hour launch window opens at 2:17PM.This will be NASA’s second attempt this week at launching its massive next-generation rockets. The first attempted launch on Monday was scrubbed after one of the four RS-25 engines failed to reach the appropriate temperature to allow for liftoff.This will be NASA’s second attempt this week at launching its massive next-generation rocketsThe Artemis I mission is comprised of the 322-foot tall Space Launch System (SLS) rocket, with the Orion crew capsule at the top. If the launch is successful, the 39-day mission will see SLS carry the uncrewed Orion to an altitude of just under 4,000 kilometers before the two craft separate and the core stage of the rocket falls back to Earth.Orion will continue onward to the Moon, which it will orbit for six days before returning to Earth. The capsule is scheduled to splash down in the ocean on October 11th.",0.0,0.0
127,https://www.nbc4i.com/news/local-news/groveport/move-over-diesel-ohio-gets-first-of-its-kind-renewable-gas-station/,"Move over, diesel: Ohio gets âfirst of its kindâ renewable gas station","GROVEPORT, Ohio (WCMH) — A new kind of gas station has just opened for business in Groveport, and its first client is a massive national corporation.Calling it the “first station of its kind,” Clean Energy Fuels Corporation cut the ribbon Wednesday on a renewable natural gas station at 5900 Green Pointe Dr. The RNG fuel it provides is intended as a replacement for diesel, and is sourced from methane in livestock manure. CEFC’s intention is an environmentally-friendly fuel, which it said cuts carbon emissions by around 300% when used instead of diesel in freight trucks.The station’s first “anchor customer” will also ensure plenty of freight trucks get that opportunity. CEFC said the Groveport station was built exclusively for Amazon’s distribution truck fleet to use RNG. However, a CEFC spokeswoman added it would be open to taking on additional local fleets interested in trying the cleaner fuel. They noted that 19 similar gas stations are under construction across the country.The new renewable natural gas station will also open up a new income opportunity for Ohio farmers. Specifically for the Groveport station, CEFC said it made a partnership with South Fork Dairy Farm to source their manure for RNG. Construction crews will also build a large tank to collect manure at the farm. This will trap methane gas as the manure decomposes, preventing it from contributing to greenhouse gas emissions and allowing it to be processed and purified to make RNG locally.(Courtesy Photo/Raleigh Gerber)From here, RNG processing tanks like the one at South Fork Dairy Farm will have a direct pipeline to RNG stations for fueling. Learn more about RNG and CEFC’s new station here.",0.0,0.0
35,https://www.eurekalert.org/news-releases/969469,Factors influencing bike share among underserved populations: evidence from three US cities,"Researchers Jennifer Dill, Jiahui Ma, Nathan McNeil, Joseph Broach and John MacArthur of Portland State University have published a new article in the November 2022 issue of Transportation Part D: Transport and Environment. The open-access article, ""Factors influencing bike share among underserved populations: Evidence from three U.S. cities,"" examines bike share use and interest among lower-income residents and people of color in New York, Chicago, and Philadelphia.There is evidence that lower-income and people of color (POC) in the U.S. do not use bike share as much as higher-income and white people. Using data from residents living near bike share stations in New York, Chicago, and Philadelphia, the paper examines reasons for these disparities. Researchers looked at many factors that might explain bike share use and interest in lower-income, racially diverse, traditionally underserved neighborhoods. They focused on residents who live near bike share stations, so that proximity would not be a barrier.A few key findings:People who are not members, but are interested in using bike share, including POC, are motivated to use bike share for fun, recreation, and social reasons (as opposed to utility). Knowledge of bike share and receiving information from interactive sources (for example, bike share ambassadors) are associated with bike share use. Cost is a barrier for people who are interested in using bike share, but are not members. Discounted memberships are one solution, but survey results indicate that many people do know know about them.Some reasons for not using bike share among people of color and lower-income people may also be related to reasons for not bicycling, generally. These include concerns about traffic safety as well as personal safety.This paper is an analysis of data collected in a ""Breaking Barriers to Bike Share"" project funded by the National Institute for Transportation and Communities (NITC) and the Better Bike Share Partnership (BBSP). Read more about the original study and explore some of the products to come out of this research, including a set of ten bike share equity briefs to help operators establish equity programs based on what's been shown to work.Portland State University's Transportation Research and Education Center (TREC) is home to the U.S. DOT funded National Institute for Transportation and Communities (NITC), the Initiative for Bicycle and Pedestrian Innovation (IBPI), PORTAL, BikePed Portal and other transportation grants and programs. We produce impactful research and tools for transportation decision makers, expand the diversity and capacity of the workforce, and engage students and professionals through education and participation in research.",0.0,0.0
51,https://techcrunch.com/2019/11/07/elon-musk-says-building-the-first-sustainable-city-on-mars-will-take-1000-starships-and-20-years/,"Elon Musk says building the first sustainable city on Mars will take 1,000 Starships and 20 years","SpaceX CEO Elon Musk went into a bit more detail about the timelines and vehicle requirements to not only reach Mars, but to set up a sustainable base on the Red Planet that can serve as an actual city, supporting a local population. That’s the long-term vision for Musk and his space technology company, after all — making humans an interplanetary species. The timeline that Musk discussed today, replying to fans on Twitter, might be incredibly impressive or incredibly ambitious, depending on your perspective.Addressing a question about comments he made earlier this week at the U.S. Air Force startup pitch day event in California, Musk said that his stated launch cost of only around $2 million per Starship flight are essentially required, should the final goal be to set up a “self-sustaining city on Mars.” In order to make that city a reality, he added, SpaceX will need to build and fly around 1,000 Starships according to his estimates, which will need to transport cargo, infrastructure and crew to Mars over the course of around 20 years, since planetary alignment only really allows for a realistically achievable Mars flight once every two years.Musk addressed more near-term potential for Starship as well, including how much payload capacity Starship will provide for Earth orbital transportation. Starship’s design is intended to maximize re-use, and in fact Musk noted that ideally it can fly up to three times per day. That amounts to more than 1,000 flights per year per Starship, which means that if they end up with as many Starships as they currently have built Falcon rockets (around 100) and those can each transport as much as 100 tons to orbit, then on an annual basis, SpaceX will be able to launch upwards of 10 million tons to orbit per year.To put that in perspective, Musk points out that if you take all cargo-bearing spacecraft currently in operation into account, the total payload capacity is just 500 tons per year — with Falcon series rockets from SpaceX itself making up around half of that.That’s a lot of payload; in fact, it’s probably more than there will be demand for in any near-term time scale. But it’s also true that Musk envisions a future where orbital space is a much busier place, and a staging ground for orbital cargo transfer and refueling as Moon and Mars-bound spacecraft ready themselves for the outward journey.Of course, to set up a permanent, sustainable city on Mars, we first have to get there with a crewed flight. There’s another step between now and then, which is landing astronauts back on the Moon. NASA has set 2024 as its goal for that milestone, and SpaceX has said it hopes to land Starship there by as early as 2022 to help with staging in preparation for that landing. In the past, Musk has discussed crewed Mars mission also taking place as early as 2024, but that goal seems mighty aspirational (as do most of his timelines) from where we sit today.",0.0,0.0
32,https://www.france24.com/en/live-news/20221013-neanderthals-humans-co-existed-in-europe-for-over-2-000-years-study,"Neanderthals, humans co-existed in Europe for over 2,000 years: study","Paris (AFP) – Neanderthals and humans lived alongside each other in France and northern Spain for up to 2,900 years, modelling research suggested Thursday, giving them plenty of time to potentially learn from or even breed with each other.Advertising Read moreWhile the study, published in the journal Scientific Reports, did not provide evidence that humans directly interacted with Neanderthals around 42,000 years ago, previous genetic research has shown that they must have at some point.Research by Swedish paleogeneticist Svante Paabo, who won the medicine Nobel prize last week, helped reveal that people of European descent -- and almost everyone worldwide -- have a small percentage of Neanderthal DNA.Igor Djakovic, a PhD student at Leiden University in the Netherlands and lead author of the new study, said we know that humans and Neanderthals ""met and integrated in Europe, but we have no idea in which specific regions this actually happened"".Exactly when this happened has also proved elusive, though previous fossil evidence has suggested that modern humans and Neanderthals walked the Earth at the same time for thousands of years.To find out more, the Leiden-led team looked at radiocarbon dating for 56 artefacts -- 28 each for Neanderthals and humans -- from 17 sites across France and northern Spain.The artefacts included bones as well as distinctive stone knives thought to have been made by some of the last Neanderthals in the region.The researchers then used Bayesian modelling to narrow down the potential date ranges.'Never really went extinct'Then they used optimal linear estimation, a new modelling technique they adapted from biological conservation sciences, to get the best estimate for when the region's last Neanderthals lived.Djakovic said the ""underlying assumption"" of this technique is that we are unlikely to ever discover the first or last members of an extinct species.""For example, we'll never find the last woolly Rhino,"" he told AFP, adding that ""our understanding is always broken up into fragments"".The modelling found that Neanderthals in the region went extinct between 40,870 and 40,457 years ago, while modern humans first appeared around 42,500 years ago.This means the two species lived alongside each other in the region for between 1,400 and 2,900 years, the study said.Humans, neanderthals, Denisovan and mystery hominins AFPDuring this time there are indications of a great ""diffusion of ideas"" by both humans and Neanderthals, Djakovic said.The period is ""associated with substantial transformations in the way that people are producing material culture,"" such as tools and ornaments, he said.There was also a ""quite severe"" change in the artefacts produced by Neanderthals, which started to look much more like those made by humans, he added.Given the changes in culture and the evidence in our own genes, the new timeline could further bolster a leading theory for the end of the Neanderthals: mating with humans.Breeding with the larger human population could have meant that, over time, Neanderthals were ""effectively swallowed into our gene pool,"" Djakovic said.""When you combine that with what we know now -- that most people living on Earth have Neanderthal DNA -- you could make the argument that they never really went extinct, in a certain sense.""© 2022 AFP",0.0,0.0
318,https://www.cbsnews.com/amp/news/meta-stock-down-earnings-700-billion-in-lost-value/,"Meta's value has plunged by $700 billion. Wall Street calls it a ""train wreck.""","Facebook parent Meta Platforms is making a huge investment in virtual reality, but its actual reality is looking like a real disaster.Meta shares tumbled 24% on Thursday to its lowest level in nearly four years following an earnings report that one Wall Street analyst described as a ""train wreck."" It's a far cry from the company's position nearly a year ago, when CEO Mark Zuckerberg on October 28, 2021, announced with great fanfare that Facebook was changing its name to Meta Platforms to emphasize its focus on the ""metaverse.""Last fall, Facebook was still riding high: Its market value reached a peak of more than $1 trillion in September 2021. Revenue and profits were surging as advertisers flocked to Facebook and Instagram to reach their billions of users.Click here to view related media. click to expandTo be sure, practically the entire tech industry has taken a beating this year, but Meta's stock plunge has far outpaced the overall sector, with its shares down 67% from a year earlier compared with the tech-heavy Nasdaq's 31% slide over the same period. Meta's plunge translates into an eye-popping loss of about $700 billion in market value.On Thursday, Meta's market value sank to $268 billion, down from more than $1 trillion in September of 2021. The shares regained some ground on Friday morning, rising $1.72, or about 1.8%, to $99.66 per share.The company's travails raise questions about its all-in bet on the metaverse, as well as whether the social media company could suffer the fate of other major businesses whose gambles on the future failed to pay off. In the near-term, Meta's core Facebook business is facing challenges as the economy slows and advertisers trim spending.""Meta's results last night was an absolute train wreck that speaks to pervasive digital advertising doldrums ahead for Zuckerberg & Co. as they make the risky and head scratching bet on the metaverse,"" Wedbush analyst Dan Ives said in a report.The hit to Meta has also whittled down Zuckerberg's personal fortune, since most of his wealth stems from his 13% stake in the social media company. He is worth $37.7 billion as of October 27, according to Bloomberg Billionaires Index, having lost almost $88 billion in wealth during the past 12 months.Here are three key issues slamming Meta shares and deepening questions about its longer-term prospects.$9.4 billion in metaverse lossesOn a Wednesday conference call to discuss Meta's latest earnings, Zuckerberg told investors he is ""pretty confident this is going in a good direction.""Investors aren't convinced. The company is making what amounts to a wildly expensive bet on its ability to transform into a virtual reality behemoth and whether that technology can power the next phase in Meta's growth.Although such strategic pivots can take years for big companies to execute — as it did for IBM and Microsoft as they morphed from selling hardware to software — the early returns for Meta have been grim. For the first nine months of the year, Meta lost $9.4 billion on its metaverse unit, Reality Labs. It expects the unit to have ""significantly"" wider operating losses in 2023, the company said on Wednesday.Investors are skeptical because, at least so far, consumers aren't exactly flocking to the fledgling metaverse. Unlike the longer time-lines for building businesses common in Silicon Valley, Wall Street values companies based on near-term returns rather than hazier projections that stretch years into the future.Horizon Worlds, Meta's new virtual space, trimmed its goal for monthly active users to 280,000 from 500,000, but the space is attracting fewer than 200,000, the Wall Street Journal reported earlier this month.""[I]nvestors should remain on the sidelines as it will take many years before progress in the metaverse can be truly monetized,"" Angelo Zino, senior equity analyst CFRA Research, told investors in a research note.Slower Facebook growthBy comparison, Facebook had a massive base of 1.98 billion active daily users on average for September — a 3% increase from a year ago.That may seem respectable, but it's far from the huge growth Facebook experienced in earlier years. And the slower growth comes after Facebook in February said it had lost users for the first time in its history.The social media juggernaut, Meta's huge moneymaker, is battling challenges from upstarts like TikTok, which is grabbing younger consumers.Advertising challengesMeta's lifeblood is the advertising revenue booked by Facebook, Instagram and WhatsApp, with businesses eager to reach their billions daily users. But its ad revenue fell in the most recent quarter, with sales drooping 3.7% and adding to investor concerns.Meta announces its first hiring freeze, signaling tech slowdownOn the ad front, Meta faces a double whammy. An economic slowdown means that advertisers are cutting spending, with the company on Wednesday pointing to an ""uncertain and volatile macroeconomic landscape"" for ads. The company is also grappling with the impact of Apple's privacy changes to apps that run on its devices. That change means consumers can ask apps to not track them, and which Facebook has said will cost it $10 billion this year.",0.0,0.0
95,https://www.vice.com/en/article/akek7g/this-startup-is-selling-tech-to-make-call-center-workers-sound-like-white-americans,This Startup Is Selling Tech to Make Call Center Workers Sound Like White Americans,"On the Clock On the Clock is Motherboard's reporting on the organized labor movement, gig work, automation, and the future of work. See More →Continuing Silicon Valley’s long and storied history of misreading dystopian satires as instruction manuals, a startup has created a tech product that makes call center workers' voices sound white.The startup, called Sanas and founded by three former Stanford students, was first reported on by Joshua Bote for SFGate on Monday. On Sanas' website, you can “hear the magic”: a simulated conversation between a call center worker with an Indian accent that can be modified with a slider that applies Sanas’s accent translation. After Sanas is applied, the voice sounds more like a text-to-voice reader than another human being, but it does sound typically American and white.AdvertisementIn a demonstration for Motherboard, company President Massih Sarimand and COO Sharath Keysheva Narayana called an employee in India who talked about his background and work. Then the Sanasa filter was applied. It removed the employee’s accent and created a passable white and American-sounding voice, albeit a bit robotic.Sanas describes its approach as ""accent matching,"" and advertises on its website that it can ""improve understanding by 31% and customer satisfaction by 21%."" Apparently, the software can offer multiple accents at the touch of a button—although its demo only features an Indian accent being turned into typically white and American—and the company frames its technology as ""empowering"" workers. According to materials offered by the company to SFGate, the company claims to have garnered about $132 million worth of funding thus far.Ironically, given its focus on empowerment, Sanas' software to turn call center workers' voices into white American voices mirrors the plot of Boots Riley's 2018 dystopian satire Sorry to Bother You. In the film, the ability to put on a ""white"" voice on the phone allows the film's Black protagonist to rise up in the company, but introduces tension in the workplace that undercuts a union drive and eventually pits him against his former co-workers.In an interview with Motherboard, Sarim and Narayana sketched out their business strategy and explained why call centers were their first choice as clients.Advertisement""Call centers have a very specific speech pattern. You don't have people laughing, crying, singing—those nuances of speech are not there so it is easier to build it. The next use case is on enterprise communications. As we started going live with enterprise call centers, they said 'Hey we have teams in Asia, we have teams in Africa,'"" Naryana told Motherboard. ""We want to leverage a tool like this so that we can give them a choice and we want everybody to be heard. We want to build a very inclusive work culture and we think this could be an extremely great product and technology to actually bring people closer.""Call centers are heavily surveilled workplaces—dominated by “employee monitoring” which some are eager to argue is somehow beneficial for the workers. These workers suffer the brunt of a customer’s anger when something goes wrong but lack the autonomy to go beyond a script or narrow guidelines laid out by management. Viewed as disposable, closely surveilled, experiencing little if any autonomy, and forced to deal with angry or racist customers, call center workers typically burn out in a few months—when they don’t, their mental health suffers. The core question here, then, is what deploying Sanas will actually do to working conditions for call center workers.AdvertisementIt’s not hard to imagine scenarios where the introduction of Sanas results in companies demanding more of their workers because they now have “accent matching"" that is supposed to increase their performance with customers—a typical outcome when workplaces with minimal autonomy implement performance-boosting software. Narayana said increased performance would be a side-effect of Sanas' software, but it mainly has the potential to improve every aspect of this industry: call center labor conditions, the mental health of these workers, and the experience of customers on the phone.""I don't care about metrics, I think about mental health, employee satisfaction, retention, and overall employee happiness. All of those metrics are checked out for me,"" Narayana told Motherboard. ""I strongly believe once you keep your employees happy, all the business metrics will get better. So that's a secondary result of what we're trying to achieve. But the primary result for me is actually improving the lives of all these agents.""Sanas’s product doesn’t address the structural issues with call center work nor racism from callers, which its product implicitly side steps. Sanas acknowledges the potential for misuse of its software and says nobody will be ""forced"" to use it because workers themselves activate it with a button—however, this doesn't acknowledge the possibility of being forced to use it by default due to performance quotas. Sanas also says it has a ""code of ethics"" with three values: individual choice (it's activated by the worker), personal control (effectively the same point), and flexibility (Sanas offers multiple accents).The desire to communicate clearly and seamlessly with one another is understandable—as Sarim and Narayana reiterated to Motherboard multiple times, and as the website says, 80 percent of this company’s workers were immigrants. Sarim and Narayana have both worked call center jobs where they dealt with racism. The two insist this informs their end goal: not to simply have an accent translation engine that turns anything into white, American English (“many-to-one”) but one day to develop a translator for any accent to any accent (“many-to-many”).",0.0,0.0
462,https://techcrunch.com/2022/08/01/crypto-fraud-scam-forsage-ponzi-pyramid-scheme-sec-regulators-crackdown/,SEC spears âCrypto Crusadersâ over alleged pyramid scheme,"U.S. regulators are seizing their moment during this ongoing crypto bear market to crack down on bad actors in the space as many investors are already souring on the asset class.The U.S. Securities and Exchange Commission charged 11 people today in connection with Forsage, a crypto project that raised over $300 million from “millions of retail investors worldwide,” the agency announced today. The individuals charged include the project’s four founders — Vladimir Okhotnikov, Jane Doe aka Lola Ferrari, Mikhail Sergeev, and Sergey Maslakov — who were last sighted in Russia, Georgia and Indonesia. Several members of the “Crypto Crusaders,” a group that promoted the scheme in at least five different U.S. states were also charged, according to the announcement.Forsage was launched in January 2020 as a website that allowed retail investors to transact on the Ethereum, Tron and Binance blockchains, the SEC complaint says. In June 2020, Forsage was the most popular decentralized application on Ethereum and consumed so much bandwidth on the chain that it caused gas fees to spike. At the peak of its popularity in July 2020, over $20 million worth of ETH was sent to the platform in a single day, Dune Analytics data shows.According to the SEC, the project has operated as a pyramid scheme for more than two years and used assets from new investors to pay off old ones, typical of a Ponzi scheme structure. Operating a pyramid scheme, a fundamentally unsustainable business model wherein participants recruit others to buy in with the promise of quick returns, is illegal in the U.S.“Fraudsters cannot circumvent the federal securities laws by focusing their schemes on smart contracts and blockchains,” wrote Carolyn Welshhans, acting chief of the SEC’s Crypto Assets and Cyber Unit, a division of the SEC that rebranded to include crypto in its title and embarked on a hiring spree in May this year.This isn’t the first time Forsage has been in regulators’ crosshairs. The Securities and Exchange Commission of the Philippines sent the company a cease-and-desist order in 2020 for operating as a fraud and in 2021, the Montana Commissioner of Securities and Insurance did the same. Despite these warnings, the defendants kept promoting the scheme and denied that they were operating a pyramid scheme on various social media platforms, the SEC says.Besides the founders, Cheri Beth Bowen, Ronald R. Deering, Samuel D. Ellis, Mark F. Hamlin, Carlos L. Martinez, Alisha R. Shepperd and Sarah L. Theissen were all also charged with violating federal securities laws in connection with Forsage, according to the SEC complaint. Ellis and Theissen, the agency says, have agreed to settle the charges.The charges come at a time of heightened regulatory scrutiny over the digital asset space, particularly from the SEC itself. Coinbase has been locked in a battle with the agency over its sale of cryptocurrencies listed on its platform that it insists are commodities, not securities.Meanwhile, U.S. Senators Kirsten Gillibrand and Cynthia Lummis are seeking to build consensus in Congress for their bill that would classify most cryptocurrencies as commodities, bringing the industry largely under the jurisdiction of the U.S. Commodity Futures Trading Commission rather than leaving it open to the stricter SEC.",0.0,0.0
331,https://www.businessinsider.com/mark-zuckerberg-adds-legs-metaverse-avatar-after-graphics-criticism-2022-10,"Mark Zuckerberg showed his full avatar, which now has legs, in real-time for the first time after Meta was slammed for poor graphics","Meta CEO Mark Zuckerberg debuted the new metaverse avatars at the company's Connect conference.Zuckerberg's avatar featured legs, which he said was ""probably the most requested feature.""The company also announced a new $1,499 Quest Pro virtual reality headset, and new partnerships.Sign up for our newsletter for the latest tech news and scoops — delivered daily to your inbox. Loading Something is loading. Thanks for signing up! Access your favorite topics in a personalized feed while you're on the go. download the app Email address By clicking ‘Sign up’, you agree to receive marketing emails from Insider as well as other partner offers and accept our Terms of Service and Privacy PolicyMark Zuckerberg debuted his new avatar in real-time during Meta's Connect event on Tuesday.It was the first time the Facebook founder has held a public conference in Meta's Horizon World metaverse. Zuckerberg took the opportunity to announce the updated avatars, which he said will be rolled out later this year across phones and virtual reality headsets. He called the new avatars ""more expressive and detailed than anything else today.""The new avatars will also have legs, something Zuckerberg said was ""probably the most requested feature on our roadmap.""The metaverse avatars didn't have legs before because it was harder in virtual reality to accurately position where body parts like legs are, the Facebook founder said.""But seriously, legs are hard, which is why other virtual reality systems don't have them either,"" Zuckerberg said.Zuckerberg's announcement came just a few months after the billionaire was slammed on social media for an avatar he posted on Instagram. Social-media users were quick to diss the image which showed Zuckerberg's avatar standing in front of an Eiffel Tower, with some likening the graphics to 1990s video games like Zelda and Quake.Zuckerberg shared an updated metaverse avatar image Friday after being widely mocked for a previous version. Mark ZuckerbergAt the time, Zuckerberg responded with an updated avatar and admitted the previous image was ""basic.""""The graphics in Horizon are capable of much more — even on headsets — and Horizon is improving very quickly,"" Zuckerberg said in an Instagram post in August.Grimes also took the opportunity to slam Zuckerberg and his avatar, calling him ""under-qualified"" to run the metaverse and saying the billionaire's virtual reality plans are ""dead"" before they've truly begun.Earlier this week, The New York Times reported that Zuckerberg had fast-tracked a new avatar following the criticism, with one Meta graphic artist claiming in a since-deleted LinkedIn post that he and his team had designed roughly 40 versions of Mr. Zuckerberg's face over a four-week period before a final version was approved.""We started with simple graphics and we're doing a ton of work to meaningfully improve how Horizon will look and feel over the next year,"" Zuckerberg said at the Meta Connect event. ""The Metaverse needs to feel inspired.""But, Meta has faced headwinds in recent months, as the company's stock has been hammered amid Zuckerberg's new plans for the company. Shares of Meta neared a four-year low on Tuesday.Internal memos obtained by The Verge last week showed Meta's VP of the Metaverse, Vishal Shah, telling Metaverse employees working on the Horizon Worlds app they are on ""quality lockdown"" for the rest of the year to fix issues in the app before its released to more users.In one memo, Shah said the app's onboarding experience is ""confusing and frustrating."" Shah said employees working on the app weren't spending a lot of time on it.""Why don't we love the product we've built so much that we use it all the time,"" Shah wrote. ""The simple truth is, if we don't love it, how can we expect our users to love it?""The Facebook founder announced at the event that the new avatars will eventually be available via a partnership with Zoom, as well as on Android and Apple phones.During the event, Meta unveiled its new $1499 Quest Pro virtual reality headset. The company also announced several new partnerships with NBCUniversal and Microsoft, including a metaverse experience based on ""The Office"" and the opportunity for people to use Microsoft tools like Word and Excel in the metaverse.",0.0,0.0
282,https://techcrunch.com/2020/11/16/sequoia-backed-recycling-robot-maker-amp-robotics-gets-its-largest-purchase-order/,Sequoia-backed recycling robot maker AMP Robotics gets its largest purchase order,"AMP Robotics, the manufacturer of robotic recycling systems, has received its largest purchase order from the publicly traded North American waste handling company Waste Connections.The order, for 24 machine learning-enabled robotic recycling systems, will be used on container, fiber and residue lines across numerous materials recovery facilities, the company said.The AMP technology can be used to recover plastics, cardboard, paper, cans, cartons and many other containers and packaging types reclaimed for raw material processing.The tech can tell the difference between high-density polyethylene and polyethylene terephthalate, low-density polyethylene, polypropylene and polystyrene. The robots can also sort for color, clarity, opacity and shapes like lids, tubs, clamshells and cups — the robots can even identify the brands on packaging.So far, AMP’s robots have been deployed in North America, Asia and Europe, with recent installations in Spain and across the U.S. in California, Colorado, Florida, Minnesota, Michigan, New York, Texas, Virginia and Wisconsin.In January, before the pandemic began, AMP Robotics worked with its investor, Sidewalk Labs on a pilot program that provided residents of a single apartment building representing 250 units in Toronto with detailed information about their recycling habits.Working with the building and a waste hauler, Sidewalk Labs transported the waste to a Canada Fibers material recovery facility where trash is sorted by both Canada Fibers employees and AMP Robotics. Once the waste is categorized, sorted and recorded, Sidewalk communicates with residents of the building about how they’re doing in their recycling efforts.Sidewalk says that the tips were communicated through email, an online portal and signage throughout the building every two weeks over a three-month period.For residents, it was an opportunity to have a better handle on what they can and can’t recycle and Sidewalk Labs is betting the information will help residents improve their habits. And for folks who don’t want their trash to be monitored and sorted, they could opt out of the program.Recyclers like Waste Connections should welcome the commercialization of robots tackling industry problems. Their once-stable business has been turned on its head by trade wars and low unemployment. About two years ago, China decided it would no longer serve as the world’s garbage dump and put strict standards in place for the kinds of raw materials it would be willing to receive from other countries. The result has been higher costs at recycling facilities, which actually are now required to sort their garbage more effectively.At the same time, low unemployment rates are putting the squeeze on labor availability at facilities where humans are basically required to hand-sort garbage into recyclable materials and trash.AMP Robotics is backed by Sequoia Capital, BV, Closed Loop Partners, Congruent Ventures and Sidewalk Infrastructure Partners, a spin-out from Alphabet that invests in technologies and new infrastructure projects.",0.0,0.0
243,https://www.cnn.com/2022/10/02/us/solar-babcock-ranch-florida-hurricane-ian-climate/index.html,This 100% solar community endured Hurricane Ian with no loss of power and minimal damage,"CNN —Anthony Grande moved away from Fort Myers three years ago in large part because of the hurricane risk. He has lived in southwest Florida for nearly 19 years, had experienced Hurricanes Charley in 2004 and Irma in 2017 and saw what stronger storms could do to the coast.Grande told CNN he wanted to find a new home where developers prioritized climate resiliency in a state that is increasingly vulnerable to record-breaking storm surge, catastrophic wind and historic rainfall.What he found was Babcock Ranch — only 12 miles northeast of Fort Myers, yet seemingly light years away.Babcock Ranch calls itself “America’s first solar-powered town.” Its nearby solar array — made up of 700,000 individual panels — generates more electricity than the 2,000-home neighborhood uses, in a state where most electricity is generated by burning natural gas, a planet-warming fossil fuel.The streets in this meticulously planned neighborhood were designed to flood so houses don’t. Native landscaping along roads helps control storm water. Power and internet lines are buried to avoid wind damage. This is all in addition to being built to Florida’s robust building codes.Some residents, like Grande, installed more solar panels on their roofs and added battery systems as an extra layer of protection from power outages. Many drive electric vehicles, taking full advantage of solar energy in the Sunshine State.Climate resiliency was built into the fabric of the town with stronger storms in mind.So when Hurricane Ian came barreling toward southwest Florida this week, it was a true test for the community. The storm obliterated the nearby Fort Myers and Naples areas with record-breaking surge and winds over 100 mph. It knocked out power to more than 2.6 million customers in the state, including 90% of Charlotte County.But the lights stayed on in Babcock Ranch.“It certainly exceeded our expectations of a major hurricane,” Grande, 58, told CNN.A damaged building is seen in Babcock Ranch after Hurricane Ian. Courtesy Nancy ChorpenningAn uprooted tree in Babcock Ranch after Hurricane Ian. Courtesy Nancy ChorpenningSign up for CNN’s Life, But Greener newsletter.The storm uprooted trees and tore shingles from roofs, but other than that Grande said there is no major damage. Its residents say Babcock Ranch is proof that an eco-conscious and solar-powered town can withstand the wrath of a near-Category 5 storm.“We have proof of the case now because [the hurricane] came right over us,” Nancy Chorpenning, a 68-year-old Babcock Ranch resident, told CNN. “We have water, electricity, internet — and we may be the only people in Southwest Florida who are that fortunate.”Grande said Hurricane Ian came through southwest Florida “like a freight train.” But he wasn’t afraid that he would lose everything in a storm, like he was when he lived in Fort Myers.“We’re very, very blessed and fortunate to not be experiencing what they’re experiencing now in Sanibel Island and Fort Myers Beach,” Grande said. “In the times that we’re living in right now with climate change, the beach is not the place to live or have a business.”Solar successSyd Kitson, a former professional football player for the Green Bay Packers and Dallas Cowboys, is the mastermind behind Babcock Ranch. Kitson envisioned it to be an eco-conscious and innovative neighborhood that is safe and resilient from storms like Ian.The ranch broke ground in 2015 with the construction of the solar array — which was built and is run by Florida Power and Light — and its first residents moved into the town in 2018. Since then, the array has doubled in size and thousands of people have made Babcock their home.Around 700,000 solar panels power Babcock Ranch. Dennis Axer/Alamy“It’s a great case study to show that it can be done right, if you build in the right place and do it the right way,” said Lisa Hall, a spokesperson for Kitson, who also lives in Babcock Ranch.“Throughout all this, there’s just so many people saying, ‘it worked, that this was the vision, this is the reason we moved here,’” Hall told CNN.Perhaps the highest endorsement for the city is that it is now a refuge for some of Ian’s hardest-hit victims. The state opened Babcock Neighborhood School as an official shelter, even though it didn’t have the mandated generator. The solar array kept the lights on.Some of Chorpenning’s friends who live on Sanibel Island — which is now cut off from the mainland after Ian’s devastating storm surge severed the causeway — came to shelter at a friend’s house at Babcock Ranch. It will be a while before they can go back, she said.“They’re going to be renting a place over here for a while, while they figure out what’s going to happen out there,” she said. “I joked that we may be the only people in southwest Florida whose property value just increased.”Even Kitson chose to ride out the storm in Babcock to see how the community would fare in the hurricane. Kitson declined CNN’s request for an interview; Hall said he is focused on helping neighboring communities rebuild.“He was there during the storm; he said, ‘where else would I be?’” Hall said. “We built it to be resilient and as much as you plan and think you’ve done the right thing, you don’t know until you put it to the test.”Babcock Ranch has sold more than 2,000 homes, according to the neighborhood's website. Dennis Stephenson/AlamyAs utilities scramble to restore power across the state, Babcock residents say September storms showed that America’s energy infrastructure is not well-equipped to handle worsening extreme weather events. Hurricane Fiona ravaged Puerto Rico’s power grid when it made landfall there on September 18. Now, Ian has left millions of people in the dark in Florida.Babcock residents say their neighborhood is a model for urban development in a climate change-ravaged future.“It’s not what it was 20 or 25 years ago; the storms are getting bigger and bigger, and it’s no surprise, because the warnings have all been there,” Grande said. “I think Babcock Ranch’s future has gotten even brighter.”",0.0,0.0
395,https://techcrunch.com/2019/05/30/pitching-accuracy-rates-of-over-99-for-multiple-cancer-screens-thrive-launches-with-110-million/,"Pitching accuracy rates of over 99% for multiple cancer screens, Thrive launches with $110 million","For more than 25 years the founders of Thrive Earlier Detection have been researching ways to improve the accuracy of liquid biopsy tests.The fruits of that labor from Dr. Bert Vogelstein, Dr. Kenneth Kinzler and Dr. Nickolas Papadopoulos — all professors and researchers at Johns Hopkins University — is CancerSEEK, a liquid biopsy test that has demonstrated specificity of over 99% in a retrospective study published by Science.By minimizing false positives in cancer screening tools and providing a test with proven accuracy, doctors can take treatment actions earlier, which can lead to better survival rates for cancer patients.Now, with FDA approval for its tests for pancreatic and ovarian cancer and a new study underway with a large healthcare provider, CancerSEEK is being rolled out to market through Thrive Earlier Detection with the help of a new $110 million round of funding.Thrive works by analyzing highly targeted sets of DNA and proteins in the blood to detect cancer.“Over the past 30 years we have made great strides in understanding cancer. Combining this knowledge with the latest in molecular testing technologies, our founders have developed a simple and affordable blood test for the detection of many cancers at relatively early stages,” said Christoph Lengauer, PhD, partner at Third Rock Ventures, and co-founder and chief innovation officer of Thrive, in a statement. “We envision a future where routine preventative care includes a blood test for cancer, just as patients are now routinely tested for early stages of heart disease. We know that if cancer is caught early enough, it can often be cured.”As part of its rollout, the company’s screening tool is being evaluated in DETECT, a study of 10,000 currently healthy individuals that’s being conducted in conjunction with the healthcare organization Geisinger. So far, 10,000 women between the ages of 65 and 75 without a history of cancer have been enrolled in the trial.“To be truly useful to patients, new medical technology must be developed with rigorous evidence and designed to be affordable and readily integrated into routine medical care,” Steven J. Kafka, PhD, partner at Third Rock Ventures and chief executive officer of Thrive, said in a statement. “With the help of experts and strategic partners, Thrive is launching today to advance a novel test for the earlier detection of multiple cancers, which we aim to augment with an integrated service that helps patients maneuver the often confusing path that follows a cancer diagnosis.”Third Rock Ventures actually led the Series A financing for Thrive, and comprise the bulk of the company’s executive team, while Kinzler and Papadopoulos — the researchers from Johns Hopkins who developed the technology — will have seats on the company’s board.Other investors in the round include Bill Maris’ Section 32 investment firm, Casdin Capital, Biomatics Capital, BlueCross BlueShield Venture Partners, Invus, Exact Sciences, Cowin Venture, Camden Partners, Gamma 3 LLC and others.According to Thrive, ovarian, pancreatic and liver cancers are difficult to detect because they can develop in pathways that aren’t always well understood.Using CancerSEEK, Thrive hopes to develop a blood-based test that can be used in routine medical care, with the goal of identifying multiple cancer types at earlier stages.The technology works by following genomic mutations in circulating tumor DNA (ctDNA) and cancer-associated protein markers in plasma to identify abnormalities that are common across multiple cancers. In a retrospective study published by Science in 2018, CancerSEEK was shown to perform with greater than 99% specificity and with sensitivities ranging from 69% to 98% for the detection of five cancer types — ovarian, liver, stomach, pancreas and esophageal, which the company says are cancers for which there are no screening tests available for average-risk individuals.Thrive’s research has attracted an all-star executive team in addition to Lengauer and Kafka from Third Rock. Former Goldman Sachs lead medical technology analyst Isaac Ro is joining the company as chief financial officer, and the company’s head of research is Isaac Kinde, a co-inventor of the CancerSEEK technology.It’s hard to overstate how transformative the Thrive test could prove to be. Having a blood-based diagnostic test for cancer prevalence and the ability to initiate treatment earlier radically improves the chances for surviving a cancer diagnosis.",0.0,0.0
567,https://techcrunch.com/2016/08/23/logikcull-raises-10m-to-let-lawyers-analyze-documents-at-the-speed-of-a-thousand-interns/,Logikcull raises $10M to let lawyers analyze documents at the speed of a thousand interns,"As entertaining and interesting as made-for-TV lawsuits (like the O.J trial) are, they always leave out one key element. The hundreds of hours of research that goes on behind the scenes to prepare for an important trial.Before any big trial a lawyer (and their associates and interns) has to find, organize and examine thousands of documents. The process is officially called Discovery, and is a period when both sides gather and request all the information they think they will need for the trial.This information can look like anything from email databases to Powerpoints, and while some of the process has become computerized in recent years (aptly termed eDiscovery), it’s still remained pretty manual and inefficient.For example, eDiscovery may mean a team of associates combing through hundreds of pages of email correspondence on a screen, instead of printing it all out like lawyers used to do. A win for the environment yes, but still very, very time consuming and not really taking advantage of technology.But Logikcull is a software company trying to change this, and just closed $10M in Series A funding from OpenView Ventures and Storm Ventures to help.The company officially calls itself “cloud-based legal intelligence”, but is essentially Dropbox for the legal world.Lawyers can bulk-upload all the messy information they need to examine (even if it’s an entire hard drive of different types of files) and Logikcull will organize all the different file types into one searchable database.Need an example? Imagine uploading 1,000 pages of old contracts, then using a search engine to find the exact ones that are relevant to the case. Or uploading a 20 GB email database of tens of thousands of messages and narrowing it down to only the messages between people relevant in your case on a certain date from a certain device – you get the point.[gallery ids=""1373234,1373235,1373236,1373237""]Logikcull also uses OCR so you can upload old scanned documents that weren’t previously searchable.While originally designed for (and still mostly used by) lawyers, these tools obviously have applications in other industries. A company’s HR department could use it to sort through the thousands of documents typically involved in an internal investigation. Or a city could use it to quickly find documents related to specific FOIA requests, a process that is still sometimes done by hand. Letting a government employee quickly find the specific documents that were requested can turn a one month turnaround time for FOIA requests into just a few days.Essentially, the platform can be used for any task that requires you to organize and search a crazy amount of documents.The company charges per user, and a small law firm can expect to pay $15k-$30k per year. Expensive yes, but not if the alternative is paying hundreds of extra hours in legal fees at $600 per hour.Logikcull says they are signing up new clients at a rate that has grown revenues 3x year-over-year, which is impressive considering how expensive the service. But that’s the thing about legal tech – the alternative is so crazy expensive that startups can charge an arm and a leg as long as they are providing a solution that actually save time.",0.0,0.0
124,https://www.newscientist.com/article/2337042-two-atomic-clocks-have-been-quantum-entangled-for-the-first-time/,Two atomic clocks have been quantum entangled for the first time,"Researchers have quantum entangled atomic clocks, allowing them to be synchronised more accurately. Such entangled clocks could be used to study dark matter and gravity more preciselyAtomic clocks use lasers and atoms to record time extremely accurately Andrew Brookes/National Physical Laboratory/Science Photo LibraryTwo atomic clocks have been connected using quantum entanglement – a property that intrinsically links them so that changes in one instantaneously affect the other. The connection makes it easier to synchronise the clocks, which could be used to make more accurate measurements of dark matter and gravity.Atomic clocks consist of atoms that are very precisely controlled by lasers. Each “tick” corresponds to a frequent and measurable change in energy that occurs in the atoms’ electrons. The result is …",0.0,0.0
410,https://www.freethink.com/health/oxfords-malaria-vaccine,Breakthrough drug could save hundreds of thousands of childrenâs lives,"A malaria vaccine developed by researchers at the University of Oxford continues to impress, with a booster dose demonstrating up to 80% efficacy in children in a trial with over a year of follow-up.The challenge: Malaria is a parasitic disease spread by mosquitoes. While it’s already eradicated in many parts of the world, it’s still a major threat in Africa, killing more than 600,000 people every year.About half of all malaria deaths are children under the age of five, and even if a child survives their first malaria infection, they’re often reinfected. This repeated battle can take a toll on their immune systems and leave them vulnerable to other illnesses.The only approved malaria vaccine is a shot made by British drugmaker GSK, and it’s only 40% effective. GSK is also only committed to supplying 15 million doses annually, but 25 million children are born in Africa alone every year, and each needs multiple doses.About half of all malaria deaths are children under the age of five.Oxford’s vaccine: In 2019, 450 children between the ages of 5 months and 17 months participated in a phase 2b trial of Oxford’s malaria vaccine (R21/Matrix-M) in the African nation of Burkina Faso.The children were split into three groups. Two groups received a three-shot regimen of Oxford’s malaria vaccine, combined with either a high or low dose of an immunity-boosting adjuvant. The third group received a rabies vaccine as a control.Oxford reported that the vaccine with the high dose of the adjuvant was up to 77% effective at preventing clinical malaria over 12 months of follow-up — making it the first malaria vaccine to reach the World Health Organization’s goal of 75% efficacy.What’s new? In June 2020, 409 of the participants in Oxford’s trial were given booster shots of the same type of vaccine they received initially (i.e., if their primary vaccination was with the high dose of the adjuvant, so was their booster shot).Oxford has now reported that the booster with the high adjuvant dose was 80% effective over 12 months of follow-up, while the lower dose was 70% effective, meaning the initial three-shot regimen plus a booster results in at least two years of robust protection.“Without this investment, we risk losing the gains that have been made over the last decades.” Azra GhaniLooking ahead: Results from a phase 3 trial involving 4,800 children — ranging in age from 5 months to 36 months and living in four African nations — are expected in another few months. Those will be key to getting Oxford’s malaria vaccine approved by regulators.If the shot is approved, the Serum Institute of India, one of the world’s biggest vaccine makers, is ready to manufacture 200 million doses annually starting in 2023, and study co-author Adrian Hill told BBC News the vaccine should cost just “a few dollars” to produce.The bottom line: Oxford’s malaria vaccine could be huge in the fight against this deadly disease — but only if health officials are able to secure the funding needed to get the shots into arms.“Without this investment, we risk losing the gains that have been made over the last decades and witnessing a rising tide of malaria resurgence,” Azra Ghani, chair in infectious disease epidemiology at Imperial College London, who isn’t involved in Oxford’s vaccine, told BBC News.We’d love to hear from you! If you have a comment about this article or if you have a tip for a future Freethink story, please email us at [email protected].",0.0,0.0
352,https://medicine.yale.edu/news-article/study-reveals-how-genetics-impacts-susceptibility-to-developing-ptsd-following-trauma-exposure/,Study Reveals How Genetics Impacts Susceptibility to Developing PTSD Following Trauma Exposure,"Stem cell-derived neurons from combat veterans with and without post-traumatic stress disorder (PTSD) provide insights into how genetics can make someone more susceptible to developing PTSD following trauma exposure, according to a study conducted by scientists from several research institutions, including Yale School of Medicine.Post-traumatic stress disorder can develop following severe trauma and is an enormous public health problem for both veterans and civilians. However, the extent to which genetic and environmental factors contribute to individual clinical outcomes remains unknown.To bridge this information gap, the research team studied a cohort of 39 combat veterans with and without PTSD who were recruited from the James J. Peters Bronx Veterans Affairs Hospital. Veterans underwent skin biopsies and their skin cells were reprogrammed into induced pluripotent stem cells.“Reprogramming cells into induced pluripotent stem cells is like virtually taking cells back in time to when they were embryonic and had the ability to generate all the cells of the body,” said Rachel Yehuda, PhD, professor of psychiatry and neuroscience at Icahn Mount Sinai, director of mental health for the Department of Veterans Affairs and senior author of the paper. “These cells can then be differentiated into neurons with the same properties as that person’s brain cells had before trauma occurred to change the way they function. The gene expression networks from these neurons reflect early gene activity resulting from genetic and very early developmental contributions, so they are a reflection of the ‘pre-combat’ or ‘pre-trauma’ gene expression state.”“Two people can experience the same trauma, but they won't necessarily both develop PTSD,” said Kristen Brennand, PhD, Elizabeth Mears and House Jameson Professor of Psychiatry at Yale School of Medicine who co-led the study. “This type of modeling in brain cells from people with and without PTSD helps explain how genetics can make someone more susceptible to PTSD.”Published October 20 in Nature Neuroscience, this is the first study to use induced pluripotent stem cell models to study PTSD.The study involved researchers from Yale School of Medicine, Icahn School of Medicine at Mount Sinai, the Office of Veterans Affairs, and The New York Stem Cell Foundation Research Institute (NYSCF).To mimic the stress response that triggers PTSD, the scientists exposed the induced pluripotent stem cell-derived neurons to the stress hormone hydrocortisone, a synthetic version of the body’s own cortisol that is used as part of the ‘fight-or-flight’ response.“The addition of stress hormones to these cells simulates biological effects of combat, which allows us to determine how different gene networks mobilize in response to stress exposure in brain cells,” Yehuda said.Using gene expression profiling and imaging, the scientists found that neurons from individuals with PTSD were hypersensitive to this pharmacological trigger. The scientists also were able to identify the specific gene networks that responded differentially following exposure to the stress hormones.Most similar studies of PTSD to date have used blood samples from patients, but since PTSD is rooted in the brain, scientists need a way to capture how the neurons of prone individuals are affected by stress. Therefore, the team opted to use stem cells, as they are uniquely equipped to provide a patient-specific, non-invasive window into the brain.You can’t easily reach into a living person’s brain and pull out cells, so stem cells are our best way to examine how neurons are behaving in a patient. Kristen Brennand, PhD, Elizabeth Mears and House Jameson Professor of Psychiatry at Yale School of Medicine“You can’t easily reach into a living person’s brain and pull out cells, so stem cells are our best way to examine how neurons are behaving in a patient,” Brennand said.NYSCF scientists used their scalable, automated, robotic system – The NYSCF Global Stem Cell Array® – to create stem cells and then glutamatergic neurons from patients with PTSD. Glutamatergic neurons help the brain send excitatory signals and have previously been implicated in PTSD.“As this was the first study using stem cell models of PTSD, it was important to study a large number of individuals,” said Daniel Paull, PhD, NYSCF Senior Vice President, Discovery & Platform Development, and co-leader of the study. “At the scale of this study, automation is essential. With the Array, we can make standardized cells that allow for meaningful comparisons between numerous individuals, pointing to key differences that could be critical for discovering new treatments.”The team’s gene expression analysis revealed a set of genes that were particularly active in PTSD-prone neurons following their exposure to stress hormones.Moreover, the distinctions between how PTSD and non-PTSD cells responded to stress could be informative in predicting which individuals are at higher risk for PTSD.The researchers plan to continue leveraging their induced pluripotent stem cell models to further investigate the genetic risk factors pinpointed by this study and to study how PTSD affects other types of brain cells, helping to broaden opportunities for therapeutic discovery.“What’s special about this study is that it could have only been done by this group,” Brennand said. “It involved some of the best clinicians in this space, incredible stem cell biologists, and amazing psychiatric geneticists. Each group has unique expertise, and none of this could have been accomplished by any one team alone.”“This study is a true testament to the power of team science,” Paull said. “When researchers combine forces, we are able to ask bigger questions, make bigger discoveries, and hopefully, make a bigger difference for patients.”This work was supported by a grant to the Icahn School of Medicine at Mount Sinai from the U.S Army Medical Research Department of Defense.",0.0,0.0
467,https://techcrunch.com/2022/09/12/is-the-glass-half-empty-or-half-full-in-the-seed-market/,Is the glass half-empty or half-full in the seed market?,"New data from Carta indicates that valuations for very early-stage startups are holding up better than we might have expected in the current slowdown.But while it appears that the price at which investors are willing to put capital into various startup sectors is at times becoming more expensive, the pace at which deals are happening is slowing enough that the changing value of seed deals actually makes sense.Call it the glass half-full/glass half-empty seed market. If you are bullish, there’s good news aplenty. And if you are bearish, well, we have enough data to make that argument as well.",0.0,0.0
202,https://techcrunch.com/2016/12/06/open-bionics-partners-with-nhs-for-a-feasibility-study-to-bring-bionic-hands-to-the-u-k-health-system/,Open Bionics partners with NHS for a feasibility study to bring bionic hands to the U.K. health system,"Open Bionics partners with NHS for a feasibility study to bring bionic hands to the U.K. health systemOpen Bionics is a U.K. startup making bionic hands for patients needing prosthetics and co-founder of the company Samantha Payne came onstage today at TechCrunch Disrupt London to tell us about a new deal between Open Bionics and the National Health Service (NHS) to bring new technologies to amputees.The deal involves a feasibility study with the NHS through SBRI Healthcare to see if Open Bionics can provide a multi-grip bionic hand to amputees for significantly less money, possibly saving the NHS millions of pounds — a significant development considering hospital-grade myoelectric hands and limbs can cost up to $100,000 in some cases, take a long time to get and don’t always fit well.Open Bionics hands and limbs can produce its robotic hands in a matter of days and for a few thousand dollars.Open Bionics came out of Disney’s TechStars accelerator program with a plan to dramatically lower the cost of prosthetics using a combination of open-sourced 3D printing software and robotic sensors.We visited Open Bionics during its time with Disney. You can see that interview here:The startup began developing robotic arms with fun themes for children such as Disney’s Frozen and Star Wars with the goal to help kids missing body parts to have something fun and enjoyable to show to their peers.Daniel Mellville, who later joined Payne on stage said he wanted the other kids to say to those wearing an Open Bionics prosthetic, “What is this, how does it work and why can’t I have one?”Open Bionics said it managed to keep afloat by winning pots of money set aside in government programs and through the Techstars accelerator in the last few years of its existence but is now raising its first seed round. A seed round will help the company to grow, conduct medical testing and the several mechanical and electrical engineers needed to carry out bigger ambitions.Though Payne didn’t want to give specifics on what the company is working on next, one of the endeavors she mentioned has to do something with video games.“In video games, people even choose to lose a limb,” Payne pointed out.Open Bionics also said it wants to start building lower limbs. “There’s a huge range of robotic tech and it could be made cheaper,” Payne said.[gallery ids=""1424630,1424611,1424610,1424609,1424608,1424607,1424606,1424605,1424604,1424603""]",0.0,0.0
134,https://www.techspot.com/news/96463-5g-users-think-technology-has-overhyped-many-fail.html,"Some 5G users think the technology has been overhyped, fail to notice speedÂ improvements","In brief: Remember when 5G was just about to roll out and companies promised it would revolutionize the world? Now that it's seeing more widespread adoption, do you agree with those claims? According to a new study, many people feel 5G connectivity is overhyped and have failed to notice any speed or reliability improvements since upgrading.Research from UK-based price comparison service and switching website Uswitch found that one in six 5G users feel the technology doesn't live up to its promise. Less than half said they notice faster speeds or more stable connections since jumping to the fifth-generation cellular network.One of the problems with 5G has long been its coverage in rural areas. That's an issue everywhere mobile networks are found, including the UK, where 17% of those who live outside of urban areas say they've never been able to connect to a 5G signal—three times more than those in cities.Some mobile users in the countryside can't even get reliable connections to older networks. Only 48% of people in the county of Yorkshire said they could access 4G reliably, and 14% said they often had to revert to 2G.5G advocates have talked about its lower latency and higher speeds enabling more applications for consumers, including the use of mobile virtual and augmented reality. Many point to the metaverse as one of the biggest areas that will benefit from 5G connectivity. But most people remain apathetic towards the concept, and a recent report predicting most business projects in this virtual realm will close by 2025 hasn't helped increase enthusiasm.While it might not be living up to the hype for some users, 5G still has the distinction of being the fastest-growing mobile communications technology ever. Ericsson said coverage reached roughly 25% at the end of 2021, hitting the milestone about 18 months faster than 4G. 5G is also expected to have around one billion users by the end of the year.Part of the reason why people feel somewhat disappointed in 5G is that we're yet to see its full potential; the technology is still in its relative infancy. As 5G expands—it's expected to be the dominant network with 4.4 billion users by 2027—so will the number of applications that take advantage of it. At least that's the plan.",0.0,0.0
382,https://interestingengineering.com/health/breakthrough-cancer-research-dark-matter,Major breakthrough in cancer research: Papers reveal 'dark matter' that contributes to disease's growth,"Professor Trevor Graham, Director of the Centre for Evolution and Cancer at the Institute of Cancer Research (ICR), said in a statement: ""We've unveiled an extra level of control for how cancers behave – something we liken to cancer’s 'dark matter.' For years, our understanding of cancer has focused on genetic mutations which permanently change the DNA code. But our research has shown that the way the DNA folds up can change which genes are read without altering the DNA code and this can be very important in determining how cancers behave.""The research was led by scientists at The Institute of Cancer Research, London, Human Technopole in Milan, and the Queen Mary University of London.Epigenetic changes are involved in cancer's evolutionIn the first paper, the researchers collected 1,373 samples from 30 bowel cancers and looked at epigenetic changes as cancers grew. Their observations showed that epigenetic changes are common in cancerous cells, are heritable, and were present in cancer cells that had ""survival advantages.""The second paper intended to study why cancer cells within the same tumor can be different from one another. So, the researchers looked at the DNA sequence in diverse samples taken from different parts of the same tumor. The study revealed that less than two percent of ""changes in the DNA code in independent areas of a tumor were associated with changes in gene activity and variation in cancer cell characteristics throughout tumors is often governed by factors other than DNA mutations"".With these studies, scientists were able to track the influence of epigenetic control on the growth and evolution of bowel cancers. They also noted that epigenetic changes are heavily involved in cancer's evolution.""I hope our work will change the way we think about cancer and its treatment – and should ultimately affect the way patients are treated. Genetic testing for cancer mutations only gives us part of the picture about a person’s cancer – and is blind to ‘epigenetic’ changes to how genes are read. By testing for both genetic and epigenetic changes, we could, potentially, much more accurately predict which treatments will work best for a particular person’s cancer,"" said Graham.",0.0,0.0
40,https://techcrunch.com/2022/08/04/bill-gates-breakthrough-energy-terabase-robot-solar-farms/,Bill Gatesâ Breakthrough Energy backs Terabaseâs robot-built solar farms,"Breakthrough Energy Ventures, a climate-focused VC firm linked to some of Earth’s wealthiest individuals, has joined a $44 million bet on solar startup Terabase Energy.Terabase aims to rapidly build new solar farms “at the terawatt scale,” CEO Matt Campbell said in a statement. The startup claims its automated, on-site factory can already speed up plant construction and cut costs by employing robotic arms that lift and connect heavy solar panels to sun trackers. When asked for photos of the insides of its factory, Campbell pointed TechCrunch to previously published aerial pics and declined to share more, “for competitive reasons.”Terabase also makes software tools to manage the design and construction of solar farms. The startup recently wrapped its first commercial project, where its robots reportedly installed 10 megawatts worth of panels. There are one million megawatts in a terawatt, so the startup still has a long way to go to reach its aspirations.Breakthrough Energy Ventures was founded by Bill Gates, and its board members include Jeff Bezos and Masayoshi Son. The VC firm co-led the Terabase deal alongside Lime and Amp Robotics investor Prelude Ventures.Their investment comes as rich folks face scrutiny for their outsized climate pollution. Gates’ private jet might not be as active as Taylor Swift’s, yet the Microsoft co-founder reportedly owns several and has called private flying his “guilty pleasure.”Other recent deals for solar energy startups include panel installer Zolar ($105 million) and solar network developer Okra ($2.1 million).",0.0,0.0
25,https://www.igorslab.de/en/evga-pulls-the-plug-with-loud-bang-yet-it-has-long-been-editorial/,"EVGA pulls the plug with a loud bang, but it has been stewing for a long time | Editorial","If you want to (or have to) separate, then there are two ways to announce this: one emotionless and one where you once again seek the big stage. EVGA chose, what a coincidence, the time shortly before NVIDIA’s in-house exhibition GTC (after that, the whole thing would have gone down a bit) to drop the bombshell that wasn’t really a bombshell anymore. This media uprising and aftermath is really just the long overdue flashback after a smoldering fire that lasted for months and in which the green fuse was even shorter than Jensen’s wood screws in his old Fermi mock up.I thought long and hard about whether to write something about it (and about what), because I also have my own private opinion about the circumstances in general and EVGA’s appearance in particular, which has been formed in the last few years also due to my own experiences. That’s why I also used the weekend to chat or talk on the phone with one or the other competitor and colleague, in addition to all the benchmarks. Because the way in which and where the reason is now located and the way in which a suitable culprit is presented at the same time has caused quite a stir among many people. It’s not about defending NVIDIA, but using Jensen as the ideal object of hatred is a bit short-sighted and only distracts from one’s own failures. But you have to throw something down the throat of the investors and brand-affine customers. And that’s where the green leather jacket Hulk is best suited.My colleague Stephen Burke from Gamersnexus has actually already said most of it, I don’t need to dissect and regurgitate that again. I’ll just post the short quote from EVGA CEO Andrew Han again now before I get my own thoughts on it.We are not going to be on Jensen’s lap on stage, so I don’t want people to speculate what’s going on….EVGA has decided to nat carry the next gen. (Andrew Han, CEO)The business model: Let others do itIn principle, EVGA is nothing more than a brand without its own production. Of course, the company has its own R&D department for the engineering, but the level of creativity is not particularly high here either, if you only have to rely on the abilities of third parties in the end, be it the circuit boards, the coolers and the complete production as the final implementation. Unfortunately, having it done instead of doing it yourself costs money. And while this very concept mitigates risk and effort in manufacturing, it also reduces the margin that can still be achieved with such a highly complex product. Therefore, I asked several competitors and found out that the currently achievable margins in the worst case (like EVGA) are still 5%, and up to 10% for the do-it-yourself manufacturers, who can manage an own production.This is not less than in 2021 or 2020, only this year merchandise sales have dropped significantly due to orders staying away and a change in demand. However, that one produces at a loss because of NVIDIA’s money-grubbing claws, as EVGA colports, is considered by many to be an urban legend. These are rather homemade problems with faulty designs and a RMA rate that was beyond good and evil. I don’t want to quote myself again, but the disaster with Amazon’s New World and the scorched circuit boards was expensive, really expensive. To attach this to every card as a loss is definitely too short-sighted.Let’s say they made 10x profit than normal business last year, if you are the boss, will you quit now or waste another 10 years just to make the same profit amount last year? (Competitor)The business of brands is actually like the good old stock market business, because you should sell at the peak and best take what is still to be taken. If you have to buy almost all services at a high price, there is not much left in the graphics card business. A large manufacturer (not EVGA) easily produces around 200,000 graphics cards per week, which puts the 5 to 10 percent in a different light. In the system gastronomy, business also only works via sheer mass, which is no different with graphics cards. However, EVGA lacks exactly this mass (which can also be seen as a buffer), which can cushion smaller outliers.If you ask the competitors why they haven’t copied EVGA’s warranty, upgrade and exchange model as well, you actually only see grinning faces or shaking heads. Statements such as “economic suicide by default” are still the most polite thing to say. I wrote that the cards have become more and more complex and that the risk of failure has increased dramatically as a result. Therefore, the RMA processes do not become more favorable, on the contrary. Goodwill and generosity, as EVGA has made its trademark, must also be afforded and what was manageable 10 years ago can end in collapse any day today. House of cards and all. Here, EVGA simply lacks the critical mass to easily pull off something like this financially. Being the US market leader is all well and good, but how big is the DIY market there?If it were profitable, we would have done it long ago (Competitor)Peripherals and power supplies are much easier to keep track of and now offer much higher margins of up to 30 percent. Power supplies are just the new thermal paste and the run is still properly fueled by ATX 3.0. Speaking of power supplies, I remember how EVGA at the time (this was back in the Kepler days) made the sampling of graphics cards dependent on a positive review of the newly introduced power supplies. Back then, I was still writing for Tom’s Hardware and very stubbornly resisted the “reward for award” system. At that time, however, the “Just buy it!” philosophy did not yet exist there and one was still allowed to do such things as a reviewer.As a result, I was then excluded from sampling for a few years. By the way, I’m still alive, which shows once again that you don’t have to go along with something like that if you don’t want to. I also don’t want to repeat how EVGA products later failed my tests and the engineering used my findings (pad mod, area increase on the cooling frame, RAM monitoring in the ICX design), but the PR kicked nasty in my direction. I never asked for money for my support, but would probably have been happy to receive a thank you now and then. By the way, this is exactly where you notice the difference between a US company like EVGA and a German medium-sized company. EVGA is extremely profit-oriented, and when things don’t go so well, they just part with a division. By the way, this is not reprehensible, but the explanations should then also be more honest.The Green Light Program as a buzzkillAnd what does NVIDIA have to do with it now? Yes, even the competitors are properly pissed off that they still don’t know NVIDIA’s prices and don’t know at which dumping or scalper rate Master Jensen will beat his new Ada into the market as a playmate (depending). That’s why you won’t see so many completely new designs, and what I had already called “Playground” in the GeForce RTX 3090 Ti will mostly be continued. This is then economic prudence and not even stupid. EVGA could have thought of that as well.However, you also have to know that NVIDIA strives for total control and also mercilessly enforces these policies. There isn’t much room left for technical gimmicks á la EVGA’s special models and both sides have clashed hard not only once. EVGA always explores how far you can go and NVIDIA then intervenes to correct the situation. I have already explained this in detail in the article linked above and I don’t want to repeat myself. However, it is also a fact that NVIDIA only provides replacements if you follow “NVIDIA’s rules”. You can approve of this or not, but it leads (at least in theory) to more durable products.Things like EVGA’s Kingpin models break those rules, but that’s where they’ve found a clever loophole because it’s effectively declared a mod. Galax does the same with the HoF series. Various overclockers give their face for it (for good money) and it is not a consumer product. That’s why you don’t get a real HoF including unlimited OC tool as a normal customer, but only the “roadworthy” version under the same name. The rest is then expensive cannon fodder for the LN2 artillery. Such marketing escapades also cost money, of course, even if they can boost the company’s image. The good Kingpin must now look for another place in the money rainforest, but the choice is rather manageable there.I didn’t really want to go that far, but once you’re in such a nice writing flow, the shore you’re aiming for gets further and further away. In order to come to some kind of conclusion at the end, I’ll make it simple for myself, because I can perhaps also question some things differently: It is certainly not a loss for me (and many others), because it became apparent that the model practiced for years would no longer have been financially viable in this way. And before one admits this publicly and meekly, one looks for the last big performance and says goodbye to the shocked audience with a big bang. I only hope that all previous customers will still be dealt with gallantly and treated fairly. Then it will surely work out with the power supplies, housings and other stuff.After all, I haven’t heard from any other small Jensen exclusive customers that they now have to throw in the towel for the reasons I mentioned. But they can probably calculate better and also produce themselves. It is a pity about a colorful facet on the graphics card market, which I will also miss, but the customer will get over it.",0.0,0.0
430,https://www.psypost.org/2022/11/mothers-who-spend-more-time-on-social-media-sites-about-motherhood-experience-higher-stress-hormone-levels-study-finds-64206,"Mothers who spend more time on social media sites about motherhood experience higher stress hormone levels, study finds","A study published in the journal Biological Psychology suggests that exposure to social media content about motherhood can trigger a sense of threat among mothers, activating the body’s stress response. The study found that more time spent on social networking sites devoted to motherhood was associated with increased cortisol output among mothers.During social interactions, people frequently fall victim to social comparison — they begin comparing themselves to the people around them and making self-judgments. These self-evaluations can lead to negative feelings, particularly when they stem from upward social comparisons — comparisons to people who seem better off than oneself.Social self-preservation theory says that when a social situation threatens a person’s self-concept, this activates the hypothalamic-pituitary-adrenal (HPA) axis and stimulates the release of cortisol. Accordingly, study author Nataria T. Joseph and her co-authors wanted to test whether engaging in social comparison has a measurable impact on a person’s cortisol levels.“This project is the third of a series of projects that we executed together, with the aim of examining the complex nature of and multifactorial, biopsychosocial implications of social media use among first time mothers,” explained Joseph (@_NoCrystalStair), an associate professor at Pepperdine University who holds the Blanche E. Seaver Professor of Social Science professorship.“My collaborator Dr. Lauren Amaro‘s initial interest in the online exchanges that occur between mothers regarding parenting sparked the overall series of studies,” Joseph continued. “This last study in the series was focused on the biological health implications of these exchanges and based in my previous work using ecological momentary assessment to study daily life moments and cortisol hormone levels.”Joseph and her colleagues launched a study to explore how social comparisons occurring within the context of technology — such as social networking sites — might influence momentary cortisol levels. Since women are particularly affected by social comparison, and since social comparison and self-evaluation are common during motherhood, the researchers focused their study on mothers.“Our prior research has shown that social networking sites for moms include a range of messages about motherhood, including both positive and negative emotion,” said co-author Theresa de los Santos. “Social networking sites also provide potential community for support in which a mother might feel belonging within particular groups.“However, intensive mothering norms that influence social roles and identities can clash through social comparison practices to lower parenting satisfaction. This led us to investigate in our current study how comparisons and emotions that mothers experience on these sites and in other technology-based interactions influence a mother’s health through monitoring of the stress hormone, cortisol.”The researchers used a technique called ecological momentary assessment (EMA) to capture naturalistic experiences in daily life. The study sample consisted of 47 mothers with an average age of 34 who reported being exposed to “online content about motherhood” for at least 6 days a week. Mothers were asked to indicate how many minutes a day they spent on social networking sites or online forums in the past week. They then participated in a 4-day study where they completed short surveys and provided saliva samples four times a day — upon awakening, 4 hours after awakening, 9 hours after awakening, and at bedtime.At each survey, the participants indicated the time of their most recent technology-mediated social exposure (TMSE) about motherhood. They were asked to include “communication on social networking sites, online forums, email, texts, or any other technology and passive exposure to communications about motherhood or parenting.” The participants also responded to questions concerning the emotions they had experienced during the TMSE interaction, and any social comparisons they had made regarding motherhood.“Participants were very active on social media, with 55.3% spending at least 2 hours daily on social networking sites for mothers and 46.8% using social networking sites for mothers at least 4 times a day,” said de los Santos. “This gave us a tremendous amount of data about their technology-driven, day-to-day interactions as well as their biological data at various points throughout the day.”The researchers found that higher negative emotions during TMSE was associated with higher cortisol. Participants who self-reported more time spent on social networking sites or online forums in the past week also had higher momentary cortisol levels, as well as higher average daily cortisol output. The authors note that on these online sites, mothers often express negative emotions like anger and sadness. Exposure to these negative emotions might lead mothers to feel a heightened sense of threat, triggering self-preservation.“Social comparison is very frequent in contemporary society, and inevitable as we interact with others,” Joseph explained. “They are especially salient when we face new roles in life, such as becoming a mother for the first time. So, we hope that putting a spotlight on social comparison will make individuals pause and reflect on their social comparison tendencies and find healthy ways of making comparisons so that individuals don’t have to experience negative emotions when comparing themselves to others.”“We believe there are responsible ways of engaging with social exchanges on social media and other websites. First, being one’s authentic self on these platforms not only validates one’s self but also contributes to creating an online community in which individuals can see that others struggle and are flawed. Second, if an individual monitors his or her emotions as he or she interacts with these online platforms, that individual will be better able to recognize when his or her social comparisons are becoming unhealthy.”The results also revealed that, at a momentary level, higher engagement in social comparison during TMSE was tied to lower cortisol.Interestingly, these findings suggest that social comparison may not be detrimental on its own. While experiencing increased negative emotions during TMSE was associated with heightened cortisol levels, engaging in social comparison without increased negative feelings was not. Moreover, downward social comparisons — comparisons to mothers who are doing worse than themselves — appeared to alleviate the stress response. Mothers who reported engaging in more downward social comparisons than other participants had lower momentary cortisol levels.“We were surprised that social comparisons were associated with lower cortisol (an important stress hormone with many implications) as we hypothesized that it would be associated with higher cortisol,” Joseph told PsyPost. “One must keep in mind though, that we controlled for negative emotions in our analyses. So, the results really show that social comparisons that are not accompanied by spikes in negative emotion are associated with lower cortisol. Thus, there are some healthy ways of engaging in social comparison that protect a person’s self schema and emotional wellbeing. These healthy ways of comparing are associated with lower cortisol.”Joseph and her colleagues warn that their study results have worrying implications for mothers since heightened cortisol can damage a person’s health over time and even increase mortality risk. The results also have implications for young children, since mothers with high cortisol levels tend to have children with high cortisol levels as well.“There are certainly benefits and drawbacks to TMSEs. Based on our H.O.M.E.S. (Health Outcomes for Mothers’ Exchanges on Social Media) program and other research in the area, my advice is for mothers to first decide if the online space is the best place to seek support, given their existing tendencies to compare and their existing interpersonal relationships,” Amaro told PsyPost.“For instance, a person who is prone to upward comparison, or the practice of seeing others as ‘doing better’ while perhaps feeling inadequate in a particular role can find herself experiencing more negative emotion and less satisfaction in her parenting when engaging with these sites. She might be best suited to an in-person mom group or to relying on family members or neighbors when she needs support.”“The second step in deciding whether to go online for support or not is to determine your intention or need,” Amaro continued. “If a mom needs practical information (hey Facebook group, which pediatricians do you recommend?), online mom groups can be a wealth of knowledge and advice, though discernment is necessary. If it’s friendship or reduced feelings of isolation, some online mom groups can also be wonderfully encouraging places to make “real-life” friends, but some are not. Moms should explore the culture of a group prior to engaging. It’s always worth questioning why and what you’re scrolling.”Future studies will be needed to potentially replicate the results and expand on the current findings. The authors suggest that potential interventions for mothers might include, “educating mothers on limiting TMSE engagement, pursuing healthier self-evaluation that recognizes strengths and weaknesses in parenting thereby promoting healthier social comparison, and the management of negative emotion when engaging messages about motherhood.”The study, “Naturalistic social cognitive and emotional reactions to technology-mediated social exposures and cortisol in daily life”, was authored by Nataria T. Joseph, Theresa de los Santos, and Lauren Amaro.",0.0,0.0
89,https://www.theguardian.com/society/2022/sep/07/woman-who-can-smell-parkinsons-helps-scientists-develop-test,âWoman who can smell Parkinsonâsâ helps scientists develop test,"Scientists have harnessed the power of a woman’s hyper-sensitive sense of smell to develop a test to determine whether people have Parkinson’s disease.The test has been years in the making after academics realised that Joy Milne could smell the condition. The 72-year-old from Perth, Scotland, has a rare condition that gives her a heightened sense of smell.She noticed that her late husband, Les, developed a different odour when he was 33 – 12 years before he was diagnosed with the disease, which leads to parts of the brain become progressively damaged over many years.Milne, nicknamed “the woman who can smell Parkinson’s”, described a musky aroma, different from his normal scent.Her observation piqued the interest of scientists who decided to research what she could smell, and whether this could be harnessed to help identify people with the neurological condition.Years later, academics at the University of Manchester have made a breakthrough by developing a test that can identify people with Parkinson’s disease using a simple cotton bud run along the back of the neck.Researchers can examine the sample to identify molecules linked to the disease to help diagnose if someone has it.Though still in the early phases of research, scientists are excited about the prospect of the NHS being able to deploy a simple test for the disease.There is no definitive test for Parkinson’s and diagnosis is based on a patient’s symptoms and medical history.If the skin swab is successful outside laboratory conditions it could be rolled out to achieve faster diagnosis.Milne said it was not acceptable that people with Parkinson’s had such high degrees of neurological damage at the time of diagnosis, adding: “I think it has to be detected far earlier – the same as cancer and diabetes, earlier diagnosis means far more efficient treatment and a better lifestyle for people.“It has been found that exercise and change of diet can make a phenomenal difference.”She said her husband, a former doctor, was determined to find the right researcher to examine the link between odour and Parkinson’s and they sought out Dr Tilo Kunath at the University of Edinburgh in 2012.Kunath paired up with Prof Perdita Barran to examine Milne’s sense of smell.The scientists believed that the scent may be caused by a chemical change in skin oil, known as sebum, that is triggered by the disease.In their preliminary work they asked Milne to smell T-shirts worn by people who had Parkinson’s and those who did not. She correctly identified the T-shirts worn by Parkinson’s patients but also said that one from the group of people without Parkinson’s smelled like the disease – eight months later that individual was diagnosed with the disease.Researchers hoped the finding could lead to a test being developed to detect Parkinson’s, working under the assumption that if they were able to identify a unique chemical signature in the skin linked to the disease, they may eventually be able to diagnose it from simple skin swabs.In 2019, researchers at the University of Manchester, led by Barran, announced they had identified molecules linked to the disease found in skin swabs. The scientists have now developed a test using this information.The tests have been successfully conducted in research labs and scientists are assessing whether they can be used in hospital settings. If successful, the test could potentially be used in the NHS so GPs can refer patients for Parkinson’s tests.Sign up to First Edition Free daily newsletter Archie Bland and Nimo Omer take you through the top stories and what they mean, free every weekday morning Privacy Notice: Newsletters may contain info about charities, online ads, and content funded by outside parties. For more information see our Newsletters may contain info about charities, online ads, and content funded by outside parties. For more information see our Privacy Policy . We use Google reCaptcha to protect our website and the Google Privacy Policy and Terms of Service apply.The findings, which have been published in the Journal of the American Chemical Society, detail how sebum can be analysed with mass spectrometry – a method that weighs molecules – to identify the disease. Some molecules are present only in people who have Parkinson’s.Researchers compared swabs from 79 people with Parkinson’s with a healthy control group of 71 people.Barran said: “At the moment, there are no cures for Parkinson’s but a confirmatory diagnostic would allow them to get the right treatment and get the drugs that will help to alleviate their symptoms.“There would also be non-pharmaceutical interventions, including movement and also nutritional classes, which can really help. And I think most critically, it will allow them to have a confirmed diagnosis to actually know what’s wrong with them.”She added: “What we are now doing is seeing if (hospital laboratories) can do what we’ve done in a research lab in a hospital lab. Once that’s happened then we want to see if we can make this a confirmatory diagnostic that could be used along with the referral process from a GP to a consultant.“At the moment in Greater Manchester there are about 18,000 people waiting for a neurological consult and just to clear that list, without any new people joining it, will take up to two years. Of those 10-15% are suspect Parkinson’s.“Our test would be able to tell them whether they did or whether they didn’t (have Parkinson’s) and allow them to be referred to the right specialist. So at the moment, we’re talking about being able to refer people in a timely manner to the right specialism and that will be transformative.”Milne is working with scientists around the world to see if she can smell other diseases such as cancer and tuberculosis (TB).“I have to go shopping very early or very late because of people’s perfumes, I can’t go into the chemical aisle in the supermarket,” she said.“So yes, a curse sometimes but I have also been out to Tanzania and have done research on TB and research on cancer in the US – just preliminary work. So it is a curse and a benefit.”She said she can sometimes smell people who have Parkinson’s while in the supermarket or walking down the street but has been told by medical ethicists she cannot tell them.“Which GP would accept a man or a woman walking in saying ‘the woman who smells Parkinson’s has told me I have it’? Maybe in the future but not now.”",0.0,0.0
351,https://www.theverge.com/2022/10/7/23392375/ai-scan-retina-predict-heart-disease-stroke-risk-machine-learning,AI tool can scan your retina and predict your risk of heart disease âin 60 seconds or lessâ,"Software developed using machine learning can be used to predict someone’s risk of heart disease in less than a minute by analyzing the veins and arteries in their eye.The new research, published in the British Journal of Ophthalmology, paves the way for the development of quick and cheap cardiovascular screenings, if the findings are validated in future clinical trials. These screenings would let individuals know their risk of stroke and heart attack without the need for blood tests or even blood pressure measurements.“This AI tool could let someone know in 60 seconds or less their level of risk,” the lead author of the study, Alicja Rudnicka, told The Guardian. The study found that the predictions were as accurate as those produced by current tests.“The eye can be used as a window to the rest of the body.”The software works by analyzing the web of blood vessels contained within the retina of the eye. It measures the total area covered by these arteries and veins, as well as their width and “tortuosity” (how bendy they are). All these factors are affected by an individual’s heart health, allowing the software to make predictions about a subject’s risk from heart disease just by looking at a non-invasive snapshot of their eye.“The study adds to a growing body of knowledge that the eye can be used as a window to the rest of the body,” Pearse Keane, a researcher in ophthalmology and AI analysis not connected to the study, told The Verge. “Doctors have known for more than a hundred years that you could look in the eye and see signs of diabetes and high blood pressure. But the problem was manual assessment: the manual delineation of the vessels by human experts.” The use of machine learning, says Keane, can overcome this challenge.Using AI to diagnose disease from eye scans has proven to be one of the fastest-developing fields of machine learning medicine. The first ever AI diagnostic device approved by the FDA was used to screen for eye disease, and research suggests AI can detect a range of ailments in this way, from diabetic retinopathy to Alzheimer’s (Keane’s own area of research). Tools applying these findings are in various stages of development, but questions do remain about the reliability and universality of their diagnoses.The researcher named their software QUARTZ. Image: Rudnicka et alThis recent study, carried out by a team from St George’s, University of London, was only tested on the eye scans of white patients, for example. The team sourced their test data from the UK Biobank, a database that happens to be 94.6 percent white (reflecting the UK’s own demographics in age range of patients included in the BioBank). Such biases would have to be balanced in the future to ensure any diagnostic tool is equally accurate for different ethnicities.The researchers compared the results from their software, named QUARTZ (an inventive acronym derived from the phrase “QUantitative Analysis of Retinal vessels Topology and siZe”) with 10-year risk predictions produced by the standard Framingham Risk Score test (FRS). They found the two methods had “comparable performance.”",0.0,0.0
589,https://gizmodo.com/youtube-health-sources-doctors-nurses-1849711635,YouTube Is Making It Easier to Tell the Difference Between Real Doctors and Quacks,"In its latest effort to limit health misinformation, YouTube is trying to make it easier for users to identify and differentiate reliable, factual videos made by certified healthcare professionals from those made by wellness gurus and their ilk. Starting today, the platform will let doctors and nurses apply for verified provider labels and showcase their videos on special healthcare carousels in search results.The announcement was made on Thursday by YouTube’s global head of health Dr. Garth Graham, who pointed out in a blog post that this is the first time the platform will extend its health product features to individual healthcare providers. Previously, the features were available to organizations like universities and government agencies. YouTube has historically struggled to rein in medical misinformation, most recently during the pandemic, and has been criticized for dragging its feet on implementing fixes for the problem.AdvertisementAt the moment, only individuals in the U.S. and Germany will be able to apply to be YouTube Health Sources, although YouTube stated that the company hopes to be able to open up the process to more countries and regions in the future.“This is a big step towards helping people more easily find and connect with content that comes from the extraordinary community of healthcare creators on YouTube–the smart, dedicated and creative folks who are transforming the ways that we share medical information,” Graham said in a YouTube blog post.The company’s global head of health pointed to channels helmed by licensed individuals that provide helpful health content on the platform, such as Doctor Mike, a family doctor who debunks medical myths, and Doctor Ali, a psychologist who makes easily accessible videos on mental health.AdvertisementWhat will qualify someone to be a YouTube Health Source? According to the platform’s support page, the application process is open to licensed doctors, nurses, registered nurses, psychologists, marriage and family therapists, and licensed clinical social workers. All applicants must be licensed, YouTube notes, adding that third-party partner LegitScript will be in charge of coordinating license verification by working with licensing bodies like the Federation of State Medical Boards in the U.S.Besides obtaining license verification, YouTube states that channels must follow its monetization policies, even if it’s not monetizing content. Applicants must also have more than 2,000 valid public watch hours in the past 12 months and primarily focus on covering health information. Finally, individuals interested in being a Health Source must have no active community guidelines strikes.AdvertisementGetting accepted doesn’t mean that you’ll be a YouTube Health Source forever, though. On its support page, the platform points out that channels are periodically reassessed and may lose access to YouTube health features if the company finds they no longer meet the criteria.Interested individuals can apply here. YouTube states that it will review applicants’ channels and get back to them with an answer in within one or two months. Individuals who are accepted may start getting access to the features in early 2023.",0.0,0.0
161,https://inews.co.uk/news/environment/roads-uk-so-congested-less-healthy-more-lonely-1940265?ITO=newsnow,Roads in the UK are so congested that they are making us less healthy and more lonely,"ExclusiveBritain’s congested roads are blighting the lives and health of millions of people because they are acting as physical barriers that prevent local journeys by foot, new research has found.Unable to cross roads, that are either clogged or made dangerous by speeding traffic, residents are just opting out of what should be quick trips to local shops, friends or amenities, according to a University College London study.Or else, they are adding to the problem by getting in their cars.Researchers have found that one billion walking and cycling trips don’t take place every year because people can’t face dealing with their local traffic – that means 20 “lost” journeys per person per year.Some 135 million of those trips are replaced by car journeys, 90 million by public transport, and 775 million trips are “suppressed – trips that people want to make but end up not making because of the fear and inconvenience of road traffic”, the study has found.“Britain has a major problem with busy roads that is taking a significant mental and physical health toll in people all over the country,” Paulo Anciaes, of University College London, the lead researcher behind the findings, told i .“It is likely that millions of people in Britain have seen their quality of life reduced, to a greater or lesser extent, by living close to a busy road – with speeding cars or high volumes of traffic – and the problem appears to be getting worse.”The poorest in the country, who are more likely to live near a busy road, are most affected, along with children and people with mobility issues, such as the elderly and disabled, the report, published in the journal Transportation Research, finds.It means that millions of Britons could be missing out on valuable exercise as well as the benefit of being outdoors and socialising, at a cost to their health and wellbeing.Furthermore, shops and other local businesses are suffering from reduced customers as roads put up barriers to access.In total, the report – which includes a survey of a representative sample of 3,038 British adults – estimates that busy roads are costing local communities across Britain £3.2bn a year, or £64 per person, in the form of lower revenues for nearby businesses.Charles Musselwhite, professor at Aberystwyth University and editor-in-chief of Journal of Transport and Health, argues that “we have let cars, vans and lorries take over”, leading to a “spiral of decline in communities where people don’t know each other”.“The more traffic in an area, the less likely we are able to walk and to cycle in the local area, and this reduces our ability to know our neighbours; and the less we know our neighbours, the less there is to have a sense of community,” he said.Some 35 per cent of those surveyed for the UCL report – equating to 17.7 million British adults – said they lived near a road with heavy traffic. And a quarter – equating to 12.6 million British adults – said they lived close to a road where traffic was fast.‘It’s absolutely terrifying’ Allison Pepper lives right by the busy A540 Chester High Road just outside the town of Neston in Cheshire.This makes her family’s life much more difficult, with her children’s journey to the local secondary school, and just walking the dog, harder than it should be. “We live right by the main road by one junction, and to get to school, the children need to walk up by a very busy road which has a big distribution centre along it, so massive lorries go past,” says Ms Pepper, who, by coincidence, is a road traffic collisions solicitor. Allison Pepper lives by the A540 Chester High Road just outside Neston in Cheshire (Photo: Tom Bawden) “To get to the local secondary school, you have to walk along a very narrow pavement and then try and cross a junction. I can tell you it’s scary trying to cross that junction in a car, let alone as a pedestrian in the morning and after school. “We’re probably less than half a mile away from the school – but it takes much longer than it should. They either get a bus, which means going backwards to go forwards – with me driving them backwards to a local village for them to go forwards on a bus.” “Or they can walk twice the distance to get round using safer routes to avoid crossing a really busy junction and the road itself. It’s all a bit crackers really. And I’ve stopped walking the dog up there because it’s absolutely terrifying.”“Traffic volumes tend to be inversely related to speeds, because of congestion,” Dr Anciaes said. “This means that the problem ends up affecting all types of areas, but in different ways.“In cities, the problem is traffic volume – reported as high by 41 per cent of residents, rising to 45 per cent in London. And in rural areas, the problem is traffic speed – reported as fast by 33 per cent in villages and 39 per cent in hamlets.”Dr Anciaes says Finchley Road in north London, between Swiss Cottage and Finchley Road, is one of the biggest offenders when it comes to blocking off residents.“This has been a major barrier to walking trips for several decades. We talked with the local residents – many said they felt afraid of crossing Finchley Road and avoided going to the area on the other side of the road, as a result of that fear,” he said.“One local, a woman of 60, told us ‘Finchley Road is just a big pain, traffic is so heavy – buses, coaches and lorries. It’s not the speed as such, sometimes there is too much congestion for anyone to speed – it’s a river of traffic, constant, non-stop and you don’t want to breathe in the air it’s so full of exhaust fumes’.“The probability of living near a road with a speed perceived as high decreases almost linearly with income. And the problem seems to be worsening in the UK because road traffic volumes are still increasing. This is mostly due to the increase of traffic of light goods vehicles.”Experts have welcomed the report. Dr Stephen Watkins, a former director of public health for Stockport, and chair of the Transport and Health Science Group, said “vibrant local communities are vitally important to the health of urban residents and a busy main road through the middle of them is seriously disruptive”.Tanya Braun, director of policy and communications, Living Streets, the UK charity for everyday walking, said: “A lack of suitable crossings is a real barrier to people getting out and about. We need to see many more measures that protect pedestrians and encourage walking.”Adrian Davis, professor of transport and health at Edinburgh Napier University, said the study revealed “the barrier effect” of busy roads.“Reducing private motorised travel is the only way to solve this,” he said. “Reallocate road space to high quality public transport and walking and cycling”.Not that everyone gives in to the traffic. Dr Anciaes points to one extreme case that hit the headlines some years ago, of an 89-year-old woman living in Dorset, who was partially blind and walked using a frame.For her, a visit to the post office or shop she could see from her home on the other side of a very busy road involved a 90 minute round trip – involving a bus journey to the nearest pedestrian crossing three miles away and back again.",0.0,0.0
431,https://www.psypost.org/2022/11/new-study-links-suffering-from-long-lasting-severe-depression-to-reduction-in-brain-volume-64201,New study links suffering from long-lasting severe depression to reduction in brain volume,"A study on a large sample of patients found chronic, long-lasting depression to be associated with reduced brain volume. The reduced volume was found in brain regions relevant for planning one’s behavior, focusing attention, thinking, learning and remembering and also in regions relevant for regulating emotions. The study was published in Neurobiology and Treatment of Depression.Depression, also called major depressive disorder, is a mood disorder that causes a persistent feeling of sadness and loss of interest. It changes the way a person feels, thinks and behaves. For many people suffering from it, depressive episodes become a recurring event. More than half of patients with depression experience a relapse after 2 years and the probability of recurrent depressive episodes rises to 90% after 3-4 episodes. Studies have indicated that recurring depressive episodes might be linked to structural changes in the brain, but the existing results are not uniform.Ms. Hannah Lemke and her colleagues analyzed the data of 681 patients from the Marburg-Muenster-Affective-Cohort Study (MACS) in order to better link properties of the course of depressive disorder with specific changes in the brain structure. Patient data were collected at two sites in Germany – Muenster and Marburg.Patients participated in a clinical diagnostic interview (Structured Clinical Interview-I) that focused on the number and duration of hospitalizations and the duration of the disease, completed an assessment of depressive symptoms (Hamilton Depression Rating Scale, HDRS) and the current medication regime, and underwent brain imaging using magnetic resonance imaging and voxel-based morphometry.The results showed that an adequate description of the course of a depressive disorder needs to focus on two components – hospitalization i.e., the number and duration of lifetime hospitalizations, and duration of illness i.e., the time since the first psychiatric episodes and the number and duration of lifetime depressive episodes.These two components were found to be linked with specific changes in the brain structure. Longer durations of illness were associated with lower volumes of grey mass in the left hippocampal and dorsolateral prefrontal cortex regions of the brain. Higher hospitalization scores were associated with significantly decreased gray mass volume in the dorsolateral prefrontal cortex (on both sides) and left insula regions of the brain.An important strength of this study is that it involved a very large and diverse group of patients suffering from depression. However, the duration of illness assessment was based on self-reports, which can be affected by difficulties of remembering the previous course of illness. Hospitalization for depression is done when symptoms of depression are severe or when suicidal ideas/behavior is present.This means that the association between brain structure alterations and the hospitalization component of depression course may be the result of severity of depressive symptoms and not of the hospitalization itself. Authors conclude that stress-related mechanisms may be underlying the described effects.The study, “Association of disease course and brain structural alterations in major depressive disorder”, was authored by Hannah Lemke, Lina Romankiewicz, Katharina Förster, Susanne Meinert,Lena Waltemate, Stella M. Fingas, Dominik Grotegerd, Ronny Redlich, Katharina Dohm, Elisabeth J. Leehr, Katharina Thiel, Verena Enneking, Katharina Brosch, Tina Meller, Kai Ringwald, Simon Schmitt, Frederike Stein, Olaf Steinsträter, Jochen Bauer, Walter Heindel, Andreas Jansen, Axel Krug, Igor Nenadic, Tilo Kircher, and Udo Dannlowski.",0.0,0.0
131,https://www.psypost.org/2022/10/new-study-identifies-an-increasing-disinterest-in-fatherhood-among-childless-men-in-the-united-states-64072,New study identifies an increasing disinterest in fatherhood among childless men in the United States,"For most people throughout time, the idea of an ideal future included starting a family. Currently, over one third of American men have no children, prompting the question of why? A study published in Journal of Marriage and Family suggests that this is partially due to an increasing disinterest in fatherhood.Fertility rates ebb and flow due to many factors, including socioeconomic stability and cultural norms. In recent years, economic uncertainty and a decreasing focus on a traditional family unit seem to have led to the decrease in birth rates, which is of concern to many people due to the fact that America’s birth rate is now below replacement level. Most research on family planning and fertility focus on women, but the new research sought to understand the perspective of childless men.For his study, Robert Bozick utilized data from 3 sources: the National Survey of Family Growth, the Monitoring the Future study, and the Panel Study of Income Dynamics’ Transition to Adulthood supplement. All data was focused on the years 2000-2020.Bozick utilized data from 18,183 American men from the National Survey of Family Growth, which included questions about if participants see themselves having children in the future and how much it would bother them if they never had children. The Monitoring the Future study focused on high school seniors and asked them what number children they would have and how likely they were to want children. The Panel Study of Income Dynamics’ transition to adulthood supplement examined men aged 18 to 28. Bozick used data from 6 waves asking about the importance of family leave as an aspect of their jobs for participants.Results showed that over the past two decades, the interest in having children among childless men has decreased. In fact, the number of men reporting that they do not want children at all doubled during this time frame.Similarly, men reporting they wouldn’t be bothered if they never had kids doubled. Among high school seniors, the percentage of people who were confident they did not want children remained steady while the percentage of people reporting they were very likely to want kids decreased. Additionally, the number of men reporting that it is very important to them that their job has good parental leave decreased between 2005 and 2015.This study took important steps into better understanding the trends occurring in regard to fatherhood. Despite this, there are some limitations to note. One such limitation is that this study was only able to track descriptive trends and cannot truly answer why we are seeing these patterns.“The descriptive trends documented in this brief report clearly show that childless men are increasingly shying away from fatherhood, but the question remains: Why?” Bozick wrote in his study. “Without directly addressing this question, the contemporary research landscape of family formation and family planning is incomplete.”“On the heels of the COVID-19 pandemic and a longer-term decline in fertility rates, new questions have emerged regarding what considerations are most relevant to couples making decisions about having children—with an eye toward ensuring that couples have a broad array of options to plan for the families they so desire. Men in general, but childless men in particular, have received little attention in these scholarly conversations about family planning.”“Should the trends observed here continue, attempts at boosting fertility rates will need to consider what factors are driving this increasing disinterest among childless men,” Bozick wrote. “A logical next step is for family researchers to identify these factors – be they structural, evolutionary, cultural, or biological.”The study, “An increasing disinterest in fatherhood among childless men in the United States: a brief report“, was published July 30, 2022.",0.0,0.0
329,https://techcrunch.com/2022/10/25/google-hit-with-113-million-fine-in-india-for-anti-competitive-practices-with-play-store-policies/,"India fines Google yet again, orders to allow third-party payments","India’s antitrust watchdog has hit Google with a $113 million fine for abusing the dominant position of its Google Play Store and ordered the firm to allow app developers to use third-party payments processing services for in-app purchases or for purchasing apps, the second such penalty on the Android-maker in just as many weeks in its largest market by users.The Competition Commission of India, which opened the probe into Google in late 2020, said mandating developers to use Google’s own billing system for paid apps and in-app purchases through Play Store “constitutes an imposition of unfair condition” and thus violates provisions of the nation’s Section 4(2)(a)(i) of the Act.The regulator — which interviewed several industry players, including Paytm, Zomato, Info Edge, Samsung, Vivo, Xiaomi, Microsoft and Realme as part of the investigation — said that Google not using its billing system for its own apps such as YouTube amounts to “imposition of discriminatory conditions.”The investigation also concluded that:Mandatory imposition of GPBS [Google Play Billing System] disturbs innovation incentives and the ability of both the payment processors as well as app developers to undertake technical development and innovate and thus, tantamount to limiting technical development in the market for in-app payment processing services. in violation of the provisions of the Act. Thus, Google is found to be in violation of the provisions of Section 4(2)(b)(ii) of the Act. Mandatory imposition of GPBS by Google, also results in denial of market access for payment aggregators as well as app developers, in violation of the provisions of Section 4(2)(c) of the Act. The practices followed by Google results in leveraging its dominance in market for licensable mobile OS and app stores for Android OS, to protect its position in the downstream markets, in violation of the provisions of Section 4(2)(e) of the Act. Different methodologies used by Google to integrate, its own UPI app vis-à-vis other rival UPI apps, with the Play Store results in violation of Sections 4(2)(a)(ii), 4(2)(c) and 4(2)(e) of the Act.India is Google’s largest market by users. The company has poured billions of dollars in the South Asian market over the past decade as it aggressively searched to find major untapped regions worldwide to supercharge its growth.The company reaches nearly all of India’s 600 million internet users. Android commands 97% of the local smartphone market. Its payments app, Google Pay, is the second largest payments on the UPI network, an infrastructure built by a coalition of banks that has become the most popular way Indians transact online.The antitrust watchdog has directed Google to introduce a series of changes to its Play Store policies, which as with allowing developers to use third-party billing system, requires compliance within three months:Google shall not impose any anti-steering provisions on app developers and shall not restrict them from communicating with their users to promote their apps and offerings, in any manner. Google shall not restrict end users, in any manner, to access and use within apps, the features and services offered by app developers. Google shall set out a clear and transparent policy on data that is collected on its platform, use of such data by the platform and also the potential and actual sharing of such data with app developers or other entities, including related entities. The competitively relevant transaction/ consumer data of apps generated and acquired through GPBS, shall not be leveraged by Google to further its competitive advantage. Google shall also provide access to the app developer of the data that has been generated through the concerned app, subject to adequate safeguards, as highlighted in this order. Google shall not impose any condition (including price related condition) on app developers, which is unfair, unreasonable, discriminatory or disproportionate to the services provided to the app developers. Google shall ensure complete transparency in communicating to app developers, services provided, and corresponding fee charged. Google shall also publish in an unambiguous manner the payment policy and criteria for applicability of the fee(s). Google shall not discriminate against other apps facilitating payment through UPI in India vis-à-vis its own UPI app, in any manner.“The Commission hereby directs Google to cease and desist from indulging in anti-competitive practices,” CCI said in a statement Tuesday.Google and Apple have faced heat from developers globally in recent years for requiring them to use their own billing systems and hence accruing considerable commission. In response, Google has started to explore offering developers in some markets including India the ability to use third-party payments system for purchases on Play Store.Last week, the competition regulator fined Google $161.9 million for anti-competitive practices related to Android mobile devices and made a series of stringent redressal measures.The watchdog was investigating whether Google had assumed dominant position in five different markets: licensable OS for smartphones, app store, web search services, non-OS specific mobile web browsers and online video hosting platform in India. Google was dominant in all of those relevant markets, the regulator concluded.The antitrust watchdog said that device manufacturers should not be forced to install Google’s bouquet of apps and the search giant should not deny access to its Play Services APIs and monetary and other incentives to vendors. Amazon told the regulator that over half a dozen hardware vendors had indicated that they could not enter into a TV manufacturing relationship with the e-commerce group over fear of retaliation from Google.In response to the last week’s order, Google said CCI’s decision was a “major setback for consumers and businesses,” opened them to “serious security risks” and will raise the “cost of mobile devices for Indians.”Google said Tuesday its legal team is evaluating the order and had no immediate comment. It expressed concerns about the evidence the regulator relied on to reach its conclusion, CCI said in the order.In a statement Wednesday, a Google spokesperson said: “Indian developers have benefited from the technology, security, consumer protections, and unrivaled choice and flexibility that Android and Google Play provide. And, by keeping costs low, our model has powered India’s digital transformation and expanded access for hundreds of millions of Indians. We remain committed to our users and developers and are reviewing the decision to evaluate the next steps.”",0.0,0.0
330,https://www.reuters.com/technology/twitter-will-not-reinstate-banned-users-without-clear-process-musk-says-2022-11-02/,"Twitter will not reinstate banned users without 'clear process,' Musk says","Nov 2 (Reuters) - Banned accounts will not be allowed back onto Twitter until the social media platform has ""a clear process for doing so,"" Elon Musk tweeted in the early hours on Wednesday, giving more clarity about the potential return of Twitter's most famous banned user, former U.S. President Donald Trump.Creating such a process would take at least a few more weeks, Musk tweeted. The new timeline implies Trump will not return in time for the midterm elections on Nov. 8.Twitter users, advertisers and its own employees have been watching closely for signs of what Musk will do in his first week as Twitter's owner. The Tesla chief executive has previously said Twitter should not permanently ban users and that he would reverse the ban on Trump, who was suspended for risk of further incitement of violence after the U.S. Capitol riot last year.Musk's tweets came after he held a call with several civil rights organizations including Color of Change, the Anti-Defamation League and the NAACP on Tuesday.During the call, Musk committed to uphold Twitter's content moderation policies and enforcement around election integrity, said Rashad Robinson, president of Color of Change, in an interview.Musk also reiterated in his tweet on Wednesday that Twitter will create a content moderation council composed of representatives with ""widely divergent views.""The billionaire expressed during the call that he would like the civil society groups to join the council, Robinson said, adding the discussions were still at an early stage.""Actions will speak louder than words,"" he said. ""The issues that were addressed in this meeting were just the tip of the iceberg.""Reporting by Sheila Dang in Dallas Editing by Nick ZieminskiOur Standards: The Thomson Reuters Trust Principles.",0.0,0.0
559,https://www.vox.com/future-perfect/23362175/un-human-development-report-ord-existential-security,How to stop rolling the dice on the destruction of human civilization,"Since 1990, the United Nations Development Programme has been tasked with releasing reports every few years on the state of the world. The 2021/2022 report — released earlier this month, and the first one since the Covid-19 pandemic began — is titled “Uncertain Times, Unsettled Lives.” And unsurprisingly, it makes for stressful reading.“The war in Ukraine reverberates throughout the world,” the report opens, “causing immense human suffering, including a cost-of-living crisis. Climate and ecological disasters threaten the world daily. It is seductively easy to discount crises as one-offs, natural to hope for a return to normal. But dousing the latest fire or booting the latest demagogue will be an unwinnable game of whack-a-mole unless we come to terms with the fact that the world is fundamentally changing. There is no going back.”Those words ring true. Only a few years ago, we lived in a world where experts had long warned that a pandemic was coming and it could be devastating — now, we live in a world that a pandemic has clearly devastated. Only a year ago, there hadn’t been a large land war in Europe since World War II, and some experts optimistically assumed that two countries with McDonald’s in them would never go to war.Now, not only is Russia occupying stretches of Ukraine, but the destruction of Russia’s army in the fighting there has kicked off other regional instability, most notably with Azerbaijan attacking Armenia earlier this month. Fears of the use of nuclear weapons in wartime, quiet since the Cold War, are back as people worry about whether Putin could turn to tactical nukes if faced with a total defeat in Ukraine.Help inform the future of Vox We want to get to know you better — and learn what your needs are. Take Vox’s survey here.Of course, all of those situations are possible — even likely — to resolve without catastrophe. The worst rarely happens. But it’s hard to avoid a feeling that we’re just rolling the dice, hoping that we somehow won’t eventually hit on an unlucky number. Every pandemic, every minor war between nuclear-armed powers, every new and uncontrolled technology, may pose only a small chance of escalating to a catastrophic-scale event. But if we take that risk every year without taking precautions, humanity’s lifespan may be limited.Why “existential security” is the opposite of “existential risk”Toby Ord, senior research fellow at Oxford’s Future of Humanity Institute and the author of the existential risk book The Precipice: Existential Risk and the Future of Humanity, explores this question in an essay in the latest UNDP report. He calls it the problem of “existential security”: the challenge not just of preventing each individual prospective catastrophe, but of building a world that stops rolling the dice on possible extinction.“To survive,” he writes in the report, “we need to achieve two things. We must first bring the current level of existential risk down — putting out the fires we already face from the threats of nuclear war and climate change. But we cannot always be fighting fires. A defining feature of existential risk is that there are no second chances — a single existential catastrophe would be our permanent undoing. So we must also create the equivalent of fire brigades and fire safety codes — making institutional changes to ensure that existential risk (including that from new technologies and developments) stays low forever.”He illustrates the point with this fairly terrifying graph:The idea is this: Say we go through a situation where a dictator threatens to use nuclear war, or where tensions between two nuclear powers seem to be hitting the breaking point. Maybe most of the time the situation is defused, as indeed was the case during the many, many Cold War close calls. But if this situation recurs every few decades, then the probability we’ll defuse every single prospective nuclear war will get steadily lower. The odds that humanity will still be around in 200 years eventually become quite low, just as the odds that you can keep winning at craps drop with every roll.“Existential security” is the state where we are mostly not facing risks in any given year, or decade, or ideally even century, that have a substantial chance of annihilating civilization. For existential security from nuclear risk, for instance, perhaps we reduce nuclear arsenals to the point where even a full nuclear exchange would not pose a risk of collapsing civilization, something the world made significant progress on as countries slashed nuclear arsenal levels after the Cold War. For existential security from pandemics, we could develop PPE that is comfortable to wear and provides approximately total protection against disease, plus a worldwide system to detect diseases early — ensuring that any catastrophic pandemic would be possible to nip in the bud and protect people from.The ideal, though, would be existential security from everything — not just from the knowns, but the unknowns. For example, one big worry among experts including Ord is that once we build highly capable artificial intelligences, AI will dramatically hasten the development of new technologies that imperil the world while — because of how modern AI systems are designed — it’ll be incredibly difficult to tell what it’s doing or why.So an ideal approach to managing existential risk doesn’t just fight today’s threats but makes policies that will prevent threats from arising in the future too.That sounds great. As longtermists have argued recently, existential risks pose a particularly devastating threat because they could destroy not just the present, but a future where hundreds of billions more people could one day live. But how do we bring it about?Ord proposes “an institution aimed at existential security.” He points out that preventing the end of the world is exactly the sort of thing that’s supposed to be within the purview of the United Nations — after all, “the risks that could destroy us transcend national boundaries,” he writes. The problem, Ord observes, is that to prevent existential risk, an institution would have to have broad ability to intervene in the world. No country wants any other country to be allowed to pursue an incredibly dangerous research program, but at the same time, no country wants to give other countries purview over their own research programs. Only a supranational authority — something like the International Atomic Energy Agency, but with a far broader remit — could potentially overcome those more narrow national concerns.Often, the hard part in securing humanity’s future isn’t figuring out what needs to be done but actually doing it. With climate change, the problem and the risks were well understood for a long time before the world took action to shift away from greenhouse gases. Experts warned about the risks of pandemics before Covid-19 struck, but they largely weren’t listened to — and institutions that the US thought were ready, like the CDC, turned out to fall on their face during a real crisis. Today, there are expert warnings about artificial intelligence, but other experts assure us there’ll be no problem and we don’t need to try to solve it.Writing reports only helps if people read them; building an international institute for existential security only works if there’s a way to transform the study of existential risks into serious, coordinated action to make sure we don’t face them. “There is not sufficient buy-in at the moment,” Ord acknowledges, but “this may change over years or decades as people slowly face up to the gravity of the threats facing humanity.”Ord doesn’t speculate on what might bring that change about, but personally, I’m pessimistic. Anything that changed the international order enough to support international institutions with real authority with respect to existential risk would likely have to be a devastating catastrophe in its own right. It seems unlikely we’ll make it to the path of “existential security” without taking some serious risks — which hopefully we survive to learn from.",0.0,0.0
398,https://abcnews.go.com/Health/half-covid-survivors-fully-recovered-months-study/story?id=91444148,Nearly half of COVID survivors haven't fully recovered 6 months later: Study,"The most common symptoms were tiredness, headache and muscle aches.Nearly half of COVID-19 survivors may have symptoms of long COVID months after they were first infected, a new study suggests.Researchers from across Scotland looked at more than 33,000 patients over the age of 16 with a confirmed PCR test for COVID-19 in the past and tracked their symptoms.Results, published in the journal Nature Communications Wednesday, found that six months later, of the more than 31,000 patients who had had symptomatic COVID, 6% reported not having recovered at all. An additional 42% felt they were only partially recovered.Patients who reported no recovery were more likely to be women, to have been hospitalized when they had COVID, and to have multiple underlying conditions.Long COVID symptoms among symptomatic vs. asymptomatic patients Nature CommunicationsWhen the team looked at symptoms, they found the most common was tiredness, followed by headache, muscles aches, joint pain and difficulty breathing, respectively.Patients with an asymptomatic infection were not at increased risk of experiencing symptoms months later.What's more, having received at least one dose of a COVID-19 vaccine prior to infection reduced the risk of some symptoms including change in taste and/or smell, poor appetite, confusion and difficulty concentrating.""Our study is important because it adds to our understanding of long-COVID in the general population, not just in those people who need to be admitted to hospital with COVID-19,"" lead author Jill Pell, a professor of public health at the University of Glasgow, said in a statement.""By comparing symptoms with those uninfected, we were able to distinguish between health problems that are due to COVID-19 and health problems that would have happened anyway,"" the statement continued.Long COVID occurs when patients who have cleared the active infection still have symptoms lasting more than four weeks after recovering. In some cases, these symptoms can persist for months or even years.Patients can experience a variety of lingering symptoms including fatigue, difficulty breathing, headaches, brain fog, joint and muscle pain, and continued loss of taste and smell, according to the Centers for Disease Control and Prevention.The authors mentioned some limitations including that most of the participants were white because the study was conducted in Scotland, which has a 96% white population.""Therefore, it is important that ethnic-specific outcomes are reported by other long-COVID studies with more ethnically diverse populations,"" the authors wrote.Additionally, some of the common symptoms were also reported among a control group who had never tested positive for COVID. The symptoms that were most strongly associated with COVID infection were breathlessness, chest pain, palpitations and loss of taste and smell.",0.0,0.0
297,https://www.theverge.com/2022/10/14/23401381/great-lakes-plastic-pollution-cleanup-tech-robots,How a fleet of robots could help solve the Great Lakes plastic pollution problem,"In the murky waters of Lake Ontario just off the Toronto harbor, a stream of trash inches toward a round, tubular-looking device floating in the water. A piece of white styrofoam bumps up against the device’s lip. Then, in one fluid motion, it tumbles over the edge. With tendrils of marine plants circling the waste, it looks like the styrofoam could have entered a portal to an undersea world. Instead, the device is a gateway to a less mystical — yet vital — destination: the garbage dump.“It’s basically like a floating trash can,” says Chelsea Rochman, professor of ecology and evolutionary biology at the University of Toronto, who has worked with a team at the university to capture trash in Lake Ontario with bins like these since 2019. Powered from shore, the device, called a Seabin, uses a motor to create a vortex that gently pulls in floating waste from a 160-foot radius and then stores the trash in an attached basket.Across the Great Lakes, which stretch from Duluth, Minnesota, to the border between the United States and Canada in northern New York, dozens of Seabins now work alongside stormwater filters in a cross-border project dubbed the Great Lakes Plastic Cleanup. In mid-September, they were also joined by aquatic waste-collection drones and beach-cleaning roving robots — all to remove some of the 22 million pounds of plastic that enter the lakes each year and help researchers like Rochman understand the Great Lakes waste problem.People can’t remove waste 24 hours a day like the devices can“We know that the amount of litter we have out there needs more power than the people power that we have,” Rochman explains. Though local groups have organized beach cleanups for decades, people can’t remove waste 24 hours a day like the devices can, nor can they pick up the tiny pieces that machines are able to capture.Standing on the shore of Lake Ontario, with Toronto’s streetcars rattling by, Rochman points out the overflowing municipal trash bin along the sidewalk — one of several sources of the trash. Municipal sewage systems, industrial spills, stormwater runoff, recreational boating and beach waste, and agricultural debris all wind up in the lakes as well. In one bin, toothbrushes, tampon applicators, dental flossers, shoe strings, eyeglasses, food scraps, and syringes are entwined in the tendrils of marine plants. Between the leaves, tiny flecks of plastic poke out.Bright colored plastic floats among leaves and other debris in one of the Great Lakes Image: Great Lakes Plastic CleanupIn the lakes, which 40 million people rely on as their primary drinking water source, this waste breaks down, turning into microscopic pieces of plastic and debris, which are then eaten by fish, sucked into surrounding water treatment plants, or pulled to shore or out into the ocean. When plastic is consumed by fish, it can release chemicals like dyes and flame retardants, irritating and potentially damaging their digestive systems. In big sport fish, like lake trout or salmon, Rochman expects to find hundreds of pieces of plastic. Microplastics have also been found in drinking water in the region, where many water treatment plants are ill-equipped to filter the tiny pieces out. (The risk of consuming microplastics for humans remains unclear, though researchers continue to investigate the potential problem.)Once captured by researchers like Rochman, each piece of trash becomes another data point. Each day during the summer, students haul out the bins to count, classify, and dispose of their contents. “They know how many cigarette butts we collect, how many straws we collect, how many foam containers we collect,” Rochman says. Some days, the catch is more surprising — students have counted slices of deli meat, old shoes, and, once, a coconut in Seabins this summer.The Seabins capture 28 grams of waste, on average, each day. “It’s going to sound like a small number because plastic is light,” says Rochman. That weight translates to a couple hundred to 2,000 pieces of microplastic, along with multiple pieces of larger waste. This summer, Rochman expects her team to remove the amount of plastic equivalent to 7,000 plastic water bottles — and that’s only in the 12 bins the university oversees, which make up just a fraction of the devices deployed at 45 marinas across the Great Lakes region.From the northern shores of Lake Superior in Thunder Bay, Ontario, to the harbor of Buffalo, New York, just a short drive from Niagara Falls, Seabins like the ones in the Toronto harborfront are deployed at 44 other locations, typically in operation from May to November. These bins are monitored not by researchers but by marina owners or local organizations. Partners at the participating sites weigh and dispose of the bins’ contents as they fill up and perform full waste characterizing audits five to 10 times each year. Many marinas also have catch basin baskets installed, called LittaTraps, that sit inside stormwater drains to capture waste before it enters the lake system. Between 2020 and 2021, the project’s technology captured over 74,000 pieces of trash, a number that the team expects will increase as they continue outreach to marinas and municipalities in the region.A promotional photo of the beach-cleaning BeBot. Image: The Searial CleanersIn September, a waste collecting drone and beach-cleaning robot also joined the project’s fleet of trash catching technology. The devices, built by French waste capture technology company The Searial Cleaners, collect waste from lakes and beaches, working both via remote control and autonomously. The roving robots are also key public engagement tools, says Claire Touvier, the company’s chief executive. “That’s why this robot needed to be sexy and cool and fun, and to also have a cool name — these are extremely efficient tools when it comes to raising awareness,” she says.Still, the technology remains a reactive approach. Robots can help clean up the lakes, but human choices about how much plastic to produce, consume, and throw out are at the core of the Great Lakes trash problem. Changing them will be key to any long-term solution, says Melissa De Young, policy and programs director at the Canadian nonprofit Pollution Probe, one of the project’s main funders. “We’re doing what we can to remove plastic from the water, but we know that the technologies alone are not going to solve the problem,” she explains. “The data that we’re collecting is really critical because it provides, first, an understanding of the extent of the problem.”If large macroplastics wind up in capture devices in a certain area, for example, that can indicate communities nearby may lack easy access to disposal facilities or may be uninformed on why proper waste disposal is important. Alternatively, if small plastic pieces used to build other products, called preproduction pellets, or nurdles, are more common, that can indicate that somewhere upstream, a manufacturer may be improperly disposing of its trash.The PixieDrone collects plastic. Image: The Searial CleanersThe captured waste then informs the group’s approach to local solutions, whether that means starting a new educational campaign, meeting with policymakers, or advocating for new industry mandates. Last year, the team consulted on a new Ontario law that requires the foam used to build floating docks for cottages and marinas to be fully enclosed so it does not break down into the water. The group has also contributed to proposed legislation to include mandates for filters on washing machines to prevent microfibers from entering the sewage system in Ontario and stronger laws regarding preproduction plastic disposal in Illinois.“When we go to government policymakers, when we go to industry in the region, when we go to others to say, ‘Listen, we’ve got a problem here and we need to fix it,’ having that localized data, having that regional data, really aids us in those conversations in terms of capturing people’s attention and really motivating them to do something,” says Mark Fisher, head of the Council for the Great Lakes, a binational organization that also funds the project.“We don’t want to have to have trash traps in the water forever.”Other researchers in the region are hopeful about the new technology in the lakes, too. No initiative is going to be able to pick up 22 million pounds of plastic out of the Great Lakes every year, but a project that can motivate public and political action can have magnifying results, explains Timothy Hoellein, a biology professor at Loyola University Chicago who has worked on separate lake cleanup projects but is not involved in this one. When it comes to the Seabins, “Their individual footprint is pretty small,” Hoellein says. “But on a collective basis, it could really make a difference.”As the strategy garners success in the region, its lessons have begun to reach far beyond the shores of the Great Lakes. Rochman and the team at the University of Toronto have partnered with the nonprofit environmental group Ocean Conservancy to found the International Trash Trap Network, which works with groups from Fiji to Florida to help create more trash trapping strategies. Wherever trash traps capture waste, data collection follows.It’s all part of the goal of achieving a future where freshwater sources, like the Great Lakes, are no longer dumping zones for waste, Rochman says. “We don’t want to have to have trash traps in the water forever,” she adds.",0.0,0.0
471,https://techcrunch.com/2022/08/31/solid-63m-embedded-fintech/,Solid banks $63M for easier deployment of embedded fintech products,"Solid, which rebranded from Wise in 2021, raised a $63 million Series B round of funding to continue providing its fintech-as-a-service offering for companies wanting to launch and scale their own fintech products.The San Mateo-based company works with fintech and vertical SaaS companies and offers banking, payments, cards and cryptocurrency products via easy-to-integrate APIs.We last profiled the company in 2020, before its name change, and after it had picked up both a $5.7 million seed and a $12 million Series A.Arjun Thyagarajan, co-founder and CEO at Solid, told TechCrunch that the company spent the last 18 months working with early customers on product-market fit.Traditional fintech infrastructure was not built for the modern company, he explained, and that results in companies needing dozens of point solutions and often spending millions in upfront and ongoing maintenance costs, all before launching an actual product.Instead, by utilizing APIs and a few lines of code, customers can embed fintech products and get them up-and-running quickly.“Customers aren’t looking for UI/UX, but really for DI/DX, that developer interface with a powerful dashboard that is self-service,” he said. “We understood what they were looking for — that demand for modern infrastructure. They work with banks, but those often don’t have tools for launching the fintech experience or the building blocks to make it easy to put together.”It was also during that time that they decided to rebrand as they solidified their business-to-business focus. The new Solid name also resonated more with customers, Thyagarajan added.Over the past year, Solid grew 10x in revenue, doubled its customers to 100 and became profitable. Year to date, the company processed $2 billion in transactions.After being in sort of a stealth mode during the past 18 months, Thyagarajan said the company was now on a journey to get to 100 customers. To do that, he and co-founder Raghav Lal thought it was time to go after new funding. They started the process in May and closed the Series B at the end of July.“We saw early signs of product market fit, so our thought process was to do the Series B when we were ready for hypergrowth, and now we have cash in the bank,” Thyagarajan said. “We are going after the mid-market, so we had to go back and fine-tune our product as we figured out what businesses need. The key was to build our technology from the ground up to own the complete experience so we could give customers what they want.”FTV Capital led the new investment and was joined by existing investor Headline. To date, Solid has raised $80.7 million. Thyagarajan didn’t disclose a specific valuation with the new round, but did reveal it was 5x over Solid’s Series A valuation.The capital infusion will help accelerate Solid’s entrance into some new verticals like travel, logistics, construction, healthcare, education and the gig economy. The company is looking at where money is moving and identified 40 to 50 different verticals where there is an impedance in how money moves, but they want to benefit their customers.The company is also focusing on mid-market and larger companies, which is another reason why Thyagarajan said the investment was important.“We are talking to Fortune 1000 companies and they feel more comfortable working with companies with a strong balance sheet,” he added. “A lot of work has been under the radar, so we are getting the brand out and showcasing we are the ‘AWS of fintech,’ a one-stop shop. Our goal is to be alongside them as a partner, not just a vendor.”",0.0,0.0
45,https://techcrunch.com/2021/08/25/zeits-early-warning-wearable-for-sleep-strokes-could-save-hours-and-lives/,Zeitâs early warning wearable for sleep strokes could save hours and lives,"Those at risk are always vigilant for the signs of a stroke in progress, but no one can be vigilant when they’re sleeping, meaning thousands of people suffer “wake-up strokes” that are only identified hours after the fact. Zeit Medical’s brain-monitoring wearable could help raise the alarm and get people to the hospital fast enough to mitigate the stroke’s damage and potentially save lives.A few decades ago, there wasn’t much anyone could do to help a stroke victim. But an effective medication entered use in the ’90s, and a little later a surgical procedure was also pioneered — but both need to be administered within a few hours of the stroke’s onset.Orestis Vardoulis and Urs Naber started Zeit (“time”) after seeing the resources being put toward reducing the delay between a 911 call regarding a stroke and the victim getting the therapy needed. The company is part of Y Combinator’s Summer 2021 cohort.“It used to be that you couldn’t do anything, but suddenly it really mattered how fast you got to the hospital,” said Naber. “As soon as the stroke hits you, your brain starts dying, so time is the most crucial thing. People have spent millions shrinking the time between the 911 call and transport, and from the hospital door to treatment. but no one is addressing those hours that happen before the 911 call — so we realized that’s where we need to innovate.”If only the stroke could be identified before the person even realizes it’s happening, they and others could be alerted and off to the hospital long before an ambulance would normally be called. As it turns out, there’s another situation where this needs to happen: in the OR.Surgeons and nurses performing operations obviously monitor the patient’s vitals closely and have learned to identify the signs of an impending stroke from the EEG monitoring their brainwaves.“There are specific patterns that people are trained to catch with their eyes. We learned from the best neurologists out there how they process this data visually, and we built a tool to detect that automatically,” said Vardoulis. “This clinical experience really helped, because they assisted in defining features within the signal that helped us accelerate the process of deciding what is important and what is not.”The team created a soft, wearable headband with a compact EEG built in that monitors the relevant signals from the brain. This data is sent to a smartphone app for analysis by a machine learning model trained on the aforementioned patterns, and if anything is detected, an alarm is sent to the user and pre-specified caregivers. It can also be set to automatically call 911.“The vast majority of the data we have analyzed comes out of the OR,” said Vardoulis, where it can immediately be checked against the ground truth. “We saw that we have an algorithm that can robustly capture the onset of events in the OR with zero false positives.”That should translate well to the home, they say, where there are actually fewer complicating variables. To test that, they’re working with a group of high-risk people who have already had one stroke; the months immediately following a stroke or related event (there are various clinically differentiated categories) is a dangerous one when second events are common.“Right now we have a research kit that we’re shipping to individuals involved in our studies that has the headband and phone. Users are wearing it every night,” said Vardoulis. “We’re preparing for a path that will allow us to go commercial at some point in 2023. We’re working with he FDA to define the clinical proof needed to get this clear.”They’ve earned a “Breakthrough Device” classification, which (like stroke rehabilitation company BrainQ) puts them in position to move forward quickly with testing and certification.“We’re going to start in the U.S., but we see a need globally,” said Naber. “There are countries where aging is even more prevalent and the support structure for disability care is even less.” The device could significantly lower the risk and cost of at-home and disability care for many people who might otherwise have to regularly visit the hospital.The plan for now is to continue to gather data and partners until they can set up a large-scale study, which will almost certainly be required to move the device from direct-to-consumer to reimbursable (i.e., covered by insurance). And although they are totally focused on strokes for the present, the method could be adapted to watching for other neurological conditions.“We hope to see a future where everyone with a stroke risk is issued this device,” said Vardoulis. “We really do see this as the missing puzzle piece in the stroke care continuum.”",0.0,0.0
590,https://techcrunch.com/2019/09/29/badass-millennial-women-are-supercharging-startup-investments/,Badass millennial women are supercharging startup investments,"Across the political, social and economic stage, women’s issues are finally receiving heightened attention and priority.There are more women than ever seeking political office; funding for female-founded startups is reaching record levels (even if they still have a long way to go to reach gender parity); a sizable cohort of female-founded and led companies have achieved billion-dollar unicorn valuations; and several women-led companies, including PagerDuty, The RealReal, and Eventbrite, have entered the public markets with successful IPOs.What’s driving so much positive change?Clearly, broadened awareness of gender and power issues, largely due to #MeToo, as well as an increase in the number of female investors, thanks to groups like All Raise, are all contributing catalysts. In addition, women now outnumber men in college, a majority of American moms are in the workforce, and in 40 percent of households those women are the breadwinners. But it’s more than that; I believe that there’s a profound generational shift afloat, and that this first wave of female-led unicorns is just the tip of the NASDAQ iceberg.Unlike previous generations who may have either looked at self-investment as self-indulgence or who simply didn’t have the resources or technology available to make supplementary investments in themselves, today’s badass millennial women are unapologetic about their desire to invest in their own success and well-being. Determined to succeed without compromising their values or physical and mental wellness, these uber-empowered millennial women are making viable a new generation of startups to help them realize their dreams and feel comfortable in their skin. I refer to this economic wave as She-conomy 2.0.For decades now there have been tech companies, which I refer to as She-conomy 1.0 , catering to traditional and homogeneous identities of women primarily as shoppers and caregivers. In contrast, these new modern She-conomy 2.0 brands address latent, historically unmet, often un-discussed and under-served needs that speak to the multitude of other facets of our identities.These companies have less to do with what women buy and more to do with their willingness to invest in themselves — in their careers and in their physical and emotional health and well-being. They are seeking and are willing to pay for products and services that help them advance their careers, feel comfortable about their bodies, and provide the physical and emotional support they’re seeking.Women are taking control of their careers and supporting each other.More than two decades ago, when I had my first child, I joined a mom’s group at Stanford Hospital. We were all working moms trying to juggle career and motherhood. It was a truly challenging time for each of us. The group provided such helpful support that we met every Monday evening for five years until our kids were in kindergarten. Why Mondays? Because Mondays are especially hard for working parents, marking yet another week in search of balance. We realized that meeting on Monday evenings provided us with the support we needed to make it through the work week. Perhaps even more critically, it gave us something about Mondays to look forward to.There’s something incredibly empowering about experiencing a major transition like a new job or new parenthood as part of a cohort. Sheryl Sandberg famously sought to institutionalize this kind of support for working women with her non-profit Lean In. It has dramatically raised awareness around working women’s struggles. However, individual Lean In group leaders are usually volunteers running these sessions on the side while working and shouldering life’s endless list of other responsibilities.Now a new generation of organizations is offering this support — for a fee. As for-profit organizations, they’re doing so in a scalable, consistent and reliable way. Women don’t have to worry about whether the organizer will be able to carve out time to orchestrate a meeting because doing so is the organizer’s job. Chief, Declare, The Assembly * , The Wing and The Riveter are all examples of companies that are growing and thriving because they’re offering valuable space, support and services that women are willing to pay for. Most of these organizations initially targeted millennials, but women of all generations are benefiting and participating.Women are changing the narrative around previously taboo topics and promoting inclusiveness and acceptance of oneself.It wasn’t long ago that mannequins, much like cover models, only came in one size. Now mainstream brands not only sell broader offerings; they increasingly showcase them in magazines, catalogs, stores and the runway. For example, Nike’s flagship store in London featured both plus-sized mannequins and para-sport mannequins for people with physical and intellectual abilities, and Rhianna’s new inclusive lingerie line regularly presents both plus-size and pregnant models.Millennials (like all of us) don’t want to feel shamed; they want to feel empowered and beautiful. Instead of settling for frumpy, ill-fitting clothing or outdated product design, millennials are using their social media megaphones to tell the market what they want. Traditional companies like Victoria’s Secret have moved at a molasses-like pace to evolve from treating women as objects of fantasy to celebrating their right to feel great about themselves. Their antiquated practices have created the opportunity for new startups to create brands centered on body positivity. Some companies are filling largely underserved market needs by catering exclusively to larger and specialty sizes, and others are addressing previously taboo topics like body hair, which also contribute strongly to feelings around body positivity. Eloquii offers extended clothing sizes, Ruby Ribbon * and Third Love provide a wide sizing range of under garments and bras, and Fur addresses body hair and grooming.Women are dedicating more attention to their own health and relationships.Self-help books have been around for ages, but tech is paving the way for a new generation of services to provide guidance and support that are more convenient and targeted. At the same time, women are increasingly willing to discuss health issues that were previously taboo, like menstruation, menopause and perimenopause, fertility, and depression. Advancements in technology are making health-related self-care more accessible from the convenience of our wristbands and phones. Meanwhile, people are spending a disproportionate amount of their wealth on health, making the entire healthcare industry ripe for disruption.All of these factors are making femtech big business. Countless new companies are helping women take more active control of their sexual health, including birth control and STI testing (Pill Club and Nurx), period tracking (Flo Health), fertility and egg freezing (Kind Body and Carrot Fertility), menopause (Rory, Genneve), postpartum depression and miscarriage (Maven) and even our relationships (Relish* and Bumble). In addition, no shortage of femtech companies are addressing period care, such as Lola, Cora, The Flex Company, Thinx, and Sustain Natural.These companies are only viable because so many women — beginning with millennials but expanding out to the rest of us — are now willing and able to invest in themselves. United across a shared mission of female empowerment and inclusivity, She-onomy 2.0 is making it more realistic than ever to empower us to advance our careers, feel good about ourselves and stay healthy. Hats off to the badass millennial women leading this charge; we’re all better off professionally, emotionally and even physically thanks to you!*Denotes portfolio company for Trinity Ventures",0.0,0.0
397,https://ajph.aphapublications.org/doi/10.2105/AJPH.2022.307050,"COVID-19 Vaccine Uptake and Factors Affecting Hesitancy Among US Nurses, MarchâJune 2021","Objectives. To characterize COVID-19 vaccine uptake and hesitancy among US nurses.Methods. We surveyed nurses in 3 national cohorts during spring 2021. Participants who indicated that they did not plan to receive or were unsure whether they planned to receive the vaccine were considered vaccine hesitant.Results. Among 32 426 female current and former nurses, 93% had been or planned to be vaccinated. After adjustment for age, race/ethnicity, and occupational variables, vaccine hesitancy was associated with lower education, living in the South, and working in a group care or home health setting. Those who experienced COVID-19 deaths and those reporting personal or household vulnerability to COVID-19 were less likely to be hesitant. Having contracted COVID-19 doubled the risk of vaccine hesitancy (95% confidence interval [CI] = 1.85, 2.53). Reasons for hesitancy that were common among nurses who did not plan to receive the vaccine were religion/ethics, belief that the vaccine was ineffective, and lack of concern about COVID-19; those who were unsure often cited concerns regarding side effects or medical reasons or reported that they had had COVID-19.Conclusions. Vaccine hesitancy was unusual and stemmed from specific concerns.Public Health Implications. Targeted messaging and outreach might reduce vaccine hesitancy. (Am J Public Health. 2022;112(11):1620–1629. https://doi.org/10.2105/AJPH.2022.307050)",0.0,0.0
178,https://news.osu.edu/considering-covid-a-hoax-is-gateway-to-belief-in-conspiracy-theories/,Considering COVID a hoax is âgatewayâ to belief in conspiracy theories,"Belief that the COVID-19 pandemic was a hoax – that its severity was exaggerated or that the virus was deliberately released for sinister reasons – functions as a “gateway” to believing in conspiracy theories generally, new research has found.In the two-survey study, people who reported greater belief in conspiracy theories about the pandemic – for which there is no evidence – were more likely to later report they believed that the 2020 presidential election had been stolen from Donald Trump through widespread voter fraud, which is also not true. Participants’ overall inclination to believe in conspiracy theories also increased more among those who reported believing COVID-19 was a hoax.Based on the results, the Ohio State University researchers have proposed the “gateway conspiracy” hypothesis, which argues that conspiracy theory beliefs prompted by a single event lead to increases in conspiratorial thinking over time.Preliminary evidence suggests a sense of distrust may function as one trigger.“It’s speculative, but it appears that once people adopt one conspiracy belief, it promotes distrust in institutions more generally – it could be government, science, the media, whatever,” said senior author Russell Fazio, professor of psychology at Ohio State. “Once you start viewing events through that distrustful lens, it’s very easy to adopt additional conspiracy theories.”The study is published today (Oct. 26, 2022) in the journal PLOS ONE.The field of conspiracy theory research is relatively young, and to date has tended to look for traits that predict the tendency to believe in conspiracy theories at a given point in time.“But if you read interviews or forums frequented by conspiracy theorists, you see a phenomenon where people tend to go down the rabbit hole after something happens in their life that triggers general interest in conspiracy theories,” said first author Javier Granados Samayoa, who completed the work while a graduate student in psychology at Ohio State. “With COVID-19, there was this large event that people could not control, so how could they make sense of it? One way is by adhering to conspiracy theories.”The researchers asked 501 participants in a June 2020 survey to answer questions assessing their beliefs in COVID-19 conspiracy theories, political ideology and what is called conspiracist ideation, or one’s overall affinity for conspiracy theories. In this section, participants used a 5-point scale ranging from “definitely not true” to “definitely true” to rate statements such as “Some UFO sightings and rumors are planned or staged in order to distract the public from real alien contact” and “New and advanced technology which would harm current industry is being suppressed.”Six months later, in December 2020, 107 of those same participants again responded to statements gauging their level of conspiratorial thinking. Researchers further assessed conspiracist ideation by asking participants to report the extent to which they believed that there had been extensive voter fraud in the 2020 presidential election.Statistical analysis showed that participants who reported greater belief that the SARS-CoV-2 virus was released for dark purposes and that the severity of COVID-19 disease was blown out of proportion also reported greater belief that the 2020 election had been stolen from Trump. And compared to their baseline conspiracist ideation measured in the June survey, COVID skeptics had higher levels of general endorsement of conspiracy theories six months later.The association held true even after the analysis took into account the association between belief in conspiracy theories about COVID-19 and voter fraud and conservative political views, said Granados Samayoa, now a postdoctoral fellow at the University of Pennsylvania.The team also cited data from a large United Kingdom multi-part survey conducted during the early spring and late fall of 2020 that supported the gateway conspiracy hypothesis: The Ohio State team’s analysis showed that belief among a nationally representative sample of UK adults that the pandemic was a hoax predicted increases in conspiracist ideation over time.The Ohio State data showed one strong trend suggesting that financial distress during the lockdown could have been a factor in adopting conspiracy theory beliefs about the pandemic – even among those who started off with low levels of conspiracist ideation.“And then there is the question: Once that happens, what changes over time? That’s where we got into this longitudinal work, which has been absent in previous research,” Fazio said.While some past conspiracy theories have turned out to be true, this study focused on beliefs that are not supported by evidence and are undermined by the evidence that does exist. The researchers noted that a better understanding of the dynamics of conspiratorial thinking could help stop the spread of conspiracist ideation, which is associated with a higher risk for violence and discrimination and poor health choices, among other negative individual and societal outcomes.“These findings show that we need to be prepared for any additional large-scale events similar to COVID-19 to stem off conspiracist ideation because once people go down the rabbit hole, they may get stuck,” Granados Samayoa said.This work was supported by the National Science Foundation. Additional co-authors, all from Ohio State, included Fazio lab members Courtney Moore, Shelby Boggs, Jesse Ladanyi and Benjamin Ruisch, now at the University of Kent in England.",0.0,0.0
261,https://scitechdaily.com/for-the-first-time-a-robot-has-learned-to-imagine-itself/,A swarm of tiny robots could soon brush and floss your teeth for you,"A robot created by Columbia Engineers learns to understand itself rather than the environment around it.Our perception of our bodies is not always correct or realistic, as any athlete or fashion-conscious person knows, but it’s a crucial factor in how we behave in society. Your brain is continuously preparing for movement while you play ball or get dressed so that you can move your body without bumping, tripping, or falling.Humans develop our body models as infants, and robots are starting to do the same. A team at Columbia Engineering revealed today that they have developed a robot that, for the first time, can learn a model of its whole body from scratch without any human aid. The researchers explain how their robot built a kinematic model of itself in a recent paper published in Science Robotics, and how it utilized that model to plan movements, accomplish objectives, and avoid obstacles in a range of scenarios. Even damage to its body was automatically detected and corrected.The robot watches itself like an infant exploring itself in a hall of mirrorsThe researchers placed a robotic arm within a circle of five streaming video cameras. The robot watched itself through the cameras as it undulated freely. Like an infant exploring itself for the first time in a hall of mirrors, the robot wiggled and contorted to learn how exactly its body moved in response to various motor commands. After about three hours, the robot stopped. Its internal deep neural network had finished learning the relationship between the robot’s motor actions and the volume it occupied in its environment.“We were really curious to see how the robot imagined itself,” said Hod Lipson, professor of mechanical engineering and director of Columbia’s Creative Machines Lab, where the work was done. “But you can’t just peek into a neural network, it’s a black box.” After the researchers struggled with various visualization techniques, the self-image gradually emerged. “It was a sort of gently flickering cloud that appeared to engulf the robot’s three-dimensional body,” said Lipson. “As the robot moved, the flickering cloud gently followed it.” The robot’s self-model was accurate to about 1% of its workspace.A technical summary of the study. Credit: Columbia EngineeringSelf-modeling robots will lead to more self-reliant autonomous systemsThe ability of robots to model themselves without being assisted by engineers is important for many reasons: Not only does it save labor, but it also allows the robot to keep up with its own wear-and-tear, and even detect and compensate for damage. The authors argue that this ability is important as we need autonomous systems to be more self-reliant. A factory robot, for instance, could detect that something isn’t moving right, and compensate or call for assistance.“We humans clearly have a notion of self,” explained the study’s first author Boyuan Chen, who led the work and is now an assistant professor at Duke University. “Close your eyes and try to imagine how your own body would move if you were to take some action, such as stretch your arms forward or take a step backward. Somewhere inside our brain we have a notion of self, a self-model that informs us what volume of our immediate surroundings we occupy, and how that volume changes as we move.”Self-awareness in robotsThe work is part of Lipson’s decades-long quest to find ways to grant robots some form of self-awareness. “Self-modeling is a primitive form of self-awareness,” he explained. “If a robot, animal, or human, has an accurate self-model, it can function better in the world, it can make better decisions, and it has an evolutionary advantage.”The researchers are aware of the limits, risks, and controversies surrounding granting machines greater autonomy through self-awareness. Lipson is quick to admit that the kind of self-awareness demonstrated in this study is, as he noted, “trivial compared to that of humans, but you have to start somewhere. We have to go slowly and carefully, so we can reap the benefits while minimizing the risks.”Reference: “Fully body visual self-modeling of robot morphologies” by Boyuan Chen, Robert Kwiatkowski, Carl Vondrick and Hod Lipson, 13 July 2022, Science Robotics.DOI: 10.1126/scirobotics.abn1944The study was funded by the Defense Advanced Research Projects Agency, the National Science Foundation, Facebook, and Northrop Grumman.The authors declare no financial or other conflicts of interest.",0.0,0.0
233,https://techcrunch.com/2022/05/10/sencrop-predicts-weather-conditions-at-a-microclimate-level-for-farmers/,Sencrop predicts weather conditions at a microclimate level for farmers,"French startupFrench startupWeather forecasting is a complicated industry as it requires a ton of data to create an accurate forecasting model. That’s why Sencrop is drawing inspiration from Netatmo or Waze and betting on crowdsourcing to improve its service.Weather forecasting is a complicated industry as it requires a ton of data to create an accurate forecasting model. That’s why Sencrop is drawing inspiration from Netatmo or Waze and betting on crowdsourcing to improve its service.Sencrop customers can buy their own connected stations to measure temperature, humidity, rainfall, wind speed and sunlight. These weather stations all contribute to Sencrop’s real-time data.Sencrop customers can buy their own connected stations to measure temperature, humidity, rainfall, wind speed and sunlight. These weather stations all contribute to Sencrop’s real-time data.And it’s been working well as the company has already sold over 20,000 weather stations. In France, there’s one weather station per 20 square kilometers on average. The company operates in 20 countries and has office in France, the Netherlands, the U.K., Germany, Spain and Italy.And it’s been working well as the company has already sold over 20,000 weather stations. In France, there’s one weather station per 20 square kilometers on average. The company operates in 20 countries and has office in France, the Netherlands, the U.K., Germany, Spain and Italy.Customers can see current weather conditions and export historical data. But they can also move around the map, set up alerts and select between multiple forecasting models to prepare for the next few days and anticipate agronomic risks. Sencrop can help you when it comes to water stress and irrigation management as well. There are multipleCustomers can see current weather conditions and export historical data. But they can also move around the map, set up alerts and select between multiple forecasting models to prepare for the next few days and anticipate agronomic risks. Sencrop can help you when it comes to water stress and irrigation management as well. There are multipleSencrop also provides multiple integrations with Decision Support Tools, such as Rimpro, VitiMeteo, fruitweb, 360 viti and Idroplan. This metric-driven way of growing fruits, cereals or vines should lead to better productivity and an improvement on the bottom line.Sencrop also provides multiple integrations with Decision Support Tools, such as Rimpro, VitiMeteo, fruitweb, 360 viti and Idroplan. This metric-driven way of growing fruits, cereals or vines should lead to better productivity and an improvement on the bottom line.In addition to JVP, other investors in today’s round include EIT Food, Stellar Impact, IRD Management and some of the company’s existing shareholders, such as Bpifrance, Demeter IM and NCI Waterstart.In addition to JVP, other investors in today’s round include EIT Food, Stellar Impact, IRD Management and some of the company’s existing shareholders, such as Bpifrance, Demeter IM and NCI Waterstart.“Sencrop’s mission is to democratize precision farming and reduce crop risks for farmers,” Sencrop co-founder and General Manager Martin Ducroquet said in a statement. “We have developed a unique microclimate technology which today allows more than 20,000 professionals — farmers, winegrowers, fruit growers, etc. — to access ultra-precise and ultra-local information for better daily monitoring of their crops and the risks on their plots.”“Sencrop’s mission is to democratize precision farming and reduce crop risks for farmers,” Sencrop co-founder and General Manager Martin Ducroquet said in a statement. “We have developed a unique microclimate technology which today allows more than 20,000 professionals — farmers, winegrowers, fruit growers, etc. — to access ultra-precise and ultra-local information for better daily monitoring of their crops and the risks on their plots.”Up next, the company wants to accelerate its international expansion, starting with North America.Up next, the company wants to accelerate its international expansion, starting with North America.",0.0,0.0
236,https://www.euronews.com/green/2022/10/13/scientists-dream-up-a-massive-floating-solar-farm-in-space-heres-how-it-would-work,Scientists dream up a massive floating solar farm in space - here's how it would work,"It sounds like the stuff of science fiction - but Europe might one day be powered by giant floating solar panels orbiting the planet.The European Space Agency (ESA) has unveiled a plan to harvest the sun’s energy in space and beam it back down to Earth.The technology is still in the preliminary testing phase - but the end goal is the construction of a 2km long solar space farm, generating as much energy as a nuclear power plant.The farm would orbit an eye-watering 36,000 km above the Earth.“[Such a project] would ensure that Europe becomes a key player– and potentially leader – in the international race towards scalable clean energy solutions for mitigating climate change,” the ESA said in a statement.How will the space farm technology work?Solar power is one of the best sources of clean energy, but it’s currently held back by a few limitations. Panels can only harness power in the daytime, and even then, much of the sunlight is absorbed by the atmosphere on its journey to the ground.In Space, the sun’s beams are around ten times as intense as they are on Earth.The ESA have partnered with Airbus - a European multinational aerospace corporation - to develop ‘wireless power transmission’ to capture this 24-hour source of electricity and beam it down to us.The sun's rays are 10 times as strong in space, where they are not diluted in the atmosphere. ClearedThe technology is based on the transmission used by TV and communication satellites every day, Airbus engineer Nicolas Schneider explains.""We are not very far from a 4G antenna, except that what we want is not to radiate in all directions, we want to be very precise like a laser, in fact,” he says.“It’s a wave that can be directed to this receiving antenna which will then transform this wave into electricity.""The problem is scale. The satellite would have to be massive, so would be difficult to launch and build.But with technology evolving rapidly, the project could be a reality in coming decades. The ESA will discuss the Solaris project at its meeting in November.The satellite would be repaired by robots while in orbit, explains Gwenaëlle Aridon, hHead of the Robotics Laboratory at Airbus Defence and Space.""The robot will be able to come and repair a panel, remove it and put a new one on if necessary,” she said.“Having [robot] manipulators reboot arms would effectively reduce the cost of the operations that are carried out.”It may be a logistical challenge - but as energy crises shift and unfold, it could eventually be a game changer.A single solar power satellite of the planned scale would generate around two gigawatts of power, equivalent to a conventional nuclear power station or six million solar panels on earth.The resulting energy could power more than one million homes.",0.0,0.0
223,https://www.npr.org/2022/10/30/1130239008/fires-from-exploding-e-bike-batteries-multiply-in-nyc-sometimes-fatally,Fires from exploding e-bike batteries multiply in NYC â sometimes fatally,"Fires from exploding e-bike batteries multiply in NYC — sometimes fatallyEnlarge this image toggle caption FDNY FDNYNEW YORK — Four times a week on average, an e-bike or e-scooter battery catches fire in New York City.Sometimes, it does so on the street, but more often, it happens when the owner is recharging the lithium ion battery. A mismatched charger won't always turn off automatically when the battery's fully charged, and keeps heating up. Or, the highly flammable electrolyte inside the battery's cells leaks out of its casing and ignites, setting off a chain reaction.""These bikes when they fail, they fail like a blowtorch,"" said Dan Flynn, the chief fire marshal at the New York Fire Department. ""We've seen incidents where people have described them as explosive — incidents where they actually have so much power, they're actually blowing walls down in between rooms and apartments.""Brooklyn: 374 East 9th Street @FDNY operating at a 3 Alarm Fire in a 3 story private dwelling with extention to adjoining building pic.twitter.com/oCs3VI39SQ — NYRRT (@NYRRT) April 21, 2022A fire in Brooklyn in April was traced to a faulty e-bike or e-scooter battery that ignited and gutted two houses.And these fires are getting more frequent.As of Friday, the FDNY investigated 174 battery fires, putting 2022 on track to double the number of fires that occurred last year (104) and quadruple the number from 2020 (44). So far this year, six people have died in e-bike-related fires and 93 people were injured, up from four deaths and 79 injuries last year.In early August, a 27-year-old Venezuelan immigrant, identified as Rafael Elias Lopez-Centeno, died after his lithium ion battery caught fire and ripped through the Bronx apartment where he was staying. Carmen Tiburcio, a neighbor, said Lopez's aunt told her he had tried to escape through the front door, but the bike was in the way. Instead, he took refuge in the bathroom, where he tried to fill up the bathtub with water to protect himself from the flames. But the smoke got to him, she said.""He didn't make it,"" Tiburcio said. ""His lungs were very bad.""Another danger to delivery workMany, if not most, of the fires in New York involve e-bike batteries owned by restaurant delivery workers, who work long shifts, traveling dozens of miles a day.""The bikes tend to get beat up, subjected to the elements,"" Flynn said. ""They're not really made for our streets.""The longer the batteries are used, the more time it takes to fully recharge them, and it can take up to 8 hours. That in turn makes it harder for owners to keep on eye on their batteries the whole time they are plugged in, which is key for safety.Enlarge this image toggle caption FDNY FDNYIn addition, new batteries are costly, and the temptation to opt for a less-expensive refurbished battery for much less money is great — especially for couriers who make an average of $12.21 an hour after expenses, according to a survey by Los Deliveristas Union, an advocacy and membership organization.Several e-bike owners interviewed by NPR in New York City said they were aware of the risks batteries posed, and took measures to reduce them.""A lot of guys have four, five, six bikes in their apartment and they swap out chargers for different bikes when it doesn't belong to that bike,"" said Rafael Cardanales, who lives on the Lower East Side. ""You can't just use any charger, you know.""Musfiqur Rahman said that when he first got into the delivery business, he bought two new Arrow brand batteries — for $550 each. He did it specifically to avoid fires.""As far as I know, this brand never get involved in this kind of incident,"" the 27-year-old Bangladeshi immigrant said.The FDNY says most batteries are so destroyed by fire when they inspect them that they can make no conclusions about which brand is safer than another.The FDNY has begun posting videos on social media warning about the dangers of recharging lithium ion batteries.Living in close quartersE-bike related fires have occurred elsewhere, such as London, San Francisco, Michigan and South Florida. But nowhere does concern for them appear to be as high as in New York, perhaps because of the prevalence of apartment living — and also the prevalence of ordering take-out.While restaurants sometimes store bikes overnight for employees, fewer people are now working for particular restaurants and many more for themselves, using apps like Door Dash or Uber Eats to connect with customers. And these couriers often don't have any other place to store and recharge their e-bikes except in their apartments.That, in turn, creates a fire hazard not just for the workers, but also for their neighbors. This summer, the New York City Housing Authority proposed banning e-bikes and batteries from its 2,600 buildings. But the proposal created an uproar, and officials have not gone through with it.Enlarge this image toggle caption Matthew Schuerman/NPR Matthew Schuerman/NPRCity councilmembers have proposed their own solutions. One bill, for instance, would ban the sale of used batteries within city limits. Another would require all batteries to be sold to be approved by a national testing service, such as Underwriters Laboratories. Mayor Eric Adams recently announced he would direct $1 million to create hubs for delivery workers with charging stations and other amenities — though they would likely be used during the day and not provide overnight charging.Councilmember Gale Brewer, who sponsored the legislation that would outlaw the sale of used batteries, says she recognizes that new batteries could be prohibitively expensive to delivery workers.""They do, you know, God's work, so to speak, because New Yorkers like to have food delivered,"" she said. ""So now the question is how do they get the new batteries that are not going to cause fires?""",0.0,0.0
241,https://electrek.co/2022/10/10/wind-turbine-24-hour-power-world-record/,A turbine prototype just broke a 24-hour wind power world record,"Siemens Gamesa’s 14-222 DD offshore wind turbine prototype has, according to the Spanish-German wind giant today, set a world record for the most power output by a single wind turbine in a 24-hour period: 359 megawatt-hours.UnderstandSolar is a free service that links you to top-rated solar installers in your region for personalized solar estimates. Tesla now offers price matching, so it’s important to shop for the best quotes. Click here to learn more and get your quotes. — *ad.This would be enough energy, according to the company, for a mid-sized electric vehicle – think a Tesla Model 3 – to drive around 1.12 million miles (1.8 million km).Siemens Gamesa’s huge wind turbine achieved this power output milestone only 10 months after it produced its first electricity and delivered it to the grid at the test center in Østerild, Denmark.The SG 14-222 DD is a 14 megawatt (MW) offshore wind turbine with a capacity of up to 15 MW with Power Boost.It features a 222-meter (728 feet) diameter rotor, 108-meter-long (354-feet-long) B108 blades that are cast in a single piece and can now be recycled, and a swept area of 39,000 square meters (419,792 square feet).The SG 14-222 DD can provide enough energy to power around 18,000 households annually.Siemens Gamesa writes:By increasing the rotor diameter to 222 meters with 108 meter-long blades, the SG 14-222 DD delivers more than 25% [annual energy production] AEP compared to its predecessor. With every new generation of our offshore direct drive turbine technology – which uses fewer moving parts than geared turbines – component improvements have enabled greater performance while maintaining reliability. We are able to reduce time to market of the SG 14-222 DD thanks to standardized processes and a fully developed supply chain. Enabling high volume production at low risk. The serial production is planned for 2024.In June, Siemens Gamesa was awarded a firm order for 60 of its SG 14-222 DD offshore wind turbines, which will be installed at the 882-megawatt (MW) Moray West offshore wind farm in Scotland. It will be the first installation of this model.Read more: The world’s most powerful wind turbine will make its debut in ScotlandPhoto: Siemens Gamesa",0.0,0.0
242,https://pv-magazine-usa.com/2022/10/13/global-polysilicon-capacities-may-nearly-double-by-end-of-2023-to-536-gw/,Global polysilicon capacities may nearly double by end of 2023 to 536 GW,"In its Q2 2022 PV Supplier Market Intelligence Program Report (SMIP), solar and storage supply technical advisory Clean Energy Associates (CEA) said polysilicon production capacity may reach 295 GW by the end of 2022, and 536 GW year’s end 2023.CEA said it expects this production capacity to far exceed solar installations next year. While this may suggest supply problems could begin to be alleviated, CEA said module capacity expansions are slowing. Many manufacturers are instead expanding cell production capacity, catering to the trend of n-type TOPCon and HJT manufacturing.Ingot capacity grew almost 30 GW this quarter, most of which can be attributed to two facilities bringing 23 GW online.Wafer capacity decreased slightly, said CEA, primarily due to a major provider retiring its multi-crystalline wafer capacity. The 17 suppliers covered in the report boosted cell capacity by 22% in Q2 2022, bringing 47 GW of capacity online, reaching a total of 262 GW.Module production reached 324 GW in Q2. CEA forecasts this may expand 20% by the end of the year, reaching 400 GW.Only seven suppliers covered by the CEA report are fully vertically integrated from ingot to module production, with most others operating at the cell and module link in the supply chain. “With growing merchant wafer options, there is little need for most suppliers to expand upstream,” said CEA.The report said suppliers are working to optimize wafer sizes after the industry standardized 210 mm (G12) and 182 mm (M10) module dimensions. The “182 mm Plus” (182P) has increased wafer heights to further reduce “white space” caused by intercell gaps to achieve up to 5 W of additional output, said CEA. The “210 mm Reduced” (210R) reduced wafer widths for niche rooftop applications at the expense of power output. CEA said it expects new module sizes for the residential solar market to be introduced.Many analysts have predicted China will break 100 GW of installations this year. CEA expects slightly lower installations in China during 2022 due to high module prices impacting utility-scale projects. It said many investment decisions have been deferred as projects could not meet their internal rate of return thresholds.Most of the polysilicon supply chain originates in China. Outside of China, production capacities are 11 GW of ingot, 42 GW of cell, and 50 GW of module capacity. By end of 2023, these capacities are expected to expand to 23 GW, 73 GW, and 74 GW, respectively.“Policy uncertainties continue to defer expansion plans of suppliers as they remain cautious due to lingering policy uncertainty in the United States surrounding the Uyghur Forced Labor Prevention Act and anticircumvention investigation,” said CEA in the report.",0.0,0.0
244,https://electrek.co/2022/10/13/miners-cut-co2-emissions-in-half-switching-electric-vehicles/,Miners are cutting CO2 emissions in half by switching to electric vehicles for extracting critical minerals,"While you may notice more electric vehicles on the road today than ever before, the technology is now making its way to miners, the companies extracting the critical minerals needed to build EVs, ensure adequate global food supply, etc. A new contract to supply battery electric vehicles to the Jansen potash project (potentially the world’s largest potash mine) expects to slash carbon emissions in half compared to its peers. What if we could apply this technology to miners in the EV industry, creating a full circle sustainable supply chain?BHP’s Jansen potash project is expected to be the largest of its kind, with initial capacity forecasts of 4.3 to 4.5 Mtpa.Potash is often found in fertilizer and is a rich source of potassium, a mineral essential for our health. Since potassium is not produced by the body naturally, it must be consumed through food. Potash is the most commonly used potassium fertilizer, but over 70% is based on conventional underground mining that uses heavy-duty equipment to extract it.Although underground mining can release half the CO2 emissions of open-pit mining, the company is taking it further by introducing several battery electric vehicles.Normet Canada, the mining company behind the project, was awarded a new contract to use battery electric vehicles at the Jansen potash project, including 10 underground EV loaders and one electric tethered loader.With these heavy-duty electric vehicles, BHP says the Jansen project is forecast to reduce CO2 emissions by 50% compared to the Saskatchewan potash mine.The electric vehicle deliveries are expected to begin in March 2023 and run through 2024, which will work perfectly as the miners aim to start production in 2026.Like potassium is critical for humans, electric vehicles also require certain minerals such as lithium and nickel. These miners are looking for ways to build on the momentum electric vehicles are establishing in reducing carbon emissions, completing a complete sustainability supply chain. Several companies are now working to make this a reality.Normet electric mining equipment (Source: Normet)Miners using electric vehicles can complete the sustainability supply chainAlmost every automaker has set its intentions to scale production of its electric vehicles to meet the growing demand for zero-emission cars while setting carbon reduction targets.For example, GM is going all-electric by 2035, Ford looks to produce 2 million EVs annually by 2026, and Volkswagen plans to be fully electric in Europe by 2035, while North America follows.Tesla, only selling electric cars, continues breaking records with 343,000 EVs delivered in Q3 on its way to producing 20 million annually.However, getting to these numbers will require mining. A few companies have already begun working to build a sustainable EV supply chain.Snow Lake Lithium outlined its plans in February to develop the world’s first all-electric lithium mine, one of the most critical minerals used to build EV batteries. The mining company’s CEO said at the time if you are going to mine for these resources that will be used to protect the environment, then obtaining them must also be done in a sustainable matter.The company is working with Meglab, an electrical equipment provider and mining solutions company, to make the dream a reality.There are operations around the world working to reduce emissions in the mining sector. In July 2021, Opibus (now ROAM) converted a Toyota Land Cruiser fitted with an electric powertrain to use a mining vehicle.Miners using electric vehicles can significantly reduce the heat and carbon exposure they typically experience with diesel-powered equipment. Furthermore, EV mining technology can cost less as it requires less ventilation and cooling.The point is, as the auto industry transitions to electric vehicles, companies are figuring out ways to build on the momentum EVs are establishing in reducing emissions. If miners get on board, it will come full circle, creating a complete sustainable EV supply chain.",0.0,0.0
199,https://arstechnica.com/gadgets/2022/11/pantone-wants-15-month-for-the-privilege-of-using-its-colors-in-photoshop/,Pantone wants $15/month for the privilege of using its colors in Photoshop,"If you want to use up-to-date versions of Adobe's Creative Cloud apps, you've already been paying subscription fees for years now. And if you want to use Pantone colors inside of Adobe's apps, it's about to get even more expensive. Starting this month, the Pantone color books in Adobe's apps are mostly going away, and continuing to use those colors in your files will require a new Pantone Connect extension.Using that extension is free once you've created an account, but using the full library of colors, creating unlimited color palettes, and ""a dozen more tools to create smarter, more impactful palettes"" will now require a subscription that will run $15 per month or $90 per year, on top of what you're already paying to use Adobe's apps in the first place. I could browse through colors using the basic version of the extension, but trying to browse and select most colors from most libraries prompted me to pay for a subscription.Strange as it might seem for a company to be able to ""own"" colors, that's an oversimplification of what Pantone does—it maintains a large library of reference colors and physical color samples used in print publishing and many design industries to ensure that colors look the way they're supposed to look, no matter what material they're being used on. If you want to see what a given color will look like when printed on a matte sheet of paper versus a glossy sheet of paper versus plastic versus cloth (among other things), and you want to know that the manufacturer or printer sees the exact same color you do, that's when Pantone colors can be useful. Different computer, tablet, and phone displays will also show different colors differently based on how the displays are calibrated and what colors they're capable of showing—Pantone colors and physical samples help to eliminate some guesswork and inconsistency.AdvertisementFun times ahead for #Adobe designers. Today, if you open a PSD (even one that's 20 years old) with an obscure PANTONE colour, it will remove the colour and make it black. Pantone want US$21/month for access, and Solid Coated goes behind the paywall in early November. pic.twitter.com/BUxzViYFaQ — Iain Anderson (@funwithstuff) October 28, 2022This change seems to be rolling out gradually. Some users have already encountered Photoshop error messages informing them of the change, and that Pantone colors in old Photoshop files are being replaced with black when they're opened in newer versions of the software. Adobe says that the Solid Coated and Solid Uncoated Pantone libraries will be removed ""after November 2022,"" leaving only the CMYK Coated, CMYK Uncoated, and Metallic Coated Pantone libraries behind.Ars asked Adobe about the color replacement issue, and were told the following by an Adobe spokesperson: ""We are currently looking at ways to lessen the impact on our customers. In the meantime, customers also have access to up to 14 extensive color books through Creative Cloud subscriptions.""On an M1 MacBook Air running the most current version of Photoshop, I can still access all Pantone color libraries as before, including the Solid Coated and Solid Uncoated libraries that are supposedly going away. (Adding insult to injury for Mac users, the current version of the Pantone Connect extension isn't Apple Silicon-compatible and requires launching the app in the slower Intel emulation mode.)To hear Pantone tell it, Adobe had not been updating the Pantone color libraries in its apps for more than a decade, which prompted the end of the previous licensing deal and the wholesale removal of the old libraries from Adobe's apps in favor of the Pantone Connect Extension. But communication around this issue has been muddled, with conflicting and changing dates for when the removal of the existing Pantone libraries begins and different pricing data based on the source you're looking at. The Pantone FAQ and coverage from earlier this year list an $8/month or $60/year subscription price for Pantone Connect, much lower than the prices listed on the plugin's product page.AdvertisementThat Pantone FAQ also claims that ""existing Creative Cloud files and documents containing Pantone Color references will keep those color identities and information,"" a statement that seems to be contradicted by the Adobe licensing error message. For its part, Adobe's FAQ says that versions of its apps released before August 2022 ""will continue to have all previous Pantone Color books pre-loaded and available.""In a pinch, this means you could use Creative Cloud's ""other versions"" feature to install an older version of your apps that can still see and work with Pantone colors as you could before (Photoshop 23.4, InDesign 17.3, and Illustrator 26.4 appear to be the most recent versions released before August 2022).This is only a stopgap; Adobe doesn't offer older versions of its apps indefinitely. But for people who don't use Pantone colors heavily or regularly, it can allow you to open and modify your files so you don't end up with blacked-out colors in your images. Others have suggested that manually copying these Pantone color libraries from older versions of the apps and re-adding them to the newer versions could also be a workaround for some users.We asked Adobe about all the contradictory information we've run into: the exact date users can expect to see these changes; whether old files will have their colors removed or whether they'll be unchanged; and whether any missing colors can be restored by installing the Pantone Connect plugin (something we can't test for because Pantone colors are still working fine on our end). The company had nothing else to share about these specific questions as of this writing.",0.0,0.0
198,https://arstechnica.com/science/2022/10/myth-busted-formation-of-namibias-fairy-circles-isnt-due-to-termites/,"Myth, busted: Formation of Namibiaâs fairy circles isnât due to termites","So-called ""fairy circles"" are bare, reddish-hued circular patches notably found in the Namibian grasslands and northwestern Australia. Scientists have long debated whether these unusual patterns are due to termites or to an ecological version of a self-organizing Turing mechanism. A few years ago, Stephan Getzin of the University of Göttingen found strong evidence for the latter hypothesis in Australia. And now his team has found similar evidence in Namibia, according to a new paper published in the journal Perspectives in Plant Ecology, Evolution and Systematics.""We can now definitively dismiss the termite hypothesis, as the termites are not prerequisite to form new fairy circles,"" Getzin told Ars. This holds both for Australian and Namibian fairy circles.As we've reported previously, Himba bushmen in the Namibian grasslands have passed down legends about the region's mysterious fairy circles. They can be as large as several feet in diameter. Dubbed ""footprints of the gods,"" it's often said they are the work of the Himba deity Mukuru, or an underground dragon whose poisonous breath kills anything growing inside those circles.Scientists have their own ideas, and over the years, two different hypotheses emerged about how the circles form. One theory attributed the phenomenon to a particular species of termite (Psammmotermes allocerus), whose burrowing damages plant roots, resulting in extra rainwater seeping into the sandy soil before the plants can suck it up—giving the termites a handy water trap as a resource. As a result, the plants die back in a circle from the site of an insect nest. The circles expand in diameter during droughts because the termites must venture farther out for food.AdvertisementThe other hypothesis—the one espoused by Getzin—holds that the circles are a kind of self-organized spatial growth pattern (a Turing pattern) that arise as plants compete for scarce water and soil nutrients. In his seminal 1952 paper, Alan Turing was attempting to understand how natural, non-random patterns emerge (like a zebra's stripes), and he focused on chemicals known as morphogens. He devised a mechanism involving the interaction between an activator chemical and an inhibitor chemical that diffuse throughout a system, much like gas atoms will do in an enclosed box.It's akin to injecting a drop of black ink into a beaker of water. Normally this would stabilize a system: the water would gradually turn a uniform gray. But if the inhibitor diffuses at a faster rate than the activator, the process is destabilized. That mechanism will produce a Turing pattern: spots, stripes, or, when applied to an ecological system, clusters of ant nests or fairy circles.In 2019, Getzin's team conducted a study of fairy circles in northwestern Australia, near an old mining town called Newman. The team dug more than 150 holes in almost 50 fairy circles in the region to collect and analyze soil samples, specifically to test the termite hypothesis. They also used drones to map larger areas of the continent to compare the gaps in vegetation typically caused by harvester termites in the region, with the fairy circles that sometimes form.The vegetation gaps caused by harvester termites were only about half the size of the fairy circles and much less ordered, so they didn't find any hard subterranean termitaria that would prevent the growth of grasses. But they did find high soil compaction and clay content in the circles, evidence for the contribution of heavy rainfall, extreme heat, and evaporation to their formation. ""Termite constructions can occur in the area of the fairy circles, but the partial local correlation between termites and fairy circles has no causal relationship,"" Getzin said at the time. ""So no destructive mechanisms, such as those from termites, are necessary for the formation of the distinct fairy circle patterns; hydrological plant-soil interactions alone are sufficient.”AdvertisementHaving effectively disproven the Australian termite origin hypothesis, Getzin turned his attention to specifically testing the termite hypothesis for Namibia, using a similar methodology. While his earlier work on Namibian fairy circles did not specifically address the investigations of plant roots, this new study shows that plant roots are not touched by insect herbivores.""For the first time, we went right after rainfall to the fairy circles and checked the new grasses for termite herbivory,"" Getzin told Ars. ""Our excavations demonstrate that termites did certainly not cause the death of the grasses. If you come too late to the fairy circles, the grasses are long dead and detritivores like termites may have already fed on the lignified grass. But they did not kill the grass. We are showing unambiguously that the grasses die before and completely independent of any termite action.""So what's next for Getzin? He believes more research is needed on the swarm intelligence of plants, likening plants to beavers in the sense that they can act as ""ecosystem engineers"" that modify their environment. ""Most people cannot believe this or are unwilling to believe that, because plants have no brains,"" said Getzin. ""But plants act similarly like the beaver as ecosystem engineers because their only way to survive is forming optimal, strictly geometric patterns""—in other words, Turing patterns.DOI: Perspectives in Plant Ecology, Evolution and Systematics, 2022. 10.1016/j.ppees.2022.125698 (About DOIs).",0.0,0.0
594,https://techcrunch.com/2017/03/21/the-mednet-launches-its-quora-for-cancer-an-online-medical-knowledge-base/,"The Mednet launches its âQuora for cancer,â an online medical knowledge base","A New York City startup called The Mednet today launched a platform that gives physicians a knowledge-sharing tool that’s as easy to use as Quora, but provides them with expert answers about the latest research in their field. The site has focused, so far, strictly on cancer.Due to rules governing medical information and patients’ privacy, questions posted to The Mednet cannot be case-based. They are situation-based only, meaning doctors don’t share patient info, not even blurred photos.While the startup’s site, theMednet.org, has been in development for about 2.5 years, the company officially launched today and is part of the latest batch of the Y Combinator accelerator. Co-founders Nadine Housri, a radiation oncologist, and her brother CEO Samir Housri told TechCrunch their company has raised some grant funding and equity funding to date, including from YC and The Hope Foundation.Results on the platform have been hope-inspiring so far to Nadine Housri, she said. Cancer experts regularly help each other there to figure out complex issues that will immediately impact their patients. For example, a new study published in the prestigious New England Journal of Medicine came out, and an investigator in that study, Howard Sandler, answered questions about it on The Mednet, helping other doctors decide whether or not to use hormones, along with radiation, to treat a prostate cancer patient.His study had found that adding hormonal therapy to radiation treatment improved the average long-term survival of men with prostate cancer who have had their prostate gland removed. But of course, the science was complicated and the regimen wasn’t recommended for any or every patient.Nadine Housri said when theMednet.org first launched, she wasn’t sure if oncologists, professors, department chairs and other cancer researchers would be too busy to give away their expertise on some new online platform. But, she explained, “Experts are willing to give away info to random people here because they constantly field phone calls, emails and answer questions at medical conferences anyway. One reason you go into academia or medicine is to have a great impact on people, on your community. On Mednet experts can put their answers out there, clear up misconceptions on research and clinical practices.”Like many startups, The Mednet has spent its early years focused on building an expert user community, and becoming a vital resource to users, as well. The Housris said their network will always be accessible for free to doctors, and they want it to serve as a knowledge base for medicine broadly. The company plans to expand beyond oncology over the long run.It is exploring the potential to generate revenue by helping companies raise awareness of and enroll patients in their clinical trials. It could also aggregate some of its expert answers into automated decision support for clinics, the founder said. Depending on its monetization strategy, The Mednet could compete with online resources for physicians like Figure 1 or UpToDate over the long run. But when it comes to medicine, there probably can’t be too many tools to help people get good, up-to-date information.",0.0,0.0
582,https://techcrunch.com/2017/05/17/clue-now-advises-women-who-forgot-to-take-their-contraceptive-pill/,Clue now advises women on what to do if they forgot to take their contraceptive pill,"Clue now advises women on what to do if they forgot to take their contraceptive pillClue, the app for tracking your period and all things related, surveyed a fraction of its 5 million worldwide users and found out that in some countries a lot of young women didn’t know what to do if they didn’t take their contraceptive pill on time.In Russia, for instance, you can buy the pill without a prescription and Clue found one out of four women there were given zero advice to go along with even the basics about their period. Not taking the pill on time can start a woman’s cycle and could potentially lead to an unwanted pregnancy. Young women not aware of that point could find themselves in an awful situation.Clue’s younger user base now relies on the app for information on topics they are too uncomfortable asking an adult or medical provider, says founder Ida Tin. And in that, she saw an opportunity in education. Now women who forgot to take their pill or took it the wrong way can get advice from the app on what to do next.Clue already helped women track when they were taking their pill as well as whether it was taken late, on time, missed, or double dosed. However, Tin says the app now offers medically validated advice, based on the type of pill you take. The new feature also helps users track the side effects of a combined pill or progestogen-only pill, and could prove useful for those thinking of changing to another type of pill but are too embarrassed to ask a professional about it.Users on the pill will now be able to track categories relevant to the type of pill they take and will see empty dots for days they didn’t take the pill. The feature showing a user’s fertile window will also go away if they opt to instead track contraception.“Clue’s ultimate aim is to help people better understand their bodies by providing them with scientifically accurate, easy to understand information. The Clue app is not a form of contraception, and with the pill being the most commonly used form of birth control, we thought it hugely important to offer our users a feature that not only helps them track their usage, but that also offers immediate and unbiased advice on what to do if a pill is missed or taken late,” Tin said.You can read the rest of the findings in Clue’s worldwide survey of 90,000 women here.",0.0,0.0
545,https://www.supercluster.com/editorial/detection-of-venus-phosphine-survives-heavy-scrutiny,Itâs been two years since researchers made a stunning announcement.,"While the debate and data still churn, the unexpected finding of phosphine offered enough intrigue and wonder to change the tide of opinions and interest in our sister planet. Venus has been considered the forgotten planet, as it has been 30 years since NASA has sent a space mission to Venus, but that is about to change. At least six spacecraft are scheduled to visit Venus in the next ten years, including two NASA missions that could launch as early as 2028: DAVINCI will explore Venus' atmosphere and VERITAS will use radar to map Venus’ surface. India’s Shukrayaan-1 is scheduled to launch as soon as 2024 and will include an instrument that will be able to detect phosphine. A private company, Rocket Lab is hoping to send their own spacecraft to hunt for the source of phosphine in Venus’ atmosphere.",0.0,0.0
408,https://newatlas.com/medical/cancer-metastasis-breakthrough-rethink/,Cambridge cancer breakthrough may prompt rethink of metastasis,"Cancer’s ability to spread through the body is one of its most devastating tricks. Scientists at Cambridge have now identified a protein that plays a key role in metastasis, which not only hints at a new potential treatment but reveals for the first time that this process isn’t unique to cancer.No matter where in the body it originates, cancer can eventually begin to colonize other organs and tissues through a process known as metastasis, which makes it much harder to treat. Unfortunately, there’s still much about metastasis that scientists don’t understand, but ongoing research is continually uncovering mechanisms that could lead to new therapy options.In the new study, Cambridge scientists discovered not just a new mechanism for metastasis, but completely recontextualized its role. It’s long been thought that metastasis was an abnormal process that arises in cancer, but the new study found that it’s a process used by healthy cells as well – cancer just hijacks it for its own purposes.The team made the discovery while investigating a cellular structure known as sodium leak channel, non-selective (NALCN). These channels are located on cell membranes and control how salt goes in and out of the cell. In the new study, the researchers found that NALCN also regulates the release of cells from tissues into the bloodstream, where they can be taken up by other organs and tissues.In tests in mice, the scientists blocked the function of the NALCN protein, and found that it triggered metastasis in stomach, intestinal and pancreatic cancers. That suggests this could be a new target for preventing metastasis, potentially improving outcomes for patients with cancer.But the most surprising discovery came when the team tested the technique in mice without cancer. Blocking NALCN also caused healthy cells to migrate away from their original organs to other ones – pancreatic cells, for instance, moved to the kidney and became healthy kidney cells instead.“These findings are among the most important to have come out of my lab for three decades,” said Professor Richard Gilbertson, Group Leader of the study. “Not only have we identified one of the elusive drivers of metastasis, but we have also turned a commonly held understanding of this on its head, showing how cancer hijacks processes in healthy cells for its own gains. If validated through further research, this could have far-reaching implications for how we prevent cancer from spreading and allow us to manipulate this process to repair damaged organs.”The team now plans to investigate ways to take advantage of this discovery to prevent metastasis, including repurposing existing drugs.The research was published in the journal Nature Genetics.Source: University of Cambridge",0.0,0.0
425,https://www.psypost.org/2022/10/pilots-tend-to-have-less-emotional-intelligence-than-the-average-person-new-research-suggests-64172,"Pilots tend to have less emotional intelligence than the average person, new research suggests","Being emotionally intelligent may be important for a teacher, salesman, or therapist, but what about for a pilot? A study published in Nature’s Scientific Reports suggests that pilots are less likely to be emotionally intelligent compared to the average person.Trait emotional intelligence is a concept that captures an individual’s general ability to manage, perceive, and express emotions. It has been linked with many other positive constructs, such as leadership abilities, self-control, mental strength, and the ability to manage stress well. Though aviation does not seem like a field that would require emotional intelligence, many of the aforementioned advantages could be helpful for pilots. Previous research has studied emotional intelligence in military pilots and did not compare them to a control group, and this study seeks to bridge that gap in literature.For their study, Zachary Dugger and colleagues utilized 44 pilots ranging in age from 24 to 67 years old to serve as the sample. All participants were required to have an active flight qualification and the majority of participants were either current or former military pilots. The control group was drawn from a US dataset and was matched on age, gender, ethnicity, and education as best as possible. In total, 88 control subjects were used. All 132 participants completed measures on trait emotional intelligence and demographics.Results showed that pilots scores lower in trait emotional intelligence, including the subfactors of well-being, emotionality, and sociability. Though pilots have been found to be an extraverted group, it is thought that they score lower in these constructs because their job requires careful precision. The lower scores could also be related to organizational culture.“Pilots have long been associated with a masculine culture that emphasizes aggressiveness, competition, and performance orientation,” the researchers said. “In practice, the pilot selection and training process may produce pilots, primarily male but also female, who fit within this culture.”In regard to self-control, there were no significant differences between control participants and pilots. This is likely because self-control allows people to maintain situational awareness, which is very important for people operating an aircraft.This study took steps into better understanding trait emotional intelligence in pilots. Despite this, there are limitations to note. One such limitation is that the sample was overwhelmingly male. Another limitation is that the sample size of pilots was relatively small and still consisted mainly of people with military service. Future research could focus on obtaining a more diverse sample of pilots.“Overall, the findings show that pilots tend to have lower trait [emotional intelligence] scores, indicating less confidence and reliance on their emotional world, with all the advantages and disadvantages this might entail,” the researchers concluded. “Although exploratory, these findings highlight promising avenues for future trait [emotional intelligence] research within the broader sector of international aviation. Such research will help practitioners identify new opportunities in pilot training and organizational culture, the better to equip pilots for aviation duty, ultimately leading to improved safety, performance, and all-around satisfaction.”The study, “Trait emotional intelligence in American pilots“, was authored by Zachary Dugger, K. V. Petrides, Nicole Carnegie, and Bernadette McCrory.",0.0,0.0
378,https://spectrum.ieee.org/brain-computer-interface-speech,This Implant Turns Brain Waves Into Words,"Edward Chang, the chair of neurological surgery at University of California, San Francisco, is developing brain-computer interface technology for people who have lost the ability to speak. His lab works on decoding brain signals associated with commands to the vocal tract, a project that requires not only today’s best neurotechnology hardware, but also powerful machine learning models.",0.0,0.0
585,https://techcrunch.com/2018/08/29/contraception-app-natural-cycles-facebook-ad-banned-for-being-misleading/,Contraception app Natural Cyclesâ Facebook ad banned for being misleading,"Natural Cycles, a Swedish startup which touts its body temperature-based algorithmic method for tracking individual fertility as an effective alternative to hormonal birth control, has been wrapped by the UK advertising regulator which today upheld three complaints that an advert the company ran last year via Facebook’s platform was misleading.The regulator has banned Natural Cycles from running the advert again, and warned it against exaggerating the efficacy of its product.The ad had stated that “Natural Cycles is a highly accurate, certified, contraceptive app that adapts to every woman’s unique menstrual cycle. Sign up to get to know your body and prevent pregnancies naturally”, and in a video below the text it had also stated: “Natural Cycles officially offers a new, clinically tested alternative to birth control methods”.The company has leaned heavily on social media marketing to target its ‘digital contraception’ app at young women.“We told Natural Cycles Nordic AB Sweden not to state or imply that the app was a highly accurate method of contraception and to take care not to exaggerate the efficacy of the app in preventing pregnancies,” said the Advertising Standards Authority (ASA) handing down its decision.While Natural Cycles gained EU certification for its app as a contraceptive in February 2017, and most recently FDA clearance for marketing the app as a contraception in the US (with the regulator granting its De Novo classification request this month), those regulatory clearances come with plenty of caveats about the complexity of the product.The FDA, for example, warns that: “Users must be aware that even with consistent use of the device, there is still a possibility of unintended pregnancy.”At the same time, Natural Cycles has yet to back up the efficacy claims it makes for the product with the scientific ‘gold standard’ of a randomized control trial. So users wanting to be able to compare the product’s efficacy against other more tried and tested birth control methods (such as the pill or condoms) are not able to do so.No birth control method (barring abstention) is 100% effective of course but, as we’ve reported previously, Natural Cycles’ aggressive marketing and PR has lacked nuance and attempted to downplay concerns about the complexity of its system and the chance of failure even though the product’s performance is impacted by multiple individual factors — from illness, to irregular periods. Which risks being irresponsible.In the ruling, the ASA flags up the relative complexity of Natural Cycles’ system vs more established forms of contraception — pointing out that:The Natural Cycles app required considerably more user input than most forms of contraception, with the need to take and input body temperature measurements several times a week, recording when intercourse had taken place, supplemented with LH measurements, abstention or alternative methods of contraception during the fertile period.The company also remains under investigation in Sweden by the medical regulator after a local hospital reported a number of unwanted pregnancies among users of the app. A spokesperson for the Medical Products Agency told us that it has finalized its investigation and plans to publish the findings next week.Despite all that, Natural Cycles’ website bills its product as “effective contraception”, claiming the app is “93% effective under typical use” and making the further (and confusingly worded) claim that: “With using the app perfectly, i.e. if you never have unprotected intercourse on red days, Natural Cycles is 99% effective, which means 1 woman out of 100 get pregnant during one year of use.”Perfect use of the app actually means a woman would accurately perform daily measurement of her body temperature without fail or fault, and before she’s even sat up in bed, at least several times a week, correctly inputting the data. Forgetting to do so once because — say — you got up to go to the toilet or were otherwise interrupted before taking or inputting a reading could constitute imperfect use.The BBC spoke to a women who says she made the decision to use the app after seeing that 99% effective claim in Natural Cycles’ marketing on Instagram — and subsequently fell pregnant while using it. “I was sort of sucked into this “99% effective” [claim],” she told the broadcaster. “You know “even more effective than the pill”… What could possibly go wrong?”In its ruling, the regulator said it investigated two issues related to the advert run by Natural Cycles on Facebook on July 20, 2017, and both issues were upheld.The complaints were that Natural Cycles’ advert included misleading and unsubstantiated claims — specifically that the product was: 1. “Highly accurate contraceptive app”; and 2. “Clinically tested alternative to birth control methods”.Natural Cycles told the ASA that the latter claim is in fact a quote from a Business Insider article which it “considered to be correct” and had thus reproduced in its marketing.After taking expert evidence, and reviewing three published papers on accumulated data obtained from the app, the regulator deemed the combination of the two claims to be misleading.It writes:We considered that in isolation, the claim “clinically tested alternative to birth control methods” was unlikely to mislead. However, when presented alongside the accompanying claim “Highly accurate contraceptive app”, it further contributed to the impression that the app was a precise and reliable method of preventing pregnancies which could be used in place of other established birth control methods, including those which were highly reliable in preventing unwanted pregnancies. Because the evidence did not demonstrate that in typical-use it was “highly accurate” and because it was significantly less effective than the most reliable birth control methods, we considered that in the context of the ad the claim was likely to mislead.The ASA also found the advert to have breached rules for substantiation and exaggeration of marketing messages in the Medicines, medical devices, health-related products and beauty products category, as well as being misleading.At the time of writing Natural Cycles had not responded to requests for comment. Update: A spokeswoman has now emailed us the following statement in response to the ASA ruling:We respect the outcome of the investigation by the UK Advertising Standards Authority (ASA) into one Facebook advertisement, which ran for approximately 4 weeks in mid-2017. The investigation was initiated nearly 12 months ago and the advertisement was removed as soon as we were notified of the complaint. This investigation triggered an internal review of all our advertisements and the way that we communicate more broadly, to ensure our message is clear and provides women with the information they need to determine if Natural Cycles is right for them. As part of these efforts, every advertisement now undergoes a strict approval process by a dedicated taskforce to ensure that it gives an accurate overall impression to the viewer. We actively seek feedback from Natural Cycles users to help us improve the quality of our communications and, moving forwards, we plan to work even more closely with HCPs, women and our user community to test and refine our marketing approach. Natural Cycles has been independently evaluated and cleared by regulators in Europe and the US based on clinical evidence demonstrating its effectiveness as a method of contraception.This report was updated with comment from the Swedish medical products regulator, and with comment from Natural Cycles",0.0,0.0
501,https://techcrunch.com/2022/02/22/verdant-aims-to-be-the-robotic-king-of-carrot-weeders/,Verdant aims to be the (robotic) king of carrot weeders,"Agtech is a massive industry aching to be disrupted by robotics. It’s a big category that’s going to require a number of solutions to various problems, though lately it’s been hit by a number of false starts. Abundant Robotics, for instance, went under, only to be resurrected by a new brand currently exploring the equity crowdfunding route. Meanwhile, strawberry-picking Traptic quite literally took itself out of the field, getting snapped up by Bowery for vertical farming applications.Founded in 2018, East Bay-based Verdant Robotics has raised $21.5 million to date, including an $11.5 million Series A, back in 2019. The firm appears to be casting its net fairly wide, though it’s starting specifically with carrot crops, offering up its system through a RaaS (robotics as a service) model to select farmers.The model seems to make the most sense for these systems — at least during the early stages. Likely most important to a company like Verdant is getting as many of its robotic systems as possible out to farms for real-world testing and data collection. Rental is a much easier way to do that, versus selling them outright — especially for an as of yet early technology, which likely requires technicians to implement (or at least monitor) these systems.The “autonomous farm-robot” does dual-duty — spraying and laser weeding — while building AI-based crop modeling, designed to give farmers a better picture of what their plants crave.“Farmers told us not to give them more data, but to figure out what to do with the mountains of data they already have, or better yet just go do it,” Verdant co-founder and CEO Gabe Sibley says. “They want a complete solution that takes action in real time and keeps farmers in control — all while improving profitability and automating dangerous, back-breaking field work.”The company says it logged “thousands” of hours over the course of 2021 and plans to fully commercialize a “precision multi-action machine for orchard” next year.",0.0,0.0
290,https://techcrunch.com/2020/11/23/recycling-robotics-company-amp-robotics-could-raise-up-to-70-million-sources-say/,Recycling robotics company AMP Robotics could raise up to $70M,"AMP Robotics, the recycling robotics technology developer backed by investors including Sequoia Capital and Sidewalk Infrastructure Partners, is close to closing on as much as $70 million in new financing, according to multiple sources with knowledge of the company’s plans.The new financing speaks to AMP Robotics’ continued success in pilot projects and with new partnerships that are exponentially expanding the company’s deployments.Earlier this month the company announced a new deal that represented its largest purchase order for its trash-sorting and recycling robots.That order, for 24 machine learning-enabled robotic recycling systems with the waste-handling company Waste Connections, was a showcase for the efficacy of the company’s recycling technology.That comes on the back of a pilot program earlier in the year with one Toronto apartment complex, where the complex’s tenants were able to opt into a program that would share with the building’s renters recycling habits monitored by AMP Robotics in an effort to improve their recycling behavior.The potential benefits of AMP Robotic’s machine learning-enabled robots are undeniable. The company’s technology can sort waste streams in ways that traditional systems never could and at a cost that’s far lower than most waste-handling facilities.As TechCrunch reported earlier, the tech can tell the difference between high-density polyethylene and polyethylene terephthalate, low-density polyethylene, polypropylene and polystyrene. The robots can also sort for color, clarity, opacity and shapes like lids, tubs, clamshells and cups — the robots can even identify the brands on packaging.AMP’s robots already have been deployed in North America, Asia and Europe, with recent installations in Spain and across the U.S. in California, Colorado, Florida, Minnesota, Michigan, New York, Texas, Virginia and Wisconsin.At the beginning of the year, AMP Robotics worked with its investor, Sidewalk Labs, on a pilot program that provided residents of a single apartment building representing 250 units in Toronto with detailed information about their recycling habits. Sidewalk Labs is transporting the waste to a Canada Fibers material recovery facility where trash is sorted by both Canada Fibers employees and AMP Robotics.Once the waste is categorized, sorted and recorded, Sidewalk communicates with residents of the building about how they’re doing in their recycling efforts.It was only last November that the Denver-based AMP Robotics raised a $16 million round from Sequoia Capital and others to finance the early commercialization of its technology.",0.0,0.0
12,https://www.cnbc.com/2022/09/27/chipotle-mexican-grill-will-test-robotic-tortilla-chip-maker-.html,Chipotle Mexican Grill will test robotic tortilla chip maker 'Chippy' in California restaurant,"Chipotle Mexican Grill is moving one step closer to having a robot make its tortilla chips.The burrito chain said Tuesday that it will test ""Chippy,"" an autonomous kitchen assistant made by Miso Robotics, next month in a restaurant in Fountain Valley, California. Chipotle has already tested Chippy's ability to make and season its tortilla chips with salt and lime at its headquarters' innovation hub in Irvine, California.Like the rest of its new tech and menu items, the company is relying on its ""stage-gate process"" to test and learn from workers and customers to decide how to roll out the technology nationwide. Today, workers at Chipotle restaurants fry and season the chips, which can be time consuming.Restaurants and retailers have been testing robotics and automation to speed up operations and reduce menial tasks for workers. Starbucks recently unveiled new systems for more efficiently making cold coffee drinks, brewing drip coffee and serving food. Elsewhere, Panera Bread and McDonald's have been testing automated drive-thru ordering to cut down service times, while White Castle and Buffalo Wild Wings also are testing Miso Robotics' technology.In addition to the Chippy restaurant test, Chipotle said it's piloting a new kitchen management system that uses machine learning to predict demand for its ingredients in order to improve freshness and minimize food waste. The system designed by PreciTaste is being tested at eight restaurants in Orange County.And in Cleveland, the company said 73 of its restaurants are piloting location-based technology to improve its mobile app. The program is meant to help customers and delivery drivers know when orders are ready, if they're at the wrong location and to scan loyalty QR codes. The technology created by Flybuy by Radius Networks is also being used by retailers like Harris Teeter, Albertsons and Vineyard Vines.",0.0,0.0
510,https://www.eurekalert.org/news-releases/969839,"Reduced-nicotine cigarettes result in less smoking in anxious, depressed smokers","HERSHEY, Pa. — Lowering the amount of nicotine in cigarettes to non-addictive levels may reduce smoking without worsening mental health in smokers with mood or anxiety disorders, according toHERSHEY, Pa. — Lowering the amount of nicotine in cigarettes to non-addictive levels may reduce smoking without worsening mental health in smokers with mood or anxiety disorders, according toTobacco remains the leading preventable cause of premature death and disease in the United States. Recent proposals by the U.S. Food and Drug Administration and the New Zealand government seek to limit the amount of nicotine in cigarettes to minimally addictive levels. Prior research indicates that reducing nicotine content could help smokers quit, but there is little evidence to demonstrate if these policies could adversely affect smokers with current or prior affective disorders like depression and anxiety disorders — which affect anTobacco remains the leading preventable cause of premature death and disease in the United States. Recent proposals by the U.S. Food and Drug Administration and the New Zealand government seek to limit the amount of nicotine in cigarettes to minimally addictive levels. Prior research indicates that reducing nicotine content could help smokers quit, but there is little evidence to demonstrate if these policies could adversely affect smokers with current or prior affective disorders like depression and anxiety disorders — which affect anAccording toAccording toThe researchers studied 188 smokers with a history of or who had a current mood or anxiety disorder and had no plans to quit. Volunteer participants were randomly assigned to a group that received either research cigarettes containing the usual amount of nicotine (11.6 mg nicotine/cigarette) or a progressively reduced amount of nicotine for an additional 18-week period (the final amount was 0.2 mg nicotine/cigarette). At the beginning and conclusion of the study, the researchers measured levels of cotinine, a metabolite of nicotine, levels of harmful chemicals, cigarette dependence indexes and various mental health measures.The researchers studied 188 smokers with a history of or who had a current mood or anxiety disorder and had no plans to quit. Volunteer participants were randomly assigned to a group that received either research cigarettes containing the usual amount of nicotine (11.6 mg nicotine/cigarette) or a progressively reduced amount of nicotine for an additional 18-week period (the final amount was 0.2 mg nicotine/cigarette). At the beginning and conclusion of the study, the researchers measured levels of cotinine, a metabolite of nicotine, levels of harmful chemicals, cigarette dependence indexes and various mental health measures.The researchers observed no statistically significant differences in mental health measures between the two groups at the conclusion of the study. The team used theThe researchers observed no statistically significant differences in mental health measures between the two groups at the conclusion of the study. The team used the“These findings are important because we want to understand the effect these policies would have on smokers with anxiety or depressive disorders,” said Foulds, a“These findings are important because we want to understand the effect these policies would have on smokers with anxiety or depressive disorders,” said Foulds, aSimilar to what prior studies reported, Foulds and team found that groups in the reduced nicotine content group were absorbing lower amounts of nicotine and ingesting lower levels of harmful carcinogens such as the biomarker 4-(methylnitrosamino)-1-(3-pryidyl)-1-butanol), more commonly known as NNAL. That group also smoked fewer cigarettes and reported lower levels of nicotine addiction by the end of the randomized phase of the trial. The results were published in PLOS ONE today, Nov. 2.Similar to what prior studies reported, Foulds and team found that groups in the reduced nicotine content group were absorbing lower amounts of nicotine and ingesting lower levels of harmful carcinogens such as the biomarker 4-(methylnitrosamino)-1-(3-pryidyl)-1-butanol), more commonly known as NNAL. That group also smoked fewer cigarettes and reported lower levels of nicotine addiction by the end of the randomized phase of the trial. The results were published in PLOS ONE today, Nov. 2.Unique to this study, participants in both groups were also given the choice to “choose their treatment,” after the 18-week period. They could go back to using their own cigarettes, continue smoking the research cigarettes or attempt to quit. Of the 188 participants in the study, those randomized to reduced nicotine content cigarettes were more likely to have quit smoking 12 weeks later (18.1%), compared to those in the control (usual nicotine content) group (4.3%).Unique to this study, participants in both groups were also given the choice to “choose their treatment,” after the 18-week period. They could go back to using their own cigarettes, continue smoking the research cigarettes or attempt to quit. Of the 188 participants in the study, those randomized to reduced nicotine content cigarettes were more likely to have quit smoking 12 weeks later (18.1%), compared to those in the control (usual nicotine content) group (4.3%).“We believe this is the first randomized trial to find that smokers who used very low nicotine cigarettes were significantly more likely to have quit smoking (with biochemical verification), three months after the end of the trial,” Foulds said.“We believe this is the first randomized trial to find that smokers who used very low nicotine cigarettes were significantly more likely to have quit smoking (with biochemical verification), three months after the end of the trial,” Foulds said.“Our results suggest that these policies will likely result in reduced nicotine absorption from cigarettes without worsening the mental health of smokers with mood or anxiety disorders,” said Dr. Eden Evins, Cox Family Professor of Psychiatry at Harvard Medical School. “They also suggest that with proper support and resources, smokers with mood and anxiety disorders could quit successfully as a result of these policies.”“Our results suggest that these policies will likely result in reduced nicotine absorption from cigarettes without worsening the mental health of smokers with mood or anxiety disorders,” said Dr. Eden Evins, Cox Family Professor of Psychiatry at Harvard Medical School. “They also suggest that with proper support and resources, smokers with mood and anxiety disorders could quit successfully as a result of these policies.”For more information on nicotine, smoking and health studies at the Penn State Center for Research on Tobacco and Health, visitFor more information on nicotine, smoking and health studies at the Penn State Center for Research on Tobacco and Health, visitSusan VeldheerSusan VeldheerThis research was supported by the National Institutes of Health through the National Institute on Drug Abuse of the National Institutes of Health (award P50DA036107) and the National Center for Advancing Translational Sciences through Penn State Clinical and Translational Science Institute (award UL1 TR000127). The research was also supported by the Center for Tobacco Products of the U.S. Food and Drug Administration. The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health or the Food and Drug Administration.This research was supported by the National Institutes of Health through the National Institute on Drug Abuse of the National Institutes of Health (award P50DA036107) and the National Center for Advancing Translational Sciences through Penn State Clinical and Translational Science Institute (award UL1 TR000127). The research was also supported by the Center for Tobacco Products of the U.S. Food and Drug Administration. The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health or the Food and Drug Administration.",0.0,0.0
217,https://arstechnica.com/science/2022/09/us-installs-record-solar-capacity-as-prices-keep-falling/,US installs record solar capacity as prices keep falling,"This week, the US Department of Energy's Berkeley Lab released its annual analysis of solar energy in the US. It found that nearly half the generating capacity was installed in the US during 2021 and is poised to dominate future installs. That's in part because costs have dropped by more than 75 percent since 2010; it's now often cheaper to build and operate a solar plant than it is to simply buy fuel for an existing natural gas plant.The analysis was performed before the passage of the Inflation Reduction Act, which contains many incentives and tax breaks that should expand solar's advantages in the coming years.Solar, by the numbersIn terms of large, utility-scale solar installs, the US added over 12.5 gigawatts of new capacity last year, bringing the total installed capacity to over 50 gigawatts. Texas led the way, with about a third of the total capacity added (3.9 GW) going online in the Lone Star State. Combined with residential and other distributed solar installations, solar alone accounted for 45 percent of the new generating capacity added to the grid last year.AdvertisementThat growth showed up in figures on how much energy solar supplies. Five states now receive more than 15 percent of their electricity from solar power, including Massachusetts and Vermont, with California receiving 25 percent of its electricity from the Sun.Solar's expansion has largely been driven by falling costs. The DOE estimates that the price of building a solar plant has been dropping by an average of about 10 percent a year, leading to a fall of over 75 percent since 2010. That has left prices averaging about $1.35 for each watt of capacity in 2021. Large-scale plants benefit the most, with projects over 50 megawatts costing about 20 percent less than those under 20 MW.The drop in prices is causing some somewhat odd trends, driven by the fact that it's becoming increasingly economical to install large facilities in states that don't get as much sun, like Maine, Michigan, and Wisconsin. As a result, the past several years have seen the average incoming energy at newly constructed facilities (measured as daily kilowatt-hours per square meter) drop by about 20 percent.That has helped cause a large spread in what's called the capacity factor, which is calculated by dividing the amount of energy produced at a facility by the maximum energy it could have generated if it produced 24 hours a day. The median capacity factor of solar plants in the US was 24 percent, but outliers were as low as 9 percent and as high as 35 percent. As prices continue to fall, this spread may become more pronounced, with more plants at the low end of the range.",0.0,0.0
207,https://techcrunch.com/2022/08/10/ford-locks-in-solar-energy-deal-with-dte-energy/,Ford locks in solar energy deal with DTE Energy,"Ford said Wednesday it has reached a deal with DTE Energy to power its electricity supply in Michigan with clean energy, a step toward its goal to become carbon neutral by 2050.The automaker’s deal with DTE, Michigan’s largest producer of renewable energy, will add 650 megawatts of new solar energy capacity in the state by 2025, allowing the carmaker to assemble each vehicle it makes there with renewable energy.Ford called the deal the largest-ever renewable energy purchase from a utility in the U.S. The arrangement will help Ford decarbonize its operations and meet its sustainability goals, including a target to power all of its global facilities with renewable energy by 2035.Ford said the purchase will help it cut its carbon dioxide emissions by up to 600,000 tons. Overall, Ford’s arrangement with DTE will increase Michigan’s solar capacity by 70%, according to the automaker.The announcement comes one day after Ford said it will raise the price of its electric F-150 Lightning pickup truck between $6,000 and $8,500 for new orders.“Due to significant material cost increases and other factors, Ford has adjusted MSRP starting with the opening of the next wave of F-150 Lightning orders,” a statement read.The entry-level Lightning will now retail for $46,974, while the top-tier “Platinum Extended Range” version starts at $96,874. The price increase will not apply to customers who have already ordered a truck and are awaiting delivery.Ford also said the truck’s standard range battery can now travel 240 miles, up from 230 miles, on a full charge.",0.0,0.0
237,https://www.engadget.com/gm-defense-ultium-prototype-battery-pack-military-dod-144524818.html,GM will make an Ultium battery pack prototype for the US military,"General Motors, through its GM Defense subsidiary, will build a battery pack prototype for the Department of Defense to test and analyze. The agency's Defense Innovation Unit is seeking a scalable design that can be used in electrified versions of tactical military vehicles.The battery pack will be based on GM's Ultium platform, which it's using to power its own electric vehicles. Due to the type of battery cells it employs, Ultium is billed as a modular and scalable system that can be adapted to different needs, so it may just fit the bill for the military.GM said the military wants a light- to heavy-duty EV for use in garrison and operational environments in order to reduce fossil fuel use. As a result, that should reduce the military's carbon emissions.Turn on browser notifications to receive breaking news alerts from Engadget You can disable notifications at any time in your settings menu. Not now Turned on Turn onThis isn't the first partnership that GM Defense has forged with the military. In July, the company secured a deal with the US Army to provide an electric Hummer for testing. Last year, GM Defense president Steve duMont said the company would build an electric military vehicle prototype based on the Hummer EV.",0.0,0.0
540,https://www.engadget.com/nasa-successfully-smacked-its-dart-impactor-spacecraft-into-an-asteroid-231706710.html,NASA successfully smacked its DART spacecraft into an asteroid,"After nearly a year in transit, NASA's experimental Double Asteroid Redirection Test (DART) mission, which sought to answer the questions, ""Could you potentially shove a asteroid off its planet-killing trajectory by hitting it with a specially designed satellite? How about several?"" has successfully collided with the Dimorphos asteroid. Results and data from the collision are still coming in but NASA ground control confirms that the DART impact vehicle has intercepted the target asteroid. Yes, granted, Dimorphos is roughly the size of an American football stadium but space is both very large and very dark, and both asteroid and spacecraft were moving quite fast at the time.NASA""It's been a successful completion of the first part of the world's first planetary defense test,"" NASA Administrator Bill Nelson said after the impact. ""I believe it's going to teach us how one day to protect our own planet from an incoming asteroid. We are showing that planetary defense is a global endeavor and it is very possible to save our planet.""NASA launched the DART mission in November, 2021 in an effort to explore the use of defensive satellites as a means of planetary defense against Near Earth Objects. The vending machine-sized DART impactor vehicle was travelling at roughly 14,000 MPH when it fatally crossed Dimorphos' path nearly 68 million miles away from Earth.Whether future iterations of a planetary defense system brimming with satellites willing to go all June Bug vs Chrysler Windshield against true planet-killer asteroids remains to be seen. Dimorphos itself is the smaller of a pair of gravitationally-entangled asteroids — its parent rock is more than five times as large — but both are dwarfed by the space rock that hit Earth 66 million years ago, wiping out 75 percent of multicellular life on the planet while gouging out the Gulf of Mexico.NASAThe DART team will likely be poring over the data generated by both the impactor and cameras released before the spacecraft made its final approach for days to come. However the team will consider shortening the orbital track of Dimorphos around Didymos by 10 minutes an ideal outcome, though any change of at least 73 seconds will still be hailed as a rousing success. The team will have to observe Dimorphos' orbit for half a day to confirm their success, as the moonlet needs nearly 12 hours to complete an circuit around Didymos.ATLAS observations of the DART spacecraft impact at Didymos! pic.twitter.com/26IKwB9VSo — ATLAS Project (@fallingstarIfA) September 27, 2022Update 9/27/2022 2:29 AM ET: The NASA funded ATLAS (Asteroid Terrestrial-impact Last Alert System) managed to record video of the impact (above). While fuzzy, it's still pretty cool.",0.0,0.0
258,https://www.globalconstructionreview.com/scientists-can-now-build-structures-with-swarms-of-flying-drones/,Scientists can now build structures with swarms of flying drones,"“We’ve proved that drones can work autonomously and in tandem to construct and repair buildings, at least in the lab,” said research leader Prof. Mirko Kovac. “Our solution is scalable and could help us to construct and repair buildings in difficult-to-reach areas in the future.”",0.0,0.0
584,https://techcrunch.com/2020/02/05/louise-samet-interview/,Blossom Capitalâs Louise Samet talks hormone tracking and femtech bets,"Early-stage European VC firm Blossom Capital is fresh from closing a $185M fund— a big jump up on its prior close. The firm makes just a handful of investments per year, mostly at the Series A stage, working very closely with founders in its portfolio, a strategy it refers to as “high conviction” investing.One of its chosen few is Inne, a Berlin-based femtech startup that’s building a novel, hormone-tracking subscription product for fertility-tracking and “natural” contraception. The aim is to offer a high-tech alternative to taking hormones to prevent pregnancy or using an established barrier method (such as a condom).Inne came out of stealth last fall to announce $8.8M in funding, giving us the first glimpse of the medical device it’s been working on since 2017. This test-at-home hormone tracker is slated to launch in select markets in Scandinavia this year, but at a scale akin to a limited beta. The startup said it would be iterating the product based on feedback from the first usersWe chatted with Blossom Capital partner Louise Samet, who led the fund’s investment in Inne, to get the inside track on that deal and further understand how the fund thinks about femtech and the key challenges and opportunities she sees for founders building products targeted to women.This interview has been edited for length and clarity.TechCrunch: How does the fund approach femtech?Samet: The way we define femtech is products that are built for women. But I think the definition of the term is not necessarily important. The more important thing is the problem the founders are focusing on solving.",0.0,0.0
577,https://techcrunch.com/2022/03/16/legal-tech-startups-bringing-law-order-to-fragmented-industry/,"Legal tech startups bringing law, order to fragmented industry","It’s long known that the legal profession has not embraced technology as quickly as other industries.It’s long known that the legal profession has not embraced technology as quickly as other industries.As a result, there are a number of legal tech startups eager to not only help lawyers, but automate some of the processes bogged down by pen and paper. Here, we take a look at two companies that recently secured funding, Justpoint and New Era ADR, to see their approaches.As a result, there are a number of legal tech startups eager to not only help lawyers, but automate some of the processes bogged down by pen and paper. Here, we take a look at two companies that recently secured funding, Justpoint and New Era ADR, to see their approaches.JustpointJustpointVictor Bornstein, founder and CEO ofVictor Bornstein, founder and CEO ofPersonal injury lawyers rely heavily on ads and easy-to-memorize 800 numbers to attract clients, but Justpoint believes that using data is a better tool.Personal injury lawyers rely heavily on ads and easy-to-memorize 800 numbers to attract clients, but Justpoint believes that using data is a better tool.Here’s why: The Boulder, Colorado-based company has collected over 300,000 historical claims and uses data extraction models to plug into a law firm to provide a score on how good the firm is at winning cases, like sexual assault, medical malpractice and product liability.Here’s why: The Boulder, Colorado-based company has collected over 300,000 historical claims and uses data extraction models to plug into a law firm to provide a score on how good the firm is at winning cases, like sexual assault, medical malpractice and product liability.That’s one side. The second is equipping the firm with information on whether a certain claim is worth the law firm’s time to take, mainly because of the time involved in diving into a case, plus the fact that firms often put up their own money initially to file lawsuits and obtain expert witnesses. Justpoint also brings medical expertise in-house to process the data and train the model.That’s one side. The second is equipping the firm with information on whether a certain claim is worth the law firm’s time to take, mainly because of the time involved in diving into a case, plus the fact that firms often put up their own money initially to file lawsuits and obtain expert witnesses. Justpoint also brings medical expertise in-house to process the data and train the model.“Lawyers have an incentive,” Bornstein said. “A claim could receive $2 million, but if they settle quickly, it will save a lot of effort, though they will receive much less. We’ve looked at how to make claims more efficient so lawyers can take a claim to the end instead of settling.”“Lawyers have an incentive,” Bornstein said. “A claim could receive $2 million, but if they settle quickly, it will save a lot of effort, though they will receive much less. We’ve looked at how to make claims more efficient so lawyers can take a claim to the end instead of settling.”The company recently raised $6.9 million in a seed extension co-led by Divergent Capital and Charge Ventures. Additional investments came from Crossbeam Venture Partners, Honeystone Ventures, Interplay.vc, Weekend Fund, Turing co-founder Vijay Krishnan, Mainstreet co-founder Jackson Moses and Stonks founder Ali Moiz. It brings the total amount raised to $7.9 million.The company recently raised $6.9 million in a seed extension co-led by Divergent Capital and Charge Ventures. Additional investments came from Crossbeam Venture Partners, Honeystone Ventures, Interplay.vc, Weekend Fund, Turing co-founder Vijay Krishnan, Mainstreet co-founder Jackson Moses and Stonks founder Ali Moiz. It brings the total amount raised to $7.9 million.Justpoint makes money when the lawyer wins their case, which explains the company’s incentive to send claims worth spending the lawyer’s time on, Bornstein said.Justpoint makes money when the lawyer wins their case, which explains the company’s incentive to send claims worth spending the lawyer’s time on, Bornstein said.“That puts a lot of work on us validating the claims,” he added. “It’s also why we are seeing an uptick in legal technology. Many firms are not interested in using technology, but this allows us to do the work for them. The way we see it is in 10 years, the legal tech space will bloom in a way we have not seen.”“That puts a lot of work on us validating the claims,” he added. “It’s also why we are seeing an uptick in legal technology. Many firms are not interested in using technology, but this allows us to do the work for them. The way we see it is in 10 years, the legal tech space will bloom in a way we have not seen.”New Era ADRNew Era ADROn the dispute resolution side,On the dispute resolution side,Co-founder Rich Lee explained that legal disputes often take 18 to 24 months and hundreds of thousands of dollars to resolve. New Era is building a digital and virtual tool that cuts down on both the time and cost of resolving disputes by up to 90%. The company highlights risks so that companies and their law firms can reduce unnecessary litigation gamesmanship.Co-founder Rich Lee explained that legal disputes often take 18 to 24 months and hundreds of thousands of dollars to resolve. New Era is building a digital and virtual tool that cuts down on both the time and cost of resolving disputes by up to 90%. The company highlights risks so that companies and their law firms can reduce unnecessary litigation gamesmanship.“We are taking the temperature down, reducing acrimony and refocusing litigation back on story-telling,” Lee added. “The procedures in court systems and current arbitration systems don’t lend themselves to fast, efficient resolutions, so we rewrote them.”“We are taking the temperature down, reducing acrimony and refocusing litigation back on story-telling,” Lee added. “The procedures in court systems and current arbitration systems don’t lend themselves to fast, efficient resolutions, so we rewrote them.”New Era manages all of the case intake, payments and scheduling and facilitates virtual meetings with arbitrators so that clients can get binding resolutions in as little as 60 days.New Era manages all of the case intake, payments and scheduling and facilitates virtual meetings with arbitrators so that clients can get binding resolutions in as little as 60 days.The Chicago-based company recently raised $4.6 million in seed funding led by Nextview Ventures, with participation from Jump Capital. The company’s original pre-seed investors, Motivate Ventures and Alumni Ventures, also participated in this round along with a group of individual investors, including David Kalt, Sean Chou, Pete Kadens and Lon Chow. This latest round gives New Era total funding of $6.3 million.The Chicago-based company recently raised $4.6 million in seed funding led by Nextview Ventures, with participation from Jump Capital. The company’s original pre-seed investors, Motivate Ventures and Alumni Ventures, also participated in this round along with a group of individual investors, including David Kalt, Sean Chou, Pete Kadens and Lon Chow. This latest round gives New Era total funding of $6.3 million.New Era charges a flat fee per case, and in less than a year, was named as the dispute resolution platform in over 50 million contracts. So far in 2022, the company has already surpassed its 2021 revenue. Lee said the goal is to triple that in the next year.New Era charges a flat fee per case, and in less than a year, was named as the dispute resolution platform in over 50 million contracts. So far in 2022, the company has already surpassed its 2021 revenue. Lee said the goal is to triple that in the next year.Continued investment in legal techContinued investment in legal techJustpoint and New Era are among friends in raising capital to bring the legal industry into the digital age, with many of them also leveraging AI.Justpoint and New Era are among friends in raising capital to bring the legal industry into the digital age, with many of them also leveraging AI.Earlier this month,Earlier this month,“There’s been growing enthusiasm for legal tech for a while now,” Zack Hutto, director of advisory within Gartner’s legal and compliance practice, told TechCrunch. “Corporate law spending is up 50% and we are projecting budgets will make a three-fold increase by 2025.”“There’s been growing enthusiasm for legal tech for a while now,” Zack Hutto, director of advisory within Gartner’s legal and compliance practice, told TechCrunch. “Corporate law spending is up 50% and we are projecting budgets will make a three-fold increase by 2025.”He cited a SeptemberHe cited a SeptemberThat was not something Hutto was surprised by, saying it was proof of all of the demand, which resulted in VCs wanting to grab a piece of the pie.That was not something Hutto was surprised by, saying it was proof of all of the demand, which resulted in VCs wanting to grab a piece of the pie.He feels like the rise has been dramatic because it started from a small base. Corporate legal departments are spending millions of dollars, but are not using technology as much as you might expect. The legal profession was most insulated from technology and digital transformation, so the trend of startups coming in was bound to happen, though there is still some skepticism of how transformative those tools will be, Hutto added.He feels like the rise has been dramatic because it started from a small base. Corporate legal departments are spending millions of dollars, but are not using technology as much as you might expect. The legal profession was most insulated from technology and digital transformation, so the trend of startups coming in was bound to happen, though there is still some skepticism of how transformative those tools will be, Hutto added.“PDF invoices do not give you the kind of insight to make better decisions around that spend,” he said. “One-third of departments were using those in 2010, and fast-forward to the last couple of years, and that number has increased to around half of organizations using e-billing technology, but you still have to marvel at the fact that there is a large, unpenetrated market there.”“PDF invoices do not give you the kind of insight to make better decisions around that spend,” he said. “One-third of departments were using those in 2010, and fast-forward to the last couple of years, and that number has increased to around half of organizations using e-billing technology, but you still have to marvel at the fact that there is a large, unpenetrated market there.”",0.0,0.0
86,https://www.thelancet.com/journals/lanhl/article/PIIS2666-7568(22)00095-2/fulltext#%20,Linking interdisciplinary and multiscale approaches to improve healthspanâa new UK model for collaborative research networks in ageing biology and clinical translation,"1 Scott AJEllison MSinclair DA The economic value of targeting aging. 2 House of Lords Science and Technology Select CommitteeAgeing: Science, Technology, and Healthy Living. Improvements in health care, sanitation, diet, and education over the past century have markedly increased life expectancy, but this has not been paralleled by concomitant increases in healthy life expectancy. Increasing healthspan, which is the time spent free of major illness or disease, is therefore an important priority worldwide. The UK Government, for example, has pledged to increase the healthy life expectancy of the UK population by an extra 5 years by 2035 without increasing inequality. Achieving this goal would simultaneously improve individual quality of life, increase productivity, and boost national wealth. Notably, a gain of just one additional healthy year is predicted to be worth US$38 trillion to the USA.However, a 2021 review of national progress in the UK towards this goal revealed that policy makers have little confidence that healthy life expectancy can be markedly improved either through focusing on technological solutions (which promote independence but not health) or on diet and exercise regimes (which are often out of reach of those who would most benefit, because of socioeconomic inequalities).2 House of Lords Science and Technology Select CommitteeAgeing: Science, Technology, and Healthy Living. 3 López-Otín CBlasco MAPartridge LSerrano MKroemer G The hallmarks of aging. 4 Fraser HCKuan VJohnen Ret al. Biological mechanisms of aging predict age-related disease co-occurrence in patients. 5 Kulkarni ASGubbi SBarzilai N Benefits of metformin in attenuating the hallmarks of aging. , 6 Justice JNNambiar AMTchkonia Tet al. Senolytics in idiopathic pulmonary fibrosis: results from a first-in-human, open-label, pilot study. The same reviewrevealed a general lack of awareness and scrutiny of the potential offered for improving health in later life by ameliorating the ageing process itself. This unawareness is alarming when set against the backdrop of a quiet research revolution in biogerontology that has seen the identification of some key hallmarks of ageing,evidence that these hallmarks and underlying mechanisms independently predict the emergence of age-related diseases in real patients,and positive outcomes from preclinical and early-stage human clinical trials based on targeting ageing mechanisms.Humanity stands on the threshold of being able to prevent multimorbidity and age-associated diseases by addressing the underlying biology of ageing; parallels with the era of antibiotics do not seem unduly hyperbolic.7 WHODecade of healthy ageing: baseline report. 8 Cox LSBellantuono ILord JMet al. Tackling immunosenescence to improve COVID-19 outcomes and vaccine response in older adults. Ignorance of these developments carries appalling costs, which have been, and will continue to be, borne by older people unless the situation changes. For example, the UK's 2017 Healthy Ageing Grand Challenge specifically excluded biomedical science research from its funding remit, and the extensive Decade of Healthy Ageing: baseline report,by WHO (2021), fails to mention these advances, or even the word biology, focussing instead on socioeconomic determinants of health and overcoming ageism. Given that hallmark ageing mechanisms cause the progressive failure of innate and adaptive immunity, it is a fascinating counterfactual to consider how the ongoing COVID-19 pandemic would have been handled had it been preceded by a sustained international effort to target immune senescence and enhance later life immune function.The need to avoid such mistakes in the future is patent, as are the triple economic benefits (lower health and social care costs, greater economic activity of older adults, and investment into new industries) that will accompany efforts in this area.2 House of Lords Science and Technology Select CommitteeAgeing: Science, Technology, and Healthy Living. 9 Cox LS The economic and scientific case for therapeutic intervention in ageing. It is perhaps the perceived complexity of ageing biology that has dissuaded policy makers from directly tackling it. As a result, academic research on ageing in many parts of the globe is fragmented and siloed,and driven by funding models and professional metrics that reward specialisation and disease-specific focus. However, the biological mechanisms that cause ageing must be a central focus if integrational and intersectional approaches aimed at improving lifelong health figure ) are to be truly effective.Figure UK Research and Innovation-funded ageing networks addressing ageing processes across the life course Show full caption 8 Cox LSBellantuono ILord JMet al. Tackling immunosenescence to improve COVID-19 outcomes and vaccine response in older adults. , 9 Cox LS The economic and scientific case for therapeutic intervention in ageing. 4 Fraser HCKuan VJohnen Ret al. Biological mechanisms of aging predict age-related disease co-occurrence in patients. 11 networks (depicted in ovals) cover a broad but overlapping range of research topics, with intersections between socioeconomic determinants of health, diet, exercise, microbiome, extracellular matrix, and molecular and cellular mechanisms of ageing, through to cognition, immunity, frailty, therapeutics, and clinical trials. This breadth allows the networks to identify interventions appropriate for different stages of the life course, with a shift in focus from disease-preventive approaches in early life and mid-life through to more intense clinical monitoring and interventions in older adults, including development and testing of new geroprotective and gerotherapeutic medicines, such as senolytic drugs.A multiscale, multisystem, and whole of life course approach to improve healthy life expectancy can be achieved by drawing these broad research disciplines together through a core focus on hallmarks that underlie the biology of ageing and drive age-related disease.AGENTS=Ageing and Nutrient Sensing network. ART=Ageing Research Translation of Healthy Ageing Network. ATTAIN=Active and healthy ageing for all. BLAST=Building Links in Ageing Science and Translation. CARINA=CAtalyst Reducing ImmuNe Ageing. CELLO=CELLular metabolism Over a life-course in socioeconomically disadvantaged populations.CFIN=Cognitive Frailty Interdisciplinary Network. ECMage=Extracellular Matrix (ECM) ageing across the life course interdisciplinary research network. Food4Years=Food for-added-life-years: putting research into action. MyAGE=Muscle resilience across the life course: from cells to society. SMiHA=Skin Microbiome in Healthy Ageing.10 UKRIResearchers at 28 UK universities team up to tackle healthy ageing. It is therefore hugely exciting that the diversity and complexity of ageing across the life course has now been recognised in a national initiative by the Biotechnology and Biological Sciences Research Council and Medical Research Council of UK Research and Innovation (the national government-sponsored research funder). Launched in March, 2022,the UK Ageing Network comprises 11 new research networks addressing core aspects of ageing biology and health in a national macro network, drawing together ageing research across systems and scales ( figure ). These networks aim to enable knowledge exchange and research beyond the narrow focus of individual research projects and academic disciplines, drawing from the social sciences, humanities, economics, and biomedical and physical sciences, as well as bringing in expertise from industry, biotechnology, the third sector, and policy makers; membership is open and non-prescriptive, and interested individuals and organisations are encouraged to join . Importantly, the networks also include the voice of those with the lived experience of ageing, to enable relevant co-design of future research strategies, together with health practitioners and clinical trialists to ensure that promising interventions can be taken forward from the laboratory into patients. Through workshops, training programmes, grassroots events, and research pump priming, the networks will not only enable integration of expertise and cross-disciplinary working to generate new knowledge and provide solutions to ageing problems, they also aim to build ageing research capacity, enticing researchers from all career stages and disciplines in academia and beyond to embrace ageing research. Dissemination of new findings and development of new training materials for a range of audiences, including clinical practitioners and policy makers, is also key to the networks’ goals, to ensure that actionable findings from ageing research are rapidly adopted into policy and practice.Initially funded for 2 years, positive outcomes from the networks should drive investment to sustain and grow them, with expansion to include colleagues from around the world. We therefore welcome input, suggestions, and support from all who wish to contribute to improve health across the life course and work towards the goal of substantially extending healthy life expectancy.",0.0,0.0
513,https://edition.cnn.com/2022/11/01/health/drinking-deaths-us-study-wellness/index.html,"1 in 5 deaths of US adults 20 to 49 is from excessive drinking, study shows","CNN —A beer, glass of wine or cocktail may feel so common place that you don’t even think about pouring another, but a new study suggested it may be important for everyone to be mindful of their alcohol use.An estimated 1 in 5 deaths of people ages 20 to 49 were attributable to excessive alcohol use in the United States, according to the study published Tuesday in JAMA Network Open. For people ages 20 to 64, drinking-related deaths accounted for 1 in 8, the study said.The percentage of deaths attributed to alcohol use varied state by state, but nationally it’s a leading cause of preventable death, said lead study author Dr. Marissa Esser, lwho leads the US Centers for Disease Control and Prevention’s alcohol program.Researchers took national and state mortality data from 2015 to 2019 and looked at deaths either fully or partially attributable to excessive drinking. Those causes of death included vehicle accidents, alcohol poisoning and other health impacts, such as liver disease, Esser said.The data showed that the deaths fully attributable to alcohol have risen in the past decade, Esser added.“I’m not surprised at the numbers,” said David Jernigan, a professor of health law, policy and management at Boston University. “This is a conservative estimate.”Jernigan was not involved in the study.Esser said there were deaths that alcohol likely contributed to that the study’s researchers could not include in their estimates. Some conditions may have had alcohol as a factor, but researchers were not able to verify for sure the role that drinking played. In other cases, they were not able to determine if someone who died of an illness used to drink excessively but then stopped, Esser added.And people often underreport how much they are drinking, Jernigan said.“It doesn’t get anywhere near the attention that it should,” he said. “The bottom line is (researchers) continue to show that excessive alcohol use is a big problem in the US.”How to know when it’s too muchFor health and safety, Jernigan said the goal for state and local government agencies should be encouraging almost everyone to drink less.“States and communities can prevent these premature deaths using evidence-based strategies to reduce the availability and accessibility of alcohol and increase its price,” Esser said.That can mean increasing taxes on alcohol or limiting where alcohol is sold, Esser added.On an individual level, Esser suggested that people could try to stop or limit alcohol consumption.The CDC defines moderate drinking as two drinks or less in a day for men or one drink or less in a day for women. Two-thirds of adults report drinking more than moderate amounts at least once a month, the organization added.The CDC also estimates that 1 in 6 adults binge drink — defined as consuming four or more drinks on an occasion for a woman or five or more drinks on an occasion for a man — with a quarter of those doing so at least weekly.Reducing drinking can have a similar effect as dieting – the more you tell yourself you can’t have it, the more you want it, said Natalie Mokari, a registered dietitian nutritionist in Charlotte, North Carolina.She recommends starting with one less drink than you would usually have at each occasion or breaking a daily habit by limiting drinking to certain days. You can also have a sparkling water in between drinks or make weaker cocktails than usual to reduce your alcohol consumption, she said previously.And if you are overcoming a social pressure to drink, remember that people may make you feel bad because they are uncomfortable about their own relationship with drinking, said Annie Grace, author of “This Naked Mind: Control Alcohol” in a prior article.It often helps to have a nonalcoholic drink in your hand at social events, so the offer to have a drink doesn’t even come up, said biological psychologist Aaron White, senior scientific adviser to the director of the National Institute on Alcohol Abuse and Alcoholism.Slow down your body’s alcohol intake by eating while drinking, alternate alcoholic and nonalcoholic drinks and planning alcohol-free days, Harvard Medical School in Boston suggests.A tool on the CDC website can help individuals evaluate their drinking and then come up with a plan to make healthier alcohol choices.If you need help or support immediately, the Substance Abuse and Mental Health Services Administration has a free, confidential National Helpline active 24/7/365 to provide information and treatment referrals to local treatment facilities, support groups and community-based organizations: 800-662-HELP (4357) and 800-487-4889 (TTY option).",0.0,0.0
177,https://news.osu.edu/humble-leaders-can-help-make-groups-more-effective/,Humble leaders can help make groups more effective,"Leaders of teacher groups who were thought of as humble helped improve professionalism and collaboration among team members, new research has shown.The study, done in China, found that teachers in the Chinese equivalent of professional learning communities (PLCs) were more willing to share their knowledge and expertise when they rated their PLC leaders as being higher in humility.The reason was that humble leaders made teachers feel more empowered to share their knowledge because they felt psychologically safe to take risks, said study co-author Roger Goddard, Novice G. Fawcett Endowed Chair and professor of educational studies at The Ohio State University.“A little humility on the part of leaders goes a long way in helping groups be more productive and collaborative,” Goddard said.“When people feel their leader admits mistakes and is open to learning from others, everyone contributes more and makes these groups more effective.”Goddard conducted the study with Yun Qu of Beijing Normal University in China and Jinjie Zhu, a doctoral student in education at Ohio State. The study was published online recently in the journal Educational Studies.In the United States and elsewhere, PLCs are designed to facilitate professional development through discussions in which teachers share their best practices and what they have learned through their experiences in the classroom.“Teachers can feel fairly isolated in the classroom,” Goddard said. “PLCs help teachers build a sense of community and learn from each other about how to improve classroom instruction.”In China, the equivalent of PLCs are called Teaching Research Groups (TRGs). The leaders of TRGs are experienced teachers who are not traditional administrators, but do serve as supervisors and coordinators and are involved in teacher evaluations, lesson planning and teacher selection.This study involved 537 teachers from 238 TRGs in a variety of both urban and rural schools in China.Teachers rated their TRG leaders on three dimensions of humility: their willingness to view themselves accurately, such as admitting when they didn’t know how to do something; their appreciation of others’ strengths; and their teachability, such as being open to other teachers’ advice.Results showed that teachers who rated their TRG leaders as being higher in humility were more likely to report that they shared their knowledge and expertise in TRG meetings.“The whole point of these groups is for teachers to share their knowledge, so the fact that humble leaders inspired individuals in their groups to be more willing to do this is very significant,” Goddard said.The study also found why humble leaders were so effective in helping their teachers share their knowledge.Results showed that in TRGs with more humble leaders, teachers reported higher levels of psychological safety – they felt they could take risks and knew that others would not act in a way to undermine their efforts.That feeling of safety led them to feel more psychologically empowered: They felt their jobs had meaning, they had autonomy to do their work, and they felt they were competent and that their work had impact in the school.So humble leadership led to teachers feeling psychologically safe, which made them feel empowered and ultimately led them to share their experience and knowledge more fully with their colleagues, Goddard said.“This feeling of teachers that they could safely share their knowledge comes from having a leader who has humility – an openness to learning from others, a willingness to revise opinions, and an appreciation for the strengths of others,” he said.While this research was done in China, Goddard said he believes the results would be similar in the United States and elsewhere.“There’s a lot of evidence that suggests trust is a key part of successful organizations. And feeling psychologically safe and empowered to share your knowledge in the workplace is part of building trust, and that’s what humble leaders help create,” he said.“That is as true in the United States as it is in China.”In the same way, the results should be applicable outside of education.“Many of the same principles that make successful organizations cut across cultures and fields. It makes sense that humble leaders will build trust and better relationships that will increase the effectiveness of any groups that have to work together,” Goddard said.",0.0,0.0
260,https://news.mit.edu/2022/microparticles-oscillating-current-1013,Tiny particles work together to do big things,"Taking advantage of a phenomenon known as emergent behavior in the microscale, MIT engineers have designed simple microparticles that can collectively generate complex behavior, much the same way that a colony of ants can dig tunnels or collect food.Working together, the microparticles can generate a beating clock that oscillates at a very low frequency. These oscillations can then be harnessed to power tiny robotic devices, the researchers showed.“In addition to being interesting from a physics point of view, this behavior can also be translated into an on-board oscillatory electrical signal, which can be very powerful in microrobotic autonomy. There are a lot of electrical components that require such an oscillatory input,” says Jingfan Yang, a recent MIT PhD recipient and one of the lead authors of the new study.The particles used to create the new oscillator perform a simple chemical reaction that allows the particles to interact with each other through the formation and bursting of tiny gas bubbles. Under the right conditions, these interactions create an oscillator that behaves similar to a ticking clock, beating at intervals of a few seconds.“We're trying to look for very simple rules or features that you can encode into relatively simple microrobotic machines, to get them to collectively do very sophisticated tasks,” says Michael Strano, the Carbon P. Dubbs Professor of Chemical Engineering at MIT.Strano is the senior author of the new paper, which appears today in Nature Communications. Along with Yang, Thomas Berrueta, a Northwestern University graduate student advised by Professor Todd Murphey, is a lead author of the study.Collective behaviorDemonstrations of emergent behavior can be seen throughout the natural world, where colonies of insects such as ants and bees accomplish feats that a single member of the group would never be able to achieve.“Ants have minuscule brains and they do very simple cognitive tasks, but collectively they can do amazing things. They can forage for food and build these elaborate tunnel structures,” Strano says. “Physicists and engineers like myself want to understand these rules because it means we can make tiny things that collectively do complex tasks.”In this study, the researchers wanted to design particles that could generate rhythmic movements, or oscillations, with a very low frequency. Until now, building low-frequency micro-oscillators has required sophisticated electronics that are expensive and difficult to design, or specialized materials with complex chemistries.The simple particles that the researchers designed for this study are discs as small as 100 microns in diameter. The discs, made from a polymer called SU-8, have a platinum patch that can catalyze the breakdown of hydrogen peroxide into water and oxygen.When the particles are placed at the surface of a droplet of hydrogen peroxide on a flat surface, they tend to travel to the top of the droplet. At this liquid-air interface, they interact with any other particles found there. Each particle produces its own tiny bubble of oxygen, and when two particles come close enough that their bubbles interact, the bubbles pop, propelling the particles away from each other. Then, they begin forming new bubbles, and the cycle repeats over and over.“One particle by itself stays still and doesn’t do anything interesting, but through teamwork, they can do something pretty amazing and useful, which is actually a difficult thing to achieve at the microscale,” Yang says.",0.0,0.0
182,https://propermanchester.com/trending/primary-school-kids-to-be-fed-insects-as-an-eco-friendly-alternative-protein/,Primary school kids to be fed insects as an eco-friendly âalternative proteinâ,"Pupils at four primary schools will be offered edible insects as scientists urge young people to embrace ‘alternative protein’ and eco-friendly meat substitutes.While most children expect to eat the likes of lasagne and fish and chips while at school, pupils at four Welsh primary schools will soon be given the chance to sample bugs and insects as part of a new environmental study.Researchers hope to feed the pupils a product called VeXo, a combination of insect and plant-based protein said to resemble ‘conventional’ mince.The children will also take part in workshops organised by scientists and teachers to inform them about the benefits of eating ‘alternative protein’ like bugs.The study will also use surveys, interviews and focus groups to explore pupil’s understandings of alternative proteins – and as part of the research they will be offered a sample if they wish to try it.According to i newspaper, researchers are hoping to use data from the study to learn how best to educate children about the nutritional and environmental benefits of eating bugs and insects – such as crickets, silkworms, locusts and mealworms – as an alternative protein source.Read More: School dinners could become smaller or use ‘cheaper ingredients’ amid cost of living crisisThe study lead, Christopher Bear from Cardiff University, said: “We want the children to think about alternative proteins as real things for now, rather than just as foods for the future, so trying some of these foods is central to the research.“Although edible insects are – for now – not sold widely in the UK, they form part of the diet of around 2 billion people worldwide.“Much of this is in parts of the world where they are part of long-standing culinary traditions. And they are increasingly popular elsewhere.”The headteacher of Roch Community Primary in Pembrokeshire, one of the schools taking part in the study, said the issue was ‘important’ but acknowledged it was ‘difficult’ for youngsters to make sense of the issue.He said: “There is an important connection between our local community, food production and wider global issues surrounding sustainable development.“These issues are important to children, but also difficult to make sense of and can often be confusing for them.”",0.0,0.0
537,https://interestingengineering.com/innovation/amazon-spacex-help-launching-starlink-rival,Amazon may have to turn to SpaceX for help launching its Starlink rival service,"Amazon signed that agreement, totaling 83 Kuiper launches, with United Launch Alliance (ULA), European firm Arianespace, and Jeff Bezos' Blue Origin.There's one important caveat, though. Those launches partially rely on rockets that have yet to reach orbit, including Blue Origin's New Glenn and the Ariane 6. In a webcast with The Washington Post, Amazon senior VP of devices and services Dave Limp touched on this concern, and he refused to rule out asking the company's rival SpaceX for help with its launches.Amazon is playing catch-up with StarlinkAmazon's two prototype satellites are set to launch aboard the new Vulcan Centaur rocket early next year, as per an October press statement. The Project Kuiper mega-constellation is eventually expected to total 3,236 satellites in low Earth orbit, bringing high-speed internet anywhere in the world, much like SpaceX's Starlink. SpaceX currently has more than 3,000 satellites in orbit, and it aims to eventually send roughly 30,000 more up to the skies.That's a lot of catching up to do, and Amazon may even need to turn to its rival for help, Limp conceded during his recent webcast interview with The Washington Post. ""You'd be crazy not to, given their track record,"" Limp said after he was asked whether Amazon might turn to SpaceX to launch its Kuiper satellites.",0.0,0.0
552,https://techcrunch.com/2022/07/28/heres-how-manchin-and-schumers-surprise-725-page-bill-could-boost-climate-tech/,Hereâs how Manchin and Schumerâs surprise 725-page bill could boost climate tech,"Senator Joe Manchin, a Democrat from West Virginia, pulled a fast one yesterday. After months of opposing major climate legislation, citing inflation risks, he suddenly changed his tune. Last night, climate legislation was back on the table, and the odds of it passing had gone up considerably.While not as large, in terms of dollars, as President Joe Biden’s Build Back Better plan, the Inflation Reduction Act of 2022 still stands as one of the most significant pieces of climate legislation proposed in the U.S. It would put $369 billion toward clean energy, electric vehicles and a range of other climate programs.Senate Democrats say that the bill could cut emissions by 40% (most likely below 2005 levels, a benchmark the Biden administration has used in the past). That’s not enough to keep warming to 1.5 degrees Celsius, the globally agreed upon level that would limit most catastrophic outcomes, but it’s close. According to Climate Action Tracker, the bill would bring the U.S. from “insufficient” to “almost sufficient,” increasing the chances that the world can keep global average temperatures from rising more than 2 degrees Celsius.The bill, at 725 pages, goes into great detail outlining how the hundreds of billions of dollars should be spent. I’ve skimmed through the entire text, reading the most relevant pages and picking out the key points. If the bill is signed into law, here’s what will be driving climate policy in the U.S. for the foreseeable future.",0.0,0.0
498,https://techcrunch.com/2022/10/07/if-its-agtech-its-climate-change-how-the-crisis-is-shaping-investors-strategies/,"If itâs agtech, itâs climate change: How the crisis is shaping investorsâ strategies","To state the (painfully) obvious: The fates of agriculture and climate change are inextricably linked.The weather dictates what grows where and when, but as the Earth warms beneath a wool blanket of excess carbon, agriculture is especially vulnerable in ways you might not expect.Record-setting heat and droughts fry grasses that farmers depend on to feed cattle, warmer temperatures are a boon for pests and fungi that harm crops, smoke from wildfires taint harvests, and extreme weather and rising seas make it more difficult to move everything (including food) around. The threats to food security and livelihoods go on and on.Undoubtedly, this has some deal-makers in tech salivating. As startups look for ways to adapt the global food system to the chaos of today, we reached out to seven agtech investors to get a better understanding of how the climate crisis has informed their strategies to date.“Climate challenges are not new to anybody operating in the broader food and agriculture space, so our approach is to invest in solutions that can help mitigate and adapt to climate change,” Yield Lab partner Camila Petignat told TechCrunch.Themes the firm looks at “include soil and water conservation, improved use of crop inputs, the shift from chemical to biological crop protection solutions and reduction of food waste,” Petignat said.“We could argue,” Petignat added, “that the increased awareness of carbon markets in recent years has triggered new opportunities at the intersection of agtech and fintech, a space that we are interested in.”“India is one of the most vulnerable countries to climate change,” Omnivore managing partner Jinesh Shah told TechCrunch. “Agriculture represents 20% of India’s GHG emissions, but the sector is also incredibly vulnerable to the impacts of climate change, which may begin to threaten Indian food security in the coming decade.” he said. Agriculture is responsible for about a quarter of global greenhouse gas emissions, per the EPA.Shah added that the firm’s strategy is to “invest in startups that align with one or more of our four key pillars — increasing smallholder profitability, enhancing smallholder resilience, improving agricultural sustainability and catalyzing climate action.” The investor went on to state that agtech in India must “evolve beyond digital technologies (farmer platforms and B2B marketplaces), and we look to agrifood life sciences for long-term solutions to climate change.”Read the full survey to learn where investors are looking to invest, what’s on their minds right now, the best way to pitch and contact them, and understand which emerging technologies have captured their attention.",0.0,0.0
482,https://techcrunch.com/2022/07/19/crop-one-emirate-worlds-largest-vertical-farm-in-dubai/,"Crop One, Emirate open âworldâs largest vertical farmâ in Dubai","Crop One Holdings and Emirates Flight Catering announced this week they opened Emirates Crop One, what they say is “the world’s largest vertical farm.”The over 330,000-square-foot facility is located in Dubai, United Arab Emirates near Al Maktoum International Airport at Dubai World Central. It has the capacity to produce over 2 million pounds of leafy greens annually.The facility got its start in 2018 when Crop One, an indoor vertical farming company, and Emirates Flight, the airline Emirates catering arm, signed a $40 million joint venture to build Emirates Crop One. AgFunder reported the $40 million was a majority debt funded.Dubbed ECO 1, the farm uses 95% less water than field-grown produce and is guaranteed an output of three tons per day, according to the companies. Passengers on Emirates and other airlines will be able to eat the leafy greens, which include lettuces, arugula, mixed salad greens and spinach on their flights starting this month.Those local to the United Arab Emirates will be able to buy the produce at stores under the Bustanica brand. The greens require no pre-washing and are grown without pesticides, herbicides or chemicals.“We are proud to bring Crop One’s best-in-class technology to this innovative food production facility alongside our joint venture partner,” said Craig Ratajczyk, CEO at Crop One., in a written statement.” ECO 1 will address growing supply chain challenges and food security issues, while introducing millions of new consumers to the benefits of vertically farmed produce. It’s our mission to cultivate a sustainable future to meet global demand for fresh, local food, and this new farm is the manifestation of that commitment. This new facility serves as a model for what’s possible around the globe.”This is Crop One’s second vertical farm after its flagship facility in Millis, Massachusetts.Emirates Crop One joins vertical farms being built all over the world. In May, Bowery Farms opened its vertical farm in Pennsylvania. Though it did not give a size for the facility, my colleague Brian Heater wrote that it was suspected to be 156,000 square feet. Earlier this year, Upward Farms was planning a 250,000-square-foot vertical farm, also in Pennsylvania, that was poised to open in mid-2023.",0.0,0.0
376,https://t.uga.edu/8sX,"Local doctor implants one of the first wireless, dual chamber pacemakers","Closeup of a wireless pacemaker (left) and a traditional pacemaker (right) held in the hands of Dr. Kent Nilsson. (Photo by Andrew Davis Tucker/UGA)New type of pacemaker is a safer, more advanced option than traditional surgeryThis March, Dr. Kent Nilsson successfully implanted one of the first wireless, dual chamber pacemakers in the world into a patient. This accomplishment makes Piedmont Hospital the first center in the Southeast and fourth in the U.S. to implant this new device. It was only the 32nd implant in a human in the world.A cardiologist at Piedmont Athens Regional Hospital and professor of medicine at the Augusta University/University of Georgia Medical Partnership, Nilsson has become an expert in implanting single chamber, wireless pacemakers. He was called upon again to test the dual chamber version as part of the clinical trial for the Abbott Aveir DR Leadless (wireless) Pacemaker System.The dual chamber wireless pacemaker is honestly one of the most transformative technologies in cardiology. Ever.” —Dr. Kent NilssonWith this procedure, the hospital joined the ranks of leading medical centers and universities in the country. The three locations ahead of Piedmont for the implantation were the University of Arizona, Cleveland Clinic and Cornell University.“The dual chamber wireless pacemaker is honestly one of the most transformative technologies in cardiology. Ever,” said Nilsson. “When the dual chamber launches, it will completely change the field.”How does a pacemaker work?A pacemaker is a device implanted into the chest to stabilize an irregular or slowly beating heart. A traditional pacemaker is inserted through an incision in the chest and is then connected to wires (leads) that have been inserted into the heart through the subclavian vein. The device sits beneath the skin and on top of the chest muscle, and the wires deliver electrical pulses to correct the heartbeat.In 2014, Piedmont joined a clinical trial to test single chamber leadless – or wireless – pacemakers, which are put directly into the lower right ventricle of the heart via the femoral vein and do not require the chest to be opened for implantation. Nilsson gladly came on board for the trial.Piedmont was the first center in Georgia and 15th in the country to implant a wireless pacemaker. By the time the 2014 trial for the single wireless pacemaker was complete, Nilsson had implanted over 30 devices.Although traditional pacemakers have come a long way (the first implantation in 1958 failed within three hours and the patient went on to have 26 pacemakers in his lifetime), Nilsson said this wireless technology is the biggest advancement in the field since the invention.Benefits of wireless pacemakersThe wireless pacemaker is about 90% smaller than the average pacemaker and the surgery lasts around 30 minutes. The battery life is also comparable with a traditional pacemaker’s 10-12 years and could be longer in some cases.Patients also will not have an incision scar on the chest or a bump protruding from the skin.“The psychological aspect of not seeing an incision or having something protruding out of your skin is beneficial,” said Nilsson. “Just being able to not broadcast to the world that there is something wrong.”Another advantage is the elimination of several complications associated with traditional pacemakers. One in 10 patients see complications with pacemaker leads, or wires. Some also experience pocket infections, hematoma, lead dislodgment and lead fracture.Wireless pacemaker patients will also see a shorter, less complicated recovery time. There are no restrictions with taking showers or getting the area wet, and there are also no mobility issues. Traditional pacemaker patients are not able to move their arm above their shoulder for six weeks after surgery.“It’s same day discharge and people are up and moving around and doing everything they need to do,” said Nilsson.The single chamber wireless pacemaker was approved by the FDA in 2016, and Nilsson is now teaching other physicians how to implant the device.“I’m one of 10 proctors teaching close to 5,000 physicians how to implant,” said Nilsson. “The reception nationwide has been overwhelming. Every day my Twitter is blowing up with pictures of people doing their first single chamber implant.”Single chamber pacemakers connect to one chamber of the heart while the dual chamber version connects to both chambers on the right side of the heart. Dual chamber pacemakers are the standard of care for pacemaker patients in the United States, so this new technology will affect more patients than the single chamber version.“Dual chambers are 95% of what we do,” said Nilsson.First implant of the new deviceNilsson kicked off the first dual implantation of the dual chamber, wireless pacemaker in March with a meaningful milestone. “Almost eight years to the day after we implanted the single chamber, we put in the dual chamber,” he said.Sixty-four-year-old Anna McKuhen was Nilsson’s first patient. She was the first in the Southeast to have the dual chamber pacemaker implanted.“I am all about new technology, so when they asked if I’d like to be a part of this trial, I said sure. It sounded exciting,” said McKuhen. “The technology amazes me.”McKuhen said she was interested in receiving the wireless pacemaker, in part, because of the greatly reduced recovery time.“My recovery was fantastic,” said McKuhen. “I did not have any problems whatsoever. I was only confined to a week of not lifting heavy objects. I’ve had zero problems.”Nilsson implanted four dual pacemakers by the time the trial concluded in September.Nilsson hopes the dual chamber will be FDA approved in 2023 and widely available soon after.“I would say this is the future of pacemakers 100 percent,” said Nilsson. “Everyone is trying to catch up at this point. This is really transformative technology.”",0.0,0.0
436,https://www.psypost.org/2022/10/people-systematically-underestimate-how-positively-recipients-will-respond-to-social-support-study-finds-64043,"People systematically underestimate how positively recipients will respond to social support, study finds","Have you ever given a stranger a compliment in passing? If you have, they probably appreciated more than you would think. A study published in Psychological Science suggests that people severely underestimate how positively recipients feel about receiving support.Social support is an integral part of a balanced and healthy life. It can have profound effects of well-being by making the recipient feeling important, loved, and cared for by others. It can even improve physical health in some cases. Despite the benefits, many people hesitate to reach out due to being unsure about how the other person will react. People may fear a negative or indifferent reaction, as well as believe their offer of social support will not have any significant impact. This study seeks to better understand the potential gap between perceived and experienced benefits for the recipient.For their research, James A. Dungan and colleagues conducted four studies to test their hypotheses. Study 1 tested expectations and interest in expressing support. Dungan and colleagues collected data through Amazon’s Mechanical Turk and utilized a sample of 100 participants. Participants were asked to identify five people who may be going through a difficult time that they could express support to, why they thought the person needed support, and how they would feel providing that support.In Study 2, Dungan and colleagues tested messages of support by utilizing a sample of 120 University of Chicago students, asked them to identify a person on campus that they believed could use their social support, and had them write an email expressing support. Participants rated how they believed the recipient would feel receiving it, and it was sent anonymously to the recipient. The recipients were asked to complete a survey about the experience of receiving the supportive email.Study 3 measured in-person support and utilized 50 pairs of strangers from the Chicago area to participate. Participants were told to introduce themselves to each other and then put in separate rooms to complete an online survey. Recipients described a difficulty they were facing, and expressers read it. Participants were put back together, and expressers were told to do their best to express support.Study 4 measured differing perspectives on support and utilized 300 participants recruited online to complete an online survey. Participants were told to complete a survey from the perspective of someone expressing or receiving support. They were told to vividly imagine what it would be like to provide or receive support and answered measures on how it felt.Results across the studies showed that even when people could recognize that someone needed social support, there were high levels of hesitation to providing it due to expectations and misconceptions around how the support would be received and responded to. This mismatch seemed to come from people who are considering providing support focusing on the competency aspect of how their support may come off, while recipients focused primarily on how warm or kind it was.“Whether facing a global pandemic or dealing with life’s tribulations, people rely on support from others to manage adversity. Our studies suggest that even when people recognize that support is needed, they may be overly reluctant to express it because they hold miscalibrated expectations of their recipients’ response,” the researchers explained.Additionally, the relationship between the provider and the recipient was a big factor, as many providers did not feel it was helpful or appropriate to provide support to acquaintances or strangers. Contrary to this, results showed that in Study 3, participants received positive benefits from getting support from a complete stranger in a lab setting. Overall, results point to a significant mismatch and suggest that social support is more appreciated than many realize.This study took important steps toward better understanding how social support feels from both giver and recipient. Despite this, there are limitations to note. One such limitation is that the population was all from the US and consisted of people who answered online ads for participants. Future research could target people experiencing significant distress to see if they benefit as much.“Each day offers opportunities to reach out and show some form of support, however large or small, to a person in need,” Dungan and colleagues concluded. “Our experiments suggest that undervaluing the positive impact of expressing support could create a psychological barrier to expressing it more often. Withholding support because of misguided fears of saying or doing the wrong thing could leave both recipients and expressers of support less happy than they could be. Understanding how these psychological barriers restrain prosocial behavior could help to encourage more routine expressions of social support, to everyone’s benefit.”The study, “Too Reluctant to Reach Out: Receiving social Support Is More Positive Than Expressers Expect“, was authored by James Dungan, David Munguia Gomez, and Nicholas Epley.",0.0,0.0
348,https://www.smithsonianmag.com/smart-news/this-wearable-ultrasound-sticker-can-continuously-image-organs-for-48-hours-180980504/,This Wearable Ultrasound Sticker Can Continuously Image Organs for 48 Hours,"Ultrasound is a convenient, noninvasive tool for doctors to look inside the human body and check out a person’s liver, heart and other internal structures, as well as the developing fetus of a pregnant patient. But today’s ultrasound imaging technology is large and technical, so it’s only available in healthcare facilities and must be operated by highly trained technicians. Plus, patients, who take time out of their schedules to go to an appointment, have to be covered in a sticky gel.Now, researchers say they’ve developed an innovative solution to some of these challenges. Engineers at the Massachusetts Institute of Technology have unveiled a new adhesive ultrasound patch that’s about the size of a postage stamp and can provide continuous imaging of the body’s inner workings for up to 48 hours. The scientists shared their new technology in a paper published last week in the journal Science.“We believe we’ve opened a new era of wearable imaging,” says Xuanhe Zhao, a mechanical engineer at MIT and one of the study’s authors, in a statement. “With a few patches on your body, you could see your internal organs.”In the past, engineers developing wearable ultrasound technologies have run into issues with image quality and flexibility, but the new MIT stickers seem to have struck the right balance. To create the small devices, which are about three millimeters thick and two square centimeters in size, engineers combined rigid transducers with a stretchy, sticky layer that encapsulates a layer of water-based hydrogel.The researchers put the stickers to the test by placing them on various body parts of healthy volunteers, including their neck, abdomen, arms and chest. Then, they asked the volunteers to move their bodies in various ways, including drinking juice, jogging, lifting weights, biking, sitting and standing.Not only did the stickers adhere to the volunteers’ skin, but they also produced clear images of their internal organs and major blood vessels for up to 48 hours. The patches allowed the researchers to watch volunteers’ stomachs expand, then shrink, when they drank juice. They could observe major blood vessels changing sizes when a volunteer was sitting versus standing, and witness the heart change shape while pumping blood during exercise.For now, the stickers must be connected to instruments to make sense of the data they’ve gathered. But in the near future, the scientists hope to refine their design so that the stickers can operate wirelessly, communicating with a patient’s smart phone for real-time, on-demand imaging.“We are working hard on the wireless version,” Zhao tells the Guardian’s Ian Sample. “Because there are already wireless point-of-care handhold ultrasounds, we are confident that we will be able to achieve the wireless version in a few years.”Already, researchers are dreaming up all the ways the stickers could be useful. Patients could wear them at home to help monitor an array of medical conditions, including cardiovascular disease and cancer. In hospitals, they could free up medical technicians for other tasks or make it possible to obtain ultrasound images in healthcare facilities with staffing issues.Recommended Videos“You don’t need a trained sonographer and you don’t need a huge ultrasound machine,” says Philip Tan, an electrical engineer at the University of Texas at Austin, to New Scientist ’s Jeremy Hsu. “You could deploy it to very low-resource communities.”",0.0,0.0
493,https://techcrunch.com/2022/04/25/ghanaian-agtech-farmerline-to-use-new-funding-to-strengthen-its-infrastructure-help-farmers-create-wealth/,"Ghanaian agtech Farmerline to use new funding to strengthen its infrastructure, help farmers create wealth","A McKinsey and Co.A McKinsey and Co.Noting critical gaps in the region’s agri-food space, Ghanaian agritechNoting critical gaps in the region’s agri-food space, Ghanaian agritech$12.9 million pre-Series A funding$12.9 million pre-Series A fundingFarmerline was founded in 2013 byFarmerline was founded in 2013 byThe equity round was led by Acumen Resilient Agriculture Fund (ARAF) and FMO, the Dutch entrepreneurial development bank, with participation from Greater Impact Foundation. Debt lenders included DEG, Rabobank, Ceniarth, Rippleworks, Mulago Foundation, Whole Planet Foundation, the Netri Foundation and Kiva.The equity round was led by Acumen Resilient Agriculture Fund (ARAF) and FMO, the Dutch entrepreneurial development bank, with participation from Greater Impact Foundation. Debt lenders included DEG, Rabobank, Ceniarth, Rippleworks, Mulago Foundation, Whole Planet Foundation, the Netri Foundation and Kiva.Attah told TechCrunch that the agtech will use its first equity funding to build physical infrastructure like warehouses and distribution networks.Attah told TechCrunch that the agtech will use its first equity funding to build physical infrastructure like warehouses and distribution networks.“We think of ourselves as the Amazon of farmers… a digital and physical infrastructure powering a marketplace that allows the movement of goods and services to and from rural areas,” said Attah.“We think of ourselves as the Amazon of farmers… a digital and physical infrastructure powering a marketplace that allows the movement of goods and services to and from rural areas,” said Attah.“We plan to use the funding to strengthen our infrastructure, that is warehouses and distribution channels. Having a network of partners that can help us quickly move inputs like fertilizer and seeds to rural areas, and farm produce from rural areas, is important and part of what we do. We don’t intend to bring all of the logistics and storage in-house, but we want to be more efficient and that means working with the right partners,” he said.“We plan to use the funding to strengthen our infrastructure, that is warehouses and distribution channels. Having a network of partners that can help us quickly move inputs like fertilizer and seeds to rural areas, and farm produce from rural areas, is important and part of what we do. We don’t intend to bring all of the logistics and storage in-house, but we want to be more efficient and that means working with the right partners,” he said.Farmerline delivers quality farm inputs and education on the best farming practices through partner agribusinesses.Farmerline delivers quality farm inputs and education on the best farming practices through partner agribusinesses.Farmerline delivers quality farm inputs and education on the best farming practices through partner agribusinesses.Greater reachGreater reachFarmerline works with agribusinesses (usually small retail shops that stock farm inputs) to ensure that farmers get access to high-quality supplies. These shop owners, usually the first point of knowledge for the farmers, are used by Farmerline to distribute educational material and to gather farmers together for training. The partnering shops use the startup’sFarmerline works with agribusinesses (usually small retail shops that stock farm inputs) to ensure that farmers get access to high-quality supplies. These shop owners, usually the first point of knowledge for the farmers, are used by Farmerline to distribute educational material and to gather farmers together for training. The partnering shops use the startup’s“We are tapping into that network of agribusiness, and in a way, we are tapping into a network of trust — the relationship that these shop owners have with farmers to help us expand,” said Attah.“We are tapping into that network of agribusiness, and in a way, we are tapping into a network of trust — the relationship that these shop owners have with farmers to help us expand,” said Attah.The partnership with retailers, said Attah, emerged after Farmerline realized that working directly with the farmers would amount to “competing with local businesses, and it didn’t make any sense. The cost of going door to door to each farmer was really high,” he said.The partnership with retailers, said Attah, emerged after Farmerline realized that working directly with the farmers would amount to “competing with local businesses, and it didn’t make any sense. The cost of going door to door to each farmer was really high,” he said.“Working with the agribusinesses made our businesses scalable, and it also helped us make more impact especially during the pandemic when we couldn’t travel — they became our eyes and ears on the ground. We sent trucks full of fertilizer and seeds to them that they would then distribute to farmers. That model worked really well.”“Working with the agribusinesses made our businesses scalable, and it also helped us make more impact especially during the pandemic when we couldn’t travel — they became our eyes and ears on the ground. We sent trucks full of fertilizer and seeds to them that they would then distribute to farmers. That model worked really well.”Using Mergdata, Farmerline can tell the performance of their partnering agribusinesses (retail shops), and develop a credit scoring program that guides the extension of business expansion loans.Using Mergdata, Farmerline can tell the performance of their partnering agribusinesses (retail shops), and develop a credit scoring program that guides the extension of business expansion loans.According to Attah, the startup more than doubled its direct-reach last year to 79,000 farmers, up from 36,000 in 2020 and 8,000 in 2019.According to Attah, the startup more than doubled its direct-reach last year to 79,000 farmers, up from 36,000 in 2020 and 8,000 in 2019.Moreover, through third party licensing for Mergdata — which is now used by 180 clients including governments, non-governmental organizations and agri-companies to ensure transparency in their supply chain and traceability — the agtech has digitized over 1 million farmers in 26 countries across the globe. Benin, in West Africa, uses the platform as a national market information system.Moreover, through third party licensing for Mergdata — which is now used by 180 clients including governments, non-governmental organizations and agri-companies to ensure transparency in their supply chain and traceability — the agtech has digitized over 1 million farmers in 26 countries across the globe. Benin, in West Africa, uses the platform as a national market information system.",0.0,0.0
302,https://www.cnbc.com/2022/10/27/elon-musk-now-in-charge-of-twitter-ceo-and-cfo-have-left-sources-say.html,"Elon Musk now in charge of Twitter, CEO and CFO have left, sources say","Tesla CEO Elon Musk is now in charge of Twitter , CNBC has learned.Twitter CEO Parag Agrawal and finance chief Ned Segal have left the company's San Francisco headquarters and will not be returning, sources said. Vijaya Gadde, the head of legal policy, trust and safety, was also fired, The Washington Post reported.Musk had until Friday to complete his $44 billion acquisition of Twitter or face a court battle with the company.The billionaire tweeted ""the bird is freed"" in an apparent reference to the takeover being completed.Twitter did not immediately respond to a request for comment.In April, Twitter accepted Musk's proposal to buy the social media service and take it private. However, Musk soon began sowing doubt about his intentions to follow through with the agreement, alleging the company failed to adequately disclose the number of spam and fake accounts on the platform.When Musk said he was terminating the deal, Twitter sued the billionaire, alleging he ""refuses to honor his obligations to Twitter and its stockholders because the deal he signed no longer serves his personal interests.""",0.0,0.0
384,https://www.nejm.org/doi/full/10.1056/NEJMoa2208375,Effect of Colonoscopy Screening on Risks of Colorectal Cancer and Related Death,"BackgroundAlthough colonoscopy is widely used as a screening test to detect colorectal cancer, its effect on the risks of colorectal cancer and related death is unclear.MethodsDownload a PDF of the Research Summary.We performed a pragmatic, randomized trial involving presumptively healthy men and women 55 to 64 years of age drawn from population registries in Poland, Norway, Sweden, and the Netherlands between 2009 and 2014. The participants were randomly assigned in a 1:2 ratio either to receive an invitation to undergo a single screening colonoscopy (the invited group) or to receive no invitation or screening (the usual-care group). The primary end points were the risks of colorectal cancer and related death, and the secondary end point was death from any cause.ResultsFollow-up data were available for 84,585 participants in Poland, Norway, and Sweden — 28,220 in the invited group, 11,843 of whom (42.0%) underwent screening, and 56,365 in the usual-care group. A total of 15 participants had major bleeding after polyp removal. No perforations or screening-related deaths occurred within 30 days after colonoscopy. During a median follow-up of 10 years, 259 cases of colorectal cancer were diagnosed in the invited group as compared with 622 cases in the usual-care group. In intention-to-screen analyses, the risk of colorectal cancer at 10 years was 0.98% in the invited group and 1.20% in the usual-care group, a risk reduction of 18% (risk ratio, 0.82; 95% confidence interval [CI], 0.70 to 0.93). The risk of death from colorectal cancer was 0.28% in the invited group and 0.31% in the usual-care group (risk ratio, 0.90; 95% CI, 0.64 to 1.16). The number needed to invite to undergo screening to prevent one case of colorectal cancer was 455 (95% CI, 270 to 1429). The risk of death from any cause was 11.03% in the invited group and 11.04% in the usual-care group (risk ratio, 0.99; 95% CI, 0.96 to 1.04).ConclusionsIn this randomized trial, the risk of colorectal cancer at 10 years was lower among participants who were invited to undergo screening colonoscopy than among those who were assigned to no screening. (Funded by the Research Council of Norway and others; NordICC ClinicalTrials.gov number, NCT00883792.)",0.0,0.0
525, decrease fat accumulation, further studies need to be performed in participants with elevated FBG, and increase insulin sensitivity.However,0.0,0.0
239,https://electrek.co/2022/09/30/offshore-wind-seaweed-farms/,Could offshore wind sites host edible seaweed farms? The Swedes think so,"Stockholm-headquartered renewable energy developer OX2 has signed letters of intent with Swedish edible seaweed companies Nordic SeaFarm and KOBB to explore the possibility of seaweed farming at one of OX2’s offshore wind farms.Seaweed and offshore windOX2’s Galatea-Galene huge 1.7 gigawatt offshore wind farm will be sited off Halland, a county on the western coast of Sweden. It’s named after two Greek sea nymphs, Galatea and Galene, and consists of two sub-areas around 15.5 miles (25 km) outside the cities of Falkenberg and Varberg.Galatea-Galene is expected to consist of up to 101 wind turbines and generate around 6 to 7 terawatt-hours of clean electricity per year. That’s the equivalent of the average annual electricity consumption of more than 1.2 million Swedish households. (There are 4.8 million households in Sweden, for perspective.)This offshore wind farm will be developed in a single phase. Construction is expected to commence in 2028 and enter into commercial operation in 2030.Simon Johansson, CEO of Nordic SeaFarm, and Benjamin Ajo, chairman of the board of KOBB, said in a joint statement [via Offshorewind.biz]:We see great opportunities, in collaboration with both the fishing industry and the wind power industry, to both maintain and create new jobs when we investigate the possibilities of creating a new industry in Sweden in the form of large-scale aquaculture. Developing the national food supply while [offshore wind] farms contribute to stopping the negative effects of climate change are more positive aspects.All seaweed needs to grow is saltwater and sunlight. It’s a superfood that’s rich in vitamins, minerals, fiber, and antioxidants, and particularly high in iodine, so it’s very nutritious. (Note that crispy seaweed in Chinese restaurants is actually cabbage.)It can be used to wrap sushi, in soups and salads, in snacks and instant noodles, and as livestock food.Seaweed also provides a source of food for marine life. In April, Electrek reported that a groundbreaking study found that the first US offshore wind farm has had no negative effect on fish and has even proven to be beneficial.Here’s a short video from Nordic SeaFarm that shows how the company grows and harvests seaweed for consumption:Electrek’s TakePairing seaweed farms and offshore wind farms seems like an inspired idea.Seaweed’s ability to absorb toxins and other contaminants from the sea make it environmentally friendly, but that’s not what humans want to consume. That’s where seaweed growers come in: they test the seaweed for safety and quality.Any multipurpose sustainable use of an offshore wind farm, particularly one that provides both clean energy and nutritious food that doesn’t require either fertilizer or fresh water to grow, is a win. It’s also another example of innovation that the clean energy revolution is bringing about in the climate change fight.Read more: This new innovation boosts wind farm energy output yet costs nothingUnderstandSolar is a free service that links you to top-rated solar installers in your region for personalized solar estimates. Tesla now offers price matching, so it’s important to shop for the best quotes. Click here to learn more and get your quotes. — *ad.",0.0,0.0
205,https://www.independent.co.uk/tech/solar-power-record-perovskite-renewable-energy-b2191443.html,Solar power world record broken with âmiracle materialâ,"For free real time breaking news alerts sent straight to your inbox sign up to our breaking news emails Sign up to our free breaking news emails Please enter a valid email address Please enter a valid email address SIGN UP I would like to be emailed about offers, events and updates from The Independent. Read our privacy notice Thanks for signing up to theBreaking News email {{ #verifyErrors }}{{ message }}{{ /verifyErrors }}{{ ^verifyErrors }}Something went wrong. Please try again later{{ /verifyErrors }}Researchers have passed the 30 per cent efficiency barrier with silicon solar cells for the first time by combining them with the so-called “miracle material” perovskite.A team from various universities and institutes in the Netherlands made the breakthrough with a tandem solar cell that compliments traditional silicon-based cells – which have an energy conversion efficiency of around 22 per cent – with the widely-acclaimed properties of perovskite.The researchers said that achieving greater than 30 per cent efficiency with the four-terminal tandem device marked “a big step in accelerating the energy transition” and would improve energy security by reducing fossil fuel dependency.“This type of solar cell features a highly transparent back contact that allows over 93 per cent of the near infrared light to reach the bottom device,” said Dr Mehrdad Najafi from the Netherlands Organisation for Applied Scientific Research (TNO).“This performance was achieved by optimizing all layers of the semi-transparent perovskite solar cells using advanced optical and electrical simulations as a guide for the experimental work in the lab.”Perovskite has been hailed for its potential to transform an array of industries, ranging from ultra-high-speed communications to renewable energy production.The researchers behind the latest solar cell record now hope to commercialise the technology to achieve a widespread roll-out.“Now we know the ingredients and are able to control the layers that are needed to reach over 30 per cent efficiency,” said Professor Gianluca Coletti, program manager of Tandem PV.“Once combined with the scalability expertise and knowledge gathered in the past years to bring material and processes to a large area, we can focus with our industrial partners to bring this technology efficiencies beyond 30 per cent into mass production.”The results were presented at the World Conference on Photovoltaic Energy Conversion (WCPEC-8) in Milan.",0.0,0.0
216,https://www.offshore-energy.biz/worlds-1st-bulker-powered-by-wind-sails-into-port-of-newcastle/,Worldâs 1st bulker powered by wind sails into Port of Newcastle,"October 24, 2022, by Jasmina Ovcina MandraImage by Port of NewcastleThe world’s first bulk carrier to be partially powered by wind, the Shofu Maru, sailed into the Port of Newcastle this morning on its maiden voyage.The 100, 422 dwt bulker, owned by Japanese shipping company Mitsui O.S.K. Lines (MOL), was delivered on October 7, 2022. The vessel is the first of its kind and it heralds a new era in modern shipping as wind propulsion marks its return as a sustainable power source.Related Article Posted: about 1 month ago World’s 1st ship equipped with ‘Wind Challenger’ delivered Posted: about 1 month agoShofu Maru is fitted with the so-called Wind Challenger system, a telescoping hard sail that harnesses wind power to propel the vessel.The system converts wind energy directly to a propulsive force. The installation of the sail on merchant ships has the potential to significantly reduce fuel consumption, which in turn reduces GHG emissions by about 5-8%. The sail can be shortened and extended (55 meters in length) adapting automatically to the wind conditions on board as it can rotate 360 degrees.The vessel was greeted in the Port of Newcastle by a delegation of port officials and diplomatic dignitaries, including Consul-General of Japan in Sydney Tokuda Shuichi, Deputy Secretary of Safety, Environment and Regulation at Transport for NSW Tara McCarthy and MOL Managing Executive Officer for East/South East Asia and Oceania Nobuo Shiotsu.The world’s first bulk carrier to be partially powered by wind, the Shofu Maru, sailed into #Newcastle this morning on its maiden voyage.The vessel’s unique hard sail will reduce greenhouse gas emissions by around 5% on its Japan-Australia journey. pic.twitter.com/RXNEqO8zB8 — Port of Newcastle (@PortofNewcastle) October 24, 2022“Port of Newcastle is pleased to join Port Authority of New South Wales in welcoming the vessel to our beautiful (and rainy) city, alongside the Consul-General of Japan in Sydney Tokuda Shuichi, Deputy Secretary of Safety, Environment and Regulation at Transport for NSW Tara McCarthy and MOL Managing Executive Officer for East/South East Asia and Oceania Nobuo Shiotsu,” the port authority said.The 235-metre-long Shofu Maru will transport coal mainly from Australia, Indonesia, and North America as a dedicated vessel for Japan’s electric services company Tohoku Electric Power.The vessel will now be loaded with its coal shipment, before it departs Newcastle on Tuesday.MOL plans to build a second bulk carrier equipped with the Wind Challenger hard sail system at Oshima Shipbuilding. Under the plan, MOL Drybulk will operate the 62,900 dwt vessel, slated for delivery in 2024. Once completed, the vessel is chartered to transport wood pellets for Enviva, which specializes in the production of sustainable wood bioenergy.MOL is also looking into the feasibility of adopting rotor sails, an auxiliary wind propulsion system developed by UK’s Anemoi Marine Technologies on the bulker. The combined use of both the Wind Challenger and rotor sails is expected to slash GHG emissions by an average of 20%.Related Article Posted: 3 months ago MOL pens deal for 2nd Wind Challenger-fitted bulker Posted: 3 months agoExploration of the wind-assisted propulsion technology forms part of MOL’s overall decarbonization strategy. The MOL Group has set mid- to long-term targets to reduce GHG emissions intensity in marine transport by approximately 45% by 2035 (i.e. versus 2019) and achieve net zero by 2050.",0.0,0.0
227,https://apnews.com/article/technology-electric-vehicles-climate-and-environment-92ab74779ba5589708e8211cc0df4663,Cheaper electric vehicles coming despite high battery costs,"A 2024 Chevrolet Equinox EV 3LT is shown in Warren, Mich., Aug. 30, 2022. General Motors is preparing to roll out a $30,000 Chevy Equinox electric vehicle in the most popular part of the U.S. auto market. (AP Photo/Paul Sancya)A 2024 Chevrolet Equinox EV 3LT is shown in Warren, Mich., Aug. 30, 2022. General Motors is preparing to roll out a $30,000 Chevy Equinox electric vehicle in the most popular part of the U.S. auto market. (AP Photo/Paul Sancya)WARREN, Mich. (AP) — Even though battery costs are rising, auto companies are rolling out more affordable electric vehicles that should widen their appeal to a larger group of buyers.The latest came Thursday from General Motors, a Chevrolet Equinox small SUV with a starting price somewhere around $30,000 and a range-per-charge of 250 miles (400 kilometers). You can get range of 300 miles (500 kilometers) if you pay more.GM won’t release the exact price of the Equinox EV until closer to the date it goes on sale, about this time next year. But the SUV is at the low end of Edmunds.com’s list of prices for electric vehicles sold in the U.S., where the average cost of an EV is around $65,000.Hitting a price around $30,000 and a range per charge close to 300 miles is key to getting mainstream buyers to switch away from gasoline vehicles, industry analysts say.“You’re kind of at that sweet spot,” said Ivan Drury, director of insights for Edmunds.com. “You’re basically at the price point that everyone is clamoring for.”ADVERTISEMENTAuto industry analysts say that if the Equinox makes efficient use of interior space with plenty of cargo and passenger room, and if it is styled similar to current gas-powered small SUVs, it should be a hit in the most popular segment of the U.S. auto market. About 20% of all new vehicles sold in the U.S. are compact SUVs.“It’s a perfect vehicle for a lot of different users, whether it’s a small family, maybe an empty nester,” said Jeff Schuster, president of global forecasting for LMC Automotive, a Detroit-area consulting firm. “You’ve got space to haul things, but it’s easy to drive.”A $30,000 EV that checks all of the boxes is just a little above the price of a comparable small gas-powered SUV. The Toyota RAV4, the top seller in the segment and the top-selling vehicle in the U.S. that isn’t a pickup, starts at just over $28,000.Until the last few years, electric vehicles were either expensive and aimed at affluent luxury buyers, or cheaper but with limited travel ranges. For example, a base version of Tesla’s Model 3, the lowest-price model from the top-selling EV brand in the U.S., starts at more than $48,000. A larger Tesla Model X SUV starts at over $120,000.ADVERTISEMENTThe only EVs with starting prices under $30,000 (including shipping) now are versions of the Nissan Leaf and Chevrolet Bolt. Both are smaller than a typical gas-powered compact SUV. The Mini Cooper Electric, Mazda MX30 and Hyundai Kona Electric are in the $30,000s, according to Edmunds.Kia’s Niro EV, Hyundai’s Ioniq 5, Ford’s F-150 Lightning pickup, the Volkswagen ID.4, Kia EV6, Toyota b24x, Ford’s Mustang Mach E, Audi’s Q4 e-tron, the Subaru Solterra, Polestar 2, and Tesla Model 3 all have starting prices in the $40,000s.GM may find it difficult to keep the Equinox price around $30,000, largely because minerals such as lithium, copper, cobalt and nickel that are key components of batteries have been rising fast. There’s a finite number of mines and increasing demand as nearly all automakers introduce new EVs.ADVERTISEMENTDrury says that even if GM is able to keep the Equinox starting price around $30,000, demand likely will be high enough so the company builds mainly higher-priced versions. And some dealers have been marking up EVs beyond the automaker’s sticker price due to high demand. In the first half of the year, U.S. EV sales rose 68% from the same period a year ago, to nearly 313,000.Some EVs could get a whole lot cheaper in the U.S., too, with federal tax credits starting next year of up to $7,500 that are part of the Inflation Reduction Act . But meeting federal requirements may be difficult.The vehicles and batteries have to be assembled in North America, and the new law phases in requirements that battery minerals and parts have to come from the continent. Most minerals such as lithium, a key battery ingredient, are now imported from China and other countries.The Equinox checks the North American assembly box. It will be made in Mexico. The company won’t say where the battery will be made, but GM has announced three joint-venture battery factories in the U.S., including one that’s operating already in Warren, Ohio.ADVERTISEMENTFrom there, GM is working on meeting the other criteria for getting the tax credit. “We’re really working through the rules and the regulations right now,” said Steve Majoros, vice president of marketing for Chevrolet. “We think it’s all lining up nicely, but more details to come on that.”Majoros hinted that it may take a couple of years to meet all the government’s requirements to get the full credit as GM takes more control of its supply chain for EV parts.The Equinox EV, Majoros said, is longer, wider and a bit shorter than the gas versions of the same vehicle. GM used new interior packaging methods to create comparable passenger and cargo space to the gas Equinox, he said. The relatively small price difference between the two should get many customers to consider EV over gas, he said.“It does a lot of things right,” Majoros said. “So when it does that, the (sales) volume follows.”ADVERTISEMENTGM CEO Mary Barra has said the company will overtake Tesla as the nation’s largest seller of EVs by the middle of this decade. The Equinox EV is a step toward that.“We think it’s going to be one of the products that’s really going to help that mainstream adoption really take off in the marketplace,” Majoros said.",0.0,0.0
332,https://www.businessinsider.com/facebook-has-hidden-tool-to-delete-your-phone-number-email-2022-10,"Facebook probably has your phone number, even if you never shared it. Now it has a secret tool to let you delete it.","Facebook almost certainly has your phone number and email address, even if you never handed them over.That's because any friend who shared their address book with Facebook also shared your details.Now the firm has a new tool to let people check if Facebook has that data, and delete it.Sign up for our newsletter for the latest tech news and scoops — delivered daily to your inbox. Loading Something is loading. Thanks for signing up! Access your favorite topics in a personalized feed while you're on the go. download the app Email address By clicking ‘Sign up’, you agree to receive marketing emails from Insider as well as other partner offers and accept our Terms of Service and Privacy PolicyFacebook's parent firm Meta has quietly rolled out a new service that lets people check whether the firm holds their contact information, such as their phone number or email address, and delete and block it.The tool has been available since May 2022, Insider understands, although Meta does not seem to have said anything publicly about it.A tipster pointed us to the tool, which is well-hidden and apparently only available via a link that is embedded 780 words into a fairly obscure page in Facebook's help section for non-users. The linked text gives no indication that it's sending you to a privacy tool, and simply reads: ""Click here if you have a question about the rights you may have.""Meta has buried its new contact-blocking tool 780 words into an obscure help page. Meta/Shona GhoshHere's how the contact-blocking tool worksOnce you have actually found the contact-blocking tool, it's pretty straightforward.Meta will scan its databases for your contact information. Meta/Shona GhoshThe company explains that even though you may not have signed up to use any core Meta service — such as the Facebook app, Messenger, or Instagram — it may still have your contact information.For many years, the firm asked users signing up for any of its apps to share their phone contacts, with the stated goal of helping them find friends. A side effect is that Meta, whose combined apps boast almost 3 billion daily users, has amassed an unknown but likely vast amount of personal contact information for people who have never signed up for an account, nor opted to share their information.The tool, in theory, allows a non-user to mitigate some of this damage. And although the tool is targeted at people who have never signed up for Meta's apps, it's likely also useful to anyone who is a user but never wanted to share this information.Enter any number or email you want to checkThe service asks whether you want to scan for a phone number, landline number, or email address that may have been uploaded by a friend who uses Meta's core apps: Facebook, Messenger, or Instagram.Meta will send a confirmation code to any phone number or email you want to check. Meta/Shona Ghosh""You can ask us to confirm whether we have your phone number or email address,"" the firm states. ""If we do, you can request that we delete it from our address book database. To prevent it from being uploaded to this database again through someone's address book, we need to keep a copy in our block list.""Meta declined to answer questions from Insider about how its block list works.You can enter any contact details you think may have been uploaded to Meta's services.It takes a few seconds to scan for that data and, if it shows up, Meta will ask if you want that contact information blocked.Meta's contact-deletion tool Meta/Shona GhoshMeta's contact-deletion tool Meta/Shona GhoshAnd here's what it looks like if Meta doesn't hold your data on its servers.Meta's contact-deletion tool Meta/Shona GhoshThe bad news: It's a drop in the ocean of what Meta has on youFiguring out the benefits of doing any of this requires a bit of intellectual reverse-engineering. A primary benefit is privacy and the knowledge your data won't contribute to the opaque power of Facebook algorithms, such as its infamous ""people you may know"" feature.It also gives more control to people whose data has been directly affected. Up until now, Meta only allowed users who had uploaded their contacts' data to delete that information.But in reality, privacy experts told Insider, deleting and blocking this small amount of data is one drop in the ocean compared to what else Meta has on you, regardless of whether or not you use its apps.For example, Meta harvests information on what people do outside its apps through Pixel, a piece of code that tracks what they do on different websites. That the firm has both browsing data and phone numbers of people who don't even use its services has given rise to the concept of ""shadow profiles.""""We first heard about shadow profiles very early in Facebook's dominance,"" Heather Burns, author of the book ""Understanding Privacy"", told Insider. ""Facebook was keeping a sort of profile on you, even if you didn't have a Facebook account, composed of data gathered through things like Facebook Pixel.""Parallel to that was this notion of uploading the contact book, which at various times in Facebook's history was enabled by default when you started an account,"" she added. ""Even if you were a privacy-conscious person, if you hit that button, you had uploaded your friend's data. It feeds into the shadow profiles of people whether or not they use the service at all.""Meta CEO Mark Zuckerberg appeared ignorant of the term ""shadow profiles"" during Congressional hearings in 2018, but admitted the firm collects data on non-users.Burns says she has never signed up for a Meta-owned service but found, on trying Meta's new privacy tool, that her email addresses and phone number had been picked up by the company. ""It's all in there, even though I've never had an account,"" she said. ""I don't believe anybody uploaded my data to Facebook in a malicious manner, I'm just in someone's address book.""But, she says, while it's positive that Meta now lets you block this information, ""that's just two strings of data.""""I still have to use a browser with multiple defense plugins to protect myself from Meta on every page I view,"" she added. ""They are still tracking people, by default, even if they don't use an account. The notion that there's a tool to remove two data strings, to me, it's both beneficial and laughable.""Meta declined to answer questions from Insider about why it has rolled out this new tool, and why this year.Meta may use this tool as a regulatory defenseBoth Burns and Eerke Boiten, professor of cybersecurity at De Montfort University, speculated that the motivation could be political or legal as regulatory scrutiny of the major tech firms increases.""There are two things — one is that installing the Messenger app leaks all of your contacts, that's an undeniable invasion of privacy,"" said professor Boiten. ""But now if anybody brings that up, Meta can always say: 'It doesn't have to be like that, you can undo the damage.'""The second reason may be WhatsApp, which was bought by Meta in 2014 and whose core messaging functionality relies on people uploading their contact data to the app. An ongoing battle between Meta and regulators is whether it can connect the data it sucks up through WhatsApp to its other apps.""Having the possibility to delist your number from Facebook in a way that it can't be used by Facebook to make friend suggestions would be an argument that 'OK, we can do this safely,'"" said Boiten. ""It wouldn't be very transparent ... the friend-suggestions algorithm is one of the least transparent of all, so it would be difficult to establish in any way that delisting a phone number would make an impact.""It's possible that Meta isn't really technically deleting your phone number and emails at all, said Boiten.""The way Facebook has organically grown, it's probably true that the way they store information on people is on all sorts of disparate siloes,"" he said.""It may well be that they only implement something like this on the outside — so at a point the phone number threatens to go outside the system, it says, 'This phone number is one we've been told we can't use,' rather than really removing information.""Although both Burns and Boiten welcomed Meta taking tentative pro-privacy steps, Burns described it as ""a classic American approach"" that involves scooping up data without asking, versus the more permission-based approach favored by European privacy regulators.""To me, the Facebook tool is privacy labor,"" she added. ""They collected data they should not have collected in the first place, and are now shifting responsibility on you to remove it.""",0.0,0.0
259,https://techcrunch.com/2018/06/25/darpa-ground-x-wheel-design/,DARPA design shifts round wheels to triangular tracks in a moving vehicle,"As part of its Ground X-Vehicle Technologies program, DARPA is showcasing some new defense vehicle tech that’s as futuristic as it is practical. One of the innovations, a reconfigurable wheel-track, comes out of Carnegie Mellon University’s National Robotics Engineering Center in partnership with DARPA. The wheel-track is just one of a handful of designs meant to improve survivability of combat vehicles beyond just up-armoring them.As you can see in the video, the reconfigurable wheel-track demonstrates a seamless transition between a round wheel shape and a triangular track in about two seconds, and the shift between its two modes can be executed while the vehicle is in motion without cutting speed. Round wheels are optimal for hard terrain while track-style treads allow an armored vehicle to move freely on softer ground.According to Ground X-Vehicle Program Manager Major Amber Walker, the tech offers “instant improvements to tactical mobility and maneuverability on diverse terrains” — an advantage you can see on display in the GIF below.While wheel technology doesn’t sound that exciting, the result is visually impressive and smooth enough to prompt a double-take.The other designs featured in the video are noteworthy as well, with one offering a windowless navigation technology called Virtual Perspectives Augmenting Natural Experiences (V-PANE) that integrates video from an array of mounted LIDAR and video cameras to recreate a real-time model of a windowless vehicle’s surroundings. Another windowless cockpit design creates “virtual windows” for a driver, with 3D goggles for depth enhancement, head-tracking and wraparound window display screens displaying data outside the all-terrain vehicle in real time.",0.0,0.0
328,https://www.businessinsider.com/alphabet-google-thousands-of-workers-added-cut-costs-hiring-freeze-2022-10,Alphabet is ramping up scrutiny of all its projects and cutting hiring in half as it tries to curb costs,"Alphabet is attempting to tighten its belt after going on a hiring spree.CEO Sundar Pichai said the company would review all projects ""pretty granularly"" and make ""course corrections.""Alphabet is facing slowing growth as advertisers pull back spending, and the company has reportedly cut some employee perks.Sign up for our newsletter for the latest tech news and scoops — delivered daily to your inbox. Loading Something is loading. Thanks for signing up! Access your favorite topics in a personalized feed while you're on the go. download the app Email address By clicking ‘Sign up’, you agree to receive marketing emails from Insider as well as other partner offers and accept our Terms of Service and Privacy PolicyAlphabet is attempting to tighten its belt after going on a hiring spree.In the last 12 months alone, the company added nearly 37,000 new workers. Now, Google's parent company faces slowing growth amid a decelerating economy and a pullback in advertising spending.""We're constantly working to make sure everyone we've brought in is working on the most important things as a company... that's a lot of what sharpening our focus has been about,"" CEO Sundar Pichai told investors and reporters on a call on Tuesday.""We are reviewing projects at all scales pretty granularly to make sure we have the right plans there, and, based on that, the right resourcing, and making course corrections. This will be an ongoing thing,"" he added.Alphabet has attempted to cut employee expenses amid a slowdown - the company reported disappointing financial results for the third quarter on Tuesday. Alphabet has said it will reduce the pace of hiring, and it has reportedly cut back on perks like employee travel and team offsites.Pichai's grievances with his company's expanded headcount have been well-documented. Earlier this year, Pichai reportedly told employees at an all-hands meeting that there are ""real concerns that our productivity as a whole is not where it needs to be for the headcount we have.""However, the number of employees at Alphabet may not be the only thing weighing on the company's bottom line. Since the start of this year, Alphabet has reported nearly $4.5 billion in losses from ""Other Bets,"" which the company calls its division that manages smaller early-stage projects.",0.0,0.0
451,https://techcrunch.com/2022/08/10/5-takeaways-from-coinbases-disappointing-q2-results/,5 takeaways from Coinbaseâs disappointing Q2 results,"Shares of U.S. crypto exchange Coinbase teetered this morning after its second-quarter results missed both top- and bottom-line expectations, off more than 5% in pre-market trading then jumping as much as 7% after markets opened.The company, once hugely profitable in the wake of its 2021 direct listing thanks to a run in crypto-related trading activities, is now working to limit costs and brave the ongoing “winter” in its market and stick to prior profitability targets for the full year.The Coinbase report — read TechCrunch’s initial look here — is replete with fascinating data, making it difficult to detail in just one column. To wrap our minds around what Coinbase reported yesterday and what its notes on the future mean for the crypto startup economy in the back half of 2022, we’re digging deeper today.What follows are five takeaways from Coinbase’s report that stood out to us. Of course, let us know if you think we missed something critical. To work!",0.0,0.0
553,https://techcrunch.com/2022/10/10/fears-of-climate-tech-underinvestment-are-probably-overblown/,Fears of climate tech underinvestment are probably overblown,"There’s been a lot of hand-wringing over whether the world will get its act together enough to prevent catastrophic warming. There’s certainly a case to be made there — we’ve spent the last several decades kicking the can down the road at every opportunity.Well, here we are again, with the can again before us and the end of the road fast approaching.Lucky for me, I tend to be an optimist. I still think we’re in for a world of pain, and we’ll probably have to rely on some exotic technologies like fusion power and direct air capture to pull ourselves back from the brink. But in my opinion, when the chips are down, humanity tends to pull through.If we use computing and software as a guide, we should expect to see a nearly fivefold increase in the capital committed in the next 30 years.That is why I think many of the gloom-and-doom scenarios regarding climate tech investments tend to be overly bearish. Take the International Energy Agency’s (IEA) forecasts, which for years habitually underestimated the growth of solar power. The agency has since added better models to its toolkit, but it and others still make predictions that go on to be proven overly pessimistic.In reality, renewable energy and other climate tech is likely to follow an adoption curve that’s similar to other industries. It might even follow an accelerated version given how broad and deep the impacts and benefits of climate tech are likely to be — and the very real prospect of Armageddon if we do nothing.To see how climate tech stands to outperform today’s forecasts, you only have to look as far back as 1970, when the computing revolution was beginning.Exponential trendsThe overarching trend of investment in the computing and telecommunications space over 50 years has been exponential. But that simplistic analysis papers over the significant growth that happened in the early years. It also fails to pick up on key technological advances that sparked wider adoption.",0.0,0.0
509,https://www.fau.eu/2022/10/04/news/research/pain-relief-without-side-effects-and-addiction/,Pain relief without side effects and addiction,"Doctoral candidate and co-lead author Philipp Seemann was one of the FAU researchers who have discovered substances that provide very effective pain relief, but without the addictive and sedative effects of drugs currently available. (Image: FAU/Stefan Löber)Better than opiates: Researchers at FAU use adrenaline receptors for highly-effective analgesicsNew substances that activate adrenalin receptors instead of opioid receptors have a similar pain relieving effect to opiates, but without the negative aspects such as respiratory depression and addiction. This is the result of research carried out by an international team of researchers led by the Chair of Pharmaceutical Chemistry at FAU. Their findings, which have now been published in the renowned scientific journal Science, are a milestone in the development of non-opioid pain relief.Opiates cause addiction, new substances do notThey are a blessing for patients suffering from severe pain, but they also have serious side effects: Opioids, and above all morphine, can cause nausea, dizziness and constipation and can also often cause slowed breathing that can even result in respiratory failure. In addition, opiates are addictive – a high percentage of the drug problem in the USA is caused by pain medication, for example.In order to tackle the unwanted medical and social effects of opioids, researchers all over the world are searching for alternative analgesics. Prof. Dr. Peter Gmeiner, Chair of Pharmaceutical Chemistry is one of these researchers. “We are focusing particularly on the molecular structures of the receptors that dock onto the pharmaceutical substances”, says Gmeiner. “It is only when we understand these on the atomic level that we can develop effective and safe active substances.” Collaborating with an international team of researchers, Prof. Gmeiner discovered an active substance in 2016 that bonds to known opioid receptors and that offers the same level of pain relief as morphine, even though it has no chemical similarity to opiates.New approach: Adrenaline receptors instead of opioid receptorsPeter Gmeiner is currently following a lead that seems very promising: “Many non-opioid receptors are involved in pain processing, but only a small number of these alternatives have as yet been validated for use in therapies”, he explains. Gmeiner and a team of researchers from Erlangen, China, Canada and the USA have now turned their attention to a new receptor that is responsible for binding adrenaline – the alpha 2A adrenergic receptor. There are already some analgesics that target this receptor such as brimonidine, clonidine and dexmedetomidine. Gmeiner: “Dexmedetomidine relieves pain, but has a strong sedative effect, which means its use is restricted to intensive care in hospital settings and is not suitable for broader patient groups.”The aim of the research consortium is to find a chemical compound that activates the receptor in the central nervous system without a sedative effect. In a virtual library of more than 300 million different and easily accessible molecules, the researchers looked for compounds that physically match the receptor but are not chemically related to known medication. After a series of complex virtual docking simulations, around 50 molecules were selected for synthesis and testing and two of these fulfilled the desired criteria. They had good bonding characteristics, activated only certain protein sub-types and thus a very selective set of cellular signal pathways, whereas dexmedetomidine responds to a significantly wider range of proteins.Pain relief without sedation in animal modelsBy further optimizing the identified molecules, for which extremely high-resolution cryo-electron microscopic imaging was used, the researchers were able to synthesize agonists that produced high concentrations in the brain and reduced the sensation of pain effectively in investigations with animal models. “Various tests confirmed that docking on the receptor was responsible for the analgesic effect,” explains Gmeiner. “We are particularly pleased about the fact that none of the new compounds caused sedation, even at considerably higher doses than those that would be required for pain relief.”The successful separation of analgesic properties and sedation is a milestone in the development of non-opioid pain medication, especially as the newly-identified agonists are comparatively easy to manufacture and administer orally to patients. However, Prof. Gmeiner has to dampen any hopes of rapid widespread use in human medicine: “We are currently still talking about basic research. The development of medication is subject to strict controls and in addition to significant amounts of funding, it takes a long time. However, these results still make us very optimistic.”Publication: https://doi.org/10.1126/science.abn7065Further information:Chair of Pharmaceutical ChemistryPhone: +49 9131 85 65547peter.gmeiner@fau.de",0.0,0.0
551,https://www.engadget.com/nasa-fixed-glitch-voyager-1-120545004.html,NASA fixed the glitch that caused Voyager 1 to send back jumbled data,"Back in May, NASA reported that the Voyager 1 space probe was sending back jumbled or inaccurate telemetry data. The probe itself seemed to be in good shape, with a signal that's still strong enough to beam back information, and nothing was triggering its fault protection systems that would put it in ""safe mode."" According to NASA, the Voyager team has not only figured the problem out since then — it has also solved the issue.Turns out we're getting jumbled data here on Earth, because the probe's attitude articulation and control system (AACS) has been sending back information through an onboard computer that had stopped working years ago. The computer was corrupting the data before it even went out. Voyager project manager Suzanne Dodd said that when her team suspected that this was the issue, they implemented a low-risk fix: They commanded the AACS to send its data through the probe's working computer again.While the engineers have fixed the glitch, they've yet to figure out why the AACS started routing information through the old computer in the first place. They believe it was triggered by a faulty command by another onboard computer, which was itself triggered by an underlying issue with the spacecraft. Voyager's engineers will keep looking for the problem's root case, NASA said, but they don't think it will have a huge effect on the spacecraft's operations.Turn on browser notifications to receive breaking news alerts from Engadget You can disable notifications at any time in your settings menu. Not now Turned on Turn onVoyager 1 has been operational for almost 45 years and had reached interstellar space in 2012. NASA expects it to continue being able to run at least one science instrument until 2025, after which it will keep drifting away from our solar system until it loses contact with NASA's Deep Space Network.",0.0,0.0
412,https://ph.ucla.edu/news/press-release/2022/oct/ucla-fielding-school-public-health-led-research-demonstrates-importance,UCLA Fielding School of Public Health-led research demonstrates the importance of influenza vaccination globally,"An international team of researchers has demonstrated that among patients hospitalized for influenza, those who were vaccinated had less severe infections, including reducing the odds for children requiring admittance to an intensive care unit by almost half.In addition, the researchers found that deaths among hospitalized adults, 65 or older, who had been vaccinated were 38% lower compared to those who had not been vaccinated.“A common complaint about influenza vaccine is that they are typically 40-60% effective against infection - or the ‘what’s the point?’ complaint. So it is important to note that although everyone in this study was hospitalized, vaccinated individuals were less likely to be severely ill or die, suggesting that you are likely to have far less severe consequences if vaccinated,” said Dr. Annette Regan, UCLA Fielding School of Public Health assistant professor of epidemiology and lead author of the peer-reviewed research, published in the October edition of The Lancet Infectious Diseases. “This is an important point, especially in light of the upcoming influenza season coupled with ongoing COVID-19 activity, both this season and into the future.”Globally, influenza contributes to 9.5 million hospitalizations, 81.5 million hospital days, and 145,000 deaths each year. Vaccination offers the best method of preventing influenza illness, reducing illness in the general population by 40–60%, experts say.Specifically, The Lancet analysis found that three groups routinely targeted for influenza vaccination experiences less severe illness. Children who had received only part of their first series of influenza vaccines had 36% lower chances of being admitted to an intensive care unit (ICU), and children who had fully completed their first series of influenza vaccines had 48% lower chances of admission to ICU compared to unvaccinated children, the researchers found.The study – “Severity of influenza illness associated with seasonal influenza vaccination among hospitalized patients in four South American countries” – is the product of an international team of researchers from the United States, Argentina, Brazil, Chile, and Paraguay, and drew on data from all four South American countries over a period of seven years. Data were obtained through the Network for the Evaluation of Vaccine Effectiveness in Latin America and the Caribbean, influenza (REVELAC-i) which is coordinated by the Pan American Health Organization (PAHO).“Although several studies have reported drops in influenza illness following influenza vaccination, the results have focused predominantly on adults in the United States, and this study aimed to evaluate the severity of influenza illness by vaccination status in a broad range of age groups, and across multiple South American countries,” said Dr. Marta Von Horoch, a co-author who serves as coordinator of the National Immunization Program in Paraguay. “We were very pleased to work with our partners in the U.S. and across the continent, and these findings demonstrate, quite clearly, the importance of influenza vaccination for children and adults, no matter where they live.”The study – the first-ever on this scale in South America - examined influenza-related hospitalization rates and outcomes across all four countries from 2013-19. Specifically, the analysts reviewed the outcomes for some 2,747 patients hospitalized with confirmed influenza virus infection, in three age groups – children aged 6–24 months, adults aged 18–64 years, and adults aged 65 years or older.Given the reality that vaccination rates have fallen, in the U.S. and globally during the COVID-19 pandemic, including among children, the findings should help make clear the benefits of timely, pro-active immunization campaigns to the public, the researchers said.“With influenza season approaching this winter and influenza vaccines now available, these results highlight the importance of getting vaccinated for flu for anyone six months of age or older – as CDC recommends,” Regan said. “It is critical that healthcare providers and the public understand the risks of missing out on vaccinations – it is so much better to prevent a serious illness than to suffer through it, for the patient and everyone in their community.”===================================================",0.0,0.0
413,https://www.hsph.harvard.edu/news/press-releases/political-ideology-of-u-s-elected-officials-linked-with-covid-19-health-outcomes/,Political ideology of U.S. elected officials linked with COVID-19 health outcomes,"For immediate release: Tuesday, November 1, 2022Boston, MA – The higher the exposure to political conservatism, the higher the COVID-19 mortality rates and stress on hospital intensive care unit (ICU) capacity, according to a new study from Harvard T.H. Chan School of Public Health.“Before our study, research on how political ideology affects COVID-19 looked solely at voters’ political lean; we expanded on that research to investigate associations of COVID-19 outcomes with the voting records of federal elected representatives and the concentration of political party power at the state level. The point is not partisan analysis, but rather to understand how politics, and political polarization, are affecting population health,” said Nancy Krieger, professor of social epidemiology at Harvard T.H. Chan School of Public Health and corresponding author of the study.The study was published online in the Lancet Regional Health – Americas on November 1, 2022.Little prior research had looked at COVID-19 health outcomes in relation to U.S. congressional districts. The researchers analyzed data on COVID-19 mortality rates and stress on ICU capacity from April 2021 to March 2022, a period when adult vaccines were available, across all 435 U.S. Congressional districts. They examined three exposure variables that had not been used previously in COVID-19 research: the political ideology of U.S. elected members of Congress, as measured by their overall voting records; their votes on four key COVID-19 relief bills; and “state trifectas,” the concentration of political power at the State level, defined as the governor, House, and Senate, all under the control of one party.The study found that the higher the exposure to conservatism on each political metric, the higher the COVID-19 age-standardized mortality rates, even after adjusting for the district’s social characteristics, voters’ political lean, and vaccination rates. The same relationship held true for stress on hospital ICU capacity.For COVID-19 mortality rates, for example, models controlling for political and social metrics and vaccination rates showed that Republican trifectas were, respectively, 11% higher and conservative voter political lean 26% higher.“Our study offers new approaches to analyzing political determinants of COVID-19 metrics—such as mortality, illness, or vaccination rates—as one component of analyzing political accountability for populations’ COVID-19 burdens. It also points to the importance of analyzing political metrics in relation to population health outcomes more generally,” said Krieger.There was no funding for the study from any agency in the public, commercial, or not-for-profit sector.“Relationship of political ideology of US federal and state elected officials and key COVID pandemic outcomes following vaccine rollout to adults: April 2021-March 2022,” Nancy Krieger, Christian Testa, Jarvis T. Chen, William P. Hanage, Alecia J. McGregor, Lancet Regional Health – Americas, online November 1, 2022, doi: 10.1016/j.lana.2022.100384Visit the Harvard Chan School website for the latest news, press releases, and multimedia offerings.For more information:Todd Datztdatz@hsph.harvard.edu617.432.8413###Harvard T.H. Chan School of Public Health brings together dedicated experts from many disciplines to educate new generations of global health leaders and produce powerful ideas that improve the lives and health of people everywhere. As a community of leading scientists, educators, and students, we work together to take innovative ideas from the laboratory to people’s lives—not only making scientific breakthroughs, but also working to change individual behaviors, public policies, and health care practices. Each year, more than 400 faculty members at Harvard Chan School teach 1,000-plus full-time students from around the world and train thousands more through online and executive education courses. Founded in 1913 as the Harvard-MIT School of Health Officers, the School is recognized as America’s oldest professional training program in public health.",0.0,0.0
417,https://www.psypost.org/2022/10/dark-personalities-perceive-pro-environmental-behaviors-as-more-costly-and-less-beneficial-64078,Dark personalities perceive pro-environmental behaviors as more costly and less beneficial,"People with “dark” personality traits tend to behave in less environmentally friendly ways in everyday life, and view pro-environmental behaviors as imposing a greater burden, according to new research published in Frontiers in Psychology. The findings provide evidence that personality traits influence how people perceive the costs and benefits associated with pro-environmental behaviors.“In view of the looming climate crisis, I personally keep asking myself why people (despite better knowledge) do not behave in a more environmentally friendly way,” said study author Jana Sophie Kesenheimer, a postdoctoral researcher at the Leopold-Franzens-University of Innsbruck. “There are psychological theories (e.g. the ‘Campbell paradigm’) that take into account the cost and benefit ratios of environmentally conscious decision-making. Our aim for the study was to bring these situational costs and benefits into connection with personality and attitude.”Kesenheimer and her colleagues were particularly interested in the so-called “light triad” and “dark tetrad” of personality.The light triad is a group of three personality traits that are associated with positive characteristics such as honesty, empathy, and trustworthiness. The three traits are Kantianism, faith in humanity, and humanism. People high in these traits agree with statements such as “I prefer honesty over charm” (Kantianism), “I tend to see the best in people” (faith in humanity), and “I tend to treat others as valuable” (humanism).The dark tetrad is a group of four personality traits that are associated with harmful behaviors. The four traits are sadism, narcissism, Machiavellianism, and subclinical psychopathy. People high in these traits agree with statements such as “I hurt others for my own pleasure” (sadism), “People see me as a natural leader” (narcissism), “I love it when a tricky plan succeeds” (Machiavellianism), and “People who mess with me always regret it” (psychopathy).The initial study included 176 participants who ranged in age from 18 to 68 years. The participants completed scientific assessments of light and dark personality traits, along with a measure of pro-environmental attitudes. After completing this initial survey, the participants received a notification on their smartphones three times a day for seven consecutive days that asked them if they had “acted pro-environmentally at least once in the past 4 hours.” The participants were further asked to rate the costs and benefits associated with these behaviors.The most commonly reported pro-environmental behaviors were related to food intake, such as eating vegetarian or locally grown food. The second most commonly reported pro-environmental behaviors were related to energy and water conservation, such as dressing warmer rather than turning up the heat.People with more pro-environmental attitudes and people with stronger light personality traits tended to engage in pro-environmental behaviors more frequently. Those with stronger dark personality traits, in contrast, tended to engage in pro-environmental behaviors less frequently. Similarly, people with more pro-environmental attitudes and people with stronger light personality traits tended to view the behaviors as having greater benefits, while those with stronger dark personality traits viewed the behaviors as having less benefits.People with stronger dark personality traits, however, reported engaging in more costly behaviors, while the opposite was true among those with stronger light personality traits.But are people with dark personality traits really engaging in more costly pro-environmental action compared to those with light personality traits? The researchers were skeptical. They proposed that the observed effect was the result of differences in the perception of what is “costly.”“We originally wanted to show that personality and attitude are more influential in high-cost/low-benefit situations, but are less predictive in high-benefit/low-cost situations (because most people should be pro-environmental in the latter case),” Kesenheimer explained. “Surprisingly, it turned out that the assessment of the costs and benefits depends very much on personality and attitude. So much so that we had to get a second opinion from an independent person (in Study 2) to assess the actions of the people in the first survey.”In the second study, a sample of 159 individuals viewed and rated the pro-environmental behaviors reported by participants in the first study. The findings confirmed the researchers’ suspicions.“Above all, we were able to show that, depending on the personality and attitude of a person, there can be a very subjective perception of the costs and benefits of a situation,” Kesenheimer told PsyPost.“For example, a rather ‘dark’ personality described a great deal of effort involved in using a lid for cooking (he first had to dig the lid out of the drawer). Other people described the same situation on average as being less costly. If you ask a ‘light’ personality or a very environmentally conscious person for their assessment, he or she would probably see much lower costs and high benefits in the same behavior than the ‘dark’ person.”“We were therefore able to show that the costs and benefits of an environmentally-conscious decision-making situation are anything but clear, but depend heavily on a person’s personality and attitude: some might always see a benefit in any environmental behavior, others just generally see high costs involved.” the researcher explained.The study, “Going Green Is Exhausting for Dark Personalities but Beneficial for the Light Ones: An Experience Sampling Study That Examines the Subjectivity of Pro-environmental Behavior“, was authored by Jana Sophie Kesenheimer and Tobias Greitemeyer.",0.0,0.0
439,https://www.nih.gov/news-events/news-releases/video-gaming-may-be-associated-better-cognitive-performance-children,Video gaming may be associated with better cognitive performance in children,"Video gaming may be associated with better cognitive performance in childrenAdditional research necessary to parse potential benefits and harms of video games on the developing brain.A study of nearly 2,000 children found that those who reported playing video games for three hours per day or more performed better on cognitive skills tests involving impulse control and working memory compared to children who had never played video games. Published today in JAMA Network Open, this study analyzed data from the ongoing Adolescent Brain Cognitive Development (ABCD) Study, which is supported by the National Institute on Drug Abuse (NIDA) and other entities of the National Institutes of Health.“This study adds to our growing understanding of the associations between playing video games and brain development,” said NIDA Director Nora Volkow, M.D. “Numerous studies have linked video gaming to behavior and mental health problems. This study suggests that there may also be cognitive benefits associated with this popular pastime, which are worthy of further investigation.”Although a number of studies have investigated the relationship between video gaming and cognitive behavior, the neurobiological mechanisms underlying the associations are not well understood. Only a handful of neuroimaging studies have addressed this topic, and the sample sizes for those studies have been small, with fewer than 80 participants.To address this research gap, scientists at the University of Vermont, Burlington, analyzed data obtained when children entered the ABCD Study at ages 9 and 10 years old. The research team examined survey, cognitive, and brain imaging data from nearly 2,000 participants from within the bigger study cohort. They separated these children into two groups, those who reported playing no video games at all and those who reported playing video games for three hours per day or more. This threshold was selected as it exceeds the American Academy of Pediatrics screen time guidelines, which recommend that videogaming time be limited to one to two hours per day for older children. For each group, the investigators evaluated the children’s performance on two tasks that reflected their ability to control impulsive behavior and to memorize information, as well as the children’s brain activity while performing the tasks.The researchers found that the children who reported playing video games for three or more hours per day were faster and more accurate on both cognitive tasks than those who never played. They also observed that the differences in cognitive function observed between the two groups was accompanied by differences in brain activity. Functional MRI brain imaging analyses found that children who played video games for three or more hours per day showed higher brain activity in regions of the brain associated with attention and memory than did those who never played. At the same time, those children who played at least three hours of videogames per day showed more brain activity in frontal brain regions that are associated with more cognitively demanding tasks and less brain activity in brain regions related to vision.The researchers think these patterns may stem from practicing tasks related to impulse control and memory while playing videogames, which can be cognitively demanding, and that these changes may lead to improved performance on related tasks. Furthermore, the comparatively low activity in visual areas among children who reported playing video games may reflect that this area of the brain may become more efficient at visual processing as a result of repeated practice through video games.While prior studies have reported associations between video gaming and increases in depression, violence, and aggressive behavior, this study did not find that to be the case. Though children who reported playing video games for three or more hours per day did tend to report higher mental health and behavioral issues compared to children who played no video games, the researchers found that this association was not statistically significant, meaning that the authors could not rule out whether this trend reflected a true association or chance. They note that this will be an important measure to continue to track and understand as the children mature.Further, the researchers stress that this cross-sectional study does not allow for cause-and-effect analyses, and that it could be that children who are good at these types of cognitive tasks may choose to play video games. The authors also emphasize that their findings do not mean that children should spend unlimited time on their computers, mobile phones, or TVs, and that the outcomes likely depend largely on the specific activities children engage in. For instance, they hypothesize that the specific genre of video games, such as action-adventure, puzzle solving, sports, or shooting games, may have different effects for neurocognitive development, and this level of specificity on the type of video game played was not assessed by the study.“While we cannot say whether playing video games regularly caused superior neurocognitive performance, it is an encouraging finding, and one that we must continue to investigate in these children as they transition into adolescence and young adulthood,” said Bader Chaarani, Ph.D., assistant professor of psychiatry at the University of Vermont and the lead author on the study. “Many parents today are concerned about the effects of video games on their children’s health and development, and as these games continue to proliferate among young people, it is crucial that we better understand both the positive and negative impact that such games may have.”Through the ABCD Study, researchers will be able to conduct similar analyses for the same children over time into early adulthood, to see if changes in video gaming behavior are linked to changes in cognitive skills, brain activity, behavior, and mental health. The longitudinal study design and comprehensive data set will also enable them to better account for various other factors in the children’s families and environment that may influence their cognitive and behavioral development, such as exercise, sleep quality, and other influences.The ABCD Study, the largest of its kind in the United States, is tracking nearly 12,000 youth as they grow into young adults. Investigators regularly measure participants’ brain structure and activity using magnetic resonance imaging (MRI) and collect psychological, environmental, and cognitive information, as well as biological samples. The goal of the study is to understand the factors that influence brain, cognitive, and social-emotional development, to inform the development of interventions to enhance a young person’s life trajectory.The Adolescent Brain Cognitive Development Study and ABCD Study are registered service marks and trademarks, respectively, of the U.S. Department of Health and Human ServicesAbout the National Institute on Drug Abuse (NIDA): NIDA is a component of the National Institutes of Health, U.S. Department of Health and Human Services. NIDA supports most of the world’s research on the health aspects of drug use and addiction. The Institute carries out a large variety of programs to inform policy, improve practice, and advance addiction science. For more information about NIDA and its programs, visit www.nida.nih.gov.About the National Institutes of Health (NIH): NIH, the nation's medical research agency, includes 27 Institutes and Centers and is a component of the U.S. Department of Health and Human Services. NIH is the primary federal agency conducting and supporting basic, clinical, and translational medical research, and is investigating the causes, treatments, and cures for both common and rare diseases. For more information about NIH and its programs, visit www.nih.gov.NIH…Turning Discovery Into Health®",0.0,0.0
387,https://www.eurekalert.org/news-releases/967916,New Omicron subvariant largely evades neutralizing antibodies,"A study at Karolinska Institutet in Sweden shows that the coronavirus variant BA.2.75.2, an Omicron sublineage, largely evades neutralizing antibodies in the blood and is resistant to several monoclonal antibody antiviral treatments. The findings, published in the journal The Lancet Infectious Diseases, suggest a risk of increased SARS-CoV-2 infections this winter, unless the new updated bivalent vaccines help to boost immunity in the population.“While antibody immunity is not completely gone, BA.2.75.2 exhibited far more dramatic resistance than variants we’ve previously studied, largely driven by two mutations in the receptor binding domain of the spike protein,” says the study’s corresponding author Ben Murrell, assistant professor at the Department of Microbiology, Tumor and Cell Biology, Karolinska Institutet.The study shows that antibodies in random serum samples from 75 blood donors in Stockholm were approximately only one-sixth as effective at neutralizing BA.2.75.2 compared with the now-dominant variant BA.5. The serum samples were collected at three time points: In November last year before the emergence of Omicron, in April after a large wave of infections in the country, and at the end of August to early September after the BA.5 variant became dominant.Only one of the clinically available monoclonal antibody treatments that were tested, bebtelovimab, was able to potently neutralize the new variant, according to the study. Monoclonal antibodies are used as antiviral treatments for people at high risk of developing severe COVID-19.BA.2.75.2 is a mutated version of another Omicron variant, BA.2.75. Since it was first discovered earlier this fall, it has spread to several countries but so far represents only a minority of registered cases.“We now know that this is just one of a constellation of emerging variants with similar mutations that will likely come to dominate in the near future,” Ben Murrell says, adding “we should expect infections to increase this winter.”Some questions remain. It is unclear whether these new variants will drive an increase in hospitalization rates. Also, while current vaccines have, in general, had a protective effect against severe disease for Omicron infections, there is not yet data showing the degree to which the updated COVID vaccines provide protection from these new variants. “We expect them to be beneficial, but we don’t yet know by how much,” Ben Murrell says.The study was conducted in collaboration with researchers at ETH Zürich in Switzerland and Imperial College London in the U.K.Funding was provided by SciLifeLab, the Erling-Persson Foundation, the European Union’s Horizon 2020 research and innovation programme. Daniel J. Sheward, Gunilla B. Karlsson Hedestam and Ben Murrell have intellectual property rights associated with antibodies that neutralize Omicron variants.Publication: “Omicron sublineage BA.2.75.2 exhibits extensive escape from neutralising antibodies.” Daniel J. Sheward, Changil Kim, Julian Fischbach, Kenta Sato, Sandra Muschiol, Roy A. Ehling, Niklas K. Björkström, Gunilla B. Karlsson Hedestam, Sai T. Reddy, Jan Albert, Thomas P. Peacock, Ben Murrell, The Lancet Infectious Diseases, correspondence, online Oct. 13, 2022, doi: 10.1016/S1473-3099(22)00663-6",0.0,0.0
385,https://interestingengineering.com/health/moderna-merck-personalized-skin-cancer-vaccine,Moderna teams up with Merck for personalized vaccine against skin cancer,"Now, Merck has exercised its option by agreeing to pay a sum of $250 million to Moderna, which will pave the way for further development and commercialization of the vaccine, a Merck press release said.How will the vaccine work?Cancerous cells can have mutations — changes in their DNA sequence that make conventional treatment ineffective. By using a personalized cancer vaccine, the patient's immune system can be prepared to generate a mutation-specific anti-tumor response.Moderna's mRNA-4517/V940 is designed to generate Tcell responses based on the mutational signature of the tumor in the patient. T cells are a type of white blood cell that are tasked with defending the body in the event of an infection.Merck's KEYTRUDA is an anti-programmed death receptor-1 (PD-1) therapy that targets the PD-1 protein that cells can use to evade detection by T cells. Since both healthy as well as cancerous cells use this mechanism to evade T cell attack, using KEYTRUDA even puts healthy cells in the firing line.In combination with Moderna's vaccine, the treatment can aim to specifically target tumor cells.KEYNOTE-942 trialMerck's KEYTRUDA is currently being used in over 1,600 trials across a wide range of cancers. Through these trials, Merck is trying to understand the various factors that might affect the effectiveness of the treatment in patients.KEYNOTE 942 is one such trial studying the effectiveness of KEYTRUDA in high-risk melanoma patients. Currently, in Phase 2, the trial has enrolled 157 patients who have been randomized into two groups following the surgical removal of their tumors.",0.0,0.0
356,https://www.thedailybeast.com/scientists-found-a-way-to-predict-your-death-by-how-you-walk?via=mobile&source=Reddit,Scientists Found a Way to Predict Your Death by How You Walk,"We’re all going to die eventually—but what if you knew when you’d be at risk for dropping dead, based solely on the way you walk? A new study shows that measurements taken with wrist-worn motion sensors can be used to predict one’s mortality risk up to five years later. As one of the largest validations of wearable technology to date, the research raises the possibility of one day using the motion detection system in smartphones to survey patient health without the need for in-person visits to the doctor’s office.The study, published Thursday in the journal PLOS Digital Health, was run using data from over 100,000 Britons from the massive UK Biobank project, which began collecting health and biometric information from participants in 2006 and will follow them for another 14 years. From a week of wrist sensor data, researchers at the University of Illinois at Urbana-Champaign designed a model that pares down a person’s acceleration and the distance they traveled into six-minute chunks. According to study author Bruce Schatz, a University of Illinois computer science researcher, the scientists chose this duration to mimic the six-minute walk test: a measurement of heart and lung function commonly taken during a medical appointment that tasks participants with walking at a normal pace for six minutes and compares their total distance traveled to benchmarks according to their age.The test is “a very good external measure of what's going on internally,” and could easily be replicated using the accelerometer present in a wrist sensor or a cheap phone, Schatz told The Daily Beast. “I know for a fact that these kinds of models will work with cheap phones.”Predictions of future death made by the researchers’ model were correct 76 percent of the time after one year, and 73 percent after five years—a similar rate of accuracy found in a study published last year that analyzed the same data set but used hours, rather than minutes, of data. This new study, argued Schatz, is a more promising demonstration of passive monitoring technology like phone and wrist sensors as his team’s model requires less data and affords a great degree of privacy to the user.“If you record all of the data, it's true that people have characteristic walks and you can tell who the individual is. But it's totally possible to take part of the signal, which is good enough to do the vitals but completely disguises who the person is,” he said.“ I know for a fact that these kinds of models will work with cheap phones. ” — Bruce Schatz, University of IllinoisEven so, using everyday technology to passively monitor patients could raise issues if users cannot give continuous informed consent, situations which could be complicated by degenerative illnesses or a lack of technological literacy. These ethical issues, said Schatz, are still speculative, but deserve coordinated thought from scientists as the research moves forward.While the sensors used in the study were near-identical to the ones in both simple cell phones and smartphones, future work should validate this model in a large sample when users carry phones in their pockets, rather than wear sensors on their wrists. Downloading an app that can measure your health as you go about your day-to-day could be a convenient and painless way to keep people healthier, longer.“If you want to raise the general health of the entire population, this kind of project is really important,” Schatz said.",0.0,0.0
453,https://techcrunch.com/2022/06/09/shield-ai-raises-165m-at-a-2-3b-valuation-to-fuel-development-of-its-military-autonomous-flying-systems/,Shield AI raises $165M at a $2.3B valuation to fuel development of its military autonomous flying systems,"Technology built with defense in mind is getting some significant and serious traction at the moment, spurred by world events, advances in technology and a growing appetite from end users to invest in more innovative ways to protect themselves. In the latest development,Technology built with defense in mind is getting some significant and serious traction at the moment, spurred by world events, advances in technology and a growing appetite from end users to invest in more innovative ways to protect themselves. In the latest development,The funding is coming in at a $2.3 billion valuation, Shield AI said. The company has been on a strong pace on that front: It follows on from a $210 million-$300 millionThe funding is coming in at a $2.3 billion valuation, Shield AI said. The company has been on a strong pace on that front: It follows on from a $210 million-$300 millionDoug Philippone at Snowpoint Ventures led the round, with Riot Ventures, Disruptive (a returning backer; it led Shield AI’s Series D) and Homebrew (it led Shield AI’s seed round). The company’s other investors include Point72 Ventures, Andreessen Horowitz, Breyer Capital and SVB Capital.Doug Philippone at Snowpoint Ventures led the round, with Riot Ventures, Disruptive (a returning backer; it led Shield AI’s Series D) and Homebrew (it led Shield AI’s seed round). The company’s other investors include Point72 Ventures, Andreessen Horowitz, Breyer Capital and SVB Capital.Philippone is an interesting person to lead on this latest round: In addition to being an investor, he is also Palantir’s global defense lead, a job he’s been in for the last 14 years. This is important not least because Palantir arguably was one of the key companies to change the game for how startups, spurred by the tech boom out of Silicon Valley, both engaged and started to win defense contracts and raised huge sums from VCs to fuel that growth.Philippone is an interesting person to lead on this latest round: In addition to being an investor, he is also Palantir’s global defense lead, a job he’s been in for the last 14 years. This is important not least because Palantir arguably was one of the key companies to change the game for how startups, spurred by the tech boom out of Silicon Valley, both engaged and started to win defense contracts and raised huge sums from VCs to fuel that growth.Another influential startup changing the conversation around funding defense tech is Anduril,Another influential startup changing the conversation around funding defense tech is Anduril,Shield AI is based out of San Diego, which you could say is a little like the Silicon Valley of the defense industry. It’s the home port of the U.S. Pacific fleet, and according toShield AI is based out of San Diego, which you could say is a little like the Silicon Valley of the defense industry. It’s the home port of the U.S. Pacific fleet, and according toAnd if you don’t follow the defense industry, but have at least seen or heard ofAnd if you don’t follow the defense industry, but have at least seen or heard of“China’s military is Netflix; the U.S. military is Blockbuster. China is Amazon; the U.S. is Barnes & Noble. China is Tesla; the U.S. is General Motors,”“China’s military is Netflix; the U.S. military is Blockbuster. China is Amazon; the U.S. is Barnes & Noble. China is Tesla; the U.S. is General Motors,”And on the company’s home page, it describes Hivemind, its AI-based autonomous software platform, as what else? “A Top Gun for every aircraft.”And on the company’s home page, it describes Hivemind, its AI-based autonomous software platform, as what else? “A Top Gun for every aircraft.”As with a lot of other companies (maybe every company) in autonomous transportation, be it in the air or on the ground, Shield AI has a mix of software and hardware that is already usable, and then products that are still in development. Some will be used in purely autonomous systems and some in tandem with humans.As with a lot of other companies (maybe every company) in autonomous transportation, be it in the air or on the ground, Shield AI has a mix of software and hardware that is already usable, and then products that are still in development. Some will be used in purely autonomous systems and some in tandem with humans.In the case of Shield AI, the company says that Hivemind and its Nova drone (or small-unmanned aircraft system, sUAS, in more formal terminology) have been in use since 2018. Ryan Tseng tells us that the specifics of exactly where and how are classified, as are most of the company’s other activities, but they are part of the U.S. Department of Defense Program of Record.In the case of Shield AI, the company says that Hivemind and its Nova drone (or small-unmanned aircraft system, sUAS, in more formal terminology) have been in use since 2018. Ryan Tseng tells us that the specifics of exactly where and how are classified, as are most of the company’s other activities, but they are part of the U.S. Department of Defense Program of Record.It’s also working on a vertical take-off and landing (VTOL) aircraft called V-BAT that will be soon equipped with Hivemind. The software is being integrated into other aircraft, too, such as the F-16 fighter jet pictured above, where it will act as a co-pilot alongside a human, with the aim for it to be used also across F-22s, F-18s and other models. In the meantime, Tseng said in an interview that its V-BAT craft also have been operational since 2018 around the globe.It’s also working on a vertical take-off and landing (VTOL) aircraft called V-BAT that will be soon equipped with Hivemind. The software is being integrated into other aircraft, too, such as the F-16 fighter jet pictured above, where it will act as a co-pilot alongside a human, with the aim for it to be used also across F-22s, F-18s and other models. In the meantime, Tseng said in an interview that its V-BAT craft also have been operational since 2018 around the globe.“The DoD and international militaries are acquiring V-BAT at a rapid rate so we’re ramping production as quickly as possible,” he said — one reason for this funding. V-BAT beat out 13 competitors to win a major Navy Program of Record, he added. Its selling point is its ability to withstand challenging conditions. “The unique design and controls allow it to take off and land in high winds, on crowded flight decks, aboard moving vessels with landing zones as small as 12’ x 12’.”“The DoD and international militaries are acquiring V-BAT at a rapid rate so we’re ramping production as quickly as possible,” he said — one reason for this funding. V-BAT beat out 13 competitors to win a major Navy Program of Record, he added. Its selling point is its ability to withstand challenging conditions. “The unique design and controls allow it to take off and land in high winds, on crowded flight decks, aboard moving vessels with landing zones as small as 12’ x 12’.”The bigger strategy is to build a “swarming” capability for its devices — essentially to use a number of them in concert as a way of evading jamming technologies from adversaries. This, Tseng said, is on track for coming to market by the end of 2023 (although since a lot of what they do is classified, they may not actually make anything public until it’s already being used).The bigger strategy is to build a “swarming” capability for its devices — essentially to use a number of them in concert as a way of evading jamming technologies from adversaries. This, Tseng said, is on track for coming to market by the end of 2023 (although since a lot of what they do is classified, they may not actually make anything public until it’s already being used).Taking both Anduril’s recent landmark round and this latest round for Shield AI, we’re in a moment right now where VCs — working themselves in a challenging financial climate — have changed their tune when it comes to backing companies in the defense space, which includes not just companies like these building military technology, but also those working in cybersecurity and other kinds of technology that helps with resilience. This could include, interestingly, alternative energy tech and of course products that can be used by more than just governments but enterprises as well.Taking both Anduril’s recent landmark round and this latest round for Shield AI, we’re in a moment right now where VCs — working themselves in a challenging financial climate — have changed their tune when it comes to backing companies in the defense space, which includes not just companies like these building military technology, but also those working in cybersecurity and other kinds of technology that helps with resilience. This could include, interestingly, alternative energy tech and of course products that can be used by more than just governments but enterprises as well.“The fundraising climate has never been more favorable for defense technology companies,” Tseng told TechCrunch. “Supporting defense was taboo in many circles. We were rejected by many early investors because defense was considered too controversial. Today, there is growing recognition that investment in defense contributes to security, stability and peace, all of which are foundational to a flourishing society.”“The fundraising climate has never been more favorable for defense technology companies,” Tseng told TechCrunch. “Supporting defense was taboo in many circles. We were rejected by many early investors because defense was considered too controversial. Today, there is growing recognition that investment in defense contributes to security, stability and peace, all of which are foundational to a flourishing society.”As noted by others who are investing in this space right now, or building for it, there has indeed been a noticeable shift in how people view companies like Shield AI and what they are trying to develop. That is still a challenge, though, which might be one reason why a company like Shield goes through the work of putting out messaging to people who may never actually be customers to still take in what they are trying to do.As noted by others who are investing in this space right now, or building for it, there has indeed been a noticeable shift in how people view companies like Shield AI and what they are trying to develop. That is still a challenge, though, which might be one reason why a company like Shield goes through the work of putting out messaging to people who may never actually be customers to still take in what they are trying to do.“Many people don’t realize the scope of conflict in the world — before Ukraine, 84 million people were displaced by violence and persecution, up from 39 million in 2011,” Tseng said. “There aren’t that many opportunities to contribute to technologies that meaningfully address humanity’s great challenges — or that create the general conditions for human achievement. When you work on AI pilots for defense — you are working on the most important and disruptive defense technology of the next thirty years — and are empowering our country and allies to advance security, stability and peace.”“Many people don’t realize the scope of conflict in the world — before Ukraine, 84 million people were displaced by violence and persecution, up from 39 million in 2011,” Tseng said. “There aren’t that many opportunities to contribute to technologies that meaningfully address humanity’s great challenges — or that create the general conditions for human achievement. When you work on AI pilots for defense — you are working on the most important and disruptive defense technology of the next thirty years — and are empowering our country and allies to advance security, stability and peace.”That is bolstered also by the fact that adversaries are also hot on the heels building their own similar systems. China is aiming for military parity by 2027 in the Pacific, Tseng pointed out, meaning they aim to exceed the U.S. by 2028. And he added that there have been reports that it is already benchmarking their prototypes against Shield AI’s pilot.That is bolstered also by the fact that adversaries are also hot on the heels building their own similar systems. China is aiming for military parity by 2027 in the Pacific, Tseng pointed out, meaning they aim to exceed the U.S. by 2028. And he added that there have been reports that it is already benchmarking their prototypes against Shield AI’s pilot.Tseng also may be biased but has a very different idea of why autonomous matters more in this context. “Waymo engineers get to build minivans that plod through the suburbs at 25 mph, we get to work autonomous fighter jets that fly 1,000+ mph, dodge missiles and find threats,” he said.Tseng also may be biased but has a very different idea of why autonomous matters more in this context. “Waymo engineers get to build minivans that plod through the suburbs at 25 mph, we get to work autonomous fighter jets that fly 1,000+ mph, dodge missiles and find threats,” he said.All this is spelling not just an opportunity in the business sense, but a wider one, too, for those backing Shield AI.All this is spelling not just an opportunity in the business sense, but a wider one, too, for those backing Shield AI.“Investors are flocking to quality. This round is a reflection of Shield AI’s success in creating great products, building a business with strong fundamentals and dominant technological leadership — with an AI pilot proven to be the world’s best in numerous military evaluations,” said Philippone in a statement. “We love that they are leveraging an AI and software backbone across a variety of aircraft to deliver truly game-changing value to our warfighters. The work they are doing today is just the tip of the iceberg.”“Investors are flocking to quality. This round is a reflection of Shield AI’s success in creating great products, building a business with strong fundamentals and dominant technological leadership — with an AI pilot proven to be the world’s best in numerous military evaluations,” said Philippone in a statement. “We love that they are leveraging an AI and software backbone across a variety of aircraft to deliver truly game-changing value to our warfighters. The work they are doing today is just the tip of the iceberg.”",0.0,0.0
360,https://techcrunch.com/2022/08/10/mawi-patch/,Mawi launches a patch to track your heart health faster and in real time,"If you’ve ever had the misfortune of needing continuous EKG monitoring, you’ve probably used a Holter monitor. It’s like carrying a 1980s walkman made of metal with a bunch of wires going from it to your chest. If that sounds uncomfortable, and as if you won’t sleep or enjoy showers much for the two weeks you need to carry it around, you’ve neatly stumbled across the use case for the Mawi Heart Patch. The company just released its product, a two-lead cardiac monitor that can be read in real time.There are consumer-grade products that can do EKG readings, including the Withings ScanWatch (and its fancier-looking sibling, the ScanWatch Horizon), and there are other patches on the market, such as the Zio patch, but Mawi claims to have done something unique, and suggests that its Heart Patch is the first ever single-use, two-lead cardiac monitor to reach the market.The company describes it as “a stick-and-go, wireless solution” and further suggests that the disposable nature of the device is a benefit; it means that cardiologists can run tests on as many patients as they need to without having to wait for reusable Holter monitors to come back from other patients and get sanitized and maintained between uses.“Holter monitors aren’t great,” Andrew Klymenko, the CEO of Mawi, says drily in an interview we did last week, and explains that the existing solutions are prone to dislodging, peeling and causing allergic reactions, thus restricting monitoring time. As a result, Mawi claims that more than 50% of arrhythmias go undetected. Equally bad: patients have to wait up to a month to receive the results.Mawi Heart Patch, the company claims, can be applied in under a minute, and you can live like normal as you wear it.“Patients can shower, sleep, work out,” says Klymenko, and highlights that it’s possible to wear the patch and live all aspects of life as normal. “Sex is a big and important part of life, and patients can have sex as normal when wearing the Mawi patch.”“Cardiovascular diseases pose the greatest risk to our long-term health and are the leading cause of death globally. With a lack of or ineffective monitoring often proving critical, many of these deaths can be avoided with the right preventative measures,” Klymenko said. “Too often, sufferers do not realize the severity of their symptoms before it’s too late. Many patients that use the Mawi Heart Patch look healthy, exercise daily and show no signs of disease, yet have a potentially lethal heart condition. We’re on a mission to prevent the heart’s ‘silent killers,’ and we’re already working with like-minded clinics that are seeing amazing results.”The patch connects to a smartphone device in the doctor’s office. That device pipes the data through to the cloud, where an AI analyzes the results and highlights anything unusual for the cardiologists to take a closer look at. The process is very quick indeed, meaning that patients can have feedback and next steps for their treatment.“In less than 24 hours [the doctors] have a very detailed, precise and actionable report,” says Klymenko, suggesting that doctors can focus on treatment, rather than having to spend a lot of time analyzing data. “It takes just two seconds to manage.”The company currently has around 30 staff, primarily concentrated in Europe. Klymenko himself is from Ukraine, and his team is spread across the world, including teams in Thailand and in the U.S. To date, the company has been bootstrapped.Mawi won’t share exactly how many devices it has in the field, but Klymenko admits they are shipping “thousands of devices” every month, to customers across the U.S., the EU, and the Middle East.The devices need to be prescribed by a doctor, and pricing is heavily dependent on whatever medical insurance and what medical care system you are operating on, but Klymenko says that the devices typically cost “under $250 per study.”",0.0,0.0
365,https://www.cnn.com/2022/06/01/health/ghost-heart-life-itself-wellness/index.html,"âGhost heartâ: Built from the scaffolding of a pig and the patientâs cells, this cardiac breakthrough may soon be ready for transplant into humans","CNN —The first time molecular biologist Doris Taylor saw heart stem cells beat in unison in a petri dish, she was spellbound.“It actually changed my life,” said Taylor, who directed regenerative medicine research at Texas Heart Institute in Houston until 2020. “I said to myself, ‘Oh my gosh, that’s life.’ I wanted to figure out the how and why, and re-create that to save lives.”That goal has become reality. On Wednesday at the Life Itself conference, a health and wellness event presented in partnership with CNN, Taylor showed the audience the scaffolding of a pig’s heart infused with human stem cells – creating a viable, beating human heart the body will not reject. Why? Because it’s made from that person’s own tissues.“Now we can truly imagine building a personalized human heart, taking heart transplants from an emergency procedure where you’re so sick, to a planned procedure,” Taylor told the audience.“That reduces your risk by eliminating the need for (antirejection) drugs, by using your own cells to build that heart it reduces the cost … and you aren’t in the hospital as often so it improves your quality of life,” she said.Debuting on stage with her was BAB, a robot Taylor painstakingly taught to inject stem cells into the chambers of ghost hearts inside a sterile environment. As the audience at Life Itself watched BAB functioning in a sterile environment, Taylor showed videos of the pearly white mass called a “ghost heart” begin to pinken.Video Ad Feedback Can we grow a personalized human heart? 24:16 - Source: CNN“It’s the first shot at truly curing the number one killer of men, women and children worldwide – heart disease. And then I want to make it available to everyone,” said Taylor to audience applause.“She never gave up,” said Michael Golway, lead inventor of BAB and president and CEO of Advanced Solutions, which designs and creates platforms for building human tissues.“At any point, Dr. Taylor could have easily said ‘I’m done, this just isn’t going to work. But she persisted for years, fighting setbacks to find the right type of cells in the right quantities and right conditions to enable those cells to be happy and grow.”Giving birth to a heartTaylor’s fascination with growing hearts began in 1998, when she was part of a team at Duke University that injected cells into a rabbit’s failed heart, creating new heart muscle. As trials began in humans, however, the process was hit or miss.“We were putting cells into damaged or scarred regions of the heart and hoping that would overcome the existing damage,” she told CNN. “I started thinking: What if we could get rid of that bad environment and rebuild the house?”Taylor’s first success came in 2008 when she and a team at the University of Minnesota washed the cells out of a rat’s heart and began to work with the translucent skeleton left behind.Soon, she graduated to using pig’s hearts, due to their anatomical similarity to human hearts.“We took a pig’s heart, and we washed out all the cells with a gentle baby shampoo,” she said. “What was left was an extracellular matrix, a transparent framework we called the ‘ghost heart.’“Then we infused blood vessel cells and let them grow on the matrix for a couple of weeks,” Taylor said. “That built a way to feed the cells we were going to add because we’d reestablished the blood vessels to the heart.”The next step was to begin injecting the immature stem cells into the different regions of the scaffold, “and then we had to teach the cells how to grow up.”“We must electrically stimulate them, like a pacemaker, but very gently at first, until they get stronger and stronger. First, cells in one spot will twitch, then cells in another spot twitch, but they aren’t together,” Taylor said. “Over time they start connecting to each other in the matrix and by about a month, they start beating together as a heart. And let me tell you, it’s a ‘wow’ moment!”This ""ghost heart,"" created by using the scaffolding of a pig's heart and injected it with human stem cells, may soon be ready for human clinical trials. Advanced Solutions Life SciencesBut that’s not the end of the “mothering” Taylor and her team had to do. Now she must nurture the emerging heart by giving it a blood pressure and teaching it to pump.“We fill the heart chambers with artificial blood and let the heart cells squeeze against it. But we must help them with electrical pumps, or they will die,” she explained.The cells are also fed oxygen from artificial lungs. In the early days all of these steps had to be monitored and coordinated by hand 24 hours a day, 7 days a week, Taylor said.“The heart has to eat every day, and until we built the pieces that made it possible to electronically monitor the hearts someone had to do it person – and it didn’t matter if it was Christmas or New Year’s Day or your birthday,” she said. “It’s taken extraordinary groups of people who have worked with me over the years to make this happen.”But once Taylor and her team saw the results of their parenting, any sacrifices they made became insignificant, “because then the beauty happens, the magic,” she said.“We’ve injected the same type of cells everywhere in the heart, so they all started off alike,” Taylor said. “But now when we look in the left ventricle, we find left ventricle heart cells. If we look in the atrium, they look like atrial heart cells, and if we look in the right ventricle, they are right ventricle heart cells,” she said.“So over time they’ve developed based on where they find themselves and grown up to work together and become a heart. Nature is amazing, isn’t she?”Billions and billions of stem cellsAs her creation came to life, Taylor began to dream about a day when her prototypical hearts could be mass produced for the thousands of people on transplant lists, many of whom die while waiting. But how do you scale a heart?“I realized that for every gram of heart tissue we built, we needed a billion heart cells,” Taylor said. “That meant for an adult-sized human heart we would need up to 400 billion individual cells. Now, most labs work with a million or so cells, and heart cells don’t divide, which left us with the dilemma: Where will these cells come from?”The answer arrived when Japanese biomedical researcher Dr. Shinya Yamanaka discovered human adult skin cells could be reprogrammed to behave like embryonic or “pluripotent” stem cells, capable of developing into any cell in the body. The 2007 discovery won the scientist a Nobel Prize, and his “induced pluripotent stem cells (iPS),” soon became known as “Yamanaka factors.”“Now for the first time we could take blood, bone marrow or skin from a person and grow cells from that individual that could turn into heart cells,” Taylor said. “But the scale was still huge: We needed tens of billions of cells. It took us another 10 years to develop the techniques to do that.”The solution? A bee-like honeycomb of fiber, with thousands of microscopic holes where the cells could attach and be nourished.“The fiber soaks up the nutrients just like a coffee filter, the cells have access to food all around them and that lets them grow in much larger numbers. We can go from about 50 million cells to a billion cells in a week,” Taylor said. “But we need 40 billion or 50 billion or 100 billion, so part of our science over the last few years has been scaling up the number of cells we can grow.”Another issue: Each heart needed a pristine environment free of contaminants for each step of the process. Every time an intervention had to be done, she and her team ran the risk of opening the heart up to infection – and death.“Do you know how long it takes to inject 350 billion cells by hand?” Taylor asked the Life Itself audience. “What if you touch something? You just contaminated the whole heart.”Once her lab suffered an electrical malfunction and all of the hearts died. Taylor and her team were nearly inconsolable.“When something happens to one of these hearts, it’s devastating to all of us,” Taylor said. “And this is going to sound weird coming from a scientist, but I had to learn to bolster my own heart emotionally, mentally, spiritually and physically to get through this process.”Dr. Doris Taylor (left) is teaching BAB the robot how to properly inject stem cells into a ghost heart. Advanced Solutions Life SciencesEnter BAB, short for BioAssemblyBot, and an “uber-sterile” cradle created by Advance Solutions that could hold the heart and transport it between each step of the process while preserving a germ-free environment. Taylor has now taught BAB the specific process of injecting the cells she has painstakingly developed over the last decade.“When Dr. Taylor is injecting cells, it has taken her years to figure out where to inject, how much pressure to put on the syringe, and the best speed and pace to add the cells,” said BAB’s creator Golway.“A robot can do that quickly and precisely. And as we know, no two hearts are the same, so BAB can use ultrasound to see inside the vascular pathway of that specific heart, where Dr. Taylor is working blind, so to speak,” Golway added. “It’s exhilarating to watch – there are times where the hair on the back of my neck literally stands up.”Taylor left academia in 2020 and is currently working with private investors to bring her creation to the masses. If transplants into humans in upcoming clinical trials are successful, Taylor’s personalized hybrid hearts could be used to save thousands of lives around the world.In the US alone, some 3,500 people were on the heart transplant waiting list in 2021.“That’s not counting the people who never make it on the list, due to their age or heath,” Taylor said. “If you’re a small woman, if you’re an underrepresented minority, if you’re a child, the chances of getting an organ that matches your body are low.If you do get a heart, many people get sick or otherwise lose their new heart within a decade. We can reduce cost, we can increase access, and we can decrease side effects. It’s a win-win-win.”Taylor can even envision a day when people bank their own stem cells at a young age, taking them out of storage when needed to grow a heart – and one day even a lung, liver or kidney.“Say they have heart disease in their family,” she said. “We can plan ahead: Grow their cells to the numbers we need and freeze them, then when they are diagnosed with heart failure pull a scaffold off the shelf and build the heart within two months.“I’m just humbled and privileged to do this work, and proud of where we are,” she added. “The technology is ready. I hope everyone is going to be along with us for the ride because this is game-changing.”",0.0,0.0
421,https://www.psypost.org/2022/10/having-more-time-to-oneself-is-the-top-reported-benefit-of-being-single-study-finds-64145,"Having more time to oneself is the top reported benefit of being single, study finds","New research published in the journal Evolutionary Psychological Science suggests that people view the single life as an opportunity to focus on self-development. Having more time for themselves, being able to focus on their goals, and having no one else dictate their actions were among the most highly rated benefits of being single.Studies suggest that more and more people are living the single life. While part of this trend may be driven by difficulties obtaining a relationship partner, it seems that a good portion of people are choosing to be single. This rise in singlehood seems to contradict evolutionary theory. According to an evolutionary perspective, people are motivated toward long-term relationships since these arrangements offer the best chances of one’s genes being passed on to future generations.“Singlehood appears to be on the rise especially in Western societies,” said study author Menelaos Apostolou, a professor at the University of Nicosia. “One reason may be that people see benefits in being single, which motivated me to ask the question ‘what people perceive as beneficial in being single?'”Apostolou and his co-author Chistoforos Christoforou launched a pair of studies to examine what people consider the advantages of being single. In a first online questionnaire, the researchers asked 269 Greek-speaking men and women to write down some of the advantages enjoyed by single people. Two independent researchers then analyzed these responses and identified 84 distinct benefits.To narrow down this list, Apostolou and Christoforou conducted a follow-up study where they presented the list of 84 advantages to a larger sample of 612 Greek-speaking people. The participants were asked to rate how important each advantage would be to them if they were single.The researchers then used a statistical technique called principal component analysis to classify the 84 items into a smaller number of broader categories based on participants’ ratings. This resulted in a set of 10 factors, and the three most highly rated factors were “more time for myself”, “focus on my goals”, and “no one dictates my actions.” The other seven factors were: “no getting hurt”, “better control of what I eat”, “freedom to flirt around”, “save resources”, “peace of mind”, “no tension and fights”, and “not do things I dislike.”The analysis further revealed significant gender differences. Men rated the factor “freedom to flirt around” as a more important advantage than women did. Conversely, women gave higher ratings to “no tension and fights” and “focus on my goals.” There were also age effects — the strongest effects were that older respondents rated “more time for myself” and “not do things I dislike” as more important than younger respondents.In line with their predictions, the authors said that respondents’ emphasis on having more time for themselves, more resources, and being able to focus on their goals suggests that people find singlehood appealing partly because it allows them to develop their own strengths. The emphasis on having peace of mind and avoiding tension, fights, and getting hurt suggests that being single helps people avoid experiencing negative emotions. Finally, the “freedom to flirt around” factor suggests that singlehood is also appreciated because it allows people to engage in casual relationships.The researchers also proposed that while there are evolutionary costs to being single, there are times when it may be advantageous. For example, being single for a period of time can allow people to focus on obtaining a job promotion or pursuing their studies. “Instead of only asking whether mated or single life is better, we can ask when it is better for an individual to be single and for how long,” Apostolou and Christoforou wrote. “Considerable more research is necessary however, in order to address such questions.”Although not predicted by the researchers’ hypotheses, the factors of “better control of what I eat”, “no one dictates my actions”, and “not do things I dislike” may reflect the various compromises that intimate relationships entail.“There are potentially several benefits in being single, such as the freedom to do whatever you want,” Apostolou told PsyPost.But “I would predict that the costs of singlehood are probably higher than its benefits, which possibly explains why many singles prefer not to be single, and why most people eventually enter into a relationship,” he added. “These costs remain to be researched.”One limitation to note is that the study was conducted among Greek-speaking participants from the Republic of Cyprus, and the findings may not generalize beyond this cultural context. Cross-cultural studies may help illuminate how singlehood is perceived in different cultures.“There is not much research on singlehood, so additional studies are needed in order to understand the phenomenon,” Apostolou said. “The current study was conducted in the Greek cultural context, so some of its findings may not readily generalize to other cultural contexts.”The study, “What Makes Single Life Attractive: an Explorative Examination of the Advantages of Singlehood”, was authored by Menelaos Apostolou and Chistoforos Christoforou.",0.0,0.0
370,https://techcrunch.com/2016/12/07/this-artificial-iris-is-like-a-pair-of-programmable-shades-in-contact-lens-form/,This âartificial irisâ is like a pair of programmable shades in contact lens form,"Smart contact lenses have been the stuff of science fiction for a long time, but as with jetpacks and faster-than-light travel, we’re still waiting on them. Research is ongoing, though, and a project at the University of Ghent shows promise not just in advancing the technology but providing some therapeutic value, as well.Herbert De Smet’s group has been working for some time with EU grant money on initial applications and executions of smart lenses, and some early results were presented at IEEE’s International Electron Devices Meeting this week. Their device embeds a tiny monochrome LCD in the lens that can be set to varying opacities and patterns.Now, these patterns would be far too close to the eye for you to make them out, except perhaps as smudges or dark areas in your vision. They’re not intended to form images, however, but rather to darken the entire field of view for people who can’t do it themselves.Some people suffer from conditions that limit the ability of their eye’s iris — that’s the colored circle — to contract and dilate the pupil and control the amount of light admitted to reach the retina. If the pupil is stuck in the open state, bright situations — normally handled by reducing the pupil to a pinhole — will overwhelm the iris and cause pain or even serious damage.A contact lens that automatically changes its shade from totally transparent to as dark as a pair of sunglasses, as required by the ambient light, would fill this role nicely. That’s exactly what De Smet’s team has created; head over to IEEE Spectrum for a video of the LCD in action.The parts are in place: the LCD-infused lens and the chip that controls it are solid, and the power system, a set of tiny photovoltaic cells, captures enough energy — but the two have yet to be integrated. Once they are, the lenses will still, of course, need to be tested for safety.You can keep up with De Smet’s work at the Centre for Microsystems Technology’s webpage.",0.0,0.0
403,https://www.eurekalert.org/news-releases/967801,Myocarditis seven times more likely with COVID-19 than vaccines,"HERSHEY, Pa. — The risk of developing myocarditis — or inflammation of the heart muscle — is seven times higher with a COVID-19 infection than with the COVID-19 vaccine, according to a recent study by Penn State College of Medicine scientists. Patients with myocarditis can experience chest pains, shortness of breath or an irregular heartbeat. In severe cases, the inflammation can lead to heart failure and death.“Our findings show that the risk of myocarditis from being infected by COVID-19 is far greater than from getting the vaccine,” said Dr. Navya Voleti, a resident physician in the Department of Medicine at Penn State Health Milton S. Hershey Medical Center. “Moving forward, it will be important to monitor the potential long-term effects in those who develop myocarditis.”Myocarditis is one of the complications of SARS-CoV-2 infection. Although vaccines have been shown to reduce severe COVID-19 symptoms, heart complications have been associated with mRNA COVID-19 vaccination — particularly myocarditis in teenage boys. However, the relative risk of myocarditis due to vaccines and infections had not been well characterized in large studies.The Penn State team conducted the largest study to date on the risk of developing myocarditis as a result of having the coronavirus vs. experiencing inflammation following COVID-19 vaccination. The researchers compared patients with COVID-19 — vaccinated and unvaccinated — to those without the virus. They found the risk of myocarditis was 15 times higher in COVID-19 patients, regardless of vaccination status, compared to individuals who did not contract the virus.Next, the researchers separately compared the rates of myocarditis in those who received the vaccines to those in unvaccinated individuals. According to the findings, the rates of myocarditis in people who were vaccinated against COVID-19 were only twofold higher than in unvaccinated people.Based on all the findings, the researchers concluded that the risk of myocarditis due to COVID-19 was seven times higher than the risk related to the vaccines.Investigators conducted a systematic review and meta-analysis of 22 studies published worldwide from December 2019 through May 2022. The studies included nearly 58 million patients who reported cardiac complications and belonged to one of two groups: the 55.5 million who were vaccinated against COVID-19 compared to those who were not vaccinated (vaccination group), and the 2.5 million who contracted the virus compared to those who did not contract the virus (COVID-19 group).In the vaccination group, the researchers separately compared the risk of myocarditis for various COVID-19 vaccines, including mRNA (Pfizer, Moderna), Novavax, AstraZeneca, and Johnson and Johnson. The median age of the study population was 49 years; 49% were men; and the median follow-up time after infection or COVID-19 vaccination was 28 days.The researchers found that among those diagnosed with myocarditis after receiving the vaccine or having COVID-19, the majority (61%) were men. Of patients diagnosed with myocarditis in both vaccination and COVID-19 groups, 1.07% were hospitalized and 0.015% died.“COVID-19 infection and the related vaccines both pose a risk for myocarditis. However, the relative risk of heart inflammation induced by COVID-19 infection is substantially greater than the risk posed by the vaccines,” said Dr. Paddy Ssentongo, a resident physician in the Department of Medicine at Penn State Health Milton S. Hershey Medical Center and the lead author of the study. “We hope our findings will help mitigate vaccine hesitancy and increase vaccine uptake.”Surya Reddy from Osmania Medical College also contributed to this research.The researchers declare no conflicts of interest or specific funding for this research.Read the full study in Frontiers in Cardiovascular Medicine.",0.0,0.0
368,https://www.digitaltrends.com/mobile/non-invasive-blood-glucose-measurement-wearables-breakthrough/,Sensor breakthrough brings us closer to blood glucose monitoring on wearables,"Blood glucose monitoring is touted to be the next big breakthrough for wearable devices like the Apple Watch. However, the hardware is yet to be seen on a commercially available, mass-market device. That might change soon.A team from Georgia’s Kennesaw State University claims to have developed a noninvasive system of blood glucose level measurement, thanks to a device called GlucoCheck. It follows the same fundamental approach as the oxygen-level analysis sensor on smartwatches like the Apple Watch Series 8 and Samsung Galaxy Watch 5.Team lead Maria Valero, an assistant professor at the institution’s College of Computing and Software Engineering (CCSE), notes that the device delivers 90% accuracy in analyzing glucose concentration in blood samples. The biosensor works in tandem with a phone application, but the team is already at work on integrating Amazon’s Alexa virtual assistant.GlucoCheck shines light across the human skin, and then a camera captures the view from the other side. The goal is to study the varying level of light absorption by blood flowing in the vessels to determine the glucose concentration.The team has already filed a patent for the tech and now aims to test it on more body types to diversify the test data. This step is of critical importance, because commercially available wearables like those made by Fitbit and even Apple are known to be inaccurate at reading data from people with dark or tattoed skin types.The latest development is remarkable because it achieves the holy grail of glucose-level monitoring, which is to develop a noninvasive method that can be miniaturized and connected to devices such as phones. Currently, people with diabetes need to prick their fingers to obtain a blood sample to analyze their sugar levels.Commercial players are also at itThis is not the first research of its kind. In July 2020, Samsung showcased a noninvasive method for blood glucose monitoring in partnership with experts from the Massachusetts Institute of Technology (MIT). The same year, Movano revealed a wearable device that can measure blood sugar levels using a light diffusion method. But it didn’t do much else.A year later, a Japanese company named Quantum Operation showcased a wearable-mounted sensor at CES 2021 that was capable of noninvasive blood glucose analysis. According to multiple reports that have surfaced over the past couple of years, both Apple and Samsung are interested in the promising tech for their smartwatches.Quantum Operation Non-Invasive Blood GlucometerU.K.-based Rockley Photonics is also working toward the same objective, but instead of LEDs, the company is focused more on laser-based analysis. Regarding the in-house tech, CEO Dr. Andrew Rickman told Digital Trends that it “collects incredibly rich data that we extract to measure, amongst other things, hydration, lactate, and blood pressure.”Notably, Apple is said to be one of the biggest clients of Rockley Photonics and is rumored to include the noninvasive blood glucose monitoring tech on the Apple Watch portfolio in the near future.Editors' Recommendations",0.0,0.0
354, and he breaks eye contact when he is uncomfortable, but with “appropriate checks to make sure that it’s done in the right way, but he did not look away when he heard his name mentioned in such company. Remembering a remark that he had once made about his hope for neurotechnology’s wide adoption,0.0,0.0
346,https://www.newscientist.com/article/2338447-face-recognition-technology-for-pigs-could-improve-welfare-on-farms/,Face recognition technology for pigs could improve welfare on farms,"Machine learning software can identify individual pigs based on their facial features with high accuracy, which could help farmers give animals individualised food and veterinary carePigs have unique facial features that can be identified by machine learning software SRUCPigs could be issued with biometric passports based on facial recognition technology, giving farmers a more practical and welfare-friendly way of identifying individuals than ear notches or tags, the current industry standards.Identifying pigs based on their unique facial features could enable them to receive individualised food and veterinary care, and be traced as they go through meat processing. With advanced algorithms and machine learning, it is possible to distinguish between the faces of even the most similar-looking …",0.0,0.0
339,https://www.thesun.co.uk/tech/20277321/instagram-down-outage-users-suspended/,Instagram âdownâ as users report mysterious outage suspending accounts for no apparent reason,"INSTAGRAM has been hit by a weird outage suspending droves of users from their accounts.Reports from confused users surged around 1.30pm UK time.1 Loads of users report getting the same suspension messagePeople flooded Twitter trying to figure out what's going on.Screenshots show masses being suspended all at once.""We suspended your account on 31 October 2022,"" the alert shows.It's not clear how widespread the problem is.But Instagram has revealed it is a problem on their end.The topic has been trending on Twitter, which usually means quite a lot of people are experiencing the same thing.""Mark Zuckerberg what hell is this my account in suspended,"" one annoyed user wrote.""Earlier it was crashing every 10-20 seconds and now they have suspended my account for no reason,"" another said.""I cannot even login to my account.""A third added: ""What’s going on with Instagram? Did they get hacked or something?""Mine says my account is suspended. I guess my pic of the hummus plate I made sent them over the edge.""A surge in reports was noticed by the Down Detector site at around 1.30pm GMT.Instagram owner Meta has acknowledged the problem, saying: ""We're aware that some of you are having issues accessing your Instagram account.""We're looking into it and apologize for the inconvenience.""We pay for your stories! Do you have a story for The Sun Online Tech & Science team? Email us at tech@the-sun.co.uk",0.0,0.0
345,https://newsroom.unsw.edu.au/news/science-tech/engineers-light-way-toward-bionics-future?utm_source=reddit&utm_medium=social,Engineers light the way to bionics of the future,"Biomedical and electrical engineers at UNSW Sydney have developed a new way to measure neural activity using light – rather than electricity – which could lead to a complete reimagining of medical technologies like nerve-operated prosthetics and brain-machine interfaces.Biomedical and electrical engineers at UNSW Sydney have developed a new way to measure neural activity using light – rather than electricity – which could lead to a complete reimagining of medical technologies like nerve-operated prosthetics and brain-machine interfaces.Professor François LadouceurProfessor François LadouceurNot only do these optrodes perform just as well as conventional electrodes – that use electricity to detect a nerve impulse – but they also address “very thorny issues that competing technologies cannot address”, says Prof. Ladouceur.Not only do these optrodes perform just as well as conventional electrodes – that use electricity to detect a nerve impulse – but they also address “very thorny issues that competing technologies cannot address”, says Prof. Ladouceur.“Firstly, it’s very difficult to shrink the size of the interface using conventional electrodes so that thousands of them can connect to thousands of nerves within a very small area.“Firstly, it’s very difficult to shrink the size of the interface using conventional electrodes so that thousands of them can connect to thousands of nerves within a very small area.“One of the problems as you shrink thousands of electrodes and put them ever closer together to connect to the biological tissues is that their individual resistance increases, which degrades the signal-to-noise ratio so we have a problem reading the signal. We call this ‘impedance mismatch’.“One of the problems as you shrink thousands of electrodes and put them ever closer together to connect to the biological tissues is that their individual resistance increases, which degrades the signal-to-noise ratio so we have a problem reading the signal. We call this ‘impedance mismatch’.Read moreRead more“Another problem is what we call ‘crosstalk’ – when you shrink these electrodes and bring them closer together, they start to talk to, or affect each other because of their proximity.”“Another problem is what we call ‘crosstalk’ – when you shrink these electrodes and bring them closer together, they start to talk to, or affect each other because of their proximity.”“The real advantage of our approach is that we can make this connection very dense in the optical domain and we don’t pay the price that you have to pay in the electrical domain,” Prof. Ladouceur says.“The real advantage of our approach is that we can make this connection very dense in the optical domain and we don’t pay the price that you have to pay in the electrical domain,” Prof. Ladouceur says.In research published recently in theIn research published recently in theScientia Professor Nigel Lovell, who heads theScientia Professor Nigel Lovell, who heads theHe says the team connected an optrode to the sciatic nerve of an anaesthetised animal. The nerve was then stimulated with a small current and the neural signals were recorded with the optrode. Then they did the same using a conventional electrode and a bioamplifier.He says the team connected an optrode to the sciatic nerve of an anaesthetised animal. The nerve was then stimulated with a small current and the neural signals were recorded with the optrode. Then they did the same using a conventional electrode and a bioamplifier.“We demonstrated that the nerve responses were essentially the same,” says Prof. Lovell. “There’s still more noise in the optical one, but that’s not surprising given this is brand new technology, and we can work on that. But ultimately, we could identify the same characteristics by measuring electrically or optically.”“We demonstrated that the nerve responses were essentially the same,” says Prof. Lovell. “There’s still more noise in the optical one, but that’s not surprising given this is brand new technology, and we can work on that. But ultimately, we could identify the same characteristics by measuring electrically or optically.”New dawn for prostheticsNew dawn for prostheticsSo far the team has been able to show that nerve impulses – which are relatively weak and measured in microvolts – can be registered by optrode technology. The next step will be to scale up the number of optrodes to be able to handle complex networks of nervous and excitable tissue.So far the team has been able to show that nerve impulses – which are relatively weak and measured in microvolts – can be registered by optrode technology. The next step will be to scale up the number of optrodes to be able to handle complex networks of nervous and excitable tissue.Prof. Ladouceur says at the beginning of the project, his colleagues asked themselves, how many neural connections does a man or woman need to operate a hand with a degree of finesse?Prof. Ladouceur says at the beginning of the project, his colleagues asked themselves, how many neural connections does a man or woman need to operate a hand with a degree of finesse?“That you can pick up an object, that you can judge the friction, you can apply just the right pressure to hold it, you can move from A to B with precision, you can go fast and slow – all these things that we don’t even think about when we perform these actions. The answer is not so obvious, we had to search quite a bit in the literature, but we believe it’s about 5000 to 10,000 connections.”“That you can pick up an object, that you can judge the friction, you can apply just the right pressure to hold it, you can move from A to B with precision, you can go fast and slow – all these things that we don’t even think about when we perform these actions. The answer is not so obvious, we had to search quite a bit in the literature, but we believe it’s about 5000 to 10,000 connections.”In other words, between your brain and your hand there is a bundle of nerves that travels down from your cortex and eventually divides into those 5000 to 10,000 nerves that control the delicate operations of your hand.In other words, between your brain and your hand there is a bundle of nerves that travels down from your cortex and eventually divides into those 5000 to 10,000 nerves that control the delicate operations of your hand.If a chip with thousands of optical connections could connect to your brain, or some place in the arm before the nerve bundle separates, a prosthetic hand could potentially be able to function with much the same ability as a biological one.If a chip with thousands of optical connections could connect to your brain, or some place in the arm before the nerve bundle separates, a prosthetic hand could potentially be able to function with much the same ability as a biological one.That’s the dream, anyway, and Prof. Ladouceur says there are likely decades of further research before it’s a reality. This would include developing the ability for optrodes to be bidirectional. Not only would they receive and interpret signals from the brain on the way to the body, they could receive feedback in the form of neural impulses going back to the brain.That’s the dream, anyway, and Prof. Ladouceur says there are likely decades of further research before it’s a reality. This would include developing the ability for optrodes to be bidirectional. Not only would they receive and interpret signals from the brain on the way to the body, they could receive feedback in the form of neural impulses going back to the brain.The long game: brain-machine interfaceThe long game: brain-machine interfaceNeural prosthetics isn’t the only space that optrode technology has the potential to redefine. Humans have long fantasised about integrating technology and machinery into the human body to either repair or enhance it.Neural prosthetics isn’t the only space that optrode technology has the potential to redefine. Humans have long fantasised about integrating technology and machinery into the human body to either repair or enhance it.Some of this is now a reality, such as Cochlear implants, pacemakers and cardiac defibrillators, not to mention smart watches and other tracking devices giving continual biofeedback.Some of this is now a reality, such as Cochlear implants, pacemakers and cardiac defibrillators, not to mention smart watches and other tracking devices giving continual biofeedback.But one of the more ambitious goals in biomedical engineering and neuroscience is the brain-machine interface that aims to connect the brain to not only the rest of the body, but potentially the world.But one of the more ambitious goals in biomedical engineering and neuroscience is the brain-machine interface that aims to connect the brain to not only the rest of the body, but potentially the world.“The area of neural interfacing is an incredibly exciting field and will be the subject of intense research and development over the next decade,” says Prof. Lovell.“The area of neural interfacing is an incredibly exciting field and will be the subject of intense research and development over the next decade,” says Prof. Lovell.While this is more fiction than fact right now, there are many biotech companies taking this very seriously. Entrepreneur Elon Musk was one of the co-founders ofWhile this is more fiction than fact right now, there are many biotech companies taking this very seriously. Entrepreneur Elon Musk was one of the co-founders ofThe Neuralink approach uses conventional wire electrodes in its devices so it must overcome impedance mismatch and crosstalk – among many other challenges – if they are to develop devices that host thousands, if not millions, of connections between the brain and the implanted device. RecentlyThe Neuralink approach uses conventional wire electrodes in its devices so it must overcome impedance mismatch and crosstalk – among many other challenges – if they are to develop devices that host thousands, if not millions, of connections between the brain and the implanted device. RecentlyRead moreRead moreProf. Ladouceur says time will tell whether Neuralink and its competitors succeed in removing these obstacles. However, given that implantable, in vivo devices that capture neural activity are currently constrained to about 100 or so electrodes, there is still a long way to go.Prof. Ladouceur says time will tell whether Neuralink and its competitors succeed in removing these obstacles. However, given that implantable, in vivo devices that capture neural activity are currently constrained to about 100 or so electrodes, there is still a long way to go.“I'm not saying that it's impossible, but it becomes really problematic if you were to stick to standard electrodes,” Prof. Ladouceur says.“I'm not saying that it's impossible, but it becomes really problematic if you were to stick to standard electrodes,” Prof. Ladouceur says.“We don't have these problems in the optical domain. In our devices, if there is neural activity, its presence influences the orientation of the liquid crystal which we can detect and quantify by shining light on it. It means we don't extract current from the biological tissues as the wire electrodes do. And so the biosensing can be done much more efficiently.”“We don't have these problems in the optical domain. In our devices, if there is neural activity, its presence influences the orientation of the liquid crystal which we can detect and quantify by shining light on it. It means we don't extract current from the biological tissues as the wire electrodes do. And so the biosensing can be done much more efficiently.”Now that the researchers have shown that the optrode method works in vivo, they will shortly publish research that shows the optrode technology is bidirectional – that it can not only read neural signals, but can write them too.Now that the researchers have shown that the optrode method works in vivo, they will shortly publish research that shows the optrode technology is bidirectional – that it can not only read neural signals, but can write them too.",0.0,0.0
442,https://www.nature.com/articles/s41598-022-20562-4,Effects of exploring a novel environment on memory across the lifespan,"ParticipantsA total of 487 visitors of the NEMO Science Center in Amsterdam aged 8 years or older volunteered to participate in this study. Data was collected during a 2-week Science Live exhibition, during which we tested all visitors interested in volunteering during all opening hours of the NEMO Science Center. While this somewhat restricted our control over the age and the total number of participants, it yielded a final sample size that largely exceeded that of prior studies (e.g., between 30 and 103 participants in references25 and28). Forty-five participants were excluded: 17 participants were excluded because of administrative issues (e.g., accidental reuse of a participant number), seven due to technical issues (e.g., task crash), seven because of language issues (e.g., unable to understand the instructions), six because they worked together or received help from a parent, five participants because they did not finish the tasks in sequence (e.g., with a long break to visit an exhibition show), and two participants because they talked on the phone during the word learning task. As such, 439 participants were included in the main analyses (401 performed the task in Dutch and 38 in English). As the landmark test did not run on all laptops due to technical issues, the number of included participants that completed this task was only 331. Participants were classified as children (8–11 years; mean = 9.33; SD = 1.15), adolescents (12–17 years; mean = 13.19; SD = 1.43), younger adults (18–44 years; mean = 32.73; SD = 8.27) or older adults (> = 45 years [range 46–77]; mean = 53.30; SD = 8.23 ) based on their age (and presumed associated differences changes in dopaminergic functioning:38,45,46). Supplementary Information (SI): Appendix 1 shows demographics and the distribution of participants over age groups and conditions. Participants in the first testing week performed a word learning task with a deep encoding, and participants in the second week performed a shallow encoding task. For participants within each age-group, age distributions were similar across the different novelty and level of processing conditions (for novelty and level of processing respectively, children: p = 0.598 and p = 0.405; adolescents: p = 0.568 and p = 0.155; young adults: p = 0.077 and p = 0.815; old adults: p = 0.658 and p = 0.733). Also sex distributions were similar over conditions (Pearson Chi-Square for novelty and level of processing respectively, children: p = 0.216 and p = 0.821; adolescents: p = 1 and p = 0.128; young adults: p = 0.214 and p = 0.853; older adults: p = 0.285 and p = 0.241).All participants or a participant’s parent in case of minors, gave written informed consent. Participants could choose to perform the tasks in Dutch or English. The study was approved by the Psychology Research Ethics committee (CEP) of Leiden University, the Netherlands. All procedures were in line with the Declaration of Helsinki (1964, and later amendments), and followed relevant COVID-19 guidelines and regulations.General procedureThroughout all procedures the experimenters were wearing a mask and gloves as a safety regulation regarding the COVID-19 pandemic. For data collection we used six laptops in two spacious testing rooms that allowed for social distancing (> = 1.5 m). The experimenter stayed in the testing room throughout the entire procedure to start the tasks and to answer questions. The entire experimental procedure took approximately 15–25 min.Data was collected at the NEMO Science Center in Amsterdam. Upon arrival, participants were asked to disinfect their hands as part of the COVID-19 protocol. Before participation, participants or their parents read the information letter and were given the opportunity to ask questions. After giving written informed consent, the participants were seated before they performed a series of tasks on a laptop.Stimuli and apparatusThe VEs were created using Unity Version 2017.2.21f1 (Unity Technologies, 2017), and were matched in size, path length, and number of intersections. Both VEs consisted of fantasy islands with unusual landmarks (such as a slot machine) at intersections or road endpoints, including land and a body of water (see Fig. 1). The VEs were presented on laptops running on Windows 10 (Microsoft, 2015). Participants could move forward using the W key on the keyboard and the mouse to determine the heading direction. During exploration the X, Y and Z coordinates of the moving agent were logged for all timepoints with a sampling rate of about 15 Hz. The VAS I, VAS 2 and word learning task were programmed and presented using Open Sesame 3.3.347, the landmark task and NS questionnaire were created using E-Prime 3.0 software (Psychology Software Tools, Pittsburgh, PA).Figure 1 Screenshots of the two virtual environments. The environments contained landmarks at intersections and road endpoints, and were matched in size, number of intersections, number of landmarks, and path length. Full size imageFor the word learning task fifteen Dutch neutral nouns were chosen from the CELEX lexical database and translated to English for non-Dutch speakers48. The same words were used in the novel and familiar, and shallow and deep encoding conditions. Four words referred to an animal (“alive”) and eleven words referred to a non-living thing (“not alive”). Similarly, four words started with a closed letter (e.g., “Boat”) and eleven with an open letter (e.g., “Wolf”).Participants were reminded of the response keys and task during the encoding, recall and recognition phase of the word learning and landmark tasks. The response keys were shown below the word, in the location corresponding to the keyboard, and in the semantic task the response keys were further accompanied by the picture of a cow (to indicate a living thing) and a chair (to indicate a non-living thing). These reminders were included to lift the working memory load, especially because this otherwise could have made the task disproportionally difficult for the younger children.Landmarks were objects from the Unity Asset store, and included a wide range of easily recognizable objects, such as an airplane and desk chair. Pictures of the landmarks presented on a grey background were used in the landmark memory test. During this test also lures were presented, which consisted of objects that were not part of either of the two VEs.Exploration phases and affective ratingsParticipants received scripted verbal instructions regarding how to navigate through the VE. The ‘W’ key (for ‘walk’) could be used to move forward, and the mouse could be used to look around and determine heading direction. The space bar could be used to jump, although there was no function in jumping, as one could not jump on top of things. Participants were instructed that they could navigate freely but should try to stay on the paths. During the first familiarization phase, participants explored the VE for 3 min. After exploration, they were asked to indicate their happiness (“How happy are you?”, from 1 = extremely unhappy to 9 = extremely happy) and arousal (“How aroused are you?”, from 1 = very calm to 9 = very excited) on a visual analogue scale (VAS) with Self-Assessment Manikins49. They could use the number keys to indicate their answers, and completing the ratings took less than 1 min.During the second exploration phase participants explored either the same (i.e., familiar) or a new VE for another 3 min (i.e., novelty and VEs were counterbalanced). After this exploration, participants were asked to rate their happiness and arousal levels again on the same two VAS as before the first exploration. See Fig. 2 for the experimental task sequence.Figure 2 Experimental task sequence. Tasks are shown in sequential order from top to bottom. During the first exploration phase participants explored one of the two virtual environments (counterbalanced between participants). Participants filled out Visual Analogue Scales to report current mood and arousal state44 In the second exploration phase participants either explored the same (familiar condition) environment again or a new one (novel condition). The depth of encoding during the word task was varied between subjects, with participants either performing a semantic (deep encoding condition) or shallow encoding task. After a short distractor task, memory ways tested with free recall and a recognition test. After a visuomotor adaptation task (not reported here) landmark memory was tested with a recognition test with confidence judgments. Finally, adults filled out the full Novelty Seeking scale of the TPQ35,36,45, while children answered NS-related questions (non-standardized). Full size imageExperimental tasksFor the word task, instructions were shown on the screen. During the encoding phase, fifteen nouns were shown in a random sequence (we believe this number of items to be sufficient to identify individual and condition differences, as the smaller 10-word learning list from the Consortium to Establish a Registry for Alzheimer’s Disease [CERAD] has been shown to be a sensitive measure for detecting mild cognitive impairment and identifying early symptoms of Alzheimer’s disease, suggesting that relatively short word lists are sufficient to robustly identify individual differences in memory performance50,51. Also other neuropsychological test batteries use relatively short word lists, such as the California Verbal Learning Test [CVLT;52] which uses 16 words, or the Rey Auditory Verbal Learning Test [R-AVLT] which uses 15 words53). In the first week of data collection, word learning involved a deep encoding task in which participants had to judge whether the shown word represented a living (e.g., a cow) or a non-living (e.g., a chair) thing. During the second test week, word learning involved a shallow encoding task in which participants had to indicate whether the first letter of the shown word had an open (such as a “W”) or closed (such as an “O”) shape. Each word was presented for a duration of 3000 ms (irrespective of whether a response was given or not). In between words a fixation cross was shown for 500 ms. After the encoding phase, participants performed a series of nine simple math problems (e.g., 4 – 3 or 7 + 1) in a distractor task. The solution to all problems varied between 1 and 9. Next, participants were prompted to enter as many words as they could remember from the encoding phase. They were instructed to press ENTER, to continue entering words or to press ESC + ENTER to continue if they could not remember any more words. In the following recognition test all 15 words from the encoding phase were randomly shown, interspersed with 10 lures (new words that were not presented during encoding). Participants had to indicate for each word whether it was old (“press X”) or new (“press N”). Each word was shown until a response was given. All phases of the word task were finished in 3–4 min. Recall was quantified by the percentage correctly remembered words, while recognition was quantified by the corrected hit rate (CHR = percentage old hits – percentage new false alarms). Next, participants performed a visuomotor adaptation task, which was completed in 2–3 min (results published in54).The landmark test assessed memory for landmarks that participants could have encountered during the second exploration phase. In total 35 landmarks were shown, of which 20 were present in the second VE (i.e., “old) and 15 were lures (i.e., “new”). Participants had to indicate for each landmark whether they saw it before (“press X for old”) or not (“press N for new”). When participants indicated “old” they were further asked to indicate whether they thought the landmark was “sure old” (“press X”), “probably old” (“press N”) or whether they guessed (“press M “). Each landmark was shown until a response was given and the test had a duration of approximately 2–3 min. As an estimate of landmark recollection, the “sure” CHR was calculated (i.e., “sure” old hits—new false alarms).Novelty seeking questionnaireFinally, participants reported their sex (male; female; other), age in years, and handedness (right; left; ambidextrous). Adults (> 17) subsequently filled out the 34 items of the NS scale of the Tridimensional Personality Questionnaire39,40,55, whereas children and adolescents filled out a simplified and abbreviated (20 item) version of the questionnaire. Each question remained on the screen until a response (“X” = yes; “M” = no) was given. All questions could be answered in about 2–5 min. Afterwards feedback was shown on basis of the total NS score (i.e., with a subdivision into low, medium, and high scorers). These cut-off scores were only used to provide the participants feedback and were not used in any analyses.AnalysesMemory performanceRecall and CHR for words were subjected to 2*2*4 ANOVAs with Novelty (novel; familiar), Encoding type (shallow; deep) and Age group (children; adolescents; younger adults; older adults) as between-subject factors. As we expected the effects of age on memory performance to be quadratic, with performance peaking in adolescents or young adults, we followed up a main effect of age group with a quadratic contrast38. In line with our hypothesis that older adults would show diminished effects of novelty, an interaction between novelty and age was followed up with three 2*2*2 ANOVAs with Novelty (novel; familiar), Encoding type (shallow; deep), and Age (either older adults vs. children, older adults vs. adolescents, or older vs. younger adults) as factors. As the groups between conditions were unequal, we also included Encoding type in this analysis, but the main effect and interactions with this factor are not interpreted. For all analyses, the α-criterion was set at 0.05, and Bonferroni-Holm correction was applied to compensate for multiple testing.Roaming entropy, and other measures of explorationRoaming entropy (RE) during the first and second exploration round was defined for each participant. In this analysis the Z-coordinates were omitted, as the VEs consisted of only one location for each of the XY coordinates (although it was possible that people jumped at a location, they could not climb on anything). As there was a very high number (6.31 million) of possible locations the likelihood that the same coordinates were visited during the 3-min exploration was small, therefore the individual paths were smoothed using a Gaussian filter with a width of 100. Then a likelihood matrix p j was calculated for each of the two VEs, where the likelihood that someone visited each of the XY positions j was calculated, by dividing the total number of visits to that location by the total number of visited locations for all participants. See Fig. 3A for the map of one of the VEs, and 3B for a heatmap depicting the number of visits for all XY coordinates for that VE.Figure 3 Maps of one of the virtual environments. (A) Depicts the map of one the VEs. (B) Shows the number of visits per XY-coordinate in a heatmap for all participants that explored that island. The spawn point in the top left is visible as a highly visited region. Outlines of landmarks can be recognized at some ends of paths. Individual navigation traces show that some people left the paths and used short-cuts to other paths. This data was used to calculate a probability matrix reflecting the likelihood that each of the locations was visited (see main text). Note, the number of visits per XY-coordinate is relatively low, despite smoothing. The probability that each location was visited was used to calculate the roaming entropy (RE) of individuals. Full size imageRoaming entropy (RE i ) was calculated per participant and exploration round by summating over the product between the individual’s path (p ij ) and the log of the probability that each location was visited (p j ) divided by the log of the number of possible locations (k):$$RE_{i} = - \sum\limits_{j = 1}^{k} {\left( {\frac{{p_{ij} \log (p_{j} )}}{\log (k)}} \right)}$$High RE indicates that the participant explored more of the less-often-walked paths, while a lower value reflects higher concordance to the often-walked paths.In addition to RE, we calculated the total distance travelled (in Unity meters) as the sum of Euclidian distances between successive datapoints (2D) and counted the number of landmarks that were encountered in the second exploration round for each participant by defining regions of interest (ROIs) for each of the landmarks for which memory was tested. These ROIs consisted of rectangular bounding boxes around the landmarks. ROIs could overlap in case landmarks were close to each other. For each participant it was determined which ROIs were visited. The total number of ROIs visited provides an additional measure of exploration, as it reflects how many regions were visited by the participant. A GLM including novelty (novel; familiar) and encoding type (deep; shallow) as categorical predictors, and RE for round 2 and age as continuous predictors of word recall was ran, to investigate whether exploration behavior as quantified by RE could predict later word recall above and beyond the effects of novelty and encoding type. We chose to include only RE and not distance travelled, or landmarks encountered in this model, as these measures were found to be positively correlated (see SI: Appendix 5). RE is the most commonly used measure of exploration and the only of these three measures for which we found a novelty effect. The GLM was ran on centered data to reduce multicollinearity. Multicollinearity was shown to be low, with all variance inflation factor (VIF) values < 1.15. It is of note that we ran our task on different laptops with varying specifications, which resulted in different sampling rates between participants, but as participants were randomly distributed over the laptops, and RE exhibits a similar pattern of results as the other exploration measures (e.g., distance traveled, and landmarks encountered) we believe that potential effects of these differences were minimal.PreprintA previous version of this manuscript was published as a preprint https://psyarxiv.com/r2tdn/",0.0,0.0
208,https://www.pv-magazine.com/2022/10/27/5-cooling-down-solar-modules-by-increasing-space-between-panel-rows/,Cooling down solar modules by increasing space between panel rows,"A research group led by the US Department of Energy's National Renewable Energy Laboratory (NREL) has proposed a new approach to utilize connective heat transfer for solar module cooling in large-scale solar power plants.Their modeling considers factors such as row spacing, panel height, and tilt angle. It also uses a length scale input to characterize the space through which air moves around or through the solar modules. In the standard models, by contrast, the length often used is a ratio of module dimensions, which ignores PV plant configuration.“The convective heat transfer curve was generated through computational flow simulations and wind tunnel experiments that allowed for convective heat transfer to be described for a lacunarity length scale value that describes the spacing of the entire PV array through a single length unit,” the scientists said, claiming that using the lacunarity length scale leads to 1.5% more accurate power production.Their techno-economic analysis considered 1 MW south-facing PV systems located in Phoenix, Arizona, with a fixed tilt angle of 30 degrees over different row spacings, or ground coverage ratio (GCR). The annual land lease cost was assumed at $0.054/m2. The row spacing of the PV plants was varied from two to 11 meters, corresponding to GCR values of 0.73 to 0.08.“Increasing spacing could enable more varieties of crops and more types of agricultural equipment to be utilized in agrivoltaic systems,” said Jordan Macknick, who leads a different NREL research project focused on agrivoltaics. “That could potentially make these spaced-out solar systems more cost-effective and compatible with larger-scale agriculture.”Popular contentThrough the modeling, the group ascertained that the optimal levelized cost of energy (LCOE) point was $0.29/kWh, with row spacing varying between 4.83 and 7.34 meters. With two-meter spacing, the LCOE was $0.33/kWh, and with 11 meters it was $0.36/kWh.The group found that the greatest LCOE improvements were registered in climates with low average annual ambient temperatures and moderate to high average annual wind speeds across the US. They presented the modeling in the study “Technoeconomic Analysis of Changing PV Array Convective Cooling Through Changing Array Spacing,” recently published in the IEEE Journal of Photovoltaics.Other recent proposals for using convective solar module cooling include packing PV panels in close proximity, and taking wind direction and module inclination into account.",0.0,0.0
520,https://ethz.ch/en/news-and-events/eth-news/news/2022/10/how-genetics-influences-our-body-weight-beyond-the-genes.html,How genetics influences our body weight beyond the genes,"Heredity plays a role in how strongly we are predisposed to put on excess weight. In recent years, researchers have extensively examined which genes and gene variants play a role in this, and have identified roughly one hundred obesity susceptibility genes. However, genome-wide association studies have shown that less than half of all cases of hereditary obesity can be explained by these genes. The other half are the result of factors that, although part of our DNA, are not genes in the classical sense. Epigenetic information would be one example of such a factor.A group of researchers led by Professor Markus Stoffel from the Department of Biology have now identified a further non-classic genetic risk factor for hereditary obesity: an endogenous microRNA molecule known as microRNA-7.Like genes, the blueprints for microRNA molecules are part of our chromosomes. But while genes act as the building instructions for proteins, the information contained in microRNA is not translated into protein form. Instead, the microRNA molecules act in our cells in the form of RNA. “MicroRNA-7 is the first microRNA for which we’ve been able to demonstrate an association with obesity,” Stoffel says.Effect on mice and humansTogether with his team, Stoffel bred mice in which microRNA-7 was missing in certain nerve cells of the hypothalamus, the control center between the endocrine system and nervous system. These mice demonstrated a pathologically increased appetite and became obese.The ETH researchers were also able to demonstrate such a link in humans. Together with scientists from the University of Cambridge, they analysed genomic and medical data, including the anonymised data held in a British database relating to 500,000 people. This allowed Stoffel and his colleagues to show that people with genetic variations on their chromosomes near the blueprint for microRNA-7 are heavier and bigger than average. The consequence of these genetic variations is that the above-mentioned nerve cells of the people affected produce less microRNA-7.The scientists were also able to show that in these cells microRNA-7 affects a biochemical pathway known to be instrumental in maintaining the body’s energy balance, regulating appetite and controlling the production of growth hormones. MicroRNA acts there by regulating the production of proteins.For Stoffel, it was no surprise that this effect can be observed in both mice and humans. As he points out, microRNA-7 is a molecule that emerged very early in the evolutionary history of the animal kingdom and has survived to this day. It persists unaltered in very many animal species – from nematodes, to all vertebrates and human beings.Therapeutic potential“Up to now, it was unclear why genetic variations were only able to provide an explanation for less than half the causes of hereditary obesity,” Stoffel says. “Our study now shows that it’s not enough to look for the answer solely in the genes that encode information for proteins. The parts of DNA outside the genes also have to be examined, such as the regions containing the blueprints for microRNA.”In theory, at least, these new findings could also be used in medicine. There are already RNA-based drugs that use the mechanisms of action of microRNA molecules in the body. It may one day be possible to develop a treatment for people who are obese as a result of their hypothalamus producing insufficient amounts of microRNA-7. Treatment for the converse case would also be conceivable – for people with a predisposition to pathological low body weight microRNA-7 could be pharmacologically inhibited.But, Stoffel says, it is more likely that the still quite novel forms of RNA treatment will initially be used for neurodegenerative conditions such as Alzheimer’s disease. In the long term, as the safety of RNA therapy in the central nervous system is established, he believes it is possible that metabolic disorders such as obesity and unintentional weight loss may also be treated in this way.",0.0,0.0
492,https://www.sciencealert.com/scientists-created-living-synthetic-cells-by-harvesting-bacteria-for-parts?utm_source=ScienceAlert+-+Daily+Email+Updates&utm_campaign=78601d00d9-RSS_EMAIL_CAMPAIGN&utm_medium=email&utm_term=0_fe5632fb09-78601d00d9-364810597,Scientists Created 'Living' Synthetic Cells by Harvesting Bacteria For Parts,"Researchers at the University of Bristol in the UK have taken a major step forward in synthetic biology by designing a system that performs several key functions of a living cell, including generating energy and expressing genes.Their artificially constructed cell even transformed from a sphere shape to a more natural amoeba-like shape over the first 48 hours of 'life', indicating that the proto-cytoskeletal filaments were working (or, as the researchers put it, were ""structurally dynamic over extended time scales"").Building something that comes close to what we might think of as alive is no walk in the park, not least thanks to the fact even the simplest of organisms rely on countless biochemical operations involving mind-bendingly complex machinery to grow and replicate.Scientists have previously focused on getting artificial cells to perform a single function, such as gene expression, enzyme catalysis, or ribozyme activity.If scientists crack the secret to custom building and programming artificial cells capable of mimicking life more closely, it could create a wealth of possibilities in everything from manufacturing to medicine.While some engineering efforts focus on redesigning the blueprints themselves, others are investigating ways to reduce existing cells to scraps that can then be reconstructed into something relatively novel.To perform this latest bottom-up bioengineering feat, researchers used two bacterial colonies – Escherichia coli and Pseudomonas aeruginosa – for parts.These two bacteria were mixed with empty microdroplets in a viscous liquid. One population was captured inside the droplets and the other was trapped at the droplet surface.The scientists then burst open the bacteria membranes by bathing the colonies in lysozyme (an enzyme) and melittin (a polypeptide which comes from honeybee venom).The bacteria spilled their contents, which were captured by the droplets to create membrane-coated protocells.The scientists then demonstrated that the cells were capable of complex processing, such as the production of the energy storage molecule ATP through glycolysis, and the transcription and translation of genes.""Our living-material assembly approach provides an opportunity for the bottom-up construction of symbiotic living/synthetic cell constructs, says first author, chemist Can Xu.""For example, using engineered bacteria it should be possible to fabricate complex modules for development in diagnostic and therapeutic areas of synthetic biology as well as in biomanufacturing and biotechnology in general.""In the future, this kind of synthetic cell technology could be used to improve ethanol production for biofuels and food processing.Combined with knowledge based on advanced models of basic biology, we could mix-and-match some structures while redesigning others completely to engineer whole new systems.Artificial cells could be programmed to photosynthesize like purple bacteria, or generate energy from chemicals just like sulfate-reducing bacteria do.""We expect that the methodology will be responsive to high levels of programmability,"" the researchers say.This paper was published in Nature.",0.0,0.0
517,https://www.psypost.org/2022/10/cannabis-use-does-not-increase-actual-creativity-but-does-increase-how-creative-you-think-you-are-study-finds-64187,"Cannabis use does not increase actual creativity but does increase how creative you think you are, study finds","A set of studies published in the Journal of Applied Psychology has failed to find evidence that cannabis has creativity-enhancing effects. But the researchers did find that cannabis elicited a sense of joviality, which in turn made cannabis users perceive their own ideas and the ideas of others as more creative.“Cannabis was legalized in Washington state a few years back. That got us talking about how cannabis is a topic which his generally ignored by the management and applied psychology research literature, with the exception of research which considers cannabis as harmful to work and health,” said study author Christopher Barnes (@chris24barnes), a Michael G. Foster Endowed Professor at the University of Washington.“We thought there might be some more nuance to the topic, and that the research literature should be expanded accordingly. A natural first step was to examine cannabis and creativity, given the common belief that they are linked.”For their study, the researchers recruited occasional cannabis users from Washington state. They ended up with a final sample of 191 participants, who were randomly assigned to one of two conditions. One group of participants were asked to begin the study within 15 minutes of using cannabis. The second group was instructed to only begin the study if they have not used cannabis in the past 12 hours.The participants first reported whether they were “happy” and “joyful” at the moment. They then completed the alternative uses task, a well-established measure of a type of creativity known as divergent thinking. In the task, the participants were asked to generate as many creative uses as they could for a brick in 4 minutes. Then, they provided a self-assessment of their creative output.Two research assistants and a separate sample of 430 individuals recruit via Prolific then viewed and rated the 2,141 ideas that had been generated. In both cases, the raters were blind to the experimental conditions.As expected, participants in the cannabis use condition were more likely to feel “happy” and “joyful” compared to those in the control condition. Those who had consumed cannabis also rated their own ideas as more creative — an effect that was associated with their improved mood. Unexpectedly, however, this state of joviality did not translate into increased creativity. That is, the independent raters found the ideas that had been generated by those in the cannabis condition to be just as creative as those in the control condition.“Cannabis probably won’t actually make you any more or less creative,” Barnes told PsyPost.In a second study, which included 140 participants, the researchers sought to replicate and extend their findings. The participants were again randomly divided into two conditions. But they also completed a measure of cognitive functioning known as the Sternberg memory scanning task. Instead of completing an alternative uses task, the participants were instructed to complete a work-focused creativity task.“Participants were instructed to imagine that they were working at a consulting firm and had been approached by a local music band, File Drawers, to help them generate ideas for increasing their revenues. They were told that their goal was to generate as many creative ideas as possible in 5 min,” the researchers explained.As in the previous study, the participants again provided a self-assessment of their creative output. In addition, they were asked to provide evaluations of other people’s ideas as well.The researchers found that cannabis use did not significantly impact cognitive functioning. However, participants in the cannabis condition tended to have more favorable evaluations of others’ creativity compared to those in the control condition. “Cannabis will make you think you are more creative, and make you think others are more creative as well,” Barnes said.The findings are in line with a previous study, published in the journal Psychopharmacology, which found no evidence that cannabis consumption boosted creativity ability. So why is there a widespread belief that cannabis improves creativity? The positive self-evaluations elicited by cannabis-induced joviality might be the culprit.“The gap between the effect of cannabis on self-evaluations of creativity versus actual creativity explains the common lay belief and why it is actually incorrect,” Barnes told PsyPost.It is also possible that “creative types” are more drawn to cannabis. A study published in 2017 found cannabis users tended to be more extraverted and open to experience. They also performed better than non-users on a test of convergent thinking — meaning the creative process of narrowing down potential solutions to find one correct answer. But their enhanced creativity was entirely explained by their heightened openness to experience.In addition, cannabis might increase creativity — just not the types of creativity that were tested in the current research. It is still possible that cannabis does increase creativity in specific contexts, such as musical and artistic production.“We have two studies which have consistent findings,” Barnes explained. “But this is still a new and developing science. We would not consider our findings to be the final word. Creativity at work across many different contexts is probably much more complex than the relatively simple creativity tasks we used in our 2 studies. So the effects of cannabis on creativity may very well be more complicated than what we found at this stage in the program of research.”“Cannabis has become legalized in many states, and probably will become legalized in many more,” the researcher added. “So many managers will either have to consider how cannabis influences their own work, or manage employees who use cannabis. Rather than ignore cannabis as a taboo topic, management and applied scholars should work to further enlighten the effects of cannabis on work. Future results are bound to be both interesting and important.”The study, “Cannabis use does not increase actual creativity but biases evaluations of creativity“, was authored by Yu Tse Heng, Christopher M. Barnes, and Kai Chi Yam.",0.0,0.0
504,https://techcrunch.com/2022/03/01/source-seed-funding/,Source makes greenhouses smarter to secure the future of food supply,"Agtech startup Source.ag today announced it harvested a $10 million investment to make greenhouses smarter. The founders have set their eyes on a horizon where, driven by climate change and a rapid increase in global food demand as population continues to increase, more crops are being forced indoors to secure greater crop yields. You wouldn’t believe the amount of restraint it takes to not make a pun about seed funding in a piece about greenhouses. I have no such restraint, so let’s report on this, ahem, growth industry.The $10 million funding round was led by Acre Venture Partners, with participation from the E14 fund and food-focused venture firm Astanor ventures. The company also raised from industry insiders, including the international association of (mostly) salad growers Harvest House, tomato specialists Agrocare and bell pepper specialists Rainbow Growers.The company is developing software to empower greenhouses to get smarter. The company argues that greenhouse agriculture is a safer, more reliable and more climate-resilient mode of food production, producing up to 15 times higher yields, using a twentieth as much water as traditional agriculture. What Source adds to the mix is the ability to use data and AI to help greenhouses operate at even higher levels of efficiency and repeatability of high-yield harvests.“Climate change is driving substantial scarcity and strains in our global food supply. As this accelerates in the coming years, we must find ways to scale efficient growing solutions that lighten the footprint of agriculture,” said Lucas Mann, managing partner at Acre. “Greenhouse agriculture is a proven and viable solution, but without innovation, demand will be impossible to meet. We believe Source.ag can play a vital role in driving its global scalability.”The funding will be used to accelerate product development and expand commercial collaborations.“Greenhouses come in all shapes and forms — both more and less technically advanced. On the higher-tech side, want to have control over every dimension you can imagine, including humidity, irrigation and nutrition. Tomatoes, for example, don’t grow in soil. They go in substrate slabs. That means that these operations are arable land independent,” explains Rien Kamman, co-founder ad CEO at Source. “Because you have more control, you’ll have to make more decisions every day. Growers are making decisions on 60-70 parameters every day, which influences how this crop will grow for the rest of the season. You need to get the decision right every day. This might include what to feed the plant, plant-specific parameters, pruning, etc. It’s really a craft and this is why it’s still so hard. You need decades of experience to be doing well at it.”The complexity of the farming operation itself isn’t in doubt, and Source’s pitch is to take all of these growth parameters, combine that with historical crop yield data and market pricing etc., to create a better experience for the growers.“Our system is comprised of two aspects. One is a recommendation system that assesses the current state of the plant. It looks at forward-looking predictors like resource prices, weather, etc. And then gives very concrete recommendations to the grower. What should you do today and tomorrow, both on the plant (i.e. how should you trim it, prune it, etc.) and on the indoor climate around the plants to maximize sustainability and production. The second part is what happens when something doesn’t go to plan? This is where the algorithms come in,” Kamman says. “They collaborate with the different control systems to take that strategy and actually make sure to do so implemented in the most efficient way possible.”Indoor farming still requires a fair chunk of manual labor, especially for big-vine crops such as tomatoes, cucumbers, peppers, etc.; but Source suggests that it can be helpful there, too — by choosing how and where to prune or how many crops to leave to ripen on the vine, you can affect various aspects of the plants’ growth. The interesting thing is overlaying real-time pricing data here — by speeding up or slowing down ripening, I can imagine that could potentially time the harvest time around when your competitors have ripe products, potentially even trading lower yields for better prices, or working with temperatures and weather conditions to reduce production costs, for example.The company is running on a SaaS model, charging growers on a sliding scale depending on the amount of space they are using for growing.“Our belief is that agriculture is at an inflection point in history. [Farming] that brought us to where we are today won’t bring us to 10 billion people with a more changing extreme climate. This is a massive market — the need for climate-resilient food systems is going to increase. And then we haven’t even talked about what other traditional agriculture crops could be moved indoors in the next decades,” says Kamman. “I think that what unites our investors and our team is that we’re not so much looking at these advantages short term, but we can build knowledge that is scalable globally.”The company declined to share screenshots of its product, stating it was “competitively sensitive”.",0.0,0.0
189,https://jamanetwork.com/journals/jamapsychiatry/fullarticle/2797528,Sex Differences in Mental Health Problems and Psychiatric Hospitalization in Autistic Young Adults,"Key PointsQuestion To what extent do young autistic female and male individuals differ in their psychiatric diagnoses and hospitalizations compared with nonautistic individuals?Findings In this population-based cohort study, autistic individuals had higher cumulative incidences for psychiatric disorders and hospitalizations. Compared with autistic male individuals, autistic female individuals were more likely to receive diagnoses and be hospitalized for psychiatric disorders, particularly anxiety, sleep, and depressive disorders.Meaning These findings show the high mental health needs of autistic young adults, particularly autistic female individuals who are at higher risk of receiving a diagnosis of, as well as being hospitalized for, psychiatric problems compared with autistic male individuals.Importance Psychiatric disorders are common among autistic children and adults. Little is known about sex differences in psychiatric disorders and hospitalization in early adulthood.Objective To examine sex differences in psychiatric diagnoses and hospitalizations in autistic compared with nonautistic young adults.Design, Setting, and Participants This population-based cohort study assessed all individuals born in Sweden between 1985 and 1997. A total of 1 335 753 individuals, including 20 841 autistic individuals (7129 [34.2%] female individuals), were followed up from age 16 through 24 years between 2001 and 2013. Analysis took place between June 2021 and August 2022.Exposures Autism was defined as having received at least 1 clinical diagnosis of autism based on the International Classification of Diseases.Main Outcomes and Measures The cumulative incidence of 11 psychiatric diagnoses up until age 25 years was estimated, and birth year–standardized risk difference was used to compare autistic female and male individuals directly. Sex-specific birth year–adjusted hazard ratios (HRs) with 95% CIs were calculated using Cox regression. Analyses were repeated for inpatient diagnoses to assess psychiatric hospitalization.Results Of 1 335 753 individuals included in this study, 650 314 (48.7%) were assigned female at birth. Autism was clinically diagnosed in 20 841 individuals (1.6%; 7129 [34.2%] female) with a mean (SD) age of 16.1 (5.1) years (17.0 [4.8] years in female individuals and 15.7 [5.2] years in male individuals) for the first recorded autism diagnosis. For most disorders, autistic female individuals were at higher risk for psychiatric diagnoses and hospitalizations. By age 25 years, 77 of 100 autistic female individuals and 62 of 100 autistic male individuals received at least 1 psychiatric diagnosis. Statistically significant standardized risk differences were observed between autistic female and male individuals for any psychiatric disorder (−0.18; 95% CI, −0.26 to −0.10) and specifically for anxiety, depressive, and sleep disorders. Risk differences were larger among autistic than nonautistic individuals. Compared with nonautistic same-sex individuals, autistic female individuals (HR range [95% CI], 3.17 [2.50-4.04.]-20.78 [18.48-23.37]) and male individuals (HR range [95% CI], 2.98 [2.75-3.23]-18.52 [17.07-20.08]) were both at increased risk for all psychiatric diagnoses. Any psychiatric hospitalization was statistically significantly more common in autistic female individuals (32 of 100) compared with autistic male individuals (19 of 100). However, both autistic female and male individuals had a higher relative risk for psychiatric hospitalization compared with nonautistic female and male individuals for all disorders (female individuals: HR range [95% CI], 5.55 [4.63-6.66]-26.30 [21.50-32.16]; male individuals: HR range [95% CI], 3.79 [3.22-4.45]-29.36 [24.04-35.87]).Conclusions and Relevance These findings highlight the need for profound mental health services among autistic young adults. Autistic female individuals, who experience more psychiatric difficulties at different levels of care, require increased clinical surveillance and support.IntroductionMental health problems are a major concern in autistic individuals1,2 (note that we use identity-first language [autistic person] rather than person-first language [person with autism] throughout this article according to preferences reported by autistic individuals and their families3). Around 70% of autistic children meet diagnostic criteria for at least 1 psychiatric disorder,4 and 54%5 to 79%6 of autistic adults receive at least 1 psychiatric diagnosis. Mental health problems are reported even among autistic individuals showing good outcomes in other areas of functioning.7Sex differences in mental health have been observed in the general population.8 (Note: The term sex refers to biological attributes of being female or male and is assigned at birth, whereas gender refers to socially constructed attributes9 as discussed in detail elsewhere.10,11) Yet, very few studies have directly investigated sex differences in psychiatric disorders among autistic individuals. Existing evidence suggests that autistic women are particularly vulnerable to psychiatric disorders5 and access psychiatric care more often than autistic men.12 One study13 on health care claims data of children and youth younger than 21 years suggested higher odds of psychiatric difficulties such as anxiety, mood, and sleep disorders in autistic girls compared with boys. A study14 using self-reported gender (instead of sex assigned at birth) in a smaller adult sample found that autistic women experience anxiety, depression, and eating disorders at higher rates than autistic men. To our knowledge, there is only 1 large population-based investigation15 of sex differences across mental health problems in a Danish cohort of autistic and nonautistic children and adolescents. This study showed that autistic female children and adolescents were at increased risk for several psychiatric disorders, compared with autistic male counterparts.A limitation of the aforementioned study is that individuals were only followed up until age 16 years. Therefore, disorders with a later onset, specifically in young adulthood, were not covered. The median age at onset for psychiatric disorders was reported to be 18 years, and more than 60% of the psychiatric problems observed in adulthood emerge for the first time in the transitional period across adolescence and young adulthood before age 25 years.16 This highlights the importance of young adulthood as a particularly sensitive period when psychiatric disorders commonly develop, which is supported by a higher prevalence of psychiatric conditions reported in autistic compared with nonautistic transition-aged youth.17Moreover, no study to date and to our knowledge has examined sex differences in psychiatric diagnoses at different levels of psychiatric care among autistic individuals. This is especially important given higher unmet health care needs in autistic individuals18 due to difficulties in accessing treatment, which might exacerbate mental health problems.19Using representative data from Swedish population registers, we aimed to explore sex differences in psychiatric diagnoses and psychiatric hospitalization among autistic young adults compared with nonautistic individuals.MethodsStudy PopulationThis register-based cohort study was approved by the Regional Ethics Review Board in Stockholm and follows the Strengthening the Reporting of Observational Studies in Epidemiology (STROBE) reporting guideline. Register studies do not require informed consent in Sweden. The study was preregistered via the Open Science Framework on June 16, 2021 (https://doi.org/10.17605/OSF.IO/QZHJS).We linked several nationwide Swedish registers (eAppendix in the Supplement). From the Medical Birth Register20 we identified all individuals born in Sweden between 1985 and 1997 (N = 1 407 253). The follow-up period was 2001 to 2013. We excluded individuals with chromosomal abnormalities (eTable 1 in the Supplement), stillbirths, individuals who died or migrated before their 16th birthday, and whose biological mother was unidentifiable. As data on gender were unavailable, we used sex assigned at birth (male/female) in the Medical Birth Register. We additionally identified sex using the Total Population Register21 and excluded individuals whose sex was missing or reported differently in the 2 registers, since we could not determine the cause of the mismatch or missing values. After exclusions, the eligible cohort included 1 335 753 individuals who were followed up from age 16 years until a diagnosis of the respective psychiatric disorder, their 25th birthday, death, emigration, or end of follow-up on December 31, 2013, whichever came first. The cohort selection process is depicted in eFigure 1 in the Supplement.MeasuresWe defined exposure as receiving at least 1 autism diagnosis from age 1 year onward based on International Classification of Diseases (ICD), Ninth Revision code 299A and ICD-10 codes F84 in the National Patient Register,22 excluding Rett syndrome, other childhood disintegrative disorders, and overactive disorder associated with intellectual disability (ID) and stereotyped movements. The validity of register-based autism diagnosis was reported to be high.23 Autism is a lifelong condition, and age at diagnosis is unlikely to accurately indicate age at onset. We therefore adopted a lifetime approach to autism (with sensitivity analyses to examine the impact of this approach). We defined psychiatric disorders as receiving a clinical outpatient or inpatient diagnosis in the National Patient Register between ages 16 and 24 years; diagnoses received before and after this age span were not considered. We looked at 11 individual disorders, recording the first occurrence of each diagnosis separately as well as first among all diagnoses (any diagnosis). For psychotic, bipolar, and sleep disorders we identified additional individuals through a dispensed prescription of medication in the Prescribed Drug Register24,25 (eTable 2 in the Supplement for ICD and Anatomical Therapeutic Chemical codes). Psychiatric hospitalization was assessed by considering only inpatient admission where psychiatric disorders were the primary reason for hospitalization.Birth year, attention-deficit/hyperactivity disorder (ADHD), and ID were selected as covariates due to their strong associations with autism.4,26,27 ADHD and ID were identified based on a clinical diagnosis in the National Patient Register. Additional individuals with ADHD were identified through a prescription of ADHD medication in the Prescribed Drug Register (eTable 3 in the Supplement).Statistical AnalysesAnalysis took place between June 2021 and August 2022. Data management was performed in SAS statistical software version 9.4.6 (SAS Institute). Data were analyzed using R version 4.0.5 (R Foundation) with the survival,28 drgee,29 and stdReg packages.30Based on matching 10 nonautistic individuals to each autistic individual on sex and birth year, we calculated the sex-specific cumulative incidence at age 25 years as the proportion of individuals who received the respective diagnosis prior to that age, using Kaplan-Meier estimation and thus accounting for censoring during follow-up. To compare autistic female and male individuals, we calculated the birth year–standardized survival probability and risk difference. We further calculated standardized risk differences in nonautistic individuals for comparison. In the full sample, we then used sex-stratified Cox regression models to compare autistic and nonautistic individuals of the same sex while accounting for differences in follow-up time. We calculated hazard ratios (HRs) and 95% CIs for any as well as for each individual psychiatric diagnosis. Attained age was the underlying time scale. In all analyses, we fitted a crude model, a second model adjusted for birth year and a third model further adjusted for ADHD and ID. To explore sex differences in psychiatric hospitalization, we repeated all analyses using only inpatient diagnoses.To account for multiple testing, we used Bonferroni-corrected significance levels in all analyses, adjusted for the number of psychiatric disorders investigated (any disorder and 11 individual psychiatric disorders). Two-sided P values were statistically significant at α = .004. For all models, CIs were estimated using a cluster robust sandwich estimator to account for related individuals in the sample using the maternal identity number.Sensitivity AnalysesTo examine the impact of the lifetime approach to defining autism, we reran the analyses restricting autistic individuals to those diagnosed with autism before age 16 years (a total of 9747 individuals, of which 2731 [28.1%] were female). We performed another sensitivity analysis including only individuals who received an autism diagnosis on more than 1 occasion (a total of 15 735 individuals, of which 5460 [34.7%] were female) to account for diagnostic uncertainty.ResultsCohort DescriptionDescriptive statistics for the study population are presented in Table 1. The cohort included 1 335 753 individuals (650 314 [48.7%] female). Detailed information on race and ethnicity was not available. Autism was clinically diagnosed in 20 841 individuals (1.6%; 7129 [34.2%] female) with a mean (SD) age of 16.1 (5.1) years (17.0 [4.8] years in female individuals and 15.7 [5.2] years in male individuals) for the first recorded autism diagnosis. Percentages of individuals receiving each psychiatric diagnosis are presented in eTable 4 in the Supplement and Figure 1.Sex Differences in Psychiatric DiagnosesWe observed sex differences in the cumulative incidence of psychiatric diagnoses between age 16 and 25 years among autistic individuals: 77 of 100 autistic female individuals, compared with 62 of 100 autistic male individuals, received at least 1 psychiatric diagnosis. Cumulative incidence was higher for autistic female individuals (0.016 [95% CI, 0.012-0.020]-0.52 [95% CI, 0.50-0.53]) than autistic male individuals (0.001 [95% CI, 0.000-0.002]-0.39 [95% CI, 0.38-0.40]) and nonautistic individuals across all individual disorders (eTable 5 in the Supplement). Comparing the standardized survival probability of autistic female and male individuals at age 25 years, we observed a statistically significant standardized risk difference for any diagnosis (−0.15; 95% CI, −0.17 to −0.13), indicating higher risk in female individuals (Figure 2). The same pattern was seen for sleep, depressive, and anxiety disorders (−0.28 [95% CI, −0.34 to −0.23] to −0.12 [95% CI, −0.14 to −0.11]; eFigure 2 in the Supplement). For most disorders risk differences between autistic female and male individuals were in the same direction yet larger than in nonautistic individuals (range of standardized risk differences at age 25 years: autistic individuals, −0.28 [95% CI, −0.34 to −0.23] to −0.007 [95% CI, −0.03 to 0.01]; nonautistic individuals, −0.10 [95% CI, −0.16 to −0.05] to 0.002 [95% CI, −0.03 to 0.03]; eTable 6 in the Supplement).Sex-specific birth year-adjusted HRs showed an elevated relative risk for all disorders for autistic female individuals (HR range [95% CI], 3.17 [2.50-4.04]-20.78 [18.48-23.37]) and male individuals (HR range [95% CI], 2.98 [2.75-3.23]-18.52 [17.07-20.08]) compared with same-sex individuals without an autism diagnosis (Figure 3, model birth year). When adjusting for ADHD and ID, most of the HRs for female and male individuals remained statistically significant, except for alcohol use disorders (Figure 3, model birth year, ADHD, and ID; eTable 7 in the Supplement). The results of the sensitivity analyses including only individuals diagnosed before age 16 years are shown in Table 2 and eFigure 3 in the Supplement. Despite attenuated HRs, autistic female individuals showed higher cumulative incidences for all disorders except alcohol use disorders compared with autistic male individuals. Results from analyses including only individuals with multiple autism diagnoses resembled the main analyses (eTable 8 in the Supplement).Sex Differences in Psychiatric HospitalizationsPercentages of psychiatric hospitalizations are presented in eTable 9 in the Supplement and Figure 1. By age 25 years, 32 of 100 autistic female individuals compared with 19 autistic male individuals, 5 nonautistic female individuals, and 3 nonautistic male individuals were hospitalized due to any psychiatric disorder. Cumulative incidence for inpatient diagnoses was higher in autistic female individuals for all individual disorders (cumulative incidence at age 25 years [95% CI], 0.01 [0.004-0.009]-0.16 [0.14-0.17]), compared with autistic male individuals and nonautistic individuals (eTable 10 in the Supplement). The standardized risk difference comparing autistic female and male individuals was statistically significant for any psychiatric disorder (−0.18; 95% CI, −0.26 to −0.10; Figure 2) but not for individual disorders (eFigure 4 in the Supplement). However, all risk differences showed a higher absolute risk for female individuals. Standardized risk differences were larger for autistic compared with nonautistic individuals (range of standardized risk differences at age 25 years: autistic individuals, −0.18 [95% CI, −0.26 to −0.10] to −0.006 [95% CI, −0.04 to 0.03]; nonautistic individuals, −0.03 [95% CI, −0.17 to 0.11] to 0.002 [95% CI, −0.04 to 0.04]; eTable 11 in the Supplement).Sex-specific birth year–adjusted HRs indicated a higher risk of hospitalizations for autistic female and male individuals compared with same-sex individuals without autism for all inpatient diagnoses (female individuals: HR range [95% CI], 5.55 [4.63-6.66]-26.30 [21.50-32.16]; male individuals: HR range [95% CI], 3.79 [3.22-4.45]-29.36 [24.04-35.87]; Figure 3, model birth year). After adjusting for ADHD and ID, sex-specific HRs remained statistically significant for all disorders, except alcohol use disorder (Figure 3, model birth year, ADHD, and ID; eTable 12 in the Supplement).DiscussionTo our knowledge, this is the largest study on sex differences in psychiatric disorders in autism to date, and the first study to comprehensively investigate psychiatric problems at different levels of psychiatric care in autistic young adults. Autistic young female individuals showed more mental health problems at multiple psychiatric care levels. Compared with autistic male individuals, autistic female individuals were at higher risk for any psychiatric disorder and specifically anxiety, depressive, and sleep disorders. They were also more likely to have been hospitalized for any psychiatric disorder compared with autistic male individuals and nonautistic individuals. Overall, sex differences observed between autistic female and male individuals resembled those in nonautistic individuals (namely higher incidence in female individuals for most disorders), but the differences in cumulative incidence were larger among autistic individuals. The findings of this large, population-based sample, including, to our knowledge, the highest number of autistic female individuals (n = 7129) studied so far, demonstrate a high level of psychiatric difficulties among young autistic female individuals, and thus clearly emphasize this group’s pressing mental health needs. Nevertheless, we need to consider psychiatric disorders in both sexes as psychiatric diagnoses and hospitalizations were more likely in autistic female and male individuals compared with nonautistic individuals of the same sex.This investigation provides an important and novel contribution by exploring sex differences in psychiatric inpatient diagnoses. Our study crucially showed that psychiatric hospitalizations are relatively common in autistic young adults. By as young as age 25 years, 22.1% of autistic female individuals and 10.9% of autistic male individuals (compared with less than 4% among nonautistic individuals) had been hospitalized for psychiatric difficulties, which have the potential to worsen over the course of their lives, if not treated appropriately. These high hospitalization rates partly reflect the severity of the disorder, indicating severe mental health problems in autistic individuals, particularly autistic female individuals. However, person-level factors often interact with system-level factors, such as availability of and barriers to services.31 Facing these barriers might make autistic individuals more likely to delay and avoid health care, thereby exacerbating their mental health problems, potentially leading to acute psychiatric crises that require hospitalization.31,32 Which factors lead to hospitalization and whether autistic individuals benefit from inpatient treatment or whether the hospital environment negatively impacts their mental health should be addressed in future studies.Possible Underlying Mechanisms for the Observed Sex DifferencesDifferent factors may exacerbate psychiatric disorders in autistic female individuals compared with male individuals. One theoretical approach is the multiple minority theory.33 Being autistic and nonmale can be viewed as a form of minority identity.14 Individuals with a minority identity tend to experience increased distress, which adversely impacts their mental health33 and could explain the results observed in this study. More proximal explanations, specifically related to the experience of being an autistic female individual, include female autism presentation34 (a qualitatively and/or quantitatively different expression of autistic symptoms and behaviors which might not be covered by current diagnostic criteria), compensatory behaviors and camouflaging, which may be more common in autistic female individuals,35 delays in diagnosis36,37 and access to support.19 These tend to be interrelated and impact mental health.38,39Besides contributing to psychiatric disorders through delayed diagnosis and access to support,19 the diagnostic bias often observed in autism36 (ie, the earlier identification of autism in young male individuals), could have directly impacted our findings. Likelihood for an autism diagnosis is increased in autistic female individuals presenting with additional problems.39,40 It has therefore been suggested that diagnosed female individuals represent the extreme end of the autistic female population.41 Consequently, autistic female individuals without such comorbidities may be missed and not diagnosed. If additional difficulties in the form of co-occurring disorders are inherent in diagnosed autistic female individuals, this might have introduced bias toward an overestimation of psychiatric disorders in this study. However, the percentages of co-occurring ADHD and ID in our study appeared similar for both autistic female and male individuals, and our estimates are in line with community-based samples recruited from outside clinics.4Clinical ImplicationsResults from this study can inform clinical practice in 2 important ways. First, services for autistic adults are scarce42 and barriers to care are pervasive, subsequently causing gaps and delays in treatment.18,43 Expanding mental health services in the transitional period from childhood to adulthood, particularly for female individuals, to reduce disruption and discontinuation of essential services is a necessary first step to accommodate the needs of autistic young adults.Second, it is essential to tailor services to autistic individuals’ needs. Autistic people, particularly female individuals, often report a lack of autism knowledge and understanding of co-occurring psychiatric disorders19,38,43-45 among medical professionals, sometimes resulting in misdiagnosis.46,47 Improving communication between autistic individuals and medical staff is key, as miscommunication tends to complicate identification and management of co-occurring disorders.48Strengths and LimitationsThe main strength of this study is the large nationwide sample, including a high number of autistic female individuals, which enabled us to comprehensively investigate psychiatric disorders, including rarer disorders. Using both outpatient and inpatient diagnoses based on reliable register data allowed us to investigate psychiatric problems at different psychiatric care levels and to draw more generalizable and robust conclusions. Nevertheless, the study is not without limitations.We cannot exclude the possibility that autistic individuals in our cohort were misdiagnosed with psychiatric disorders or that autism was undiagnosed in individuals without an autism diagnosis. Misdiagnosis of psychiatric disorders,47 and co-occurring disorders overshadowing autistic traits,39 is relatively common in autistic individuals who often report disagreeing with assigned diagnoses.46 Psychiatric diagnoses have yet to be validated in autistic individuals. The extent to which this, together with differences in validity between outpatient and inpatient diagnoses, might have influenced our findings remains uncertain.Although adjusting our analyses for ADHD/ID attenuated our estimates, we did not further stratify our analyses. How complex phenotypes with additional neurodevelopmental difficulties influence mental health in autism should be explored in future research. Initially, we aimed to account for the age of first recorded autism diagnosis, which was shown to influence co-occurring disorders in childhood.15 Underdiagnosis, misdiagnosis, or late diagnosis of autistic women36,49 alongside delays in support access50 may further exacerbate their psychiatric difficulties.19,37 However, outpatient care was only covered from 2001, restricting follow-up time. Earlier autism diagnoses, especially among older individuals, might have been missed, as indicated by the relatively high observed mean age of diagnosis. Studying the association of late diagnosis with mental health could help inferring mechanisms contributing to increased psychiatric difficulties in autistic female individuals.Because no gender variable is available in the registers, we relied on sex assigned at birth to differentiate between female and male individuals. Importantly, as effects of sex and gender are entangled, this does not imply that the observed differences are solely due to biological mechanisms.10 This is relevant because a comparably higher proportion of autistic than nonautistic individuals do not identify with their assigned sex at birth or a binary gender.51 Nonbinary and nonconforming gender identity are particularly prevalent among autistic individuals assigned female at birth,51 potentially contributing to the observed sex differences. Findings from a study14 on mental health in autistic men, women, and nonbinary/transgender individuals indicated higher rates of psychiatric disorders for the latter 2, highlighting the need to identify to which degree autistic nonbinary/transgender individuals face additional barriers, stigma, and exacerbated psychiatric difficulties. Studies on intersectionality, including gender identity as well as other factors such as race, ethnicity, and socioeconomic status, their interaction and subsequent effect on autistic individuals’ mental health constitute important avenues for future research.ConclusionsIn this cohort study, between ages 16 and 25 years, autistic female individuals experienced increased psychiatric difficulties at different levels of psychiatric care, from outpatient diagnoses to hospitalization, compared with autistic male individuals and nonautistic individuals. Higher rates compared with autistic male individuals were found for most psychiatric disorders with sex differences larger than among nonautistic individuals. This study expands the growing body of literature on autistic female individuals’ experiences and consequently the recognition of differing needs in this understudied and underserved group.Back to top Article InformationAccepted for Publication: September 7, 2022.Published Online: October 26, 2022. doi:10.1001/jamapsychiatry.2022.3475Corresponding Author: Miriam I. Martini, MSc, Department of Medical Epidemiology and Biostatistics, Karolinska Institutet, Nobels väg 12a, 17177 Stockholm, Sweden (miriam.martini@ki.se).Open Access: This is an open access article distributed under the terms of the CC-BY License. © 2022 Martini MI et al. JAMA Psychiatry.Author Contributions: Ms Martini had full access to all of the data in the study and takes responsibility for the integrity of the data and the accuracy of the data analysis.Concept and design: Martini, Butwicka, Du Rietz, D’Onofrio, Martin, Rosenqvist, Taylor.Acquisition, analysis, or interpretation of data: Martini, Kuja-Halkola, Butwicka, Du Rietz, Happe, Kanina, Larsson, Lundstrom, Rosenqvist, Lichtenstein, Taylor.Drafting of the manuscript: Martini, Kanina, Taylor.Critical revision of the manuscript for important intellectual content: Martini, Kuja-Halkola, Butwicka, Du Rietz, D’Onofrio, Happe, Larsson, Lundstrom, Martin, Rosenqvist, Lichtenstein, Taylor.Statistical analysis: Martini, Kuja-Halkola, Kanina, Martin, Rosenqvist.Obtained funding: D’Onofrio, Larsson, Lundstrom, Taylor.Administrative, technical, or material support: Kuja-Halkola, Lichtenstein.Supervision: Kuja-Halkola, Butwicka, Du Rietz, Larsson, Lichtenstein, Taylor.Conflict of Interest Disclosures: Dr Du Rietz reported grants from the Swedish Society of Medical Research, the Strategic Research Areas in Epidemiology and Biostatistics (SFOepi), Fredrik & Ingrid Thurings Stiftelse, and Fonden for Psykisk Halsa during the conduct of the study and personal fees from Shire Sweden AB (a Takeda company) outside the submitted work. Dr Happe reported personal fees from Outcomes First Group outside the submitted work and royalties from Taylor & Francis and Routledge publishers for 2 recent books on autism, one of which is an edited book about autism and women and girls. Dr Larsson reported grants and personal fees from Shire/Takeda, personal fees from Evolan, and personal fees from Medici outside the submitted work. Dr Rosenqvist reported grants from the Swedish Research Council during the conduct of the study. No other disclosures were reported.Funding/Support: This study was funded by MQ Mental Health Research (MQF20/19).Role of the Funder/Sponsor: The funder had no role in the design and conduct of the study; collection, management, analysis, and interpretation of the data; preparation, review, or approval of the manuscript; and decision to submit the manuscript for publication.",0.0,0.0
188,https://link.springer.com/article/10.1007/s11127-022-00998-y,Do political protests mobilize voters? Evidence from the Black Lives Matter protests,"Many powerful political movements arise from seemingly insignificant events that set in motion a cascade of consequences. In some cases, the process ultimately results in a change of government or the entire dissolution of a nation. Early theoretical studies struggled to explain the emergence of rebellions, since the reward they provide is a public good, whereas the potentially large costs of participation are borne by the individual (Tullock, 1971). Subsequent literature proposed a variety of explanations consistent with rational choice theory that can reconcile this seeming paradox of revolution. These explanations include bloc mobilization (Oberschall, 1994), uncertainty about the repressive capabilities of the regime (Boix & Svolik, 2013), and social preferences (Shadmehr & Bernhardt, 2011).Footnote 1 In a similar spirit, Kuran (1989) described a framework in which privately held and publicly voiced political preferences can diverge. This results in a bandwagon effect, where individuals hold their political views private until a sufficiently large number of individuals voice similar views.A recent example of such a movement is Black Lives Matter (BLM), which, although officially founded in 2013, mushroomed into a global movement of an almost unparalleled scale following the death of George Floyd in police custody on May 25, 2020. Driven by concerns about perceived racial injustices, protests occurred across the United States, as well as in many cities worldwide.Despite the large scale of the movement and its associated protests, little is known about its political consequences. Although the protests primarily targeted perceived racial injustices, they commonly involved calls to get out the vote and emphasized the importance of registering to vote to achieve political change (New York Times, 2020). Moreover, the protests received a large amount of media coverage across the political spectrum. However, this coverage was marked by a deep ideological divide, as some conservative commentators emphasized the occurrence of violent outbursts at some of these protests, seeking to reinforce their narrative that a Democratic government would threaten public safety (FiveThirtyEight, 2020).These factors suggest that the BLM protests might have contributed in important ways to the record-breaking voter registration levels and turnout observed in the 2020 presidential election by encouraging voters in support of the movement, as well as those opposing it, to cast their vote. In this study, we focus specifically on the impact of local protests on the political mobilization of previously unregistered voters by comparing temporal patterns in voter registration across observationally similar communities with and without large-scale BLM protests.The vast majority of US states require voters to register to vote, a procedure that has long been acknowledged as potentially detrimental to voter turnout, since it compels prospective voters to expend energy at a time when political interest is relatively low (Highton, 1997; Rosenstone & Wolfinger, 1978). Recent years have seen a variety of efforts to increase political participation, including the abolition of voter registration deadlines (Brians & Grofman, 2001), widespread registration drives (Nickerson, 2015), and automatic voter registration when a citizen engages with government entities (McGhee et al., 2021). Despite these advances, there remains a substantial population of eligible yet unregistered voters (Pew Charitable Trusts, 2012), particularly among low-income Americans (Brians & Grofman, 1999). This gap is highly relevant, since interventions aimed at increasing voter registrations have been shown to translate directly into higher voter turnout (Nickerson, 2015).The above-cited research thus suggests that drivers of voter registrations are an important factor to study as we seek to understand political participation in the United States.A distinct advantage of voter registration data over traditional measures of electoral participation is their availability with high frequency. Compared to biennial turnout data, this data availability considerably mitigates potential confounding. One might be concerned about the possibility that protests are endogenous to places where they maximize political mobilization due to unobserved factors, such as the potential for new registrations. As outlined by Azam (2019), such behavior would lead to a biased estimate of the effect of protests in purely cross-sectional regressions. By observing voter registrations in a panel, we can account for such unobserved factors if they are constant during the observed time period (Wooldridge, 2015). We argue that focusing on a short time horizon before and after the protests lends credibility to the assumption that confounding variables did indeed remain constant during our sampling period.However, the use of voter registrations as an outcome also has some limitations that qualify our conclusions in important ways. First, registrations capture only the political engagement of previously unregistered voters. Although studying this population is interesting in its own right, its non-representative nature limits the extent to which findings can be extrapolated to the electorate as a whole (Jackman & Spahn, 2021). Second, the analysis of timing variation in voter registrations requires assumptions about why individuals prefer to register to vote at one point in time rather than another. While time-varying costs of registration are likely important (Cantoni, 2020; Kaplan & Yuan, 2020), we argue that the salience of political events can be a strong motivating factor, especially considering the availability of online voter registration in most states by 2020.Our research contributes to several strands of the literature in economics and political science. Most notably, we analyze the impact of political protests on voter mobilization. This question has previously been studied by Madestam et al. (2013), who found that protests by the Tea Party movement led to a local increase in the vote share for the Republican party. We add to this body of knowledge by providing estimates on the local political mobilization effects of another large-scale political movement, using an alternative outcome and identification strategy. To the best of our knowledge, we are the first to estimate the effect of the Black Lives Matter protests on political mobilization.Footnote 2We further contribute to the vast literature on how voters react to dramatic external events. For example, terrorism has been found to affect voting, even though the violence was committed by independent actors without the support of political parties (Geys & Hernæs, 2020; Montalvo, 2011). The lootings and riots that accompanied some of the BLM protests provided conservative commentators with a powerful narrative contending that under a Democratic government, lootings and riots would be the norm.Footnote 3 Alternatively, the BLM movement can be viewed as an expression of dissatisfaction with prior policy. Voters might be motivated by seeing many citizens openly demand more progress on racial equality and policing. The previous literature on retrospective voting has generally confirmed that voters hold policymakers accountable for failure to control crime (Arnold & Carnes, 2012; Bateson, 2012) or failures of the education system (Holbein, 2016). Experimental evidence has shown that the context and framing in the media matter in determining how voters attribute blame (Healy & Malhotra, 2013; Malhotra & Kuo, 2008). Since conservative and liberal leaning voters consume different news sources (Allcott & Gentzkow, 2017; Bakshy et al., 2015; Gentzkow & Shapiro, 2011), we can expect that they would receive different interpretations of the legitimacy of the Black Lives Matter protests, which might change the extent to which voters are mobilized.Our results do not support the notion that local political protests affected voter mobilization, either in the aggregate or on either side of the political spectrum. Furthermore, we find similar null effects also for the subset of counties in which protests turned violent, although the considerably reduced sample size does not allow us to confidently rule out meaningful effect sizes.Although our results stand in contrast to earlier findings in the literature on the mobilization effects of political protests, these differences might be attributed to the scale of the BLM movement and its extensive media coverage. Similar to the prior literature, our analysis cannot identify the overall impact of the BLM movement but, rather, focuses on the differential in the mobilization effects induced by local protests. The vast media coverage of the BLM movement might have reduced the importance of local exposure, thus contributing to the null effect we estimate in this study.Footnote 4 The major national cable TV networks spent almost 2.5 hours per day reporting about the protests on the weekend after George Floyd’s death (FiveThirtyEight, 2020). In addition, we show that despite considerable variation in interest across states, even areas with little exposure to local protests exhibited substantial interest in BLM, as measured by Google Trends data.Section 2 of this paper describes our data sources and presents descriptive statistics of the sample; Sect. 3 describes our empirical strategy; Sect. 4 indicates our main results, heterogeneity analyses and robustness checks; and Sect. 5 provides a brief conclusion.",0.0,0.0
194,https://news.osu.edu/why-it-is-more-difficult-to-be-poor-in-some-states-than-others/,Why it is more difficult to be poor in some states than others,"Poverty rates vary between U.S. states as much as they do between European countries, a new study suggests.Findings showed that in 2016, poverty rates in the European Union ranged from 6-16% -- compared to 7-29% between U.S. states that same year.There were also sizable differences between states in the risks of poverty – such as unemployment and single motherhood – as well as how much those risks translated into the probability that households would become impoverished.One implication from the findings is that state policies play a pivotal role in how many of their residents live in poverty, said D. Adam Nicholson, author of the study and President’s Postdoctoral Scholar in sociology at The Ohio State University.“If poverty on the national level is to decrease, it likely must start with states,” Nicholson said.“Some states are much more successful than others in minimizing the risks associated with poverty and the penalties that come for those who carry those risks.”The study was published online recently in the journal The Sociological Quarterly.Nicholson used data from the 1993-2016 Annual Social and Economic Supplement of the U.S. Census Bureau’s Current Population Survey, supplemented with other data to improve income estimates. Overall, 3.5 million people were sampled over the 24 consecutive years.For this study, poverty was defined as living in a household with less than 50% of the national median equalized disposable income.Results showed that, over the 24 years, the poverty rate in the poorest state (Mississippi) averaged 24.3% - more than 3.5 times higher than the 6.6% average rate in New Hampshire, which was the lowest.One key to understanding how many people live in poverty is seeing how many residents in a state have one or more of four common risks that often push people below the poverty line: low education, single motherhood, unemployment and having a lead earner under 25 years old.As expected, states with more residents who have one or more of those risks tended to have more people in poverty. On average, one in three people in the U.S. has at least one of these risks.But in high-poverty Mississippi, 42% of residents had at least one of the four risks, compared to 25% in low-poverty New Hampshire.States not only vary in the prevalence of risk, but also in the penalties associated with those risks, Nicholson said. Penalties are the probability that any of the risks will actually push a person into poverty.And the penalties varied widely, results showed. An individual with all four risks would almost certainly experience poverty in Alabama (over 92% probability), while fewer than 25% of individuals with all four risks in Hawaii would expect to be poor.“Poverty in some states may be driven by a high prevalence of risk, while in others it may be driven by high penalties,” Nicholson said. “That’s why it is important to study poverty at the state level and not just the national level.”Changes in some trends identified in the study may be associated with the notable federal welfare reforms in 1996 which allowed states to impose work requirements and other policies that could restrict aid to those at risk of poverty.For example, after the welfare reforms, the variation in the single motherhood penalty across states more than doubled, results showed. “The penalties for single mothers differ a lot depending on the state where they live,” Nicholson said.The penalty for unemployment varied the least among the states, but it is the highest by far, making it the most consequential risk for poverty. And the penalty has increased over time, the study showed.“This supports arguments that work requirements attached to welfare benefits may have important implications for poverty levels,” he said.Race and ethnicity of residents undoubtedly play a key role in the variation in poverty levels between states, and in how states respond to poverty risks, Nicholson said. He will focus more on this issue in a future study.Overall, the results suggest that one way to help reduce poverty in the United States would be for states to mimic policies in their counterparts that have done the best at lowering risks and penalties.If the prevalence of poverty risks in the U.S. matched the lowest prevalence found across states, and the average penalties matched the lowest penalties at the state level, then the U.S. poverty rate would be nearly 5 percentage points lower than it was in 2020, Nicholson said.“That percentage may seem small, but it translates into between 11 and 16 million people being moved out of poverty,” he said. “That would be a huge success.”",0.0,0.0
179,https://phys.org/news/2022-08-infrared-wirelessly-transmit-power-meters.html,Researchers use infrared light to wirelessly transmit power over 30 meters,"Researchers created a new system that uses infrared light to safely transfer high levels of power over distances of up to 30 meters. This type of long-range optical wireless power transfer system could enable real-time power transmission to fixed and mobile receivers. Credit: Jinyong Ha, Sejong UniversityImagine walking into an airport or grocery store and your smartphone automatically starts charging. This could be a reality one day, thanks to a new wireless laser charging system that overcomes some of the challenges that have hindered previous attempts to develop safe and convenient on-the-go charging systems.""The ability to power devices wirelessly could eliminate the need to carry around power cables for our phones or tablets,"" said research team leader Jinyong Ha from Sejong University in South Korea. ""It could also power various sensors such as those in Internet of Things (IoT) devices and sensors used for monitoring processes in manufacturing plants.""In Optics Express, the researchers describe their new system, which uses infrared light to safely transfer high levels of power. Laboratory tests showed that it could transfer 400 mW light power over distances of up to 30 meters. This power is sufficient for charging sensors, and with further development, it could be increased to levels necessary to charge mobile devices.Several techniques have been studied for long-range wireless power transfer. However, it has been difficult to safely send enough power over meter-level distances. To overcome this challenge, the researchers optimized a method called distributed laser charging, which has recently gained more attention for this application because it provides safe high-power illumination with less light loss.""While most other approaches require the receiving device to be in a special charging cradle or to be stationary, distributed laser charging enables self-alignment without tracking processes as long as the transmitter and receiver are in the line of sight of each other,"" said Ha. ""It also automatically shifts to a safe low power delivery mode if an object or a person blocks the line of sight.""Going the distanceDistributed laser charging works somewhat like a traditional laser but instead of the optical components of the laser cavity being integrated into one device, they are separated into a transmitter and receiver. When the transmitter and receiver are within a line of sight, a laser cavity is formed between them over the air—or free space—which allows the system to deliver light-based power. If an obstacle cuts the transmitter-receiver line of sight, the system automatically switches to a power-safe mode, achieving hazard-free power delivery in the air.In the new system, the researchers used an erbium-doped fiber amplifier optical power source with a central wavelength of 1550 nm. This wavelength range is in the safest region of the spectrum and poses no danger to human eyes or skin at the power used. Another key component was a wavelength division multiplexing filter that created a narrowband beam with optical power within the safety limits for free space propagation.""In the receiver unit, we incorporated a spherical ball lens retroreflector to facilitate 360-degree transmitter-receiver alignment, which maximized the power transfer efficiency,"" said Ha. ""We experimentally observed that the system's overall performance depended on the refractive index of the ball lens, with a 2.003 refractive index being the most effective.""Laboratory testingTo demonstrate the system, the researchers set up a 30-meter separation between a transmitter and a receiver. The transmitter was made of the erbium-doped fiber amplifier optical source, and the receiver unit included a retroreflector, a photovoltaic cell that converts the optical signal to electrical power and an LED that illuminates when power is being delivered. This receiver, which is about 10 by 10 millimeters, could easily be integrated into devices and sensors.The experimental results showed that a single-channel wireless optical power transfer system could provide an optical power of 400 mW with a channel linewidth of 1 nm over a distance of 30 meters. The photovoltaic converted this to an electrical power of 85 mW. The researchers also showed that the system automatically shifted to a safe power transfer mode when the line of sight was interrupted by a human hand. In this mode, the transmitter produced an incredibly low intensity light that did not pose any risk to people.""Using the laser charging system to replace power cords in factories could save on maintenance and replacement costs,"" said Ha. ""This could be particularly useful in harsh environments where electrical connections can cause interference or pose a fire hazard.""Now that they have demonstrated the system, the researchers are working to make it more practical. For example, the efficiency of the photovoltaic cell could be increased to better convert light into electrical power. They also plan to develop a way to use the system to charge multiple receivers simultaneously.More information: Nadeem Javed et al, Long-range wireless optical power transfer system using an EDFA, Optics Express (2022). DOI: 10.1364/OE.468766 Journal information: Optics ExpressProvided by Optica",0.0,0.0
163,https://global.chinadaily.com.cn/a/202210/18/WS634e386ea310fd2b29e7d280.html,Systematic test of maglev running in tube successful,"chinadaily.com.cn | Updated: 2022-10-18 13:23A model of the transportation system involving a high-speed maglev train running in a low vacuum pipeline. [File photo/The Third Research Institute of China Aerospace Science and Industry Corp]Chinese researchers have successfully carried out a systematic test on a cutting-edge transportation system involving a high-speed maglev train running in a low vacuum pipeline in North China.The test has achieved a maglev train running up to 130 kilometers per hour along the 2 kilometers test line in Yanggao county of Datong, North China's Shanxi province, according to a news release from the North University of China.This is the first time that such a transportation system anywhere in the world underwent a full-scale and full-process integrated test. A series of tests will be carried out in the future.A groundbreaking ceremony for the planned Shanxi provincial laboratory for high speed maglev vehicles operating in a low vacuum pipeline and the proposed Datong (Yanggao) test line project took place on May 24 last year.The provincial lab is jointly built by the North University of China and the Third Research Institute of China Aerospace Science and Industry Corp, to provide a key test platform for low-vacuum pipeline magnetic levitation technology.The lab will build a full-scale 60-kilometer test track in Yanggao county, with the construction to be implemented in three phases, which will finally achieve a maximum speed of 1,000 km/h.The system uses the latest superconducting magnetic levitation technology to disengage from the ground to eliminate frictional resistance, while employing internal pipelines similar to a vacuum to greatly reduce air resistance.",0.0,0.0
144,https://www.sciencealert.com/tiny-robots-have-successfully-cleared-pneumonia-from-the-lungs-of-mice,Tiny Robots Have Successfully Cleared Pneumonia From The Lungs of Mice,"Scientists have been able to direct a swarm of microscopic swimming robots to clear out pneumonia microbes in the lungs of mice, raising hopes that a similar treatment could be developed to treat deadly bacterial pneumonia in humans.The microbots are made from algae cells and covered with a layer of antibiotic nanoparticles. The algae provide movement through the lungs, which is key to the treatment being targeted and effective.In experiments, the infections in the mice treated with the algae bots all cleared up, whereas the mice that weren't treated all died within three days.The technology is still at a proof-of-concept stage, but the early signs are very promising.""Based on this mouse data, we see that the microrobots could potentially improve antibiotic penetration to kill bacterial pathogens and save more patients' lives,"" says Victor Nizet, a physician and professor of pediatrics at the University of California, San Diego.The nanoparticles on the algae cells are made of tiny polymer spheres coated with the membranes of neutrophils, a type of white blood cell. These membranes neutralize inflammatory molecules produced by bacteria and the body's own immune system, and both the nanoparticles and the algae degrade naturally.Harmful inflammation is reduced, improving the fight against infection, and the swimming microbots are able to deliver their treatment right where it's needed – it's the precision that makes this approach work so well.The researchers also established that the microbot treatment was more effective than an intravenous injection of antibiotics – in fact, the injection dose had to be 3,000 times higher than the one loaded on to the algae cells to achieve the same effect in the mice.""These results show how targeted drug delivery combined with active movement from the microalgae improves therapeutic efficacy,"" says Joseph Wang, nanoengineer from UC San Diego.In humans, the pneumonia caused byPseudomonas aeruginosa bacteria used in this study occurs after patients are put on a mechanical ventilator in intensive care. The infection often prolongs stays in hospital and significantly increases the risk of death.The researchers are confident that their new method can be scaled up as required, and would be straightforward to administer to the lungs of ventilated patients (the microbots were delivered to the mice through a tube in the windpipe).Next up for the team is more research into how the microbots interact with the immune system, then scaling up the work and getting it ready to be tested in larger animals – and then eventually, humans.""Our goal is to do targeted drug delivery into more challenging parts of the body, like the lungs,"" says chemical engineer Liangfang Zhang from UC San Diego. ""And we want to do it in a way that is safe, easy, biocompatible, and long-lasting.""""That is what we've demonstrated in this work.""The research has been published in Nature Materials.",0.0,0.0
147,https://www.psypost.org/2022/10/women-are-more-critical-of-female-toplessness-than-men-which-may-be-explained-by-objectification-theory-64093,"Women are more critical of female toplessness than men, which may be explained by objectification theory","A study published in the journal Sexuality & Culture examined U.S. residents’ attitudes toward women going topless in public places. The findings suggest that for some, female toplessness is intertwined with sexuality and represents a moral issue. In line with objectification theory, women were more critical of female toplessness compared to men.Western societies tend to be far more disapproving of women going topless in public compared to men. The rationale seems to be that female breasts are inherently sexual and thus inappropriate for display in family areas like public beaches. This view fits within objectification theory, which suggests that a woman’s value is based on her appearance, as perceived through the heterosexual male gaze.Researchers Colin R. Harbke and Dana F. Lindemann conducted a study to investigate Americans’ attitudes toward female toplessness in public. While past studies have focused on the public’s perceptions of the legality of female toplessness, the current study aimed to target people’s reactions to female toplessness itself. The researchers also wanted to explore whether attitudes toward female toplessness vary by geographic region, a phenomenon that has been previously reported in Canadian samples.“We were interested in attitudes toward breastfeeding and disparate reactions to being topless in public, without nursing, came to the forefront as an potential contributing factor,” explained Harbke, a professor of psychology at Western Illinois University – Quad Cities.“We began thinking of both of these behaviors as relatively simple and innocuous on the surface, but that each are quite complicated when women’s objectification, morality, and sexism are added to the mix. Also, around that time there were some legal decisions that highlighted differences in the legality of public toplessness between not only men and women, but also between one region or state and the next.”“Most all the prior research on attitudes toward public toplessness focused on this legality issue (e.g., do people think that it should be legal for women to be topless while in public?) and we wanted to expand on this by getting a sense of how people are likely to react if they were to see someone who was topless while out in public.”The study participants were 326 U.S. residents, most of whom (78%) were women. The participants were shown a series of 60 images as part of a larger study. Interspersed within these images were six photos of topless women in one of three public settings — a beach, a park, or a city street. The photos were selected from Internet image searches and consisted of unedited photos of women who were not celebrities or models. To control for implicit biases related to body shape, skin tone, and other factors, the researchers selected only young adult White women with similar appearances.For each photo, participants rated their “impression or feelings when seeing the images” on an 11-point scale from very positive to very negative. The participants then completed demographic questionnaires and measures of disgust sensitivity, child protectiveness beliefs, and sexual attitudes and awareness.According to the findings, 80% of the variance in participants’ ratings was driven by individual differences, rather than differences in the photos. Geographic region was not related to participants’ attitudes.“It was really clear that the driving force in how someone is likely to respond to seeing a topless woman in public is not the setting, region, or the legality of where the toplessness occurs, but rather the characteristics, traits, and opinions of the person who is doing the reacting in the first place,” Harbke told PsyPost. “Even though prior surveys have shown that many people feel that being able to go topless in public should be within women’s legal rights, these findings suggest that that doesn’t necessarily mean that they will react favorably to seeing it around them.”Living in a state where female toplessness is prohibited was associated with less favorable attitudes toward the topless photos, while living in a state with ambiguous policies was related to more favorable attitudes toward the photos. These findings highlight how laws and social norms can influence people’s attitudes toward particular issues.“Much of the prior legality-based research had identified that attitudes toward public female toplessness differed based on the setting (or context) where the toplessness occurred (e.g., on a beach or at a pool, in a public park, or if one were to be walking around the city),” Harbke told PsyPost. “We expected to see differences in reactions to the pictures across settings also, and we did, but they were much smaller in magnitude than in prior legality-based studies.”“The differences in reactions for participants from states where public female toplessness was explicitly legal, explicitly illegal, or where the legality of topless was ambiguous, albeit still present, were also smaller than we anticipated.”There were also significant gender differences in ratings, with women rating the topless photos more negatively compared to men. This finding remained significant after controlling for various demographic and attitudinal variables.“What really surprised us was the magnitude of the difference that we saw between the males and females in our study who rated the images; the differences based on participant sex were about 3-times larger than that for context and nearly twice as large as both context and legality combined,” Harbke explained. “This pattern was consistent the idea that women will sometimes criticize and police other women’s behavior as sexual objects, along with other predictions and extensions from objectification theory.”In their study, Harbke and Lindemann discussed two potential interpretations for this sex difference, both of which can be explained by objectification theory. For one, men might express more favorable attitudes toward the topless photos since they are appealing to them and since they reinforce the sexual objectification of women. For another, women’s less favorable attitudes toward the photos could reflect their “policing” of other women’s behavior.Sexually-objectifying contexts have been found to encourage competition among women, and such dynamics may have led the female participants to object to the sexualized photos. The authors said it is likely that both these explanations play a role.Researchers further unearthed a pattern of findings suggesting that female toplessness is viewed as a moral issue. Higher SES, greater religiosity, and stronger child protectiveness beliefs were related to less positive ratings of the topless photos. By contrast, more positive attitudes toward sexual permissiveness and more egalitarian views of birth control were tied to more positive ratings of the topless photos.A strength of the study was high ecological validity since participants viewed real photos of topless women who they could have hypothetically encountered in real life. However, future research should replicate the study with a larger data set of diverse women of different body shapes, skin tones, and other characteristics.“This is an area of research where efforts to recruit a more diverse sample could lead to some really informative comparisons, especially when it comes to how gender identity and sexual orientations relate to attitudes toward public female toplessness,” Harbke said. “Comparisons that involve pictures of women who are not topless (e.g., wearing a swimsuit) or bare-chested men could also lead to valuable insights.”“Although a relatively understudied area when it comes to attitude research, the issue of public female toplessness brings with it a complex host of factors (e.g., objectification, morality, discrimination, legality) that are shared with a variety or other equal rights and social issues,” the researcher added. “As such, gaining understanding for how demographic and attitudinal factors contribute to reactions to public female toplessness may extend to a multitude of other areas.”The study, “Objectification and Reactions toward Public Female Toplessness in the United States: Looking Beyond Legal Approval“, was authored by Colin R. Harbke and Dana F. Lindemann.",0.0,0.0
464,https://techcrunch.com/2022/09/02/an-action-plan-for-founders-fundraising-in-fintechs-choppy-waters/,An action plan for founders fundraising in fintechâs choppy waters,"This past year has seen a wholesale shift in how the market feels about fintech. A year ago, nearly every investor had a fintech thesis, companies were racing to go public and investors at nearly every stage of the market were fighting to jam money into the hands of founders.That’s not true any longer. The collapse in valuations on the public market has been extreme. A significant number of the biggest fintech companies to go public in the last couple of years are now worth less than the money they’d raised. And that drop in confidence has now permeated to all stages of the market.Understandably, many early founders are unprepared to contemplate that the valuation of their idea — which will likely take about a decade to come to fruition — is now worth 75% less than it would have been six months ago.But the long-term outlook of the sector remains unchanged for most investors and founders. The good news is, we’re still seeing deals getting done. The founders who are succeeding in this environment have adapted to the new reality quickly.Money tends to attract money, so find ways to get the ball rolling.Here are four strategies that the best early-stage fintech founders are now employing to fundraise:Recognize that bid/ask spreads are going to be wideIt’s not you; it’s the market. The best founders recognize that the goal is to close a round, not to maximize the price or minimize dilution.Minimizing dilution is good but not at the cost of losing a deal.Plan for a long fundraiseWhile quick deals with proven founders and exceptional teams still happen, the average fundraising round, including diligence and paperwork, can now take up to four to five months. The days of the Notion-doc-over-a-weekend are firmly in the past.",0.0,0.0
450,https://spectrum.ieee.org/4d-printing-microscale,Micro 4D Printing Builds on Programmable Matter,"Edd Gent is a freelance science and technology writer based in Bangalore, India. His writing focuses on emerging technologies across computing, engineering, energy and bioscience. He's on Twitter at @EddytheGent and email at edd dot gent at outlook dot com. His PGP fingerprint is ABB8 6BB3 3E69 C4A7 EC91 611B 5C12 193D 5DFC C01B. His public key is here. DM for Signal info.",0.0,0.0
123,https://www.newscientist.com/article/2343357-hair-follicles-grown-in-the-lab-in-a-step-towards-hair-loss-treatment/,Hair follicles grown in the lab in a step towards hair loss treatment,"By modifying the embryonic skin cells of mice, researchers created hair follicles that grew up to 3 millimetres long over one monthA hair follicle generated from hair organoids – tiny, simple versions of an organ Yokohama National UniversityMature hair follicles have been grown in a laboratory for the first time, in a move that could one day treat hair loss.Artificially producing hair follicles has historically been very difficult, says Kairbaan Hodivala-Dilke at Queen Mary University of London, who wasn’t involved in the study. “Different types of cells need different sorts of nutrients and when they’re outside the body, they need different sorts of requirements compared to when they’re in the body.”Among mammals, hair follicles are typically produced in embryos as a result of interactions between skin cells and connective tissue.AdvertisementTo better understand these interactions, Junji Fukuda at Yokohama National University in Japan and his colleagues studied hair follicle organoids – tiny, simple versions of an organ.By controlling the organoids’ structure, the team was able to enhance hair follicle growth.“We examined various conditions, including growth factors, activators and inhibitors of signalling pathways and essential culture medium components,” says Fukuda.Read more: Long covid symptoms may include hair loss and ejaculation difficultiesThe team’s main breakthrough was culturing mice embryonic skin cells in a special type of gel, which allowed the cells to be reprogrammed into hair follicles.“If you think of a hair follicle, it’s got the hair down the middle of it and then it’s got layers of epithelial cells around the follicle and other specialised cells,” says Hodivala-Dilke. The gel allows these cells to grow in a laboratory in a way that means they can climb over and around each other [like they do in the body], she says.The hair follicles grew for up to one month, reaching up to 3 millimetres long. “This is probably related to the fact that the hair cycle of mice is about one month,” says Fukuda.The team is now working to recreate the experiment using human cells.According to Hodivala-Dilke, laboratory-grown human hair follicles could one day treat hair loss. “You might be able to take hair from someone whose hair is really lush and make it grow in the lab and then use those follicles to do a transplant,” she says. Existing hair transplants involve moving hair from one part of the body to an area that is thinning or bald, which can cause scarring.“This discovery is not going to cure hair loss, but it lays the foundation for somebody to potentially do so,” says Hodivala-Dilke.Journal reference: Science Advances, DOI: 10.1126/sciadv.add4603",0.0,0.0
444,https://www.technologynetworks.com/neuroscience/news/researchers-reduce-nightmare-frequency-by-altering-dreamers-emotions-367019,Researchers Reduce Nightmare Frequency by Altering Dreamersâ Emotions,"An innovative study has shown that modulating dreamers’ emotions using therapy and audio cues could reduce the frequency of terrifying nightmares.Researchers combined a well-established therapeutic approach for treating nightmares with an innovative and subliminal stimulus that enhanced the benefits of the therapy. The research, conducted by scientists at the University of Geneva, is published in Current Biology.No more nightmares?Nightmares are distressing experiences that virtually all of us have experienced. But for nearly 5% of the adult population, bad dreams become a much more serious issue. These people experience them more than once a week on average.If such regular nightmares start interfering with one’s waking life, leading international classification texts for mental health disorders, such as the Diagnostic and Statistical Manual of Mental Disorders, Fifth Edition (DSM-V), start treating scary dreams as a recognized condition, called nightmare disorder.Why do we have nightmares? The reasons why nightmares occur remain unclear. The authors write that two main models exist – one suggesting that, like insomnia disorders and post-traumatic stress disorder, clinically significant nightmares are related to a state of hyper-arousal. Evidence suggests that the brains of individuals with frequent nightmares are more active during sleep.Another theory relates to memory and fear extinction. This is a process by which the brain unlearns associations between scary events and fear if the association is no longer useful. For example, if we have a painful experience at the dentist, we might come to associate the type of music being played in the waiting room with fear. Under the fear extinction theory, a normal dreamer might hear that music, as the brain tries to reassociate it with a new scenario with a lower level of fear involved. Nightmares, however, are proposed to be a malfunction of this process, where the level of fear is not reduced, meaning the fear stimulus enters our sleeping mind.Nightmares are so common that psychotherapists have developed a bespoke process for treating them, called imagery rehearsal therapy (IRT). First author of the study Dr. Sophie Schwartz explained how IRT works in an interview with Technology Networks. “IRT is a cognitive behavioral technique that encompasses the following steps: recalling the nightmare, changing the negative story line towards a more positive ending and rehearsing the rewritten dream scenario during the day.”IRT practice takes just 5–10 minutes a day, said Schwartz. “A partial remission of nightmare frequency and severity has been observed after regular use of the technique for two to three weeks.”But for around 30% of people with regular nightmares, IRT doesn’t help. To tackle this intractable issue, Schwartz and colleagues recruited 36 patients with nightmare disorder to explore an innovative combination approach.The science of InceptionWhile 18 patients received IRT treatment as standard, the other half of the patient population were unknowingly subject to an additional intervention – the Inception-like targeted memory reactivation (TMR).During these individuals’ IRT sessions, just when they were asked to imagine a happier version of their nightmare, a sound was played – a neutral piano chord. The researchers didn’t explain the purpose of the tone, but the TMR group were told to play the same sound while they practiced their IRT over the next two weeks. While they slept, all participants wore a headband device, the sleep tracker Dreem, enabling researchers to establish when the participants were in rapid eye movement (REM) dream sleep. Unbeknownst to the participants, the researchers had adapted the device to enable it to play the TMR-linked chord to all participants when they entered deep dream sleep.The idea behind TMR is to help the brain associate cues together and boost learning. The researchers hoped that, without realizing it, the tone would help the sleeping participants recall the positive version of their nightmare scenario that they practiced during IRT, improving their sleep. One strength of this approach is that it largely eliminates “expectation effects”. These are confounding factors in experimental design that arise from patients expecting an intervention to make them feel better and getting a placebo effect boost from that expectation. With no knowledge that they were to be played the sound as they slept, the dreamers were free from such effects.Dream a little deeperWhile the participants who received IRT alone had fewer nightmares, those that also received the TMR tone were comparatively sound sleepers, said Schwartz. “The patients reported having fewer nightmares (disturbing bad dreams) over the two weeks of active treatment and still so after three months.”At that three month-mark, TMR dreamers who had been plagued by almost three nightmares a week now had less than half a nightmare over the same period on average. Dreamers who were given just IRT had 1.5 nightmares per week on average, a significantly higher rate.The researchers also surveyed the dreamers, through questionnaires and dream reports, on the emotional quality of their dream world, taking in nightmares and regular dreams. Those played the positively associated sound reported significantly higher levels of joy in their dreams compared to those who only had IRT.The exact method by which this combination of techniques improves sleep quality remains to be deciphered. The participants in the trial didn’t directly recall the positive scenario that was rehearsed in the IRT sessions – a finding that was confirmed using a machine learning technique called latent semantic analysis to scan the dream diaries that participants produced.While these unanswered riddles may keep the research team awake at night, what’s clear is that for those living with disruptive nightmares, this new technique has the potential to help them sleep more soundly.Reference: Schwartz S, Clerget A and Perogamvros L. Enhancing imagery rehearsal therapy for nightmares with targeted memory reactivation. Curr. Biol. 2022; 32: 1–9. doi:10.1016/j.cub.2022.09.032",0.0,0.0
391,https://www.technologyreview.com/2022/09/12/1059266/us-trial-cancer-blood-tests-early-detection/,The US is launching a trial for blood tests that promise to catch cancers earlier,"Questions remain about how to interpret MCED test results. Only some blood tests can pinpoint which organ the cancer is actually in. Lab tests must be run on potentially cancerous tissue to confirm a diagnosis, but you can’t biopsy someone’s entire body. False positives remain an issue for the entire field of cancer screening, which, by design, involves sifting through mounds of healthy tests to find cancer. Galleri—the MCED furthest along the path to widespread use—incorrectly flagged 57 healthy blood samples as cancerous in the aforementioned study.There’s also a risk of jumping the gun—some cancers never become invasive or life-threatening, but early detection could prompt harsh treatment like chemotherapy. Some data suggests that less worrisome cancers actually show up in the bloodstream less, which could minimize that problem.The NIC trial will help determine how blood test results for cancer should be interpreted, and it should provide a standard approach to launching cancer screening studies as companies flood the field with new tests.“I don't think most companies tend to want to compare their tests head to head,” says Timothy Rebbeck, a professor of cancer prevention at Harvard. “It's expensive and difficult. So somebody else, a neutral party like the NCI, needs to.”Rebbeck thinks the blood tests the new trial will vet will prove most helpful in the cases of pancreatic, liver, and ovarian cancer, which kill often and have no other form of screening. Still, longer trials are needed to confirm whether the time bought by these blood tests saves lives.But Rebbeck is optimistic about the Cancer Moonshot’s ultimate goal: “It seems very realistic to me to think that we could reduce death by half,” he says.",0.0,0.0
369,https://techcrunch.com/2016/11/30/sensor-studded-suit-helps-track-recovery-of-stroke-patients/,Sensor-studded suit helps track recovery of stroke patients,"Millions of people suffer from strokes every year worldwide, and severe ones can require long-term care — but as with other rehabilitation regimens, it can be hard for doctors to track the everyday activities of their patients. A high-tech suit created by a Dutch grad student may be a powerful new way to help keep better tabs on those in recovery.Bart Klaassen, from the Netherlands’ University of Twente, and the rest of his team pursued it as part of a project resulting from Europe’s FP7 research initiative. Klaassen’s doctoral thesis is based on the work, as well.The idea is that while patients are closely monitored while at the rehabilitation clinic or in regular checkups, real-world tasks such as getting out of bed, navigating the house and cooking can only be reported secondhand.“There has long been a great need for systems like this, but the technology simply was not ready,” explained Klaassen in a news release from the school. But as other projects along these lines have proved, that’s not the case any more: sensors can be made small enough, fabrics smart enough and the resulting data coherent enough that a high-tech suit like this is not only a possibility, but potentially a major advance.The suit, which is worn underneath the clothes for several months, contains 41 sensors that track strength, flexibility, gait and other relevant metrics. They’re collected wirelessly and processed by (at present) university servers.“We have succeeded in modelling all of the relevant movements, and in cleaning up the data that is relevant for the therapist by filtering out the rest,” said Klaassen. “Our project has delivered new techniques and methods that can be used to monitor patients at home for extended periods of time, and to identify any differences with structured clinical measurements.”Presumably the sensors and data could also be used for tracking progress in cases other than those suffering from strokes, but Klaassen’s research is focused on the one domain for now. If it proves useful it could be adapted for use in other forms of physical therapy.The suit isn’t in production or anything right now and there are plenty of questions, from whether it can be made cheaply to whether it can be washed at all — I’ve emailed the university with some questions and will update the post if I hear back.",0.0,0.0
373,https://techcrunch.com/2019/07/16/how-to-watch-elon-musks-neuralink-brain-control-interface-startup-presentation-live/,Watch Elon Muskâs Neuralink brain control interface startup presentation live,"https://youtu.be/r-vbh3t7WVIOne of Elon Musk’s stealthier endeavors is set to become a lot less stealthy tonight, with a presentation set for 8 PM PT (11 PM ET) streaming live directly via the embedded YouTube video above, in which we’ll learn a lot more about Neuralink, the company Musk founded in 2017 to work on brain control interfaces (BCIs) and essentially part of his larger strategy to help mitigate the risks of AI and enhance its potential benefits.Here’s what we do know about Neuralink already: Its initial goal, at least as of two years ago, was to figure out how brain interfaces could be helpful in alleviating the symptoms of chronic medical conditions, including epilepsy. This goal will involve the development of “ultra high bandwidth brain-machine interfaces to connect humans and computers,” which is the only formal description Neuralink provides of its overall mission on its own website.In a post on Wait Buy Why back when the company first broke cover, we got a lot more in-depth background about what problem Musk wants to solve and why. Summarized, Neuralink’s mission is very much on trend with Musk’s other ventures, in that it hopes to help humans avoid something he perceives as an existential threat in order that we may survive, thrive and I guess come up with other potential existential threats for him to also then solve.Ultimately, Neuralink seems to be aiming well beyond its initial exploration of medical technology, which was really just a way to potentially get testing faster with a practical application that’s easier to work with in terms of rules and regulators. Musk’s goal, per the Wait But Why explainer, is actually to eliminate the “compression” that happens when we translate our thoughts into language, and then into input via keyboard, mouse, etc. before actually transmitting it to a computer. Taking away the need to compress and then decompress the signal, in other words, will make communication between people and computers much faster, lossless and very high bandwidth.This has an existential angle because this is a key step, Musk believes, in ensuring that humanity can keep up with the increasingly advanced AI it’s developing. So to avoid a doomsday scenario where the robots take over, basically Musk proposes more or less mind-melding with the robots instead.That was a lot to digest two years ago — it’s wild to think about what Neuralink may have done in the interim to work toward or modify this goal. Luckily, we won’t have to wait much longer. That stream kicks off at 8 PM PT (11 PM ET) and will be carried live directly at the top of this post and on Neuralink.com.",0.0,0.0
374,https://www.engadget.com/the-cutting-edge-cellular-therapies-aiming-to-ease-america-organ-shortage-140025730.html,The cutting-edge cellular therapies aiming to ease America's organ shortage,"Despite being the wealthiest nation on the face of the planet, the United States chronically runs short of transplantable organs . Kidneys are far and away the most sought-after organ for transplantation , followed by livers. While the liver is the only human organ known capable of regenerating itself, if you damage yours badly enough for long enough — as some 30 million Americans have — then the only treatment is a transplant. Assuming you can even acquire one for doctors to stick in you. Every year demand for replacement livers outstrips supply by a scope of tens of thousands.“Only one-third of those on the liver transplant waiting list will be transplanted, and the demand for livers is projected to increase 23 percent in the next 20 years,” a multidisciplinary team of researchers observed in 2016’s Liver-Regenerative Transplantation: Regrow and Reset . “Exacerbating the organ shortage problem, the donor pool is expected to shrink further because of the obesity epidemic. Liver steatosis [aka fatty liver disease ] is increasingly common in donors and is a significant risk factor in liver transplantation.”To address this critical shortage, the study authors note that doctors have explored a variety of cutting-edge regimens, from cell repopulation and tissue engineering, nanoparticles to genomics, mechanical aids to porcine-derived xenotransplantation, all with varying degrees of success. Cellular repopulation has been used for years, a process that injects healthy liver cells into the patient’s damaged organ through a portal vein where they adhere themselves to the existing cellular scaffolding and grow into new, functional liver tissue.Turn on browser notifications to receive breaking news alerts from Engadget You can disable notifications at any time in your settings menu. Not now Turned on Turn onFabian Bimmer / reuters“Creating an immediately available and inexhaustible supply of functioning liver cells from autologous tissue would allow early intervention in patients with hepatic failure and would allow liver cells to be infused over a longer period of time,” the 2016 study’s authors note. “Combined with recent advances in genome-editing technology, such liver cells could be used widely to treat devastating liver-based inborn errors of metabolism and to eliminate the need for a life-long regimen of immunosuppressive drugs and their complications.” The downside to this technique is the pace at which the donor cells proliferate, making it a poor tool against acute liver failure.Extracellular Vesicle-based therapies, on the other hand, leverage the body’s intracellular communications pathways to deliver drugs with, “high bioavailability, exceptional biocompatibility, and low immunogenicity,” according to 2020’s Extracellular Vesicle-Based Therapeutics: Preclinical and Clinical Investigations . “They provide a means for intercellular communication and the transmission of bioactive compounds to targeted tissues, cells, and organs” including “fibroblasts, neuronal cells, macrophages, and even cancer cells.”EVs are the postal letters that cells send one another. They come in a variety of sizes from 30 to 1000 nm and have exterior membranes studded with multiple adhesive proteins that grant them entry into any number of different types of cells. Exploiting the biological equivalent to a janitor’s key ring, researchers have begun tucking therapeutic nanoparticles into EVs and using them to discreetly inject treatments into the targeted cells. However, these treatments are still in the experimental stages and are most effective against acute liver failure and inborn metabolic diseases rather than end-stage liver failure.Mayo ClinicMechanical aids, the hepatocytic equivalent to a dialysis machine, like the Mayo Spheroid Reservoir Bioartificial Liver (SRBAL, above) are ideal for treating cases of acute liver failure, able to take over the entirety of the patient’s liver function externally and immediately. However, such procedures are both expensive and temporary. The SRBAL can only support a patient for up to two weeks, making it more suitable for keeping someone alive until a donor can be located rather than as a permanent, pacemaker-like solution.The bioprinting and implantation of replacement livers has also shown promise, though they too are still in early development and largely not near ready for widespread adoption. Interspecies transplantation using genetically-engineered pig organs are a bit closer to clinical use , with surgeons successfully transplanting a porcine heart into a human patient for the first time this past January (though he died of complications two months later). Pig kidneys and livers have similarly been transplanted into human recipients, often with less drastic side effects than death.No matter where the transplanted organ comes from, getting it into the patient is invariably going to involve a significant surgical procedure. However, the Lygenesis company recently unveiled its non-invasive solution: tricking the patient’s body into growing a series of miniature, ectopic liver “organoids” in its own lymphatic system like a crop of blood-scrubbing potatoes.For those of you who dozed through high school bio, a quick recap of terms. The lymphatic system is a part of the immune system that serves to circulate some 20 liters of lymph throughout your body, absorb excess interstitial fluids back into the bloodstream, and incubate critical lymphocytes like T-cells . Organoids, on the other hand, are biological masses artificially grown from stem cells that perform the same functions as natural organs , but do so ectopically, in that they function in a different part of the body as a regular liver. Blood-scrubbing potatoes are self-explanatory.“Fundamentally, Lygenesis uses the lymph node, your body's natural bio reactors typically used for T-cells,” company CEO and co-founder Michael Hufford, told Engadget. “We hijacked that same biology, we engraft our therapies into the lymph nodes to grow functioning ectopic organs.”“We use an outpatient endoscopic ultrasound procedure where we're going down through the mouth of the patient using standard endoscopic equipment,” Hufford continued. “We engraft ourselves there in minutes under light sedation, so it's very low medical risk and also is really quite inexpensive.” He notes that the average cost for a proper, in-hospital liver transplant will set you back around a million dollars. Lygenesis’ outpatient procedure “is billed at a couple of thousand or so,” he said.More importantly, the Lygenesis technique doesn’t require a full donated liver, or even a large fraction of one. In fact, each donated organ can be split among several dozen recipients. “Using our technology a single donated liver can reach 75 or more patients,” Hofford said. The process of converting a single donated liver into all those engraftable samples takes a team of three technicians more than six hours and 70 steps to complete. The process does not involve any gene manipulation, such as CRISPR editing.This process is quite necessary as patients cannot donate culturable liver cells to themselves. “Once you have end-stage liver disease, you typically have a very fibrotic liver ,” Hofford noted. “It will bleed at the slightest sort of intervention.” Even the simple act of collecting cellular samples can quickly turn deadly if the wrong bit of organ is bisected.And it’s not only the transplant recipients themselves who are unable to donate. Hofford estimates between 30 and 40 percent of donated livers are too worn to be successfully transplanted. “One of the benefits of our technology is we're using organs that have been donated but will otherwise be discarded,” he said.Once engrafted into a lymph node, the liver organoid will grow and vascularize over the course of two to three months, until it is large enough to begin supporting the existing liver. Hufford points out that even with end-stage disease, a liver can retain up to 30 percent of its original functionality, so these organoids are designed to augment and support the existing organ rather than replace it outright.Lygenesis is currently in Phase 2A of the FDA approval process , meaning that a small group of four patients have each received a single engraftment in a lymph node located in their central body cavity near the liver itself (the body has more than 500 lymph nodes and apparently this treatment can technically target any of them). Should this initial test prove successful subsequent study groups will receive increasing numbers of engraftment, up to a half dozen, to help the company and federal regulators figure out the optimal number of organoids to treat the disease.",0.0,0.0
375,https://techcrunch.com/2019/04/17/consumers-get-another-digital-home-health-offering-as-tyto-care-and-best-buy-launch-tytohome/,Consumers get another digital home health offering as Tyto Care and Best Buy launch TytoHome,"Best Buy is partnering with the Israeli technology company Tyto Care to become the official retailer for the company’s all-in-one digital diagnostics kit through its physical stores in California, the Dakotas, Ohio and Minnesota, and through its online store.Tyto previously sold its technology through healthcare plans, making its handheld examination device (with attachments that act as a thermometer, a stethoscope, an otoscope and a tongue depressor) available to families with insurance that wanted to reduce the cost of checkups through remote monitoring. The company’s handheld device comes with an exam camera so it can prompt users where to position the device to get the most accurate readings.Now, through Best Buy, consumers can buy the company’s kit for $299.99. Through a partnership with American Well, users of the TytoHome kit have access to the company’s LiveHealth Online consultation service (if they live outside of Minnesota or the Dakotas). Which means patients can use the device to perform a medical exam and send the information to a physician for a diagnosis any time of the day or night.As part of the deal, Tyto Care is partnering with additional regional healthcare systems to provide medical care to consumers throughout the country. The first is Sanford Health, a Minnesota-based not-for-profit health system operating in Minnesota, North Dakota and South Dakota.For Best Buy, the move builds on the company’s attempts to move quickly into providing digital healthcare services just like it provides technical support through its Geek Squad.Last year the company bought GreatCall, which sells connected health and emergency response services to the AARP crowd.“We’re excited to partner with Best Buy, LiveHealth Online, American Well and regional health systems to extend our on-demand telehealth platform across the U.S., enhancing primary care delivery,” said Dedi Gilad, the chief executive and co-founder of Tyto Care, in a statement.The company, based in Herzliya, Israel, has raised $56.7 million to date from investors, including Sanford Health, the Japanese Itochu Corp., Shenzhen Capital Group, Ping An, LionBird, Fosun Group, Orbimed and Walgreens.The company said at the time that it would use the cash to expand in the U.S. and to other international markets in Asia and Europe.“These strategic partnerships will enable us to gain further momentum and accelerate our growth, deepening our foothold in the U.S. and other new strategic markets,” said GiladTyto Care said in a statement at the time.",0.0,0.0
466,https://techcrunch.com/2022/07/14/systemiq-vc-70-million-fund-2/,Systemiq secures $70 million to fund early-stage climate tech founders,"Systemiq Capital, a backer of early-stage climate tech startups, says it has secured $70 million to kick off its second fund.The London-based VC aims to raise as much as $130 million more; that would mark quite a step up for the firm, which says it has funneled $30 million into 19 startups since 2018.As far as putting that money to use, Systemiq says it is out to fund founders who are focused on making large industries and cities “more efficient and sustainable.” In practice, it’ll fund key areas like regenerative land use, oceans, transportation and the circular economy.Systemiq’s past deals include climate data company Jupiter, shipping data firm Nautilus Labs (whose co-founder later launched Bedrock) and ESG-focused investing startup OpenInvest. Last year, OpenInvest sold to J.P. Morgan, the world’s top funder of fossil fuels.Systemiq was co-founded by McKinsey veterans Jeremy Oppenheim and Martin Stuchtey. The consulting giant, which pulls in an estimated $10 billion a year in revenue, also has a lengthy history of work with many of the world’s top polluters.Systemiq partner and former Goldman executive Irena Spazzapan will steer the second fund, along with Oppenheim and former Unilever CEO Paul Polman, the firm said.",0.0,0.0
432,https://www.psypost.org/2022/11/pedestrians-give-panhandler-more-than-twice-as-much-money-when-he-wears-a-suit-versus-jeans-experiment-finds-64199,"Pedestrians give panhandler more than twice as much money when he wears a suit versus jeans, experiment finds","In a field experiment, pedestrians gave more than twice as much money to a panhandler when he wore clothes that signaled a higher social class versus a lower social class. Findings from a follow-up study suggest that this was due to inferences about the man’s competence, trustworthiness, humanity, and similarity to the self. The study was published in the journal Frontiers in Psychology.People make assumptions about others based on their social class. For example, people tend to perceive low-status individuals, like those experiencing homelessness or poverty, as lower in warmth and competence. These assumptions appear to influence behavior, leading people to ostracize members of low-status groups.Study author Bennett Callaghan and his colleagues wanted to explore how visible status symbols influence compassionate responding toward others. Are people more giving toward those who emanate high social status versus low social status? Some theoretical accounts suggest that compassionate responding involves judging whether or not a person “deserves” the help. Since low-status individuals are viewed as less trustworthy and competent, they may also be viewed as less deserving of help.“My coauthors and I first got interested in this topic based on research showing how social class and inequality can influence even brief social interactions or conversations,” explained Callaghan (@bennettcallag), an associated researcher at the Stone Center on Socio-Economic Inequality at the City University of New York (CUNY) Graduate Center.“Specifically, we were studying social class signaling: processes through which individuals can identify, with some accuracy, the social class (or socioeconomic status) of others through exposure to very brief and superficial cues (e.g., an accent, 60 seconds of video, or social media profile pictures). Research shows that, consciously or not, when those in power perceive and act on these cues, it leads to all sorts of negative outcomes and denied opportunities for individuals lower in social class, such as discrimination in hiring.”“We began this project to test the limits of just how powerful these cues and perceptions were: whether, instead of looking at something like hiring, we instead looked at behavior that many might think of as being purely selfless and prosocial — helping others — and did so in ‘real-world’ contexts with people sharing their own resources.”In an initial field study, Callaghan and his team tested whether people would be more likely to help a panhandler wearing clothes that signal high social class or low social class. The experiment was conducted in six busy, downtown areas in New York City and Chicago. Across various trials, the confederate stood in the street holding a paper cup and a cardboard sign with a message about homelessness.In the high-status trials, the confederate was dressed in high-status symbols — a suit, dress shirt, a tie, and slick hair. In the low-status trials, he was dressed in low-status symbols — jeans and a t-shirt. Throughout the experiment, research assistants counted the number of passersby, the number of people who donated their money, and the number of people who engaged with the confederate.The results revealed that when the confederate was wearing a suit and tie, he received 2.55 times the amount of money he received when he wore jeans. He was also approached by a larger number of donors when wearing high-status clothing, although this effect was marginally significant.“While we expected that the displaying high-status symbols would lead to an increase in giving, I was still surprised by the size of this difference — a more than two-fold increase in donations,” Callaghan explained. “I was also somewhat surprised by some of the different ways in which people interacted with me, as the confederate, in the two conditions. For instance, when I was dressed in high-status clothing, several individuals gave donations of $5 or $10 and one dropped a business card in my cup rather than give a one-time donation.”Notably, this means that the confederate earned more money when signaling higher socioeconomic status (SES). Interestingly, passersby were equally likely to interact with the confederate — whether they gave him money or not — in both conditions, suggesting that the status symbols influenced the quality of interactions with the panhandler, but not the number of them.The findings provide an indication “of just how powerful an influence social class exerts in our lives and how inequality permeates every aspect of our lived experience: even superficial symbols of social class can have large impacts on our willingness to help others in the moment — and whether we even see these others as deserving of help in the first place,” Callaghan told PsyPost.Next, a follow-up study shed light on why high-status symbols might elicit more compassionate responding. A final sample of 492 people completed an online survey where they viewed photographs of the confederate from Study 1. Depending on the condition, the confederate was pictured panhandling in either high-status or low-status clothing. Participants were asked to rate the target according to various social attributes.The results showed that participants perceived the target in high-status clothing to have higher SES compared to the target in low-status clothing. They also rated the high-status target as higher in competence, warmth, similarity to the self, and humanity.These findings suggest a potential mechanism to explain participants’ behavior in the field experiment. One interpretation is that passersby gave more money to the high-status panhandler because they perceived him to be more deserving of the money. Perceptions that he was more competent and more trustworthy may have led passersby to believe he was more likely to use the money for the intended purpose, such as personal advancement or care, as opposed to using the donations to gain wealth or purchase drugs or alcohol.Alternatively, participants may have judged the high-status confederate to be in a temporary state of need, and thus more likely to reciprocate the altruism at a later time. This would be consistent with an evolutionary concept called reciprocal altruism, which contends that people are motivated to help others who are likely to return the favor in the future.The authors of the study say their findings are evidence that symbols of social status can influence the way people judge others on basic human traits. Moreover, they can affect the tendency to respond to others’ suffering with compassion.“This research provides a further demonstration of the myriad ways in which inequality reproduces itself, and though compassion and generosity are potentially powerful tools to increase others’ wellbeing and promote equality, in this instance, it ironically increased inequality by directing these tendencies toward those who already had access to higher-status symbols (and, thus, might be presumed to be better off in the first place),”“Relatedly, I hope this research leads us to think critically about the way we approach solving social issues such as homelessness. Relying exclusively on the kindness of individuals, such as charitable donations, is more likely to be subject to the types of biases we show here, and while charity obviously has its place in addressing issues of poverty and inequality, we believe this research also shows the need for robust policy solutions and structural changes that ensure that everybody receives the help they need.”But the study, like all research, includes some caveats.“One major caveat in this research is that we do not know, exactly, how to interpret each individual’s behavior in the field experiment: for ethical reasons, we did not intentionally mislead people into thinking that I, as the confederate, was unhoused or that donations would go directly towards helping me,” Callaghan explained. “It is possible that some portion of passersby thought I was collecting on behalf of a charity, for example, and the likelihood of making this inference might depend somewhat on whether or not I was wearing a suit. Future research, then, might help to address this ambiguity by explicitly varying whether donations are going directly to the individual displaying status symbols or whether that individual is collecting on behalf of a third-party.”“The other major caveat concerns the confederate in the field study itself: we know from previous research that important social identity characteristics, such as race and gender, can influence these types of processes in complex ways. Since I collected donations, these results cannot necessarily be generalized beyond targets from advantaged social identity groups, such as those who are generally perceived to be White and male.“It is also possible that, even though I followed a standardized procedure, my own behavior could have contributed to the difference in donations in subtle ways that I was unaware of; future research should definitely investigate whether these same results hold for people from other various and intersecting social identity groups, ideally in a way that does not involve anybody familiar with the study and its hypotheses collecting donations.”The study, “The influence of signs of social class on compassionate responses to people in need“, was authored by Bennett Callaghan, Quinton M. Delgadillo, and Michael W. Kraus.",0.0,0.0
433,https://www.cbs.mpg.de/2055357/20221007-01,How the mother's mood influences her baby's ability to speak,"How the mother's mood influences her baby's ability to speakCommunicating with babies in infant-directed-speech is considered an essential prerequisite for successful language development of the little ones. Researchers at the Max Planck Institute for Human Cognitive and Brain Sciences have now investigated how the mood of mothers in the postpartum period affects their child’s development. They found that even children whose mothers suffer from mild depressive mood that do not yet require medical treatment show early signs of delayed language development. The reason for this could be the way the women talk to the newborns. The findings could help prevent potential deficits early on.If mothers are in a depressive mood two months after birth, their children are less able to process speech sounds on average at six months of age. © shutterstock/GrooveZ If mothers are in a depressive mood two months after birth, their children are less able to process speech sounds on average at six months of age. © shutterstock/GrooveZUp to 70 percent of mothers develop postnatal depressive mood, also known as baby blues, after their baby is born. Analyses show that this can also affect the development of the children themselves and their speech. Until now, however, it was unclear exactly how this impairment manifests itself in early language development in infants.In a study, scientists at the Max Planck Institute for Human Cognitive and Brain Sciences in Leipzig have now investigated how well babies can distinguish speech sounds from one another depending on their mother's mood. This ability is considered an important prerequisite for the further steps towards a well-developed language. If sounds can be distinguished from one another, individual words can also be distinguished from one another. It became clear that if mothers indicate a more negative mood two months after birth, their children show on average a less mature processing of speech sounds at the age of six months. The infants found it particularly difficult to distinguish between syllable-pitches. Specifically, they showed that the development of their so-called Mismatch Response was delayed than in those whose mothers were in a more positive mood. This Mismatch Response in turn serves as a measure of how well someone can separate sounds from one another. If this development towards a pronounced mismatch reaction is delayed, this is considered an indication of an increased risk of suffering from a speech disorder later in life.""We suspect that the affected mothers use less infant-directed-speech,"" explains Gesa Schaadt, postdoc at MPI CBS, professor of development in childhood and adolescence at FU Berlin and first author of the study, which has now appeared in the journal JAMA Network Open. ""They probably use less pitch variation when directing speech to their infants."" This also leads to a more limited perception of different pitches in the children, she said. This perception, in turn, is considered a prerequisite for further language development.The results show how important it is that parents use infant-directed speech for the further language development of their children. Infant-directed speech that varies greatly in pitch, emphasizes certain parts of words more clearly - and thus focuses the little ones' attention on what is being said - is considered appropriate for children. Mothers, in turn, who suffer from depressive mood, often use more monotonous, less infant-directed speech. ""To ensure the proper development of young children, appropriate support is also needed for mothers who suffer from mild upsets that often do not yet require treatment,"" Schaadt says. That doesn't necessarily have to be organized intervention measures. ""Sometimes it just takes the fathers to be more involved.""The researchers investigated these relationships with the help of 46 mothers who reported different moods after giving birth. Their moods were measured using a standardized questionnaire typically used to diagnose postnatal upset. They also used electroencephalography (EEG), which helps to measure how well babies can distinguish speech sounds from one another. The so-called Mismatch Response is used for this purpose, in which a specific EEG signal shows how well the brain processes and distinguishes between different speech sounds. The researchers recorded this reaction in the babies at the ages of two and six months while they were presented with various syllables such as ""ba,"" ""ga"" and ""bu.",0.0,0.0
400,https://www.science.org/content/article/evidence-suggests-pandemic-came-nature-not-lab-panel-says,"Evidence suggests pandemic came from nature, not a lab, panel says","The acrimonious debate over the origins of the COVID-19 pandemic flared up again this week with a report from an expert panel concluding that SARS-CoV-2 likely spread naturally in a zoonotic jump from an animal to humans—without help from a lab.“Our paper recognizes that there are different possible origins, but the evidence towards zoonosis is overwhelming,” says co-author Danielle Anderson, a virologist at the University of Melbourne. The report, which includes an analysis that found the peer-reviewed literature overwhelmingly supports the zoonotic hypotheses, appeared in the Proceedings of the National Academy of Sciences ( PNAS ) on 10 October.The panel’s own history reflects the intensity of the debate. Originally convened as a task force of the Lancet COVID-19 Commission, a wide-reaching effort to derive lessons from the pandemic, it was disbanded by Columbia University economist Jeffrey Sachs, the commission’s chair. Sachs alleged that several members had conflicts of interest that would bias them against the lab-origin hypothesis.Sachs and other researchers who contend the scientific community has too blithely dismissed the lab-leak possibility aren’t persuaded by the new analysis. The task force’s literature analysis was a good idea, says Jesse Bloom, a virologist at the Fred Hutchinson Cancer Center who has pushed for more investigations of the lab-leak hypothesis. But he says the zoonosis proponents haven’t provided much new data. “What we’ve seen is mostly reanalysis and reinterpretation of existing evidence.”Sachs adds that the task force report does not “systematically address” the possible research-related origins of the pandemic. And he contends there was a “rush to judgment” by the National Institutes of Health and “a small group of virologists” to dismiss the possible research-related origins of the pandemic. In September, The Lancet published a report from his commission that gave equal weight to both hypotheses.When Sachs launched the Lancet origin task force in December 2020, he tapped conservation biologist Peter Daszak to lead it. Daszak heads the nonprofit EcoHealth Alliance, which has funded work on bat coronaviruses at the Wuhan Institute of Virology (WIV). Because the first COVID-19 cases were reported in Wuhan, China, some scientists suspect research conducted at WIV led to the spread of SARS-CoV-2. Sachs came to believe Daszak and other task force members who had links to WIV and the EcoHealth Alliance could not assess that possibility fairly and should step down. After fierce infighting over issues including transparency and access to information, Sachs pulled the plug on the task force in September 2021.But the members continued to meet. “We had a distinguished, diverse group of experts across a whole range of disciplines, and we thought we had something to offer whether or not we were part of the commission,” says Gerald Keusch, an infectious disease specialist at Boston University.In assembling its report, the task force interviewed researchers who have different perspectives on the pandemic’s origin. It also reviewed the history of RNA viruses, like SARS-CoV-2, that naturally have made zoonotic jumps and triggered outbreaks. And it combed through the scientific literature for papers addressing COVID-19’s origins.The final product overlaps with the wider ranging Lancet commission report. Both stress the need to address how forces such as growing deforestation and the illicit trade of wild animals increase the risk of viral spillovers. Both emphasize the risk of lax safety measures in labs, as well as in field studies that hunt for pathogens.But the two reports part ways when it comes to the origin of the pandemic.The PNAS authors say their literature search revealed “considerable scientific peer-reviewed evidence” that SARS-CoV-2 moved from bats to other wildlife, then to people in the wildlife trade, finally causing an outbreak at the Huanan Seafood Market in Wuhan. In contrast, they say, relatively few peer-reviewed studies back the lab-leak idea, and Daszak notes much of the argument has been advanced through opinion pieces. “The most parsimonious hypothesis is that the pandemic emerged through the animal market system,” Daszak says. “And while the evidence could be a lot better, it’s fairly good.”He also agrees, however, that the question of how the pandemic began has yet to be answered conclusively. No one has independently audited how viruses were handled at WIV, for example. And no reports exist of scientists testing mammals at animal farms in China that supplied the Huanan market or the humans who handled them. “Absent those two critical pieces of data, you’re left with what’s available,” Daszak says. “What we concluded is that the weight and quality of the evidence is far higher on the natural origins idea.”The PNAS perspective also stands apart for its recommendations on how to improve warnings that a pandemic is brewing. In a section called “looking forward,” the authors promote “smart surveillance” that would concentrate on transmission hot spots where humans and wild animals frequently come in contact, using cutting-edge technologies to look for novel viruses. Assays now exist that can measure antibodies to an enormous range of viruses, offering evidence of infections that occurred in the past. Wastewater sampling could use new polymerase chain reaction techniques to fish for both known and novel pathogens. And researchers could sample the air on public transport and manure pits on farms.“For nearly 3 years we’ve been running in circles about different lab-leak scenarios, and nothing has really added to this hypothesis,” says co-author Isabella Eckerle, a virologist at the University of Geneva. “We have missed the chance to say … what can we do better the next time?”Co-author Linda Saif, a swine coronavirus researcher at Ohio State University, Wooster, says studies of human and animal viral infections remain too siloed and must be combined. “There’s no source of funding for those at this time.”",0.0,0.0
99,https://techcrunch.com/2022/05/17/legl-series-b/,"Legl, a SaaS for law firm workflows, tops up with $18M","While valuations of public software-as-a-service businesses have beenWhile valuations of public software-as-a-service businesses have beenToday, London-basedToday, London-basedThe Series B was led by several technology investors, including existing investor Octopus Ventures (which led its Series A), although Legl isn’t specifying the round’s other backers. Previously disclosed investors in the business include Backed, Samaipata and First Round Capital, plus a number of angels.The Series B was led by several technology investors, including existing investor Octopus Ventures (which led its Series A), although Legl isn’t specifying the round’s other backers. Previously disclosed investors in the business include Backed, Samaipata and First Round Capital, plus a number of angels.The startup says it has grown its customer base from around 100 UK-based law firms back in March 2021 to 170+ now — which it specifies includes 20 of the Top 200 firms in the country.The startup says it has grown its customer base from around 100 UK-based law firms back in March 2021 to 170+ now — which it specifies includes 20 of the Top 200 firms in the country.It’ll be using the Series B to kick off planned international expansion, focusing on other markets where its UK client base has offices and ploughing cash into product dev and hiring.It’ll be using the Series B to kick off planned international expansion, focusing on other markets where its UK client base has offices and ploughing cash into product dev and hiring.“There is a global opportunity for law firms to run their businesses in a more modern, efficient, revenue-driving and client-friendly way. We are working with our client base to start expanding out to their international offices which lie across multiple different geographies,” says founder and CEO, Julia Salasky.“There is a global opportunity for law firms to run their businesses in a more modern, efficient, revenue-driving and client-friendly way. We are working with our client base to start expanding out to their international offices which lie across multiple different geographies,” says founder and CEO, Julia Salasky.“Over the past year, we’ve built out our vision of a new category in the legal space — client lifecycle management — by investing in the underlying CRM that enables law firms not only to digitize previously manual business workflows across the client lifecycle but to understand their client base better. We’ve leaned into our core competencies in risk management, compliance and payments and finance, enabling law firms to both undertake activities that touch on their regulated business processes but also improve cashflow and drive better client experience.“Over the past year, we’ve built out our vision of a new category in the legal space — client lifecycle management — by investing in the underlying CRM that enables law firms not only to digitize previously manual business workflows across the client lifecycle but to understand their client base better. We’ve leaned into our core competencies in risk management, compliance and payments and finance, enabling law firms to both undertake activities that touch on their regulated business processes but also improve cashflow and drive better client experience.“With the new funding we will expand our workflow driven approach to managing business operations and in particular focus on how law firms can drive faster revenue, better and de-risked financial management and a better client experience. We already enable law firms to manage a large proportion of their client base and payment stack and plan to drive more capabilities for more firms over the coming months,” she adds.“With the new funding we will expand our workflow driven approach to managing business operations and in particular focus on how law firms can drive faster revenue, better and de-risked financial management and a better client experience. We already enable law firms to manage a large proportion of their client base and payment stack and plan to drive more capabilities for more firms over the coming months,” she adds.Salasky, whose name may also be familiar as prior founder of theSalasky, whose name may also be familiar as prior founder of theShe declines to disclose the startup’s valuation for the Series B but confirms the raise was certainlyShe declines to disclose the startup’s valuation for the Series B but confirms the raise was certainly“This is a big up round for us! Last round, last year we raised $7M and this is an $18M round (closed in this new funding climate!), building on the revenue growth and momentum we’ve had,” she notes.“This is a big up round for us! Last round, last year we raised $7M and this is an $18M round (closed in this new funding climate!), building on the revenue growth and momentum we’ve had,” she notes.Discussing whether the SaaS startup is feeling any impact from a wider market cooling on tech and SaaS stocks, she adds: “Law firms are notoriously counter-cyclical businesses, so they don’t tend to suffer as much as traditional corporates in a downturn. But in general what we see is that as we demonstrate increased value to law firms and drive better core business operations, we become more, not less valuable, irrespective of market conditions.”Discussing whether the SaaS startup is feeling any impact from a wider market cooling on tech and SaaS stocks, she adds: “Law firms are notoriously counter-cyclical businesses, so they don’t tend to suffer as much as traditional corporates in a downturn. But in general what we see is that as we demonstrate increased value to law firms and drive better core business operations, we become more, not less valuable, irrespective of market conditions.”Legl founder and CEO, Julia Salasky (Legl founder and CEO, Julia Salasky (Legl founder and CEO, Julia Salasky (Legal and compliance tech has been an increasingly active category for startups in recent years. But Salasky suggests most of the action has focused on contract management or other targeted ‘point solutions,’ whereas Legl aims to stand apart by offering a more holistic platform for law firms to power up their ability to serve clients by providing them with a suite of digital tools that can automate and support their business operations. This frees up in-house expertise to focus on more of the core legal work.Legal and compliance tech has been an increasingly active category for startups in recent years. But Salasky suggests most of the action has focused on contract management or other targeted ‘point solutions,’ whereas Legl aims to stand apart by offering a more holistic platform for law firms to power up their ability to serve clients by providing them with a suite of digital tools that can automate and support their business operations. This frees up in-house expertise to focus on more of the core legal work.“There is an explosion of investment in contract management and other areas where the substantive legal work could be improved. But what we are doing at“There is an explosion of investment in contract management and other areas where the substantive legal work could be improved. But what we are doing atCommenting on the Series B in a statement, Malcolm Ferguson, investor at Octopus Ventures, added: “We’re delighted to continue to support Julia and the team on their mission to free up lawyers’ time so they focus on creating value for their clients.  The company has grown really strongly over the last 12 months, and is positioning itself to become the go-to solution for law firms looking to modernise and automate their non-core work. Not only does this improve a law firm’s revenues, and margins, but [it] also means they can deliver a meaningfully better experience to their clients.  We’re excited to see what Julia can achieve with this funding over the coming years.”Commenting on the Series B in a statement, Malcolm Ferguson, investor at Octopus Ventures, added: “We’re delighted to continue to support Julia and the team on their mission to free up lawyers’ time so they focus on creating value for their clients.  The company has grown really strongly over the last 12 months, and is positioning itself to become the go-to solution for law firms looking to modernise and automate their non-core work. Not only does this improve a law firm’s revenues, and margins, but [it] also means they can deliver a meaningfully better experience to their clients.  We’re excited to see what Julia can achieve with this funding over the coming years.”",0.0,0.0
548,https://www.technologyreview.com/2022/10/21/1062001/spacex-starlink-signals-reverse-engineered-gps/,Starlink signals can be reverse-engineered to work like GPSâwhether SpaceX likes it or not,"In a non peer-reviewed paper published on arXiv, Humphreys claims to have provided the most complete characterization of Starlink’s signals to date. This information, he says, is the first step toward developing a new global navigation technology that would operate independently of GPS or its European, Russian, and Chinese equivalents.“The Starlink system signal is a closely guarded secret,” says Humphreys. “Even in our early discussions, when SpaceX was being more cooperative, they didn’t reveal any of the signal structure to us. We had to start from scratch, building basically a little radio telescope to eavesdrop on their signals.”To get the project started, UT Austin acquired a Starlink terminal and used it to stream high-definition tennis videos of Rafael Nadal from YouTube. This provided a constant source of Starlink signals that a separate nearby antenna could listen in on.Humphreys quickly realized that Starlink relies on a technology called orthogonal frequency-division multiplexing (OFDM). OFDM is an efficient method of encoding digital transmissions, originally developed at Bell Labs in the 1960s and now used in Wi-Fi and 5G. “OFDM is all the rage,” says Mark Psiaki, a GPS expert and aerospace professor at Virginia Tech. “It’s a way to pack the most bits per second into a given bandwidth.”The UT Austin researchers did not try to break Starlink’s encryption or access any user data coming down from satellites. Instead, they sought out synchronization sequences—predictable, repeating signals beamed down by the satellites in orbit to help receivers coordinate with them. Not only did Humphreys find such sequences, but “we were pleasantly surprised to find that they [had] more synchronization sequences than is strictly required,” he says.Each sequence also contains clues to the satellite’s distance and velocity. With the Starlink satellites transmitting about four sequences every millisecond “that’s just wonderful for dual use of their system for positioning,” says Humphreys.If the terrestrial receiver has a good idea of the satellites’ movements—which SpaceX shares online to reduce the risk of orbital collisions—it can use the sequences’ regularity to work out which satellite they came from, and then calculate the distance to that satellite. By repeating this process for multiple satellites, a receiver can locate itself to within about 30 meters, says Humphreys.",0.0,0.0
494,https://techcrunch.com/2022/03/16/cooks-venture-found-podcast-vc-backed-chicken/,The VC-backed chicken thatâs changing the way farmers breed and feed their livestock,"Most people don’t spend much time thinking about where their poultry comes from, much less what it was eating when it was alive but the feeding practices on large farms are harmful to the environment and have led to bland, unhealthy chickens. Today’s guest, Matthew Wadiak is a chef and founder and CEO of Cooks Venture, which is on a mission to create a new breed of broiler chicken that is more active, able to eat a varied diet and tastier. Through restorative agriculture and selective breeding, the Cooks Venture farm in Arkansas has bred chickens that are more heat resistant and can eat a variety of grains. As a chef and former co-founder of Blue Apron, Wadiak views it as his duty to try to change the food system for the better.Most people don’t spend much time thinking about where their poultry comes from, much less what it was eating when it was alive but the feeding practices on large farms are harmful to the environment and have led to bland, unhealthy chickens. Today’s guest, Matthew Wadiak is a chef and founder and CEO of Cooks Venture, which is on a mission to create a new breed of broiler chicken that is more active, able to eat a varied diet and tastier. Through restorative agriculture and selective breeding, the Cooks Venture farm in Arkansas has bred chickens that are more heat resistant and can eat a variety of grains. As a chef and former co-founder of Blue Apron, Wadiak views it as his duty to try to change the food system for the better.Watch the Cooks Venture videoWatch the Cooks Venture videoDon’t miss the next live episode with Shivani Siroya from Tala on 3/17 at 10 p.m. PDT/ 1 p.m. EDT.  RSVP:Don’t miss the next live episode with Shivani Siroya from Tala on 3/17 at 10 p.m. PDT/ 1 p.m. EDT.  RSVP:Take our listener surveyTake our listener surveyConnect with us:Connect with us:",0.0,0.0
130,https://www.psychologytoday.com/us/blog/how-do-you-know/202210/facebook-caused-poor-mental-health-the-beginning,Facebook Caused Poor Mental Health From the Beginning,"Source: Photo by Pixabay on Pexels.There is an epidemic of mental health problems in the U.S., and social science research is increasingly finding a connection between social media and poor mental health. This has been documented in correlational studies–which examine when two things are related, without being able to show one definitely causes the other. It has also been seen in experiments, which do allow us to establish cause and effect. For example, people who were randomly assigned to give up social media reported feeling less depression and anxiety after a week, compared to those randomly assigned to keep using social media as normal.A prominent argument on this issue is that a change in the feed—what users see when they log in to Facebook (and similar social media sites)—led social media to be particularly harmful to mental health. Yet new research using an innovative design to test whether Facebook caused mental health problems contradicts this story. Facebook has been causing poorer mental health in college students since it was first rolled out among a small group of elite colleges and universities. The study also provides some evidence for why Facebook might be causing mental health problems.First, the design: This study looked at 2004 to 2006, the period when Facebook expanded from just being available to Harvard students to then being rolled out at an increasing number of colleges and universities. National surveys were being collected on the mental health of college students throughout this time, which could be connected to the dates at which Facebook was introduced on each campus. This allowed the researchers to use a new tool for establishing cause-and-effect: a difference-in-differences analysis.The analysis looks at levels of mental health problems before Facebook was introduced, and then compares it to the levels afterwards. This allows for statistical adjustments to be made that account for baseline mental health at that college and any trends that might have been going on before Facebook was introduced. The fact that there are 58 different schools, each gaining access to Facebook at different times, means that this comparison can be made over and over. The results therefore reflect the pattern seen as Facebook was introduced at each new school. While this study didn’t include an experiment (the gold standard for establishing cause-and-effect), it was able to use advanced statistical techniques to check their assumptions about a cause-effect relationship.Source: Photo by mikoto.rawPhotographer on PexelsThe key findings, which were confirmed after checking multiple assumptions, are that after Facebook was introduced to a campus, more students on that campus reported having depression and anxiety disorders. In particular, they were more likely to say they felt hopeless, exhausted, and “severely depressed.” When Facebook was introduced to a campus, more students were also reporting that mental health problems affected their academics. Further, the effect was strongest among students who were already most susceptible to mental illness. In other words, Facebook made college students already predisposed to depression or anxiety more likely to actually experience poor mental health.Prior discussions of Facebook emphasized the way the platform evolved over time. ‘It started out simple, with friends sharing photos and details of their lives,’ the popular narrative goes. ‘Only later did the ability to gain a large audience from a post drive people to change their behavior to be better picked up by the algorithm.’ The modern experience of Facebook—with direct marketing, personal brand building, and political flamethrowing—is the problem, and it’s something that emerged after people learned how to ‘game the algorithm’ of the social media site. For example, psychologist Jonathan Haidt suggests that Facebook began to cause more problems after three changes to the site: the introduction of the feed–a constantly updating timeline of posts—in 2006, the addition of the “Like” button in 2009, and later the use of internal algorithms to show content that was predicted to drive engagement. The new research shows that this isn’t true: Facebook was causing poorer mental health from the start, before these innovations were rolled out.If Facebook had a negative effect on college students’ mental health from the beginning, this suggests that it’s not just trolls, propagandists, and a new breed of bad or cynical actors on the site that caused it. It’s something that’s been baked in from the beginning. The authors of the new research paper suggest that this deeper culprit is something much older and more common in our culture: social comparison.Source: Photo by Helena Lopes on Pexel.To support this idea, the new study does analyses of several groups of students who would be expected to compare themselves negatively to others at their college or university. For example, they found that Facebook led to even large declines in mental health for students who lived off campus. These students might believe that they weren’t experiencing as much of the “full college experience” as students living on campus. Several other related categories were examined, including not being in a fraternity or sorority; having to work on top of going to school; being overweight; and having credit card debt. In each case, being in the category that does not match the “idealized” version of a college experience was related to having worse mental health—but not always at a statistically significant level.Social media allows you to see large amounts of your peers’ lives in intimate detail, which can magnify opportunities for comparing your own life to theirs. With so many more people to compare yourself to, and so much more of your time spent looking at these comparisons, college students may have naturally started to find themselves lacking. It would be nice to believe that just by clearing out bots and advertisements, we could make Facebook a healthy source of connection. But it may be the core feature of social media itself—the ability to share private moments of daily life with friends and peers—that actually causes harm.",0.0,0.0
381,https://www.newscientist.com/article/2342535-personal-lubricant-made-from-cow-mucus-may-protect-against-hiv/,Personal lubricant made from cow mucus may protect against HIV,"In a laboratory study, human epithelial cells were treated with the lubricant before being exposed to HIV or a herpes virus, with subsequent infection rates being as low as 20 per centThe mucus in cows’ salivary glands may have anti-viral properties Getty ImagesA lubricant derived from the mucus of cow salivary glands has shown promise at preventing the human immunodeficiency virus (HIV) and a herpes virus from infecting healthy human cells.Mucus is a protective gel that lubricates the epithelial tissues that cover our organs and line our body cavities, as well as acting as a first line of defence against microorganisms. The main component of mucus, a protein called mucin, may have antiviral properties.Hongji Yan at the KTH Royal …",0.0,0.0
159,https://techcrunch.com/2008/02/21/uks-new-badass-binocs-combo-infrared-gps-to-target-baddies-three-miles-away/,"UK's new badass binocs combo infrared, GPS to target baddies three miles away","[photopress:jtasbino.jpg,full,center]Like a Certs being a candy mint and a breath mint, the SSRF is a rangefinder and a GPS targeting computer. Using a combination of technologies, the Surveillance System and Range Finder is used to identify enemies up to three miles away, then using the GPS, they call in the big guns to wipe them off the Earth. Kinda creepy.Look for a Terminator-embedded version shortly after Skynet goes active later this year.J-Tas Surveillance System Has GPS, Thermal Imaging, Hunts Predators [The Giz]",0.0,0.0
8,https://www.economist.com/business/2022/10/24/the-end-of-apples-affair-with-china,The end of Appleâs affair with China,"B y a dusty stretch of the deafening road from Chennai to Bengaluru lie three colossal, anonymous buildings. Inside, away from the din of traffic, is a high-tech facility operated by Foxconn, a Taiwanese manufacturer. A short drive away Pegatron, another Taiwanese tech firm, has erected a vast new factory of its own. Salcomp, a Finnish gadget-maker, has set one up not far away. Farther west is a 500-acre campus run by Tata, an Indian conglomerate. What these closely guarded facilities have in common is their client: a demanding and secretive American firm known locally as “the fruit company”.Listen to this story. Enjoy more audio and podcasts on iOS or Android Your browser does not support the <audio> element. Listen to this story Save time by listening to our audio articles as you multitask OKThe mushrooming of factories in southern India marks a new chapter for the world’s biggest technology company. Apple’s extraordinarily successful past two decades—revenue up 70-fold, share price up 600-fold, a market value of $2.4trn—is partly the result of a big bet on China. Apple banked on China-based factories, which now churn out more than 90% of its products, and wooed Chinese consumers, who in some years contributed up to a quarter of its revenue. Yet economic and geopolitical shifts are forcing the company to begin a hurried decoupling. Its turn away from China marks a big shift for Apple, and is emblematic of an even bigger one for the world economy.Apple’s packaging proclaims “Designed by Apple in California”, but its gadgets are assembled along a supply chain that stretches from Amazonas to Zhejiang. At the centre is China, where 150 of Apple’s biggest suppliers operate production facilities. Tim Cook, who was Apple’s head of operations before he became chief executive in 2011, pioneered the firm’s approach to contract manufacturing. A regular visitor to China, Mr Cook has maintained good relations with the Chinese government, obeying its requirements to remove apps and to hold Chinese users’ data locally, where it is available to the authorities.Now a change is under way. Big tech is showing strains. On October 25th Alphabet and Microsoft presented disappointing quarterly results. Meta, which lost another fifth of its value after reporting the second straight quarter of declining sales, is a shadow of its former self. Apple’s latest earnings, due out after The Economist went to press on October 27th, may be dented by creaky Chinese supply chains and softening demand from Chinese consumers. So Mr Cook, who has not been seen in China since 2019, is wooing new partners. In May he entertained Vietnam’s prime minister, Pham Minh Chinh, at Apple’s futuristic headquarters. Next year Apple is expected to open its first physical store in India (whose prime minister, Narendra Modi, is a fan of gold iPhones).The two countries are the main beneficiaries of Apple’s strategic shift. In 2017 Apple listed 18 large suppliers in India and Vietnam; last year it had 37. In September, to much local fanfare, Apple started making its new iPhone 14 in India, where it had previously made only older models. The previous month it was reported that Apple would soon start making its MacBook laptops in Vietnam. Some of Apple’s newer gadgets show the way things are going. Almost half its AirPod earphones are made in Vietnam and by 2025 two-thirds will be, forecasts JPMorgan Chase. The bank reckons that, whereas today less than 5% of Apple’s products are made outside China, by 2025 the figure will be 25% (see chart 1). As Apple’s production system is shifting, its suppliers are diversifying away from China, too. One crude measure of this is the share of long-term assets that Taiwanese tech-hardware and electronics firms have located in China. In 2017 the average figure was 43%. Last year that had fallen to 31%, according to our estimates using company and Bloomberg data. The most urgent reason for the scramble is the need to spread operational risk. Two decades ago the garment industry beefed up its operations outside China after the sars epidemic paralysed supply chains. “ sars made it very clear to everyone operating in China that you needed a ‘China+1’ strategy,” observes Dominic Scriven of Dragon Capital, an investment firm in Vietnam. Covid taught tech firms the same lesson. Lockdowns in Shanghai in the spring temporarily shut a factory run by Quanta, a Taiwanese firm, believed to be making most of Apple’s MacBooks. Avoiding this kind of chaos is the “primary driving force” for Apple’s supply-chain moves, says Gokul Hariharan of JPMorgan Chase. Another motive is containing costs. Average wages in China have doubled in the past decade. By 2020 a Chinese manufacturing worker typically earned $530 a month, about twice as much as one in India or Vietnam, according to a survey by JETRO , a Japanese industry body. India’s ropey infrastructure, with bad roads and an unreliable electrical grid, held the country back. But it has improved, and the Indian government has sweetened the deal with subsidies. Vietnam offers tax rebates and holidays, too, as well as free-trade deals, including one recently signed with the eu . Bureaucracy around visas and customs remains a pain. But the work ethic is similar to that in China: “Confucius still gets them out of bed in the morning,” says one foreign executive in Vietnam.Apple also increasingly sees locals as potential customers, particularly in India, the world’s second-largest smartphone market. Though iGadgets are too pricey for most Indians, that is changing. Apple said in July that its revenues in India had nearly doubled in the past quarter, year on year, driven by the “engine” of iPhone sales.This is diminishing China’s relative importance as a consumer market. At its high point in 2015, China accounted for 25% of Apple’s annual sales, more than Europe. Since then its share has steadily shrunk, to 19% so far this financial year (see chart 2). By the sounds of it Xi Jinping, China’s president, would like it to fall further. At a Communist Party shindig on October 16th he urged “self-reliance and strength in science and technology”, suggesting that foreign importers may face stiffer competition from Chinese national champions. He repeated the phrase five times.An iWire actThis points to perhaps the biggest reason for Apple’s shift: geopolitics. Rising Sino-American tensions are making China an awkward place to do business. Heightened Chinese sensitivity is adding friction. This summer Apple reportedly had to ask Taiwanese manufacturers to label their products “Made in Chinese Taipei” to appease newly finicky Chinese customs officials (at the risk of angering Taiwanese ones).America, for its part, has become more aggressive in its competition with China’s domestic tech industry. On October 7th America announced a ban on “ us persons” working for some Chinese chipmakers. On the same day it added 30 Chinese companies to a list of “unverified” firms its officials had been unable to inspect. Apple had reportedly been about to sign a deal to buy iPhone memory chips from one such company, ymtc , which can offer low prices thanks in part to Chinese government subsidies. Following America’s export controls that deal was put on ice, according to Nikkei, a Japanese newspaper.The question is whether shifting production out of China will be enough to avoid future crackdowns. Even as Apple makes more of its gadgets outside China, it is no less reliant on Chinese-owned companies to build them. Chinese manufacturers such as Luxshare, Goertek and Wingtech are taking an increasing share of Apple’s business beyond China’s borders.Luxshare and Goertek are reported to be making AirPods in Vietnam, helped by the fact that some Taiwanese rivals, like Inventec, have scaled back their work for Apple in recent years. In September press reports hinted that the Indian government might let some Chinese companies set up production facilities in India. Chinese companies’ share of iPhone electronics production will rise from 7% this year to 24% by 2025, believes JPMorgan Chase, which predicts that in the next three years Chinese companies will increase their share of production across Apple’s range of products.Could Chinese manufacturers outside China be targeted by American sanctions? For now this is unlikely, believes Nana Li of Impax, an asset manager. “There are no handy alternative [suppliers] available with the same level of experience, efficiency and cost-effectiveness,” so cutting them off would hurt American firms, she notes. In time, that may change. Countries like India and Vietnam are keen to cultivate their own suppliers. Tata is reportedly in talks with Wistron, a Taiwanese manufacturer, about making iPhones in India. Indian firms report that “the fruit company” is discreetly on the hunt for local suppliers.Given the growing rift between America and China, it is sensible for Apple to place some side-bets, before restrictions go any further. Chinese firms outside China are safe for now, says one Western investor in Asia. But “the noose is tightening”. ■To stay on top of the biggest stories in business and technology, sign up to the Bottom Line, our weekly subscriber-only newsletter.",0.0,0.0
456,https://arstechnica.com/information-technology/2022/10/passkeys-microsoft-apple-and-googles-password-killer-are-finally-here/,"PasskeysâMicrosoft, Apple, and Googleâs password killerâare","For years, Big Tech has insisted that the death of the password is right around the corner. For years, those assurances have been little more than empty promises. The password alternatives—such as pushes, OAUTH single-sign ons, and trusted platform modules—introduced as many usability and security problems as they solved. But now, we’re finally on the cusp of a password alternative that’s actually going to work.The new alternative is known as passkeys. Generically, passkeys refer to various schemes for storing authenticating information in hardware, a concept that has existed for more than a decade. What’s different now is that Microsoft, Apple, Google, and a consortium of other companies have unified around a single passkey standard shepherded by the FIDO Alliance. Not only are passkeys easier for most people to use than passwords; they are also completely resistant to credential phishing, credential stuffing, and similar account takeover attacks.On Monday, PayPal said US-based users would soon have the option of logging in using FIDO-based passkeys, joining Kayak, eBay, Best Buy, CardPointers, and WordPress as online services that will offer the password alternative. In recent months, Microsoft, Apple, and Google have all updated their operating systems and apps to enable passkeys. Passkey support is still spotty. Passkeys stored on iOS or macOS will work on Windows, for instance, but the reverse isn’t yet available. In the coming months, all of that should be ironed out, though.What, exactly, are passkeys?Passkeys work almost identically to the FIDO authenticators that allow us to use our phones, laptops, computers, and Yubico or Feitian security keys for multi-factor authentication. Just like the FIDO authenticators stored on these MFA devices, passkeys are invisible and integrate with Face ID, Windows Hello, or other biometric readers offered by device makers. There’s no way to retrieve the cryptographic secrets stored in the authenticators short of physically dismantling the device or subjecting it to a jailbreak or rooting attack.Even if an adversary was able to extract the cryptographic secret, they still would have to supply the fingerprint, facial scan, or—in the absence of biometric capabilities—the PIN that’s associated with the token. What’s more, hardware tokens use FIDO’s Cross-Device Authentication flow, or CTAP, which relies on Bluetooth Low Energy to verify the authenticating device is in close physical proximity to the device trying to log in.Until now, FIDO-based security keys have been used mainly to provide MFA, short for multi-factor authentication, which requires someone to present a separate factor of authentication in addition to the correct password. The additional factors offered by FIDO typically come in the form of something the user has—a smartphone or computer containing the hardware token—and something the user is—a fingerprint, facial scan, or other biometric that never leaves the device.AdvertisementSo far, attacks against FIDO-compliant MFA have been in short supply. An advanced credential phishing campaign that recently breached Twilio and other top-tier security companies, for instance, failed against Cloudflare for one reason: Unlike the other targets, Cloudflare used FIDO-compliant hardware tokens that were immune to the phishing technique the attackers used. The victims who were breached all relied on weaker forms of MFA.But whereas hardware tokens can provide one or more factors of authentication in addition to a password, passkeys rely on no password at all. Instead, passkeys roll multiple authentication factors—typically the phone or laptop and the facial scan or fingerprint of the user—into a single package. Passkeys are managed by the device OS. At the user’s option, they can also be synced through end-to-end encryption with a user’s other devices using a cloud service provided by Apple, Microsoft, Google, or another provider.Passkeys are “discoverable,” meaning an enrolled device can automatically push one through an encrypted tunnel to another enrolled device that’s trying to sign in to one of the user’s site accounts or apps. When signing in, the user authenticates themselves using the same biometric or on-device password or PIN for unlocking their device. This mechanism completely replaces the traditional username and password and provides a much easier user experience.“Users no longer need to enroll each device for each service, which has long been the case for FIDO (and for any public key cryptography),"" said Andrew Shikiar, FIDO's executive director and chief marketing officer. ""By enabling the private key to be securely synced across an OS cloud, the user needs to only enroll once for a service, and then is essentially pre-enrolled for that service on all of their other devices. This brings better usability for the end-user and—very significantly—allows the service provider to start retiring passwords as a means of account recovery and re-enrollment.”Ars Review Editor Ron Amadeo summed things up well last week when he wrote: ""Passkeys just trade WebAuthn cryptographic keys with the website directly. There's no need for a human to tell a password manager to generate, store, and recall a secret—that will all happen automatically, with way better secrets than what the old text box supported, and with uniqueness enforced.""",0.0,0.0
473,https://techcrunch.com/2022/08/02/identity-verification-company-youverify-extends-seed-funding-to-2-5m-as-it-expands-across-africa/,Identity verification company Youverify extends seed funding to $2.5M as it expands across Africa,"This past month has seen several African fintechs such as Flutterwave and Union54 make headlines for compliance checks issues and fraud allegations. Both unlinked events re-emphasize the importance of know your customer (KYC) and anti-money laundering (AML) checks and why regulators enforce strict policies that financial institutions need to be held accountable to while operating across the continent and globally.For the many startups whose services help keep the operations of financial institutions such as banks and fintechs in check, this period highlights their relevance more than ever. In the latest development, Youverify, a Lagos and San Francisco–based identity verification company helping African banks and startups automate KYC and other compliance procedures, is announcing that it has secured a $1 million seed round extension. The startup raised a $1.5 million round in 2020, bringing its total seed raise to $2.5 million.Africa-focused VCs Orange Ventures and LoftyInc Capital, the two investors who co-led its initial seed round, also led the extension. Additional investment came from Octerra Capital, Plug & Play Venture, Syntax Ventures, HTTP Investors, Afer Group and Fronesyz Capital.The proliferation of financial services in Africa is beginning to attract more scrutiny from regulators. According to reports, transactions worth $116 billion will be made through digital payment channels this year, requiring stringent measures to prevent identity theft and fraud. Therefore, the rise in focus on maintaining transparency in financial regulations and improving strategies for KYC and AML by implementing regulatory technologies has become a significant growth factor for the market. And as regtech demand globally increases, so will Africa’s, with reports saying it will reach about $1.2 billion in the next five years.Youverify came into Africa’s regtech scene when founder and CEO Gbenga Odegbami founded the company in 2018. Launched in the Nigerian market, Youverify first provided API for address and identity verification to several financial institutions. Now it has added more KYC products and expanded into new markets such as Ghana, Côte d’Ivoire, South Africa, Kenya and Uganda.“The way our customers see us is that we help them automate their KYC and compliance issues,” said Odegbami on a call with TechCrunch.In addition to verifying identities beyond Nigeria’s bank verification number (BVN) and addresses, Odegbami says Youverify layers KYC and compliance products such as transaction monitoring. He further explained that these offerings cater to issues some fintech platforms have faced recently: alleged AML issues in the case of Flutterwave in Kenya and Ping Express in the U.S. and fraud in the case of Union54’s chargebacks. In the latter, Youverify claims it could’ve prevented large-scale chargeback fraud by identifying the pattern of transactions to flag fraud, blocking the virtual cards and tying them back to fraudsters committing the multiple fake chargebacks.“They [Union54] grew faster than they could put in place the proper transaction monitoring and fraud detection systems that will identify transactions happening from their customers,” the CEO said of the chargeback situation Union54 has dealt with over the past couple of months. “A system like ours will be able to identify previous and new patterns in such a way that we would’ve been able to help such the company.”It wasn’t until last year that Youverify started dealing with fintechs. Initially, most of its customers were governmental bodies, big corporations like Bolt and banks. Nearly two-thirds of Nigeria’s commercial banks, such as Standard Chartered, Standard Bank and Fidelity Bank, use the platform’s identity verification and KYC products, Youverify said.However, in a bid to serve more clients, the company launched its proprietary technology, the Youverify OS (YVOS), which provides a single platform for automating due diligence and combines risk and compliance management with its core identity verification platform to deliver these fintechs an enterprise-grade compliance solution. With its other product, vFORM, a low and no-code tool, businesses can create a custom process for onboarding new customers using a drag-and-drop builder.As a result of diversifying its clientele and demand for its KYC products, Odegbami said Youverify’s customer base increased by 300% to serve more than 400 banks and high-growth startups. In the last 24 months, Youverify’s application processes have grown by more than 1,000% to more than 5 million applications that have helped its clients hire talent, sell financial products, and remotely onboard ride-hailing drivers. The company’s YouID digital identity platform added more than 500,000 users, with 600 service providers on its marketplace waitlist across the continent. Odegbami said the Lagos-based identity verification company crossed an ARR of over $1 million last year.Youverify isn’t the only identity verification company in Africa. Similar providers include Smile Identity and YC-backed companies IdentityPass and Dojah. Without mincing words, Odegbami said his company is a “market leader” because it came into the market much earlier and possesses more experience, and provides more data sets than the others.Over the next 18 months, Youverify plans to grow its footprint to cover 30 countries, especially in the southern, eastern and francophone parts of Africa, where Odegbami says the company will be recruiting aggressively. It also intends to increase the number of IDs it can verify, from 400 million to 2 billion, and develop new automated compliance products for the gaming, travel, healthcare and telecommunications industries.",0.0,0.0
6,https://www.engadget.com/scientists-find-affordable-way-break-down-pfas-185743322.html,Scientists may have found an affordable way to destroy forever chemicals,"A team of scientists may have found a safe and affordable way to destroy “forever chemicals.” PFAS, or perfluoroalkyl and polyfluoroalkyl substances, are found in many household items, including non-stick Teflon pans and dental floss. According to the US Environmental Protection Agency , at least 12,000 such substances exist today. They all share one common feature between them: a carbon-fluorine backbone that is one of the strongest known bonds in organic chemistry. It’s what gives PFAS-treated cookware its non-stick quality. However, that same characteristic can make those substances harmful to humans.Since they’re so durable from a molecular perspective, PFAS can stay in soil and water for generations. Scientists have shown that prolonged exposure to them can lead to an increased risk of some cancers, reduced immunity and developmental effects on children. Researchers have spent years trying to find a way to destroy the carbon-fluorine bond that makes PFAS so stubborn, but a breakthrough could be in sight.In a study published Thursday in the journal Science , a group of chemists from UCLA, Northwestern University and China found that a mixture of sodium hydroxide, a chemical used in lye, and an organic solvent called dimethyl sulfoxide was effective at breaking down a large subgroup of PFAS known as perfluoro carboxylic acids or PFCAs. When lead author Brittany Trang heated the mixture between 175 and 250 degrees Fahrenheit (about 79 to 121 degrees Celsius), it began breaking down the bonds between the PFAS molecules. After a few days, the mixture can even reduce any fluorine byproducts into harmless molecules. The sodium hydroxide is part of what makes the mixture so potent. It bonds with PFAS molecules after the dimethyl sulfoxide softens them and hastens their breakdown.Turn on browser notifications to receive breaking news alerts from Engadget You can disable notifications at any time in your settings menu. Not now Turned on Turn on",0.0,0.0
121,https://www.npr.org/2022/10/05/1126900340/florida-community-designed-weather-hurricane-ian-babcock-ranch-solar,One Florida community built to weather hurricanes endured Ian with barely a scratch,"One Florida community built to weather hurricanes endured Ian with barely a scratchEnlarge this image toggle caption Carlos Osorio for NPR Carlos Osorio for NPRBABCOCK RANCH, Fla. — Like many others in Southwest Florida, Mark Wilkerson seemingly gambled his life by choosing to shelter at home rather than evacuate when Hurricane Ian crashed ashore last week as a Category 4 storm.But it wasn't just luck that saved Wilkerson and his wife, Rhonda, or prevented damage to their well-appointed one-story house. You might say that it was all by design.In 2018, Wilkerson became one of the first 100 residents of Babcock Ranch — an innovative community north of Fort Myers where homes are built to withstand the worst that Mother Nature can throw at them without being flooded out or losing electricity, water or the internet.The community is located 30 miles inland to avoid coastal storm surges. Power lines to homes are all run underground, where they are shielded from high winds. Giant retaining ponds surround the development to protect houses from flooding. As a backup, streets are designed to absorb floodwaters and spare the houses.Enlarge this image toggle caption Carlos Osorio for NPR Carlos Osorio for NPRWilkerson says he and his wife moved here from Illinois. ""We'd almost been ready to build north of Tampa, on the Gulf,"" he says. ""And then the last hurricane came through and reminded me that ... I want to be in a place where I don't have to evacuate.""Most residents chose to ride out the storm at homeSo when the storm hit, Wilkerson and his wife stayed put, as did most other residents here. Although the community didn't experience the hurricane at its most intense, Wilkerson says they felt 100-mph winds. At one point, the lights in his house flickered but ""lo and behold, we never lost power.""In fact, his house didn't even lose a shingle. That's the basic story of Babcock Ranch, post-Ian: Aside from a traffic light at the development's main entrance that's no longer there, a few street signs lying on the ground and some knocked-over palm trees, you'd hardly know that a hurricane came through.Unfortunately, not so for many of the surrounding communities, where damaged structures and power outages have not been uncommon.Enlarge this image toggle caption Carlos Osorio for NPR Carlos Osorio for NPRWilkerson has worked in the solar industry since the 1980s, and one of the things that drew him to Babcock Ranch is its innovative use of solar energy: 870 acres of land owned by the development sport 650,000 photovoltaic panels, operated by Florida Power & Light.The solar array powers the whole community — and then some. It can supply 30,000 homes. Babcock Ranch has only about 5,000 residents, though. The excess goes back into the grid and is used to power surrounding communities. At night and on cloudy days, a natural gas generator kicks in to fill the gap.Developers aim for a strong and sustainable communityBabcock Ranch is the brainchild of Syd Kitson, a 64-year-old former professional football player who made his name in the 1980s with the Green Bay Packers. He went on to found a real estate development company, Kitson & Partners, and Babcock Ranch is one of firm's showcase projects.Jennifer Languell is a sustainability engineer who helped design Babcock Ranch, and she lives here too. ""We felt you could develop and improve land, not just develop in a traditional way where people think you are destroying the land.""""We have a lot of open spaces. We have a lot of trails. We have a lot of parks,"" she says.""The things that we do, you don't see. The strength of the buildings, or the infrastructure that deals with stormwater, or the utilities. You don't see that stuff,"" she says. ""Which is good, because most people don't need or want to think about it.""Enlarge this image toggle caption Carlos Osorio for NPR Carlos Osorio for NPRAs confident as Languell is of the community's durability, even she was a little unnerved by the storm's sheer strength. ""I can definitely tell you that I pulled up my construction drawings and I verified the wind speed,"" she says.Their good fortune pays dividends for others in needAdmittedly, Babcock Ranch has a slightly insular feel to it. But partly because residents were spared the full wrath of the hurricane, they have been able to reach out and help those in need.A community center here was designed to double as a reinforced storm shelter. Everyone staying there right now has come in from other hard-hit communities. Babcock Ranch residents have been fielding requests on social media and shuttling in supplies.Enlarge this image toggle caption Carlos Osorio for NPR Carlos Osorio for NPRJudith Schrag, 70, who uses a walker, is sitting out front of the shelter smoking a cigarette. She arrived at the Babcock Ranch shelter a few days agoafter her Port Charlotte apartment was flooded out.The community has been ""absolutely phenomenal in terms of donations,"" Schrag says. ""They are what have helped to keep this place going.""Enlarge this image toggle caption Carlos Osorio for NPR Carlos Osorio for NPRHurricane Ian was a big test for this community, where houses start at around $250,000. Languell says the storm provided ""proof of concept"" for the community's design. The developers of Babcock Ranch welcome imitators, she adds. Communities elsewhere in the U.S. might benefit from what has been learned here.But there's still more to learn, Languell says.""We don't want to brag by any stretch of the imagination, because you do that, and the next thing you know, you get hit by a Category 5 and something doesn't work as well,"" she says.",0.0,0.0
213,https://www.psu.edu/news/research/story/battery-tech-breakthrough-paves-way-mass-adoption-affordable-electric-car/,Battery tech breakthrough paves way for mass adoption of affordable electric car,"UNIVERSITY PARK, Pa. — A breakthrough in electric vehicle battery design has enabled a 10-minute charge time for a typical EV battery. The record-breaking combination of a shorter charge time and more energy acquired for longer travel range was announced today (Oct. 12) in the journal Nature.“The need for smaller, faster-charging batteries is greater than ever,” said Chao-Yang Wang, the William E. Diefenderfer Professor of Mechanical Engineering at Penn State and lead author on the study. “There are simply not enough batteries and critical raw materials, especially those produced domestically, to meet anticipated demand.”In August, California’s Air Resources Board passed an extensive plan to restrict and ultimately ban the sale of gasoline-powered cars within the state. By 2035, the largest auto market in the United States will effectively retire the internal combustion engine.If new car sales are going to shift to battery-powered electric vehicles (EVs), Wang explained, they’ll need to overcome two major drawbacks: they are too slow to recharge and too large to be efficient and affordable. Instead of taking a few minutes at the gas pump, depending on the battery, some EVs can take all day to recharge.“Our fast-charging technology works for most energy-dense batteries and will open a new possibility to downsize electric vehicle batteries from 150 to 50 kWh without causing drivers to feel range anxiety,” said Wang, whose lab partnered with State College-based startup EC Power to develop the technology. “The smaller, faster-charging batteries will dramatically cut down battery cost and usage of critical raw materials such as cobalt, graphite and lithium, enabling mass adoption of affordable electric cars.”The technology relies on internal thermal modulation, an active method of temperature control to demand the best performance possible from the battery, Wang explained. Batteries operate most efficiently when they are hot, but not too hot. Keeping batteries consistently at just the right temperature has been major challenge for battery engineers. Historically, they have relied on external, bulky heating and cooling systems to regulate battery temperature, which respond slowly and waste a lot of energy, Wang said.Wang and his team decided to instead regulate the temperature from inside the battery. The researchers developed a new battery structure that adds an ultrathin nickel foil as the fourth component besides anode, electrolyte and cathode. Acting as a stimulus, the nickel foil self-regulates the battery’s temperature and reactivity which allows for 10-minute fast charging on just about any EV battery, Wang explained.“True fast-charging batteries would have immediate impact,” the researchers write. “Since there are not enough raw minerals for every internal combustion engine car to be replaced by a 150 kWh-equipped EV, fast charging is imperative for EVs to go mainstream.”The study’s partner, EC Power, is working to manufacture and commercialize the fast-charging battery for an affordable and sustainable future of vehicle electrification, Wang said.The other coauthors on the study are Teng Liu, Xiao-Guang Yang, Shanhai Ge and Yongjun Leng of Penn State and Nathaniel Stanley, Eric Rountree and Brian McCarthy of EC Power.The work was supported by the U.S. Department of Energy, the U.S. Department of Defense, the U.S. Air Force and the William E. Diefenderfer Endowment.",0.0,0.0
136,https://www.space.com/james-webb-space-telescope-miri-glitch-september-2022,NASA investigating glitch on James Webb Space Telescope's ultracold camera,"James Webb Space Telescope's ultracold camera has experienced a technical glitch that is forcing the ground team to postpone some observations.The problem affected the James Webb Space Telescope 's Mid-Infrared Instrument's (MIRI) grating wheel, which allows scientists to choose the wavelength of light they want to focus on. The wheel is used in only one of MIRI 's four observation modes, the medium-resolution spectroscopy (MRS) mode, in which the camera takes not images but light spectra (fingerprints of light absorption of the various chemical elements in the observed objects).The ground control teams first detected friction in the wheel in late August, NASA officials wrote in a statement (opens in new tab) released on Tuesday (Sept. 20), and after further investigation decided to pause observations in the affected mode. On Sept. 6, the agency convened an anomaly review board ""to assess the best path forward,"" the statement added.Related: Marvel at the James Webb Space Telescope's largest image of the cosmos yet""The Webb team has paused in scheduling observations using this particular observing mode while they continue to analyze its behavior and are currently developing strategies to resume MRS observations as soon as possible,"" NASA officials wrote in the statement. ""The observatory is in good health, and MIRI's other three observing modes — imaging, low-resolution spectroscopy and coronagraphy — are operating normally and remain available for science observations.""MIRI, one of four high-tech instruments on the James Webb Space Telescope, is a combined camera and spectrograph, which means it takes both images and light spectra of the distant universe . A specialist in detecting mid-infrared wavelengths, MIRI can see light from far-away galaxies , as well as stars forming inside of shrouds of dust. While all of Webb's instruments require extremely low temperatures to observe properly, MIRI is the coldest of them all.The other three instruments — NIRCam, NIRSpec and FGS/NIRISS — rely on the telescope's tennis-court-sized sunshield to reach temperatures of minus 369.4 degrees Fahrenheit (minus 223 degrees Celsius). MIRI, in addition to the sunshield, requires special cryocoolers to achieve an even colder temperature of minus 447 degrees F (minus 266 degrees C), only 12 degrees F (7 degrees C) above absolute zero, the temperature at which the motion of atoms stops.",0.0,0.0
96,https://cleantechnica.com/2022/10/29/researchers-discover-substitutes-for-rare-earth-materials-in-magnets/,Researchers Discover Substitutes For Rare Earth Materials In Magnets,"Researchers at the University of Cambridge, in collaboration with colleagues in Austria, report that tetrataenite, a “cosmic magnet” that takes millions of years to develop naturally in meteorites, can potentially be used instead of rare earth materials in magnets.Researchers at the University of Cambridge, in collaboration with colleagues in Austria, report that tetrataenite, a “cosmic magnet” that takes millions of years to develop naturally in meteorites, can potentially be used instead of rare earth materials in magnets.Previously, attempts to make tetrataenite in the laboratory have depended on extreme and impractical methods, but the researchers say they have found a way to bypass those prior techniques by using phosphorus. In a research paper published in the journalPreviously, attempts to make tetrataenite in the laboratory have depended on extreme and impractical methods, but the researchers say they have found a way to bypass those prior techniques by using phosphorus. In a research paper published in the journal“Rare earth” is a misleading term that is sort of an inside joke among organic chemistry aficionados. It refers to a group of elements on the periodic table. “Noble gases” is another term that has little meaning except to organic chemists. In truth, “rare earth” elements aren’t all that rare in the grand scheme of things, but extracting them and purifying them is a challenge.“Rare earth” is a misleading term that is sort of an inside joke among organic chemistry aficionados. It refers to a group of elements on the periodic table. “Noble gases” is another term that has little meaning except to organic chemists. In truth, “rare earth” elements aren’t all that rare in the grand scheme of things, but extracting them and purifying them is a challenge.Rare Earth Materials And Permanent MagnetsRare Earth Materials And Permanent MagnetsThe real reason why this news is important is that rare earth materials are critical to making the permanent magnets that are an essential component of the electric motors that the transition to an emissions free economy depends upon.The real reason why this news is important is that rare earth materials are critical to making the permanent magnets that are an essential component of the electric motors that the transition to an emissions free economy depends upon.The sticking point is that China, with it predilection for dominating so many of the manufacturing processes for making electric vehicles, solar panels, and other critical technologies needed to address an overheating planet, controls over 80% of the world market for rare earth elements.The sticking point is that China, with it predilection for dominating so many of the manufacturing processes for making electric vehicles, solar panels, and other critical technologies needed to address an overheating planet, controls over 80% of the world market for rare earth elements.We know the danger of allowing tyrants in Saudi Arabia and Russia to control our access to fossil fuels. That experience suggests letting China be the gatekeeper for the new technologies we need to transfer away from relying on fossil fuels may be similarly fraught with danger in the future.We know the danger of allowing tyrants in Saudi Arabia and Russia to control our access to fossil fuels. That experience suggests letting China be the gatekeeper for the new technologies we need to transfer away from relying on fossil fuels may be similarly fraught with danger in the future.Professor Lindsay Greer of the materials science and metallurgy department at Cambridge University tellsProfessor Lindsay Greer of the materials science and metallurgy department at Cambridge University tellsOne of the most promising alternatives for permanent magnets is tetrataenite, an iron-nickel alloy with an ordered atomic structure. The material forms over millions of years as a meteorite slowly cools. This offers the iron and nickel atoms enough time to order themselves into a particular stacking sequence within the crystalline structure, resulting in a material with magnetic properties similar to those of rare earth magnets.One of the most promising alternatives for permanent magnets is tetrataenite, an iron-nickel alloy with an ordered atomic structure. The material forms over millions of years as a meteorite slowly cools. This offers the iron and nickel atoms enough time to order themselves into a particular stacking sequence within the crystalline structure, resulting in a material with magnetic properties similar to those of rare earth magnets.In the 1960s, tetrataenite was artificially formed by blasting iron-nickel alloys with neutrons, which allowed the atoms to form the desired ordered stacking. However, this technique is unsuitable for mass production. “Since then, scientists have been fascinated with getting that ordered structure, but it’s always felt like something that was very far away,” Greer says.In the 1960s, tetrataenite was artificially formed by blasting iron-nickel alloys with neutrons, which allowed the atoms to form the desired ordered stacking. However, this technique is unsuitable for mass production. “Since then, scientists have been fascinated with getting that ordered structure, but it’s always felt like something that was very far away,” Greer says.Over the years, many scientists have attempted to make tetrataenite on an industrial scale, but the results have been disappointing. Now Greer and his colleagues from the Austrian Academy of Sciences, and the Montanuniversität in Leoben, have found a potential alternative that avoids these extreme methods.Over the years, many scientists have attempted to make tetrataenite on an industrial scale, but the results have been disappointing. Now Greer and his colleagues from the Austrian Academy of Sciences, and the Montanuniversität in Leoben, have found a potential alternative that avoids these extreme methods.Taking A Closer LookTaking A Closer LookThe team studied the mechanical properties of iron-nickel alloys containing small amounts of phosphorus, which is present in meteorites. Inside these materials were a pattern of phases that indicated the expected tree-like growth structure called dendrites.The team studied the mechanical properties of iron-nickel alloys containing small amounts of phosphorus, which is present in meteorites. Inside these materials were a pattern of phases that indicated the expected tree-like growth structure called dendrites.“For most people, it would have ended there: nothing interesting to see in the dendrites, but when I looked closer, I saw an interesting diffraction pattern indicating an ordered atomic structure,” said first author Dr Yurii Ivanov, who completed the work while at Cambridge and is now based at the Italian Institute of Technology in Genoa.“For most people, it would have ended there: nothing interesting to see in the dendrites, but when I looked closer, I saw an interesting diffraction pattern indicating an ordered atomic structure,” said first author Dr Yurii Ivanov, who completed the work while at Cambridge and is now based at the Italian Institute of Technology in Genoa.Initially, the diffraction pattern of tetrataenite looks like the structure expected for iron-nickel alloys, namely a disordered crystal not of interest as a high-performance magnet. But when Ivanov looked closer, he identified the tetrataenite.Initially, the diffraction pattern of tetrataenite looks like the structure expected for iron-nickel alloys, namely a disordered crystal not of interest as a high-performance magnet. But when Ivanov looked closer, he identified the tetrataenite.According to the team, phosphorus allows the iron and nickel atoms to move faster, enabling them to form the necessary ordered stacking without waiting for millions of years. They were able to accelerate tetrataenite formation by between 11 and 15 orders of magnitude by mixing iron, nickel, and phosphorus in the right quantities. This meant the material was able to form over a few seconds in a simple casting.According to the team, phosphorus allows the iron and nickel atoms to move faster, enabling them to form the necessary ordered stacking without waiting for millions of years. They were able to accelerate tetrataenite formation by between 11 and 15 orders of magnitude by mixing iron, nickel, and phosphorus in the right quantities. This meant the material was able to form over a few seconds in a simple casting.“What was so astonishing was that no special treatment was needed. We just melted the alloy, poured it into a mold, and we had tetrataenite,” says Greer. “The previous view in the field was that you couldn’t get tetrataenite unless you did something extreme, because otherwise, you’d have to wait millions of years for it to form. This result represents a total change in how we think about this material.”“What was so astonishing was that no special treatment was needed. We just melted the alloy, poured it into a mold, and we had tetrataenite,” says Greer. “The previous view in the field was that you couldn’t get tetrataenite unless you did something extreme, because otherwise, you’d have to wait millions of years for it to form. This result represents a total change in how we think about this material.”Although the research is promising, more work is needed to decide whether it will be suitable for high performance magnets. The team is hoping to collaborate with major magnet manufacturers to determine this.Although the research is promising, more work is needed to decide whether it will be suitable for high performance magnets. The team is hoping to collaborate with major magnet manufacturers to determine this.The TakeawayThe TakeawayWhy do we write about topics that are not yet out of the laboratory stage? Because theWhy do we write about topics that are not yet out of the laboratory stage? Because theNew types of batteries that are lighter, more powerful, faster charging, less expensive, and kinder to the environment are being researched in hundreds of laboratories all around the world as you read this. We don’t know where the breakthroughs will occur but we know they will come, just as those first crude internal combustion gasoline and diesel engines became the ultra-sophisticated machines that power hundreds of millions of vehicles today.New types of batteries that are lighter, more powerful, faster charging, less expensive, and kinder to the environment are being researched in hundreds of laboratories all around the world as you read this. We don’t know where the breakthroughs will occur but we know they will come, just as those first crude internal combustion gasoline and diesel engines became the ultra-sophisticated machines that power hundreds of millions of vehicles today.There areThere areThe odds are, by 2030 electric cars will have taken a quantum leap forward as more and more new innovations become commercially available. We can’t wait!The odds are, by 2030 electric cars will have taken a quantum leap forward as more and more new innovations become commercially available. We can’t wait!Featured image:Featured image:Appreciate CleanTechnica’s originality and cleantech news coverage? Consider becoming aAppreciate CleanTechnica’s originality and cleantech news coverage? Consider becoming aDon't want to miss a cleantech story? Sign up forDon't want to miss a cleantech story? Sign up forHave a tip for CleanTechnica, want to advertise, or want to suggest a guest for our CleanTech Talk podcast?Have a tip for CleanTechnica, want to advertise, or want to suggest a guest for our CleanTech Talk podcast?AdvertisementAdvertisementCT new after-postCT new after-postzox-post-body",0.0,0.0
461,https://techcrunch.com/2020/01/29/all-eyes-are-on-the-next-liquidity-event-when-it-comes-to-space-startups/,All eyes are on the next liquidity event when it comes to space startups,"At the FAA’s 23rd Annual Commercial Space Transportation Conference in Washington, DC on Wednesday, a panel dedicated to the topic of trends in VC around space startups touched on public versus private funding, the right kinds of space companies that should even be considering venture funding and, perhaps most notably, the big L: Liquidity.Moderator Tess Hatch, vice president at Bessemer Venture Partners, addressed the topic in response to an audience question that noted while we’ve heard a lot about how much money will flow into space-related startups from the VC community, we haven’t actually seen much in the way of liquidity events that prove out the validity of these investments.“In 2008, a company called Skybox was created and a handful of years later Google acquired the company for $500 million,” Hatch said. “Every venture capitalist’s ears perked up and they thought ‘Hey, that’s pretty good ROI in a short amount of time — maybe the space thing is an investable area,’ and then a ton of venture capital investments flooded into space startups, and all of these venture capitalists made one, or maybe two investments in the area. Since then, there have not been many — if any — liquidity events: Perhaps Virgin Galactic going public via the SPAC (special purpose vehicle) on the New York Stock Exchange late last year would be the second. So we’re still waiting; we’re still waiting for those exits, we are still waiting for companies to pave the path for the 400+ startups in the ecosystem to return our investment.”Hatch added that she’s looking at a number of companies who have the potential to break this somewhat prolonged exit drought in 2020, including five that are either quite mature in terms of their development, naming SpaceX, Rocket Lab, Planet and Spire as all likely candidates to have some kind of liquidity event in 2020, with the mostly likely being an IPO.Space as an industry was described to me recently as a “maturing” startup market by Space Angels CEO Chad Anderson, by virtue of the distribution of activity in terms of the overall investment rounds in the sector. There is indeed a lot of activity with early-stage companies and seed rounds, but the fact remains that there hasn’t been much in the way of exits, and it’s also worth pointing out that corporate VCs haven’t been as acquisitive in space as some of their consumer and enterprise technology counterparts.The panel touched on a lot more apart from liquidity, which actually only came up toward the end of the discussion. Panelists included Astranis CEO and co-founder John Gedmark; Capella Space CEO and founder Payam Banazadeh and Rocket Lab VP of Global Commercial Launch Services Shane Fleming. Both Gedmark and Banazadeh addressed aspects of the risks and benefits of seeking VC as a space technology company.“Not every space business is a venture-backable business,” said Banazadeh earlier in the conversation. “But there are a lot of space businesses that are specifically going after raising venture money, and that’s dangerous for everyone — because at the end of the day, venture is looking at high risk, high return. The ‘high return’ comes from being able to get substantial amounts of revenue in a market that’s bigenough for those revenues to be coming from. But if your idea is to go build, maybe, some very specific part in a satellite, then you have to make the case of why you’ll be able to make those returns for the investors, and in a lot of cases, that’s just not possible.”Banazadeh also concedes that doing any kind of space technology development is expensive, and the money has to come from somewhere. Gedmark talked about one popular source, government funding and grants, and why that often isn’t as obviously a positive thing for startups as it might seem.“Small government grants can be great, and obviously a fantastic source of non-dilutive capital,” Gedmark said. “But there is a little bit of a trick there, or something to be aware of: I think people are often surprised how much time is spent in the early days of a startup refining the exact idea and the product, and if you’re not certain that you have that product market fit […] then, the government grant can be extremely dangerous, because they will fund you to do something that is sort of similar to what to what you’re doing, but it really prevents you changing your approach later; you’re going to end up spending time executing on the specific project of the program manager on the government side and you’re executing on what they want.”VC funds, on the other hand, come with the built-in expectation that you’re going to refine and potentially even change direction altogether, Gedmark says. Depending on the terms of the public funding you’re seeking, that flexibility may not be part of the arrangement, which ultimately could be more important than a bit of equity dilution.",0.0,0.0
153,https://tech.hindustantimes.com/tech/news/signatures-of-alien-technology-could-be-how-humanity-first-finds-extraterrestrial-life-71666434581103.html,Signatures of alien technology could be how humanity first finds extraterrestrial life,"Signatures of alien technology could be how humanity first finds extraterrestrial lifeIf an alien were to look at Earth, many human technologies – from cell towers to fluorescent light bulbs – could be a beacon signifying the presence of life.We are two astronomers who work on the search for extraterrestrial intelligence – or SETI. In our research, we try to characterise and detect signs of technology originating from beyond Earth.These are called technosignatures. While scanning the sky for a TV broadcast of some extraterrestrial Olympics may sound straightforward, searching for signs of distant, advanced civilisations is a much more nuanced and difficult task than it might seem.Saying ‘hello' with radios and lasersThe modern scientific search for extraterrestrial intelligence began in 1959 when astronomers Giuseppe Cocconi and Philip Morrison showed that radio transmissions from Earth could be detected by radio telescopes at interstellar distances.The same year, Frank Drake, launched the first SETI search, Project Ozma, by pointing a large radio telescope a two nearby Sun-like stars to see if he could detect any radio signals coming from them.Following the invention of the laser in 1960, astronomers showed that visible light could also be detected from distant planets.These first, foundational attempts to detect radio or laser signals from another civilisation were all looking for focused, powerful signals that would have been intentionally sent to the solar system and meant to be found.Given the technological limitations of the 1960s, astronomers did not give serious thought to searching for broadcast signals – like television and radio broadcasts on Earth – that would leak into space.But a beam of a radio signal, with all of its power focused towards Earth, could be detectable from much farther away – just picture the difference between a laser and a weak light bulb.The search for intentional radio and laser signals is still one of the most popular SETI strategies today. However, this approach assumes that extraterrestrial civilizations want to communicate with other technologically advanced life.Humans very rarely send targeted signals into space, and some scholars argue that intelligent species may purposefully avoid broadcasting out their locations. This search for signals that no one may be sending is called the SETI Paradox.Leaking radio wavesThough humans don't transmit many intentional signals out to the cosmos, many technologies people use today produce a lot of radio transmissions that leak into space. Some of these signals would be detectable if they came from a nearby star.The worldwide network of television towers constantly emits signals in many directions that leak into space and can accumulate into a detectable, though relatively faint, radio signal.Research is ongoing as to whether current emissions from cell towers in the radio frequency on Earth would be detectable using today's telescopes, but the upcoming Square Kilometre Array radio telescope will be able to detect even fainter radio signals with 50 times the sensitivity of current radio telescope arrays.Not all human-made signals are so unfocused, though. Astronomers and space agencies use beams of radio waves to communicate with satellites and space craft in the solar system.Some researchers also use radio waves for radar to study asteroids. In both of these cases, the radio signals are more focused and pointed out into space.Any extraterrestrial civilisation that happened to be in the line of sight of these beams could likely detect these unambiguously artificial signals.Finding megastructuresAside from finding an actual alien spacecraft, radio waves are the most common technosignatures featured in sci-fi movies and books. But they are not the only signals that could be out there.In 1960, astronomer Freeman Dyson theorised that, since stars are by far the most powerful energy source in any planetary system, a technologically advanced civilisation might collect a significant portion of the star's light as energy with what would essentially be a massive solar panel.Many astronomers call these megastructures, and there are a few ways to detect them.After using the energy in the captured light, the technology of an advanced society would re-emit some of the energy as heat.Astronomers have shown that this heat could be detectable as extra infrared radiation coming from a star system.Another possible way to find a megastructure would be to measure its dimming effect on a star. Specifically, large artificial satellites orbiting a star would periodically block some of its light.This would appear as dips in the star's apparent brightness over time. Astronomers could detect this effect similarly to how distant planets are discovered today.A whole lot of pollutionAnother technosignature that astronomers have thought about is pollution.Chemical pollutants – like nitrogen dioxide and chlorofluorocarbons on Earth are almost exclusively produced by human industry. It is possible to detect these molecules in the atmospheres of exoplanets with the same method the James Webb Space Telescope is using to search distant planets for signs of biology.If astronomers find a planet with an atmosphere filled with chemicals that can only be produced by technology, it may be a sign of life.Finally, artificial light or heat from cities and industry could also be detectable with large optical and infrared telescopes, as would a large number of satellites orbiting a planet.But a civilisation would need to produce far more heat, light and satellites than Earth does to be detectable across the vastness of space using technology humans currently possess.Which signal is best?No astronomer has ever found a confirmed technosignature, so it's hard to say what will be the first sign of alien civilisations.While many astronomers have thought a lot about what might make for a good signal, ultimately, nobody knows what extraterrestrial technology might look like and what signals are out there in the Universe.Some astronomers support a generalised SETI approach which searches for anything in space that current scientific knowledge cannot naturally explain. Some, like us, continue to search for both intentional and unintentional technosignatures.The bottom line is that there are many avenues for detecting distant life. Since no one knows what approach is likely to succeed first, there is still a lot of exciting work left to do.By Macy Huston and Jason Wright, Penn State (The Conversation)",0.0,0.0
209,https://www.africanews.com/2022/09/15/undersea-power-cable-to-connect-egypt-to-europe-via-greece/,Undersea power cable to connect Egypt to Europe via Greece,"How can Europe manage to secure abundant and cheaper electricity?One of the most ambitious projects in the planning is the interconnection of Europe with Egypt via Greece.An undersea cable that will carry 3,000 MW RES electricity and connect northern Egypt directly to Attica in Greece.The project has been undertaken by the Copelouzos Group, whose management met last week with the Egyptian leadership to speed up the procedures""By bringing 3,000 MW of clean energy to Europe, via Greece, we are helping Europe wean itself off Russia's fossil fuels and natural gas. Also, the green energy we will transport will be much cheaper than today's energy prices. You understand that this will help both Greek and European consumers"", said Ioannis Karydas, CEO of Renewables, Copelouzos Group.The so-called ""GREGY interconnection” is a 3.5 billion euro project that has been categorized as a Project of Common Interest (PCI) by the European Union.It will carry clean electricity produced in Egypt (or other African countries) through solar or wind parks.""Approximately one third (of the electricity that will come from Egypt) will be consumed in Greece, and mainly in Greek industries, another third will be exported to neighboring European countries and one third will be used in Greece, for the production of green hydrogen. The majority of this hydrogen will also be exported to neighboring European countries"", added Ioannis Karydas.Egypt has completed interconnections with Libya, Sudan and Saudi Arabia and aspires to become a major energy hub for SE Europe too.The ""GREGY interconnection” is expected to be operational in 7 to 8 years.",0.0,0.0
557,https://techcrunch.com/2022/08/16/winners-losers-abound-as-inflation-reduction-act-becomes-law/,"Winners, losers abound as Inflation Reduction Act becomes law","President Joe Biden signed the climate-and-energy-focused Inflation Reduction Act into law today, a turn of events that just a few months ago seemed impossible. The move will undoubtedly bolster the United States’ stance in the next round of climate negotiations. And by the end of the decade, it’s expected that the law will reduce the country’s emissions by 40% below 2005 levels. That’s enough to put the country within spitting distance of reductions that could limit warming to 1.5 degrees Celsius.As with any legislation, there are winners and losers. In the new law, climate tech is undoubtedly a winner, with provisions that will bolster renewable power, net-zero buildings and zero-emissions transportation.But the details matter, and some sectors got a better deal than others. Here’s a rundown of which companies are likely to benefit and which didn’t get what they expected.The winnersAt or near the top of the list are renewable-energy developers. Before the Inflation Reduction Act passed, tax credits on solar and wind were going to expire at the end of 2024. Now, they’re a little sweeter and are extended through 2032. For developers like Terabase, which recently raised a $44 million round led by Breakthrough Energy Ventures, and Arcadia, which recently closed a $200 million Series E, that’ll be a boon.",0.0,0.0
563,https://www.cnbc.com/2022/10/12/new-zealand-plans-to-tax-emissions-from-livestock-burps-and-dung.html,New Zealand plans to tax emissions from livestock burps and dung,"Cattle photographed in New Zealand. Agriculture plays a major role in New Zealand's economy, especially when it comes to exports. David Clapp | Stone | Getty ImagesNew Zealand plans to tax agricultural emissions — including those related to the burps, urine and dung from livestock like cows and sheep — in a move its government hopes will help the country meet climate change goals. The aim is for the ""agricultural emissions-pricing system"" to come into force in 2025. A consultation looking at how levies are set, transition assistance and sequestration — which the document defines as ""the process of removing carbon dioxide from the atmosphere"" — was launched this week, and will run until Nov. 18. The government said revenue from the levy would be ""recycled back into [the] agriculture sector through new technology, research and incentive payments to farmers."" The idea of introducing such a system by the middle of this decade was contained within an emissions reduction plan published in May 2022, as well as a recommendation published in June by the He Waka Eke Noa – Primary Sector Climate Action Partnership.In a statement Tuesday, New Zealand's Prime Minister Jacinda Ardern backed the plans. ""This is an important step forward in New Zealand's transition to a low emissions future and delivers on our promise to price agriculture emissions from 2025,"" she said. ""No other country in the world has yet developed a system for pricing and reducing agricultural emissions, so our farmers are set to benefit from being first movers,"" Ardern went on to say. Agriculture plays a major role in New Zealand's economy, including exports, but it accounts for a considerable chunk of the country's emissions. In the consultation document, authorities said greenhouse gas emissions from agriculture — carbon dioxide, nitrous oxide and methane — were responsible for more than half of New Zealand's gross emissions. According to the document, carbon dioxide stems from urea, while nitrous oxide comes from livestock dung and urine. Methane is emitted through belching and, to a lesser extent, gas.",0.0,0.0
550,https://www.cnbc.com/2022/10/12/japanese-moon-company-ispace-launching-cargo-mission-in-november.html?utm_term=Autofeed&utm_medium=Social&utm_content=Main&utm_source=Twitter#Echobox=1665585387,Japanese lunar company ispace aims to launch first cargo mission to the moon next month,"Japanese lunar exploration company ispace announced plans on Wednesday to launch its first cargo mission next month, racing to be the first of several private ventures to deliver payloads to the moon's surface.The private company aims to launch its ""Mission 1"" lunar lander during a window between Nov. 9 and Nov. 15, riding on one of SpaceX's Falcon 9 rockets from Cape Canaveral, Florida.Mission 1 will carry a variety of payloads for both companies and governments, including a pair of rovers. The company completed testing of its spacecraft in September, and is about to transport the lander to Florida.Alongside ispace in the burgeoning lunar cargo marketplace are the likes of U.S. companies Astrobotic and Intuitive Machines, both of which plan to launch missions to the moon's surface next year.Born out of Google's Lunar XPRIZE competition last decade, ispace aims to provide a wide variety of lunar-focused services, ranging from transportation of cargo to selling data to space agencies.It now has more than 200 employees across its offices in Japan, Luxembourg and the U.S. To date ispace has raised more than $200 million in funding.",0.0,0.0
166,https://futurism.com/garth-illingworth-james-webb,The JWST's Data Is So Incredible That Even Those Who Built It Are Questioning Previous Science,"UC Santa Cruz astronomer Garth Illingworth, former Deputy Director of the Space Telescope Science Institute, has had a hell of a career.He's dedicated decades to the pursuit of finding and understanding the most distant galaxies, and was a leader on the team that built the Hubble Space Telescope. And before the Hubble was even in the sky, he'd already started to develop the James Webb Space Telescope (JWST) — yes, that James Webb Space Telescope, the one that's currently blowing Earthlings' minds on the daily with wildly beautiful images of our universe.While most of us look at those JWST pictures and just see pictures, Illingworth and his peers see all that and more: data. Over its few operational months, Webb has already offered an illuminating breadth of information — findings that have confirmed, confounded, and even contradicted existing theories about the cosmos. Curious about what that data means ourselves, we caught up with Illingworth to talk about space telescopes, far away worlds, and the ever evolving scientific process.This interview has been edited and condensed for length and clarity.Futurism: Your work has been extensive. Can you tell us a bit about your research and where it's taken you?Garth Illingworth: Sure, I'll give you the scientific framework. I'm an astronomer, and my key interests have been the early galaxies in the universe. Basically, we live 13.8 billion years after the Big Bang in a great, wonderful spiral galaxy, the Milky Way. But we had to get to this point.The very beginnings have intrigued me for a long time, ever since I saw the Hubble Deep Field back in 1995 — the first deep Hubble image of a blank part of the sky, which turned out not to be blank, but just absolutely packed with galaxies. That's what I've been working on for 25 or so years. Actually, back in the 80s, when I first started thinking about Webb, we hadn't even launched Hubble. Riccardo Giacconi, the director of the Space Telescope Science Institute at that time, said to me: ""You guys really need to work on the next big telescope. Trust me, it's gonna take a long time.""We had to do a rather interesting thing at that point. We had to project forward, even when we didn't know what Hubble was going to discover. We realized that we should go to longer wavelengths, we should really go into the infrared — we felt there were so many ways in which that could reveal aspects of the universe that Hubble would never reveal. It had to be a big telescope to work in the infrared. It had to be really cold, which meant it needs to be a long way from here. When we look back at the drawings now, these very simple-minded drawings, it's completely different from Webb, but in fact Webb operates and has the characteristics we thought of then. It's a big telescope, it's infrared, it's really cold, it's a hell of a long way away from us [laughs].Correct me if I'm wrong, but you and your team discovered what's believed to be the most distant and earliest galaxy that humans have yet seen, dating back to about 400 million years after the Big Bang.Yes. So, about seven or eight years ago, using Hubble, we amazingly found an object that was about 400 million, 450 million years after the Big Bang. I think if you'd asked me 10 years ago whether Hubble would have done that, I would have said no way. But it turned out that right at the limits of Hubble, we were able to find this early galaxy, and we could actually see it with the Spitzer Space Telescope — we could show there was a fuzzy blob there. That sat around as a real enigma for, like, seven years. We couldn't learn much about it, but it pointed to a very interesting change in the way galaxies were building up at early times. So the moment Webb got operational, the big question was: is this object unique? Or are there lots of others like that?Within four days of the Webb data being released in early-to-mid July, we already had a paper submitted to the preprint server. Actually, there were two groups to do it the same day, saying that we've discovered a couple of other objects like that one, and one of them was even further away. This was the sort of step that we had hoped that Webb would do — that it would expand our horizons into earlier times, and it did that incredibly quickly and very well.I think that goes back to the point about working on getting Hubble into space, but already thinking about the next thing. Now, it seems like the James Webb is happening very quickly — but it's because there's already such a large scientific foundation.Yeah, exactly. In the late 1990s, after the Hubble Deep Field came out, the goal of finding the first galaxies became the central goal for Webb. But right around that time, we discovered the first exoplanets. Dark energy was being discussed, and dark matter. There were so many things that Hubble was finding that we knew Webb would make a difference on — we just ended up having to wait 23 years.In July, when the first images were released, we had an hour where we were all seeing them for the first time. I was sitting in the same auditorium at Space Telescope where we had held the first meeting 33 years ago. It was a bit bizarre sitting there, looking around going God, this room looks pretty much the same as when we first talked about Webb, and here we're now seeing the first images coming in. And they're absolutely amazing.One particularly juicy takeaway from the James Webb is that some new data appears to contradict previous findings. Can you tell us more about that early galaxy that was a lot more massive than previously expected?Yes, sure. So this one, which we gave the name GNZ11 — not a very imaginative name, but astronomers are pretty boring when it comes to naming objects [laughs] — pointed to something unusual at these very early times.So in the in the first four days after the Webb images were released, we wrote these papers, and we realized that GNZ11 wasn't unique — there were others of these very bright, very luminous galaxies, which we interpreted as being unusually massive. Then, within weeks, there was another one even further back in time, closer to the Big Bang, that was still very massive. That has really been a surprise. We have to ask ourselves: is it really massive? Or does it have really unusual stars in it that are very bright, but not so much mass? We just don't know at this point, but Webb can answer these questions.What we need to do now is go in and look at those objects in more detail, see if we can learn more about what's actually in that galaxy. What the stars are like, whether there's lots of smaller stars that contribute a lot of mass. Theorists are now wondering: how do you build a galaxy like this so quickly, and does it have a black hole that's been building extremely rapidly in there as well? Are we been deceived? Galaxies can be pretty tricky. The universe can play games with you, even when you have Webb-quality data, but not enough of it.What do you think that a situation like this says about the scientific process itself?This is interesting, because I would say that in times past there was a very slow process of doing things. Data didn't come in very fast. We spent a lot of time working with it, sometimes you'd have to go back and get some more. Then, you know, the papers would come out, and we'd be pretty definitive. Papers come out, everybody thinks ""oh, this is great."" Then a year later, some new data comes along that goes ""well, that was wrong."" You have to recognize you can be wrong at any point, but when you're wrong, you learn new things.I think I've never felt particularly bad if people take the care to do as well as they can at the time, and then go back and revise things. Being wrong isn't bad, it's part of the process. And it's probably inevitable at this stage.Webb has been busy. Is there an upcoming target on its list that you're particularly excited to see and learn more about?Yes, the big image that was shown originally, of the cluster of galaxies, that was pointed to what I think will be extremely valuable in the future for learning more about galaxies. But I don't want to just emphasize the distant galaxies — exoplanets are going to be amazing, and then of course those star-forming regions like Carina and the Tarantula Nebula. Those look magnificent, but there's an incredible amount of science in those as well.And I would just say, you know, when I was sitting there watching the first images, I was just blown away by their beauty and the character there, the information. But one of the things I was thinking afterwards was: in that hour, I saw, like, six sets of data. I have to say, that's more data than I've ever seen from anything in any sort of reasonable time period in my whole life. Scientists are going to be working on those alone for ages, because there's so much information in those. And that was just a pathfinder — I mean, that was tens of hours of time, so we're gonna multiply that by 100, 1000 times every year.One of the things that I often get asked is: why does it matter? It's a lot of money. I've often thought about this, and I think the human race has a deep interest in our origins. We're interested in how we came about, how life came about. And then you really go, well, we're sitting on this little planet, how do the planets form? You can take this origins question, and that's what astronomy is really about. Webb, Hubble, these things are just origins machines. And what I really like about this, in so many ways, is that we're living in a very divisive environment, and this interest cuts across the lot of these political and otherwise areas beautifully.It's one of those places where we still have some common interests — which I hope we can expand in the future! Webb at least should contribute to that.More on the James Webb Space Telescope: Scientists Puzzled Because James Webb Is Seeing Stuff That Shouldn't Be There",0.0,0.0
586,https://techcrunch.com/2021/03/26/vibrant-raises-7-5m-for-a-drug-free-mechanical-pill-to-treat-constipation/,Vibrant raises $7.5M for a drug-free mechanical pill to treat constipation,"Vibrant, a medical technology company that’s developed a disposable vibrating pill to treat chronic constipation, today announced its Series E for $7.5 million. The company is based in Tel Aviv and is lead by Lior Ben-Tsur, a startup veteran. Since its founding in 2007, the company has raised a total of $25 million. This round is being led by Unorthodox Ventures, with participation by Sequoia.Vibrant, which is going through its third and final round of Food and Drug Administration (FDA) testing, plans to launch in the U.S. in the next year. The capsules are about the size of a multi-vitamin, Ben-Tsur said.“Patients are used to taking drugs day in and day out, so this wouldn’t be a different experience in that regard, but this pill doesn’t have any medication,” Ben-Tsur said. While Ben-Tsur is not a founder, he was brought on about 10 years ago to serve as the company’s CEO.According to a study published in the American Gastroenterological Association, about 16% of American adults suffer from constipation, and the number jumps to 33.5% in adults between the ages of 60-101. Also, constipation is 1.5 times more common in women than in men.The most common way to treat constipation is through the use of over-the-counter or prescription drugs, most of which target the nerves in the colon, which in turn prompt a bowel movement. The Vibrant Capsule, however, “once swallowed, kickstarts the natural impulses of your intestinal wall to contract, relax and get things moving again — without the use of chemicals,” the company said in a statement.In addition to being medication-free, the value of Vibrant over laxatives, according to the company, is that the bowel movements are more controlled, whereas laxatives can cause unexpected diarrhea and long-term side effects. Also, while laxatives are meant to be taken on a daily basis, the disposable capsule can be used anywhere from 2-5 times per week. The capsules connect to an app that automatically records when you take a pill, and upon having a bowel movement, the person notes it in the app, which then sends a monthly report to the patient’s doctor, allowing them to monitor and adjust the treatment protocol as necessary.In a 2019 human trial organized by Vibrant, 250 patients were enrolled in a double-blind study (Vibrant Capsule = 133, placebo = 117). The results showed that those who took the Vibrant Capsule were more likely to experience a bowel movement within three hours. The trial details and the results were published in the journal of Neurogastroenterology and Motility.Several years ago a group of doctors and engineers performed a test in a live pig’s colon, and accidentally pinched the side of the colon wall. As a result, they noticed that the pig promptly had a bowel movement. The test was actually about something totally unrelated to constipation, and the results were a random discovery. To replicate the effects, the team created a vibrating belt that when worn for about three hours, would also cause a bowel movement.“The problem is no one wants to shake for three hours to have a bowel movement,” said Ben-Tsur. With this information in hand, the group set out to develop a treatment for constipation in humans that would produce similar results but where the vibrations couldn’t be felt. There were other mechanical capsules already on the market, such as the Smart Pill, a mechanical diagnostic capsule that reports on generalized motility through the entire digestive tract and aids doctors in diagnosing motility disorders, so the team knew that people could safely swallow and excrete capsules.According to Ben-Tsur, there hasn’t been any development in the treatment of constipation in the last 20 years — the treatment protocol has continued to focus on medication. When he learned about the market size, the lack of innovation in the space and the potential, he was convinced that he wanted to lead Vibrant.Vibrant plans on using this round of funding to take the capsule to market in the U.S. — its first market. The company is currently speaking with healthcare providers and insurance companies so that the capsule will be covered by insurance starting at the time of launch. The Smart Pill, while only used once as a diagnostic test, is still not covered and costs, on average, about $1,400 out of pocket. Ben-Tsur and his team aim to offer a product that is accessible. “From day one we were on a mission to build something that wouldn’t be more expensive than existing drugs,” he said.Early Stage is the premier “how-to” event for startup entrepreneurs and investors. You’ll hear firsthand how some of the most successful founders and VCs build their businesses, raise money and manage their portfolios. We’ll cover every aspect of company building: Fundraising, recruiting, sales, product-market fit, PR, marketing and brand building. Each session also has audience participation built-in — there’s ample time included for audience questions and discussion. Use code “TCARTICLE” at checkout to get 20% off tickets right here.",0.0,0.0
571,https://techcrunch.com/2018/08/17/klarity-uses-ai-to-strip-drudgery-from-contract-review/,Klarity uses AI to strip drudgery from contract review,"Klarity, a member of the Y Combinator 2018 Summer class, wants to automate much of the contract review process by applying artificial intelligence, specifically natural language processing.Company co-founder and CEO Andrew Antos has experienced the pain of contract reviews first hand. After graduating from Harvard Law, he landed a job spending 16 hours a day reviewing contract language, a process he called mind-numbing. He figured there had to be a way to put technology to bear on the problem and Klarity was born.“A lot of companies are employing internal or external lawyers because their customers, vendors or suppliers are sending them a contract to sign,” Antos explained They have to get somebody to read it, understand it and figure out whether it’s something that they can sign or if it requires specific changes.You may think that this kind of work would be difficult to automate, but Antos said that contracts have fairly standard language and most companies use ‘playbooks.’ “Think of the playbook as a checklist for NDAs, sales agreements and vendor agreements — what they are looking for and specific preferences on what they agree to or what needs to be changed,” Antos explained.Klarity is a subscription cloud service that checks contracts in Microsoft Word documents using NLP. It makes suggestions when it sees something that doesn’t match up with the playbook checklist. The product then generates a document, and a human lawyer reviews and signs off on the suggested changes, reducing the review time from an hour or more to 10 or 15 minutes.They launched the first iteration of the product last year and have 14 companies using it with 4 paying customers so far including one of the world’s largest private equity funds. These companies signed on because they have to process huge numbers of contracts. Klarity is helping them save time and money, while applying their preferences in a consistent fashion, something that a human reviewer can have trouble doing.He acknowledges the solution could be taking away work from human lawyers, something they think about quite a bit. Ultimately though, they believe that contract reviewing is so tedious, it is freeing up lawyers for work that requires a greater level of intellectual rigor and creativity.Antos met his co-founder and CTO, Nischal Nadhamuni, at an MIT entrepreneurship class in 2016 and the two became fast friends. In fact, he says that they pretty much decided to start a company the first day. “We spent 3 hours walking around Cambridge and decided to work together to solve this real problem people are having.”They applied to Y Combinator two other times before being accepted in this summer’s cohort. The third time was the charm. He says the primary value of being in YC is the community and friendships they have formed and the help they have had in refining their approach.“It’s like having a constant mirror that helps you realize any mistakes or any suboptimal things in your business on a high speed basis,” he said.",0.0,0.0
483,https://techcrunch.com/2022/07/13/bowery-farming-found-podcast/,Vertical farming founder is reimagining agriculture from the ground up,"Welcome back to Found, the TechCrunch podcast that brings you the stories behind the startups.This week’s guest, Bowery Farming founder and CEO Irving Fain wants you to taste the best strawberry you’ve ever had, grown only a few miles from your urban home. As the leading and largest vertical farming company in the U.S, their goal is to make agriculture possible in urban spaces while also making it possible to grow a wide array of crops from anywhere in the world. Darrell and Jordan talk to him about how agtech companies all have a space in the fight against climate change, what led him to start Bowery, and how they are innovating and scaling thoughtfully.Subscribe to Found to hear more stories from founders each week.Connect with us:",0.0,0.0
113,https://www.theguardian.com/business/2022/nov/02/tech-firms-becoming-too-big-to-govern-says-uber-whistleblower,"Tech firms becoming âtoo big to governâ, says Uber whistleblower","Governments are losing the battle to regulate big tech and company insiders should step forward to expose “bad apples” in the sector, according to the Uber whistleblower.Mark MacGann – the taxi firm’s former chief lobbyist in Europe, the Middle East and Africa – leaked more than 124,000 company files to the Guardian this year, revealing how the ride-hailing company flouted laws, duped police, exploited violence against drivers and secretly lobbied governments from 2013 to 2017.Speaking at the Web Summit in Lisbon on Wednesday, MacGann said governments were still struggling to rein in major tech firms.“Governments and democracy are losing this battle in trying to regulate … big tech,” said MacGann, who is Irish.“Some of these tech firms have become too big to govern, too big to regulate and are richer and more powerful than some of the states that are trying to regulate them.”Moves are afoot to regulate the tech industry in some of its biggest markets. The EU is introducing the Digital Services Act, which addresses issues such as harmful content and ad targeting, while the bloc’s Digital Markets Act aims to tackle anti-competitive behaviour within the industry.In the UK, however, the landmark online safety bill, which creates a framework for dealing with damaging social media content, is once again being paused after Rishi Sunak became prime minister last month.Paying tribute to Facebook and Instagram whistleblowers Frances Haugen and Daniel Motaung, MacGann said the list of big tech whistleblowers was nonetheless “small”.Speaking at the Web Summit last year, Haugen said the CEO of Facebook and Instagram’s parent business, Mark Zuckerberg, should step down to make way for a leader more focused on user safety.Sign up to TechScape Free weekly newsletter Alex Hern's weekly dive in to how technology is shaping our lives Privacy Notice: Newsletters may contain info about charities, online ads, and content funded by outside parties. For more information see our Newsletters may contain info about charities, online ads, and content funded by outside parties. For more information see our Privacy Policy . We use Google reCaptcha to protect our website and the Google Privacy Policy and Terms of Service apply.Asked if he had a message for would-be whistleblowers among the 70,000 in attendance at the summit or those watching it online, MacGann said: “Remember why you joined, remember the power of technology, the power of telecommunications, the power of brilliant software. And don’t let a few bad apples screw it all up.”MacGann added that whistleblowers did not need to go public in order to highlight problems at their companies. But people with concerns about how their workplaces are run should step forward.“You don’t have to change your life and be the public face to try to correct the wrongdoing. But if you stand back and say nothing, then you’re going to have that on your conscience for a long time,” he said.",0.0,0.0
342,https://news.mit.edu/2022/sensors-face-masks-fit-1020,MIT engineers develop sensors for face masks that help gauge fit,"The study is a collaboration between Dagdeviren’s lab; Siqi Zheng, the STL Champion Professor of Urban and Real Estate Sustainability in the Department of Urban Studies and Planning; and Tolga Durak, managing director of MIT’s Environment, Health, and Safety programs. Jin-Hoon Kim, an MIT postdoc, is the lead author of the paper, which appears today in Nature Electronics.The researchers hope that their sensor will help people to find masks that fit them better, and that designers could use it to create masks that fit a wider variety of face shapes and sizes. The sensor can also be used to monitor vital signs such as breathing rate and temperature, as well as environmental conditions such as humidity.“What we realized by analyzing our collected data from the individuals in the study was that the masks that we use in daily life are not very suitable for female participants,” says Canan Dagdeviren, the LG Career Development Professor of Media Arts and Sciences at MIT and the corresponding author of the study.Using this sensor, the researchers analyzed the fit of surgical masks on male and female subjects, and found that overall, the masks fit women’s faces much less closely than they fit men’s faces.Currently, there are no simple ways to measure the fit of a mask, but a new sensor developed at MIT could make it much easier to ensure a good fit. The sensor, which measures physical contact between the mask and the wearer’s face, can be applied to any kind of mask.Wearing a mask can help prevent the spread of viruses such as SARS-CoV-2, but a mask’s effectiveness depends on how well it fits.Fit qualityThe researchers began working on this project before mask-wearing became common during the Covid-19 pandemic. Their original intention was to use sensors embedded in masks to measure the effectiveness of mask-wearing in areas with high levels of air pollution. However, once the pandemic started, they realized that such a sensor could have more widespread applications.With so many different kinds of masks available during the pandemic, the researchers thought this kind of sensor could be useful to help individuals find the best-fitting mask for them. Currently, the only way to measure mask fit is to use a machine called a mask fit tester, which evaluates the mask fit by comparing air particle concentrations inside and outside of the face mask. However, this type of machine is only available in specialized facilities such as hospitals, which use them to evaluate mask fit for health care workers.The MIT team wanted to create a more user-friendly, portable device to measure mask fit. Dagdeviren’s lab, the Conformable Decoders group, specializes in developing flexible, stretchable electronics that can be worn on the skin or incorporated into textiles to detect signals from the body.“In this project, we wanted to monitor both biological and environmental conditions simultaneously, such as breathing pattern, skin temperature, human activities, temperature and humidity inside the face mask, and the position of the mask, including whether people are wearing it properly or not,” Kim says. “We also wanted to check the fit quality.”To integrate their sensors into face masks, the researchers created a device that they call a conformable multimodal sensor face mask (cMaSK). Sensors that measure a variety of parameters are embedded in a flexible polymer frame that can be reversibly attached to the inside of any mask, around the edges.To measure fit, the cMaSK has 17 sensors around the edge of the mask that measure capacitance, which can be used to determine whether the mask is touching the skin at each of those locations.The cMaSK interface also has sensors that measure temperature, humidity, and air pressure, which can detect activities such as speaking and coughing. An accelerometer within the device can reveal if the wearer is moving around. All of the sensors are embedded into a biocompatible polymer called polyimide, which is used in medical implants such as stents.The conformable electronics are laminated and delaminated on a surgical mask.The researchers tested the cMaSK interface in a group of five men and five women. All of the subjects wore surgical masks, and the researchers monitored the readings from the sensors as the participants performed a variety of activities, such as speaking, walking, and running. They also tested the sensors in a variety of temperature conditions.Using data obtained by the capacitance sensors, the researchers created a machine-learning algorithm to calculate mask fit quality for each subject in the study. These measurements revealed that mask fit was significantly worse for women than men, due to differences in face shape and size. However, the fit for women could be improved slightly by wearing smaller surgical masks. The researchers also found that mask fit quality was low for one of the male subjects who had a beard, which created gaps between the mask and the skin.To verify their results, the researchers also collaborated with MIT’s Environment, Health, and Safety Office on the design and evaluation of the fit, and found that the fit results for each study participant were very similar to what they found using the cMaSK.Customized fitThe researchers hope that their findings will encourage mask manufacturers to design masks that fit a variety of face shapes and sizes, especially women’s faces. Dagdeviren’s lab is planning to work on mass production and large-scale deployment of the cMaSK interface.“We hope to think about ways to design masks and come up with the best fit for individuals,” Dagdeviren says. “We have different sizes for shoes, and you can even customize your shoes. So why can’t you customize and design your mask, for your own health and for societal benefit?”The researchers also hope to return to their original idea of studying the effects of air pollution on people who work outside.“Our technology can really help to quantify the social costs of these environmental hazards, and also to measure the benefits of any kind of policy intervention,” Zheng says.The research was funded by the MIT Media Lab Consortium, the 3M Non-Tenured Faculty Award, and the MIT International Science and Technology Initiative (MISTI) Global Fund.",0.0,0.0
148,https://www.psypost.org/2022/10/trump-voters-conspiracy-beliefs-about-the-democratic-party-increased-after-the-2020-election-according-to-a-five-wave-study-64154,"Trump votersâ conspiracy beliefs about the Democratic party increased after the 2020 election, according to a five-wave study","The outcome of an election can influence voters’ conspiracy beliefs, according to study findings published in the journal Applied Cognitive Psychology. Following the 2020 U.S. presidential election, Trump voters endorsed more conspiracy beliefs about the Democratic party, while Biden voters endorsed fewer conspiracy beliefs about the Republican party.Following Donald Trump’s 2020 election loss, conspiracy theories were widely circulated in conservative media claiming that the election outcome was rigged. Such conspiracy beliefs can have troubling consequences for society, and scientists are working to uncover how these beliefs develop.“In general, I am interested in conspiracies, because sometimes conspiracies can cause social problems like distrust and polarization,” said study author Haiyan Wang, a PhD candidate at Vrije Universiteit Amsterdam and the Netherlands Institute for the Study of Crime and Law. “There are many conspiracies related to the U.S. presidential elections, we were wondering what’s the difference between election losers’ and winners’ conspiracy beliefs.”Wang and his co-author Jan-Willem van Prooijen launched a five-wave longitudinal study to examine how Americans’ conspiracy beliefs changed over time in the wake of the 2020 election. Specifically, they assessed how the election results influenced voters’ belief that the election was rigged by the other party. The researchers further explored how the election results impacted Americans’ general conspiracy mentality.Wang and van Prooijen recruited a total of 376 Americans to participate in the study. Data collection took place between October 13 and December 20, 2020 — two waves took place before the election, and three waves took place after the election. At each wave, participants rated the plausibility of specific conspiracy theories about the election. They also completed a measure of conspiracy mentality that assessed a general tendency to believe in conspiracy theories.At every wave, participants also indicated which candidate they intended to vote for (Waves 1 and 2) or which candidate they had voted for (Waves 3 to 5). The researchers focused their analysis on Biden and Trump voters only, resulting in a sample of 229 Biden voters and 71 Trump voters.First, the findings revealed that conspiracy mentality remained relatively constant over the two months, for both Biden and Trump voters. This is consistent with the view that conspiracy mentality is a stable trait. However, participants’ belief in specific conspiracy theories about the election did change over time, and these changes looked different for Biden and Trump voters.Outgroup conspiracy beliefs — conspiracy beliefs about the opposing political party — decreased over time among Biden voters. Specifically, Biden voters’ belief that the Republican party had conspired during the election decreased over time. However, the opposite was true for Trump voters. For them, belief that the Democratic party had conspired during the election (e.g., ‘The elections will be (were) rigged to favor Joe Biden’) increased over time.“After the election, conspiracy beliefs of voting fraud increased among people who voted for Trump,” Wang told PsyPost. “However, they decreased among people who voted for Biden.”Ingroup conspiracy beliefs — conspiracy beliefs about one’s preferred political party — decreased over time among both Trump and Biden voters. Specifically, Biden voters’ belief that the Democratic party had conspired during the election and Trump voters’ belief that the Republican party had conspired during the election decreased following the results. Notably, ingroup conspiracy beliefs were more common among Trump voters, especially at the first wave. This finding may support previous evidence that conspiracy beliefs are more prevalent among Republicans compared to Democrats.Wang and van Prooijen say their study results demonstrate that election events can influence voters’ conspiracy beliefs, but not conspiracy mentality. This suggests the possibility that the two types of conspiracy thinking involve different cognitive processes. The new findings also support previous research that found supporters of a losing candidate are especially likely to endorse conspiracy theories, since Trump voters’ outgroup conspiracy beliefs increased after the election results while Biden voters’ decreased.Among other limitations, the study sample was small and non-representative of the American electorate. The authors also say that future research should include a longer study period since it is possible that changes in conspiracy mentality would have been captured with additional waves.The study, “Stolen elections: How conspiracy beliefs during the 2020 American presidential elections changed over time”, was authored by Haiyan Wang and Jan-Willem van Prooijen.",0.0,0.0
66,https://techcrunch.com/2022/10/16/top-climate-tech-deals-net-nearly-4b-in-q3-outpacing-other-industries/,"Top climate tech deals net nearly $4B in Q3, outpacing other industries","Climate tech wrapped a strong Q3, landing three of the top four equity deals, including the whopping $1 billion Series A raised by fleet-charging startup TeraWatt.While the broader market might be cooling, climate tech continues to be a hot ticket, with investment figures for top deals in Q3 outpacing the two previous quarters this year. In total, five climate tech startups made CB Insights’ top 10 equity deals list in Q3, pulling in a combined $3.7 billion. That far exceeds last quarter’s $2.5 billion across eight top startups and Q1’s $1.4 billion across five top startups.Top climate tech investments continued to diversify, too, showing just how deeply it’s becoming embedded into the economy.",0.0,0.0
164,https://gizmodo.com/facebook-meta-photos-ads-race-gender-age-study-1849706492,"Facebook Segments Ads by Race and Age Based on Photos Whether Advertisers Want It or Not, Study Says","Facebook’s promise to advertisers is that its system is smart, effective, and easy to use. You upload your ads, fill out a few details, and Facebook’s algorithm does its magic, wading through millions of people to find the perfect audience.The inner workings of that algorithm are opaque, even to people who work at Meta, Facebook’s parent company. But outside research sometimes offers a glimpse. A new study, published Tuesday in the Proceedings of the 22nd ACM Internet Measurement Conference, finds that Facebook uses image recognition software to classify the race, gender, and age of the people pictured in advertisements, and that determination plays a huge role in who sees the ads. Researchers found that more ads with young women get shown to men over 55; that women see more ads with children; and that Black people see more ads with Black people in them.In the study, the researchers created ads for job listings with pictures of people. In some ads they used stock photos, but in others they used AI to generate synthetic pictures that were identical aside from the demographics of the people in the images. Then, the researchers spent tens of thousands of dollars running the ads on Facebook, keeping track of which ads got shown to which users.AdvertisementThe results were dramatic. On average, the audience that saw the synthetic photos of Black people was 81% Black. But when it was a photo of a white person, the average audience was only 50% Black. The audience that saw photos of teenage girls was 57% male. Photos of older women went to an audience that was 58% women.The study also found that the stock images performed identically to the pictures of artificial faces, which demonstrates that it’s just demographics, not other factors, which determines the outcome.Assuming Facebook targeting is effective, this may not be problematic when you’re considering ads for products. But “when we’re talking about advertising for opportunities like jobs, housing, credit, even education, we can see that the things that might have worked quite well for selling products can lead to societally problematic outcomes,” said Piotr Sapiezynski, a researcher at Northeastern University, who co-authored the study alongside PhD candidate Levi Kaplan, undergraduate Nicole Gerzon, and professor Alan Mislove.In response to a request for comment, Meta said the research highlights an industry-wide concern.“We are building technology designed to help address these issues,” said Ashley Settle, a Meta spokesperson. “We’ve made significant efforts to prevent discrimination on our ads platform, and will continue to engage key civil rights groups, academics, and regulators on this work.”AdvertisementFacebook’s ad targeting by race and age may not be in advertisers’ best interests either. Companies often choose the people in their ads to demonstrate that they value diversity. They don’t want fewer white people to see their ads just because they chose a picture of a Black person. Even if Facebook knows older men are more likely to look at ads depicting young women, that doesn’t mean they’re more interested in the products. But there are far bigger consequences at play.“Machine learning, deep learning, all of these technologies are conservative in principle,” Sapiezynski says. He added that systems like Facebook’s optimize systems by looking at what’s worked in the past, and assume that’s how things should look in the future. If algorithms are using crude demographic assumptions to decide who sees ads for housing, jobs, or other opportunities, that can reinforce stereotypes and enshrine discrimination.AdvertisementThat’s already happened on Facebook’s platform. A 2016 ProPublica investigation found Facebook let marketers hide ads for housing from Black people and other protected groups in violation of the Fair Housing Act. After the Department of Justice stepped in, Facebook stopped letting advertisers target ads based on race, religion, and certain other factors.But even if advertisers can’t explicitly tell Facebook to discriminate, the study found that the Facebook algorithm might be doing it based on the pictures they put in their ads anyway. That’s a problem if regulators want to force a change.AdvertisementSettle, the Meta spokesperson, said that Meta has invested in new technology to address its housing discrimination problem and that the company will extend those solutions to ads related to credit and jobs. The company will have more to share in the coming months, she added.AdvertisementYou could look at these results and think, “so what?” Facebook doesn’t publish the data, but maybe ads with pictures of Black people perform worse with white audiences. Sapiezynski said even if that’s true, it’s not a reasonable justification.In the past, newspapers separated job listings by race and gender. Theoretically, that’s efficient if the people doing the hiring were prejudiced. “Maybe this was effective, at the time, but we decided that this is not the right way to approach this,” Sapiezynski said.AdvertisementBut we don’t have even enough data to prove Facebook’s methods are effective. The research may demonstrate that the platforms ad system isn’t as sophisticated as they want you to think. “There isn’t really a deeper understanding of what the ad is actually for. They look at the image, and they create a stereotype of how people behaved previously,” Sapiezynski said. “There is no meaning to it, just crude associations. So these are the examples, I think, that show that the system is not actually doing what the advertiser wants.”Correction: 10/27/2022 3:45 p.m. ET: The original version of this story misstated the name of the journal where the study was published.",0.0,0.0
555,https://news.sky.com/story/un-chief-antonio-guterres-tells-rich-countries-to-impose-tax-on-fossil-fuel-firms-feasting-on-windfall-profits-12701867,UN chief Antonio Guterres urges rich countries to impose tax on fossil fuel firms 'feasting' on windfall profits,"The leader of the United Nations has urged all rich countries to impose a windfall tax on fossil fuel companies.The industry is ""feasting on hundreds of billions of dollars in subsidies and windfall profits while household budgets shrink and our planet burns"", Antonio Guterres told world leaders in New York.Record profits enjoyed by fossil fuel firms at a time of high energy costs and a cost of living crisis have prompted calls in many countries for leaders to impose a one-off tax on the extra income.Money raised should be used to help people struggling with rising food and energy bills, as well as to compensate countries suffering the most severe effects of climate change, the secretary-general told the United Nations General Assembly, which is expected to be dominated by discussions of Russia's invasion of Ukraine.Sparks fly over damage from climate changeIn spite of demanding ""polluters must pay"", Mr Guterres cannot mandate action from developed countries, many of which are grappling with extreme weather, high food and energy prices and the Ukraine war.But Antony Froggatt, from international affairs think tank Chatham House, said the statement ""is an important signal"" and highlights the ""unequal nature of the current crisis, with some countries, companies and citizens benefiting hugely"".But Mr Guterres has previously urged an end to funding for more oil and gas exploration and production, ""which has not stopped these taking place"", Mr Froggatt added.The European Union plans to raise about €140bn (£121bn) by imposing windfall taxes on energy companies' ""abnormally high profits"", a move that could put pressure on Prime Minister Liz Truss to do more in the ""mini budget"" on Friday.AdvertisementMs Truss decided against extending the UK's windfall tax for North Sea extractors - set at 25% but which can largely be avoided if companies reinvest the money in new extraction. Instead she has pledged to freeze energy bills at an average of £2,500 a year, which will be paid for by borrowing.The UN chief told world leaders that nations are ""gridlocked in colossal global dysfunction"" and are not ready or willing to tackle the major challenges that threaten the future of humanity and the fate of the planet.He warned of ""cascading"" climate, energy and cost of living crises that are ""feeding on each other, compounding inequalities, creating devastating hardship, delaying the energy transition and threatening global financial meltdown"".Please use Chrome browser for a more accessible video player 3:03 'I am against a windfall tax'""Social unrest is inevitable - with conflict not far behind,"" he said.Mr Froggatt said that ""adapting to and preparing for further environment and resource shocks will be a, if not the challenge"", in future.Mr Guterres also said that it was time to hold to account fossil fuel companies ""and their enablers"", including financial and PR firms that are ""raking in billions to shield the fossil fuel industry from scrutiny"".""Fossil fuel interests need to spend less time averting a PR disaster and more time averting a planetary one,"" Mr Guterres said.Scientists agree that pollution must be reduced by 45% by 2030 to have any hope of reaching net zero by 2050, and stave off the worst of climate breakdown. But emissions, which mostly come from burning oil, gas and coal, are on course to rise by 16% by 2030, compared with 2010 levels.Ipek Gençsü, from global affairs think tank ODI, said windfall taxes are unpopular with fossil fuel companies as well as from some economic perspectives, which argue they disincentivise private investment by ""changing the rules of the game"".But we cannot have conversations about windfall taxes ""without understanding the bigger picture, and the fact that fossil fuel companies and fossil fuel emissions are the biggest contributor to the climate crisis,"" she said.Watch the Daily Climate Show at 3.30pm Monday to Friday, and The Climate Show with Tom Heap on Saturday and Sunday at 3.30pm and 7.30pm.All on Sky News, on the Sky News website and app, on YouTube and Twitter.The show investigates how global warming is changing our landscape and highlights solutions to the crisis.",0.0,0.0
542,https://techcrunch.com/2019/09/11/relativity-space-signs-its-the-satellite-transportation-company-momentus-as-its-first-customer/,Relativity Space signs the satellite transportation company Momentus as a new customer,"Relativity Space, the startup developing manufacturing technologies for entirely 3D printed rockets and space equipment, has signed its latest paying customer, the orbital transportation startup, Momentus.Relativity’s Terran 1 rocket will carry Momentus’ small and medium-sized satellite payloads on its rocket and Momentus will then move those satellites into geosynchronous orbit using its own in-space shuttle technology.The deal between Momentus and Relativity covers the first Terran 1 launch scheduled for 2021, with the option for five additional Relativity launches, according to a statement from the company.Carrying Momentus’ payloads enables the company to include more diverse ranges of orbits for Terran 1’s initial launch, including geostationary transfer orbit, Lunar and deep space orbits, lower inclinations and phasing multiple spacecraft in low Earth orbit, the company said.The tie-up links two of Y Combinator’s space-focused alumni, with Momentus graduating in 2018 and Relativity launching from the accelerator in 2016.In July, Momentus closed on a $25 million round of funding to move its business from simply providing a thruster for existing small-sats to becoming a full-service provider of orbital transportation services for payloads. The company’s key innovation was the development of a water-based plasma propulsion system for low-cost transportation in space. That’s what powers the company’s Vigoride orbital shuttle.Meanwhile, Relativity Space is barreling ahead with its own technology development.With the goal of building a rocket that goes from raw materials to launch-ready in less than 60 days with a payload capacity of up to 1250 kilograms, the company is planning its first test launch in 2020 with a commercial payload ready for 2021.So far the company has performed 200 engine tests to date across 14 different serial numbers and begun conducting turbo pump testing as well. Testing has also begun on the company’s initial avionics hardware, according to company co-founder Tim Ellis.Relativity has also started printing and stress testing some second stage structures and is beginning to print its larger primary stage structures now.“With Momentus’ innovations in sustainable in-space ‘last mile’ solutions, we look forward to working together to expand Terran 1’s flexibility and offering beyond LEO, offering small and medium satellite launch opportunities with industry-defining lead time, flexibility, and cost,” Ellis said in a statement. “This partnership will enable us to build the space economy faster, and accelerate the future of humanity in space.”The company has dramatically expanded its production, testing and launch facilities to include 280,000 square feet of operations on facilities at Cape Canaveral in Florida and the NASA Stennis Space Center in Mississippi.Relativity also has customer agreements with Telesat, to support their low Earth orbit constellation; the Thai satellite and space technology company, mu Space; and Spaceflight Industries to launch their smallsat ride-shares.",0.0,0.0
145,https://www.salon.com/2022/10/16/ukraine-isnt-the-worlds-only-nuclear-flashpoint-taiwan-is-getting-ugly_partner/,Ukraine isn't the world's only nuclear flashpoint: Taiwan crisis is getting ugly,"Thanks to Vladimir Putin's recent implicit threat to employ nuclear weapons if the U.S. and its NATO allies continue to arm Ukraine — ""This is not a bluff,"" he insisted on Sept. 21 — the perils in the Russo-Ukrainian conflict once again hit the headlines. And it's entirely possible, as ever more powerful U.S. weapons pour into Ukraine and Russian forces suffer yet more defeats, that the Russian president might indeed believe that the season for threats is ending and only the detonation of a nuclear weapon will convince the Western powers to back off. If so, the war in Ukraine could prove historic in the worst sense imaginable — the first conflict since World War II to lead to nuclear devastation.But hold on! As it happens, Ukraine isn't the only place on the planet where a nuclear conflagration could erupt in the near future. Sad to say, around the island of Taiwan — where U.S. and Chinese forces are engaging in ever more provocative military maneuvers — there is also an increasing risk that such moves by both sides could lead to nuclear escalation.While neither American nor Chinese officials have explicitly threatened to use such weaponry, both sides have highlighted possible extreme outcomes there. When Joe Biden last spoke with Xi Jinping by telephone on July 29, the Chinese president warned him against allowing House Speaker Nancy Pelosi to visit the island (which she nonetheless did, four days later) or offering any further encouragement to ""Taiwan independence forces"" there. ""Those who play with fire will perish by it,"" he assured the American president, an ambiguous warning to be sure, but one that nevertheless left open the possible use of nuclear weapons.As if to underscore that point, on Sept. 4, the day after Pelosi met with senior Taiwanese officials in Taipei, China fired 11 Dongfeng-15 (DF-15) ballistic missiles into the waters around that island. Many Western observers believe that the barrage was meant as a demonstration of Beijing's ability to attack any U.S. naval vessels that might come to Taiwan's aid in the event of a Chinese blockade or invasion of the island. And the DF-15, with a range of 600 miles, is believed capable of delivering not only a conventional payload, but also a nuclear one.In the days that followed, China also sent nuclear-capable H-6 heavy bombers across the median line in the Taiwan Strait, a previously respected informal boundary between China and that island. Worse yet, state-owned media displayed images of Dongfeng-17 (DF-17) hypersonic ballistic missiles, also believed capable of carrying nuclear weapons, being moved into positions off Taiwan.One day after Nancy Pelosi met with senior officials in Taipei, China fired 11 Dongfeng-15 (DF-15) ballistic missiles — all capable of carrying a nuclear payload — into Taiwanese waters.Washington has not overtly deployed nuclear-capable weaponry in such a brazen fashion near Chinese territory, but it certainly has sent aircraft carriers and guided-missile warships into the area, signaling its ability to launch attacks on the mainland should a war break out. While Pelosi was in Taiwan, for example, the Navy deployed the carrier USS Ronald Reagan with its flotilla of escort vessels in nearby waters. Military officials in both countries are all too aware that should such ships ever attack Chinese territory, those DF-15s and DF-17s would be let loose against them — and, if armed with nuclear warheads, would likely provoke a U.S. nuclear response.The implicit message on both sides: A nuclear war might be possible. And although — unlike with Putin's comments — the American media hasn't highlighted the way Taiwan might trigger such a conflagration, the potential is all too ominously there.""One China"" and ""strategic ambiguity""In reality, there's nothing new about the risk of nuclear war over Taiwan. In both the Taiwan Strait crises of 1954-1955 and 1958, the United States threatened to attack a then-non-nuclear China with such weaponry if it didn't stop shelling the Taiwanese-controlled islands of Kinmen (Quemoy) and Mazu (Matsu), located off that country's coast. At the time, Washington had no formal relations with the communist regime on the mainland and recognized the Republic of China (ROC) — as Taiwan calls itself — as the government of all China. In the end, however, U.S. leaders found it advantageous to recognize the People's Republic of China (PRC) in place of the ROC and the risk of a nuclear conflict declined precipitously — until recently.Credit the new, increasingly perilous situation to Washington's changing views of Taiwan's strategic value to America's dominant position in the Pacific as it faces the challenge of China's emergence as a great power. When the U.S. officially recognized the PRC in 1978, it severed its formal diplomatic and military relationship with the ROC, while ""acknowledg[ing] the Chinese position that there is but one China and [that] Taiwan is part of China."" That stance — what came to be known as the ""One China"" policy — has, in fact, underwritten peaceful relations between the two countries (and Taiwan's autonomy) ever since, by allowing Chinese leaders to believe that the island would, in time, join the mainland.Want a daily wrap-up of all the news and commentary Salon has to offer? Subscribe to our morning newsletter, Crash Course.Taiwan's safety and autonomy has also been preserved over the years by another key feature of U.S. policy, known as ""strategic ambiguity."" It originated with the Taiwan Relations Act of 1979, a measure passed in the wake of the U.S. decision to recognize the PRC as the legal government of all China. Under the act, still in effect, the U.S. is empowered to supply Taiwan with ""defensive"" arms, while maintaining only semi-official ties with its leadership. It also says that Washington would view any Chinese attempt to alter Taiwan's status through violent means as a matter ""of grave concern,"" but without explicitly stating that the U.S. will come to Taiwan's aid if that were to occur. Such official ambiguity helped keep the peace, in part by offering Taiwan's leadership no guarantee that Washington would back them if they declared independence and China invaded, while giving the leaders of the People's Republic no assurance that Washington would remain on the sidelines if they did.Since 1980, both Democratic and Republican administrations have relied on such strategic ambiguity and the One China policy to guide their peaceful relations with the PRC. Over the years, there have been periods of spiking tensions between Washington and Beijing, with Taiwan's status a persistent irritant, but never a fundamental breach in relations. And that — consider the irony, if you will — has allowed Taiwan to develop into a modern, prosperous quasi-state, while escaping involvement in a major-power confrontation (in part because it just didn't figure prominently enough in U.S. strategic thinking).From 1980 to 2001, America's top foreign-policy officials were largely focused on defeating the Soviet Union, dealing with the end of the Cold War, and expanding global trade opportunities. Then, from Sept. 11, 2001, to 2018, their attention was diverted to the Global War on Terror. In the early years of the Trump administration, however, senior military officials began switching their focus from the War on Terror to what they termed ""great-power competition,"" arguing that facing off against ""near-peer"" adversaries, namely China and Russia, should be the dominant theme in military planning. And only then did Taiwan acquire a different significance.The Pentagon's new strategic outlook was first spelled out in the National Defense Strategy of February 2018 in this way: ""The central challenge to U.S. prosperity and security is the reemergence of long-term, strategic competition"" with China and Russia. (And yes, the emphasis was in the original.) China, in particular, was identified as a vital threat to Washington's continued global dominance. ""As China continues its economic and military ascendance,"" the document asserted, ""it will continue to pursue a military modernization program that seeks Indo-Pacific regional hegemony in the near-term and displacement of the United States to achieve global preeminence in the future.""An ominous ""new Cold War"" era had begun.Taiwan's strategic significance risesTo prevent China from achieving that most feared of all results, ""Indo-Pacific regional hegemony,"" Pentagon leaders devised a multi-pronged strategy, combining an enhanced U.S. military presence in the region with beefed-up, ever more militarized ties with America's allies there. As that 2018 National Defense Strategy put it, ""We will strengthen our alliances and partnerships in the Indo-Pacific to a networked security architecture capable of deterring aggression, maintaining stability, and ensuring free access to common domains."" Initially, that ""networked security architecture"" was only to involve long-term allies like Australia, Japan, South Korea and the Philippines. Soon enough, however, Taiwan came to be viewed as a crucial part of such an architecture.To grasp what this meant, imagine a map of the Western Pacific. In seeking to ""contain"" China, Washington was relying on a chain of island and peninsular allies stretching from South Korea and Japan to the Philippines and Australia. Japan's southernmost islands, including Okinawa — the site of major American military bases (and a vigorous local anti-base movement) — do reach all the way into the Philippine Sea. Still, there remains a wide gap between them and Luzon, the northernmost Philippine island. Smack in the middle of that gap lies… yep, you guessed it, Taiwan.In seeking to ""contain"" China, Washington relies on a chain of island and peninsular allies stretching from South Korea and Japan to the Philippines and Australia. Smack in the middle of that chain lies Taiwan.In the view of the top American military and foreign policy officials, for the U.S. to successfully prevent China from becoming a major regional power, it would have to bottle up that country's naval forces within what they began calling ""the first island chain"" — the string of nations stretching from Japan to the Philippines and Indonesia. For China to thrive, as they saw it, that nation's navy would have to be able to send its ships past that line of islands and reach deep into the Pacific. You won't be surprised to learn, then, that solidifying U.S. defenses along that very chain became a top Pentagon priority — and, in that context, Taiwan has, ominously enough, come to be viewed as a crucial piece in the strategic puzzle.Last December, Assistant Secretary of Defense for Indo-Pacific Security Affairs Ely Ratner summed up the Pentagon's new way of thinking about the island's geopolitical role when he appeared before the Senate Foreign Relations Committee. ""Taiwan,"" he said, ""is located at a critical node within the first island chain, anchoring a network of U.S. allies and partners that is critical to the region's security and critical to the defense of vital U.S. interests in the Indo-Pacific.""This new perception of Taiwan's ""critical"" significance has led senior policymakers in Washington to reconsider the basics, including their commitment to a One China policy and to strategic ambiguity. While still claiming that One China remains White House policy, President Biden has repeatedly insisted all too unambiguously that the U.S. has an obligation to defend Taiwan if attacked. When asked recently on ""60 Minutes"" whether ""U.S. forces…would defend Taiwan in the event of a Chinese invasion,"" Biden said, without hesitation, ""Yes."" The administration has also upgraded its diplomatic ties with the island and promised it billions of dollars' worth of arms transfers and other forms of military assistance. In essence, such moves constitute a de facto abandonment of ""One China"" and its replacement with a ""one China, one Taiwan"" policy.Not surprisingly, the Chinese authorities have reacted to such comments and the moves accompanying them with increasing apprehension and anger. As seen from Beijing, they represent the full-scale repudiation of multiple statements acknowledging Taiwan's indivisible ties to the mainland, as well as a potential military threat of the first order should that island become a formal U.S. ally. For President Xi and his associates, this is simply intolerable.""The repeated attempts by the Taiwan authorities to look for U.S. support for their independence agenda as well as the intention of some Americans to use Taiwan to contain China"" are deeply troubling, Xi told Biden during their telephone call in November 2021. ""Such moves are extremely dangerous, just like playing with fire. Whoever plays with fire will get burned.""Since then, Chinese officials have steadily escalated their rhetoric, threatening war in ever more explicit terms. ""If the Taiwanese authorities, emboldened by the United States, keep going down the road for independence,"" Qin Gang, China's ambassador to the U.S., typically told NPR in January 2022, ""it most likely will involve China and the United States, the two big countries, in military conflict.""To demonstrate its seriousness, China has begun conducting regular air and naval exercises in the air- and sea-space surrounding Taiwan. Such maneuvers usually involve the deployment of five or six warships and a dozen or more warplanes, as well as ever greater displays of firepower, clearly with the intention of intimidating the Taiwanese leadership. On Aug. 5, for example, the Chinese deployed 13 warships and 68 warplanes in areas around Taiwan and, two days later, 14 ships and 66 planes.Each time, the Taiwanese scramble their own aircraft and deploy coastal defense vessels in response. Accordingly, as China's maneuvers grow in size and frequency, the risk of an accidental or unintended clash becomes ever more likely. The increasingly frequent deployment of U.S. warships to nearby waters only adds to this explosive mix. Every time an American naval vessel is sent through the Taiwan Strait — something that occurs almost once a month now — China scrambles its own air and sea defenses, producing a comparable risk of unintended violence.This was true, for example, when the guided-missile cruisers USS Antietam and USS Chancellorsville sailed through that strait on Aug. 28. According to Zhao Lijian, a spokesperson for the foreign ministry, China's military ""conducted security tracking and monitoring of the U.S. warships' passage during their whole course and had all movements of the U.S. warships under control.""No barriers to escalation?If it weren't for the seemingly never-ending war in Ukraine, the dangers of all of this might be far more apparent and deemed far more newsworthy. Unfortunately, at this point, there are no indications that either Beijing or Washington is prepared to scale back its provocative military maneuvers around Taiwan. That means an accidental or unintended clash could occur at any time, possibly triggering a full-scale conflict.Imagine, then, what a decision by Taiwan to declare full independence or by the Biden administration to abandon the One China policy could mean. China would undoubtedly respond aggressively, perhaps with a naval blockade of the island or even a full-scale invasion. Given the increasingly evident lack of interest among the key parties in compromise, a violent outcome appears ever more likely.If a U.S.-China conflict erupts, it may be difficult to contain the fighting to a ""conventional"" level. Both sides have shaped their military forces for rapid, intensive combat and decisive victory.However such a conflict erupts, it may prove difficult to contain the fighting at a ""conventional"" level. After all, both sides are wary of another war of attrition like the one unfolding in Ukraine and have instead shaped their military forces for rapid, firepower-intensive combat aimed at securing a decisive victory quickly. For Beijing, this could mean firing hundreds of ballistic missiles at U.S. ships and air bases in the region with the aim of eliminating any American capacity to attack its territory. For Washington, it might mean launching missiles at China's key ports, air bases, radar stations, and command centers. In either case, the results could prove catastrophic. For the U.S., the loss of its carriers and other warships; for China, the loss of its very capacity to make war. Would leaders of the losing side accept such a situation without resorting to nuclear weapons? No one can say for sure, but the temptation to escalate would undoubtedly be great.Unfortunately, at the moment, there are no U.S.-China negotiations under way to resolve the Taiwan question, to prevent unintended clashes in the Taiwan Strait or to reduce the risk of nuclear escalation. In fact, China quite publicly cut off all discussion of bilateral issues, ranging from military affairs to climate change, in the wake of Pelosi's visit to Taiwan. So it's essential, despite the present focus on escalation risks in Ukraine, to recognize that avoiding a war over Taiwan is no less important — especially given the danger that such a conflict could prove of even greater destructiveness. That's why it's so critical that Washington and Beijing put aside their differences long enough to initiate talks focused on preventing such a catastrophe.",0.0,0.0
355,https://www.euronews.com/next/2022/10/14/inside-the-us-facility-where-199-legally-dead-humans-and-almost-100-pets-await-being-reviv,Inside the US facility where 199 'legally dead' humans and almost 100 pets await being revived,"On the wall full of patients' portraits is Matheryn Naovaratpong from Thailand who lost her life at an early age.""[She is] by far our youngest patient, not quite three years old... who had brain cancer. Both her parents were doctors and she had multiple brain surgeries and nothing worked, unfortunately,"" said Max More, President emeritus of the cryonics facility Alcor Life Extension Foundation in Arizona, the United States.According to More, the facility currently accommodates 199 people and almost 100 pets inside tanks filled with liquid nitrogen in hopes to revive them when technology has been advanced enough to treat them.He says the patients are only ""legally dead"" but not biologically and believes cryonics could be their saviour.The process is a lot more complicated than just freezing and defrosting.After the patient has been declared legally dead, the body will be soaked in an ice bath.During this procedure, a mechanical CPR device is used to ensure blood circulation and medications in order to protect the cells against damage.At the end of the day, I think this notion of freezing ourselves into the future is pretty science fiction and it's naive Dr Arthur Caplan Professor of Bioethics, New York University Grossman School of MedicineMore says this prevents the patient from returning to consciousness and blood clots. He also adds maintaining blood pressure is crucial for viability, much as in the organ donation process.He says the bodies are not technically frozen, but vitrified.""We don't want to freeze the patient. We want to vitrify them... And the reason is that once you cool to very cold below freezing, the solution, instead of crystallising, will just get thicker and thicker and it's like a glassy block holding all the cells in place without any internal structure and so does no damage,"" said More.""And once we reach that point, around minus 110 degrees, the body becomes truly solid and absolutely nothing is happening in the body. There's no biochemical activity whatsoever, certainly no neurological activity. So at that point, it doesn't matter whether you wait a day or 100 years, you're going to be just the same as when you started"".'Pretty science fiction and naive'More’s wife, futurist and author Natasha Vita-More believes those who opted in for cryopreservation won’t be lonely once revived.""(They) will most likely have family members and or friends who have also signed up for cryonics… A person who had cancer or ALS or some other type of injury or disease is revived. The disease or injury cured or fixed, and the person is, has a new body cloned or a whole body prosthetic or their body reanimated and meet up with their friends again,"" she said.For Dr Arthur Caplan, Director of the Division of Medical Ethics and a professor of Bioethics at the New York University Grossman School of Medicine, the idea of cryonics is no more than “a college dormitory discussion”.""So, at the end of the day, I think this notion of freezing ourselves into the future is pretty science fiction and it's naive,"" he said.""It's almost like what you'd be thinking about in a college dormitory discussion, 'if I could just freeze myself and then defrost myself kind of like a bag of peas and wind up way in the future, wouldn't that be cool?' Sounds okay, but then you realise how much we are products of our own time,"" Caplan added.For more on this story, watch the video in the media player above.",0.0,0.0
506,https://news.nus.edu.sg/novel-technique-to-grow-meat-in-the-lab-using-magnetic-field/,NUS scientists develop novel technique to grow meat in the lab using magnetic field,"Scientist from the National University of Singapore (NUS) have found a novel way of growing cell-based meat by zapping animal cells with a magnet. This new technique simplifies the production process of cell-based meat by reducing reliance on animal products, and it is also greener, cleaner, safer and more cost-effective.Cultured meat is an alternative to animal farming with advantages such as reducing carbon footprint and the risk of transmitting diseases in animals. However, the current method of producing cultured meat involves using other animal products, which largely defeats the purpose, or drugs to stimulate the growth of the meat.To cultivate cell-based meat, animal cells are fed animal serum – usually foetal bovine serum (FBS), which is a mixture harvested from the blood of foetuses excised from pregnant cows slaughtered in the dairy or meat industries – to help them grow and proliferate. This is a critical, yet cruel and expensive, step in the current cell-based meat production process. Ironically, many of these molecules come from the muscles within the slaughtered animal, but scientists did not know how to stimulate their release in production scale bioreactors. Other methods to promote cell growth are using drugs or relying on genetic engineering.The complex production process for cell-based meat increases cost, limits the manufacturing scale and undermines the commercial viability of cell-based meat.To help address this challenge, a multidisciplinary research team led by Associate Professor Alfredo Franco-Obregón, who is from the NUS Institute for Health Innovation & Technology and the NUS Yong Loo Lin School of Medicine, came up with an unconventional method of using magnetic pulses to stimulate the growth of cell-based meat.",0.0,0.0
224,https://apnews.com/article/science-health-california-cancer-climate-and-environment-83c87000f5c52692431218842378a089,"Study: Cancer-causing gas leaking from CA stoves, pipes","In this 2022 image provided by PSE Healthy Energy, a gas stove is tested for benzene in California. Stoves in California homes are leaking the cancer-causing gas benzene, researchers found in a new study published on Thursday, Oct. 20, though they say more research is needed to understand how many homes have leaks. (PSE Healthy Energy via AP)In this 2022 image provided by PSE Healthy Energy, a gas stove is tested for benzene in California. Stoves in California homes are leaking the cancer-causing gas benzene, researchers found in a new study published on Thursday, Oct. 20, though they say more research is needed to understand how many homes have leaks. (PSE Healthy Energy via AP)Gas stoves in California homes are leaking cancer-causing benzene, researchers found in a new study published on Thursday, though they say more research is needed to understand how many homes have leaks.In the study, published in Environmental Science and Technology on Thursday, researchers also estimated that over 4 tons of benzene per year are being leaked into the atmosphere from outdoor pipes that deliver the gas to buildings around California — the equivalent to the benzene emissions from nearly 60,000 vehicles. And those emissions are unaccounted for by the state.The researchers collected samples of gas from 159 homes in different regions of California and measured to see what types of gases were being emitted into homes when stoves were off. They found that all of the samples they tested had hazardous air pollutants, like benzene, toluene, ethylbenzene and xylene (BTEX), all of which can have adverse health effects in humans with chronic exposure or acute exposure in larger amounts.ADVERTISEMENTOf most concern to the researchers was benzene, a known carcinogen that can lead to leukemia and other cancers and blood disorders, according to the National Cancer Institute .The finding could have major implications for indoor and outdoor air quality in California, which has the second highest level of residential natural gas use in the United States.“What our science shows is that people in California are exposed to potentially hazardous levels of benzene from the gas that is piped into their homes,” said Drew Michanowicz, a study co-author and senior scientist at PSE Healthy Energy, an energy research and policy institute. “We hope that policymakers will consider this data when they are making policy to ensure current and future policies are health-protective in light of this new research.”Homes in the Greater Los Angeles, the North San Fernando Valley, and the San Clarita Valley areas had the highest benzene in gas levels. Leaks from stoves in these regions could emit enough benzene to significantly exceed the limit determined to be safe by the California Office of Environmental Health Hazards Assessment.This finding in particular didn’t surprise residents and health care workers in the region who spoke to The Associated Press about the study. That’s because many of them experienced the largest-known natural gas leak in the nation in Aliso Canyon in 2015.ADVERTISEMENTBack then, 100,000 tons of methane and other gases, including benzene , leaked from a failed well operated by Southern California Gas Co. It took nearly four months to get the leak under control and resulted in headaches, nausea and nose bleeds.Dr. Jeffrey Nordella was a physician at an urgent care in the region during this time and remembers being puzzled by the variety of symptoms patients were experiencing. “I didn’t have much to offer them,” except to help them try to detox from the exposures, he said.That was an acute exposure of a large amount of benzene, which is different from chronic exposure to smaller amounts, but “remember what the World Health Organization said : there’s no safe level of benzene,” he said.ADVERTISEMENTKyoko Hibino was one of the residents exposed to toxic air pollution as a result of the Aliso Canyon gas leak. After the leak, she started having a persistent cough and nosebleeds and eventually was diagnosed with breast cancer, which has also been linked to benzene exposure . Her cats also started having nosebleeds and one recently passed away from leukemia.“I’d say let’s take this study really seriously and understand how bad (benzene exposure) is,” she said.___Follow Drew Costley on Twitter: @drewcostley .___The Associated Press Health and Science Department receives support from the Howard Hughes Medical Institute’s Department of Science Education. The AP is solely responsible for all content.",0.0,0.0
441,https://www.nature.com/articles/s41598-022-20841-0,Birdsongs alleviate anxiety and paranoia in healthy participants,"Power calculation and study registrationA power calculation was conducted for an interaction effect (repeated measures ANOVA), in G*Power 3.1.9.7 with f = 0.10, α = 0.05, power = 0.90, 4 groups, correlation between repeated measures r = 0.60, resulting in a minimum required total sample size of N = 288 (n = 72 per group). According to the general rule of thumb for Cohen’s f statistic, f ≥ 0.10 < 0.25 is a small effect, f ≥ 0.25 < 0.40 is a medium effect, and, f ≥ 0.40 a large effect (see Cohen, 1988)25. We opted for a small effect size as a similar study as ours, conducted by van Hedger et al.16, also using a repeated-measures ANOVA data analysis approach, reported interaction effects type ([2] natural vs. urban soundscapes) by time ([2] pre-to-post exposure) on mood, whereby Cohen’s d for negative affect was between 0.36 and 0.40. These results were non-significant, as the study was underpowered for detecting small effects. The interaction effects observed concerning cognition in that paper, applying the same tests as in the present paper, were large (d between 0.71 to 0.76). Since we were interested in detecting effects on mood and to study yet unknown effects on state paranoia, we opted for and intermediate effect size between small and medium.The study was pre-registered at aspredicted.org (study name: “Sounds_Online”, trial identifier: #67702, https://aspredicted.org/d5j7j.pdf) on 06/04/2021.Recruitment and in- and exclusion criteriaThe study was programmed using Inquisit 526 (https://www.millisecond.com) and accordingly run on the Millisecond server. Participants were recruited from the crowdsourcing platform Prolific and received 10€ reimbursement for their full participation. Adult individuals were pre-screened on Prolific (i.e., visibility of the study only for candidates with a suited profile) concerning fluent German language skills (as this was the study language), having no diagnosed lifetime mental illness, and having no hearing difficulties. Pre-screened individuals could then access the study, where in- and exclusion criteria were checked further. This included no regular substance or drug intake, no suicidal thoughts, or tendencies, and availability of headphones for the purpose of the study.Study procedureAfter providing informed consent, sociodemographic information was assessed, including education, income, and further variables, which were assessed for potential additional or exploratory analyses, but for the sake of conciseness are not reported in this paper. Psychosis liability was assessed. For an according overview on sample characteristics, see Table 2. Hereafter, pre-test assessments were conducted, including an assessment of mood (depression, anxiety), paranoia, the digit-span, and n-back tasks. Participants were randomized to one of four sound conditions: (1) low diversity traffic noise soundscape n = 83, (2) high diversity traffic noise soundscape n = 69, (3) low diversity birdsong soundscape n = 63, or (4) high diversity birdsong soundscape n = 80, (for details on the stimuli, see “Stimuli” section). The soundscapes each lasted for exactly 6 min. Participants were instructed to set their audio system volume to 80% (which was piloted with members of our research unit beforehand and deemed to be an optimal average volume) and to listen to the sounds until the end, when participants were required to continue by clicking with their mouse. Participants were told that a code, consisting of two spoken digits (in German), would be audible towards the end of the sound presentation, which they were required to type in correctly afterwards. This was implemented to assure listening-compliance and attention. After the sound presentation, the pre-test measures were repeated. Finally, several items to assess perceived sound quality, including beauty, pleasantness, and monotony (vs. diversity) were presented.Table 2 Descriptive sample data and between-group differences for socio-demographic variables. Full size tableSampleInitially, N = 401 individuals started the survey. Of those, n = 76 quit during the sociodemographic assessment, n = 24 lacked pre-test data, and n = 6 lacked post-test data. These n = 106 cases were excluded from the analyses, resulting in a final sample of N = 295. Of these, some participants had incomplete post-test data (n = 10 missing digit span, 5 missing n-back, and n = 8 missing the qualitative assessments [sound rating]).For detailed information and inferential statistics comparing the groups at baseline see Table 2. The participants were in their middle to late twenties on average and there were in tendency more males than females. Net income was mostly reported to be in the lowest category (i.e., < 1.250€, 40–50% of participants of all groups), but also between 5 and 20% of participants did not wish to reveal their monthly net income. Positive symptom frequency levels did not differ significantly between the groups, albeit there were relatively marked descriptive differences (p = 0.058). The values were mostly similar and within a confidence interval range that has previously been reported for healthy individuals19. Due to the trend-level nature of the differences in positive symptom frequency, we decided to repeat the main analyses, controlling for this variable as covariate in the repeated measures ANOVAs.MeasuresFor all mood and the paranoia scales, item scores were computed (i.e., summing up responses on all items and dividing this by the number of items). This way, the interpretation of scores is facilitated, as it corresponds to the Likert-scale of the respective measure.Psychosis liabilityPsychosis-liability or sub-clinical psychosis levels was assessed using the Community Assessment of Psychic Experiences (CAPE)19, in its German version, to assesses lifetime positive, negative and depressive symptoms (http://www.cape42.homestead.com/index.html). The CAPE, including the German version, has been validated extensively17. Items refer to the lifetime prevalence of specific symptoms, rated on an ordinal response scale for frequency (categories: 1 = ‘never’, 2 = ‘sometimes’, 3 = ‘often’, 4 = ‘nearly always’). The total scale consists of 42 items, whereby the positive symptom scale includes 20 (e.g., ‘Do you ever feel as if things in magazines or on TV were written especially for you?’), the negative symptom scale 14 (e.g., ‘Do you ever feel that your mind is empty?’), and the depressive symptom scale 8 items (e.g., ‘Do you ever feel like a failure?’). To test for comparative baseline levels across all groups in psychosis liability, mean frequency scores for the positive symptom subscale was used, for which Mossaheb and colleagues have provided descriptive data for individuals with ultra-high risk for psychosis (n = 84) vs without risk (i.e., healthy controls; n = 81)19. The positive dimension (frequency) of the CAPE had excellent internal consistency in the present sample, with Cronbach’s α = 90.Mood and paranoid symptomsMood was assessed with the State Trait Anxiety Depression Inventory (STADI)27. The scale contains 40 items, whereby the same 20 items are once presented in trait and once in state format. Only the latter was used in the present study. The scale differentiates between depression (low euthymia [inverted items], dysthymia) and anxiety (hyperarousal and worry), whereby each of the subscales is assessed by 5 items. The response format is a 4-point Likert (1 = ‘not at all’, 4 = ‘strongly applies’). Internal consistency (Cronbach’s α) at pre-test was good both for the state anxiety (0.85) and depression (0.86) scales.Paranoia was assessed with a brief, change sensitive state version of the paranoia checklist, which has been validated and comparable to the long, state adapted 18-item version17. The scale comprises 3 statements (e.g., ‘I need to be on my guard against others’, ‘Strangers and friends look at me critically’, ‘People try to upset me’), rated on an 11-point Likert-scale (each from 1 to 11) for the degree of agreement to the statement, associated distress and conviction, at present. The latter two categories were only presented if the rating of agreement to the statement was > 1 (which accordingly often results in a large amount of missing data). In the present study, only agreement was evaluated. Internal consistency at pre-test was acceptable with Cronbach’s α = 0.78.CognitionTo assess digit span cognitive performance, both the forward and backward version were used, as available in Inquisit 526 [retrieved from https://www.millisecond.com] which is based on the original task reported by Woods et al.28. Two parameters are recommended for evaluation: the two-error maximum length (TE_ML) and the maximum length recalled (ML). The two-error maximum length is defined as the last digit span a participant gets correct before making two consecutive errors while the maximum length is the digit span that a participant recalled correctly during all trials irrespective of the number of errors in-between. Starting with a successive visual presentation of 3 digits, the participants need to correctly recall a by 1 digit increasing sequence of digits and reproduce it by clicking on the correct digits in correct order. After two wrongly recalled sequences of the same length, the digit span is decreased by 1 digit until the digit span length again reaches the starting point of 3. The total amount of trials is 14 making the shortest span possible 3 digits long and the longest span 16 digits long. The participants were explicitly reminded not to use any memory assisting methods such as paper and pencil. The dual n-back task, also available in the Inquisit 526 (retrieved from https://www.millisecond.com) was assessed. The task is based on the original work by Jaeggi et al.29. It consists of 4 experimental blocks demanding 2-back and 3-back level performance. While performing the task, subjects pay attention to their computer screen while also listening to a computer audio. On each trial a blue square appears in one out of eight grid-like locations around a central fixation cross, while at the same time a (German) letter is presented via the headphones. In the 2-back block condition, the subjects are instructed to press the “A” button on their keyboard when the current square position matches the square position from two trials before. Subjects are also instructed to press the “L” button on their keyboard if the spoken letter matched the letter two trials before. The same instruction, but having to match stimuli 3 trials back, is provided for the 3-back condition. In the present study, participants trained each condition once, and then went on with the experimental blocks. The performance parameter was the so-called d prime value calculated as the proportion of ((visual_TotalHits − visual_TotalFA) + (auditory_TotalHits − auditory_TotalFA)/2)/number of total experimental blocks. The highest possible d prime (greatest sensitivity) was 6.93 and the lowest was 0. Visual hits are defined as correct responses with respect to the location of the square and auditory hits are defined as the correct responses with respect to the spoken letter. Visual false alarms (FA) are defined as responses in the absence of a target in the visual domain, thus with respect to the location of the square and auditory false alarms are responses in the absence of a target in the auditory domain, thus with respect to the spoken letter.Soundscape perceptionThe participant’s perception of the soundscapes was assessed using a one item questionnaire per dimension (diversity/monotony, pleasantness, and beauty). Participants were asked to report on a 0 to 100 visual scale how diverse/monotone, beautiful, and pleasant they had perceived the soundscape they had listened to during the experiment. The items have been formulated by the authors themselves while the use of an aesthetic rating of the soundscapes per se was a replication from the van Hedger et al.16 study where we exchanged the “like–dislike” affective response with a more detailed aesthetic rating splitting the response up into a pleasantness and a beauty dimension. The dimension of diversity/monotony has been to perform a manipulation check on diversity for the soundscapes used in the present study.StimuliThe soundscapes for all four categories have been generated in the same way. Single sound snippets were gathered and then adapted and merged within the audio software Steinberg Cubase10. An exemplary visualization of the resulting soundscape can be seen in the Supplementary Material (see Supplementary Fig. 1). For the nature category a database of birdsong recordings (https://www.xeno-canto.org/explore/region) from a central European origin was used. For the low diversity birdsong condition, eight recordings from the same two species were used (common chiffchaff & wood warbler). For the high diversity birdsong condition, the same approach was chosen, but recordings from eight different bird species were used to create the soundscape (garden warbler, honey buzzard, woodlark, Eurasian sparrow hawk, coal tit, greenshank, common crane, and black woodpecker). In both birdsong conditions, additionally subtle water and wind sounds were played in the background, to create a constant auditory experience. For the traffic noise conditions, sound snippets from eight car recoding’s (https://freesound.org/search/?q=city) were used for the low diversity traffic noise condition while audio-snippets from eight diverse sources of noise pollution associated with the city were used for the high diversity traffic noise condition (ambulance siren, construction, trucks, train, motorcycle, airplane, bus and fire-fighter siren). In both traffic noise soundscapes, a constant subtle traffic flow was audible in the background.To ensure that all soundscapes were perceived with a similar loudness level, all soundscapes were engineered to have a similar loudness value. The loudness values from all four conditions range between 19.4 and 27.8 loudness units relative to full scale (LUFS). All soundscapes had a duration of 6 min. Prior to the experiment the soundscapes have been presented to a small set of pilot participants rating the similarity of the audio level ensuring a comfortable audio level across all conditions. As a result, at the beginning of the experiment, participants were instructed to set their headphone loudness level to 80%. Soundscapes can be accessed openly via this link https://osf.io/4y3vh/.Statistical analysesAnalyses were run in SPSS 27 (IBM Corp., 2020). To test the differences of all measures at baseline, several univariate analyses of variance (ANOVA) were run. In order to test the effects of high vs. low diverse traffic noise vs. birdsong soundscapes on mood, paranoia, and cognition, repeated measures analyses of variance (ANOVA) were run testing for a 2 (timepoint: pre vs. post) × 2 (soundscape type: birdsong vs. traffic noise) × 2 (diversity: low vs. high) interaction effect. The analyses were once run with all participants, and then only with those who entered at least one of the digits (control of compliance of listening to audio, see “Study procedure” section) correctly, to check for the robustness of findings. In order to further check for the robustness of effects on mood and cognition repeated measures ANOVAs were run controlling for baseline sample differences on sample characteristics or outcomes (i.e., state paranoia, age and positive symptoms) as covariates. To check the robustness of effects on paranoia a univariate analysis of covariance (ANCOVA) with paranoia at baseline as covariate and post-test paranoia as outcome, predicted by type and diversity as factors, was computed. Significant interactions (i.e., of interest were the type × time and type × diversity × time) interactions identified for any of the outcomes were followed up by subsequent detailed post-hoc-tests. To explore mean differences between the qualitative ratings of soundscapes (i.e., beauty, pleasantness, and monotony vs. diversity), a one-way multivariate analysis of variance (MANOVA) was conducted. In case of significant omnibus tests indicating global differences across the qualitative sound rating dimensions, follow-up between group t-tests were conducted. Due to the exploratory nature of the study, no p-level correction was applied.The partial eta squared effect size was used to interpret the ANOVA based analyses, with the corresponding rule of thumb defining η2 = 0.01 as a small effect size, η2 = 0.06 as a medium effect size and η2 = 0.14 as a large effect size30. Cohen’s d effect size was used to interpret post-hoc test effect sizes, with the corresponding rule of thumb defining a value of ≥ 0.2 as a small effect size, a value of ≥ 0.5 as a medium effect size and a value of ≥ 0.8 as a large effect size. The criteria for interpreting the effect size for Hedge’s g stem from the corresponding rule of thumb with the same definition30.Ethics statementAll procedures performed in studies involving human participants were in accordance with the ethical standards of the institutional and/or national research committee and with the 1964 Helsinki Declaration and its later amendments or comparable ethical standards. Informed consent was obtained from all participating subjects. The experimental protocol was approved by the ethical committee from the University Clinic Hamburg Eppendorf.",0.0,0.0
257,https://petapixel.com/2022/10/04/white-house-releases-blueprint-for-artificial-intelligence-bill-of-rights/,White House Releases Blueprint for Artificial Intelligence Bill of Rights,"On behalf of President Joe Biden, the White House has released five principles that it believes should guide the design, use, and deployment of automated systems to protect the American public in the age of artificial intelligence (AI).Called The Blueprint for an AI Bill of Rights, the White House hopes that it will serve as a guide to protect people from real threats to society that are caused by leaning heavily on automated, AI-driven systems.“Automated systems have brought about extraordinary benefits, from technology that helps farmers grow food more efficiently and computers that predict storm paths, to algorithms that can identify diseases in patients. These tools now drive important decisions across sectors, while data is helping to revolutionize global industries,” the Office of Science and Technology Policy writes.“[But] this important progress must not come at the price of civil rights or democratic values.”The White House outlines five principles that it believes should be used as a guideline whenever automated systems have the potential to meaningfully impact the public’s rights, opportunities or access to critical needs: Safe and Effective Systems, Algorithmic Discrimination Protections, Data Privacy, Notice and Explanation, and Human Alternatives, Consideration, and Fallback.This AI Bill of Rights is supported by the American Civil Liberties Union, which published a statement in conjunction with and in support of its announcement.“Just as our Constitution’s Bill of Rights protects our most basic civil rights and liberties from the government, in the 21st century, we need a ‘bill of rights’ to protect us against the use of faulty and discriminatory artificial intelligence that infringes upon our core rights and freedoms,” ReNika Moore, director of the American Civil Liberties Union’s Racial Justice Program, says.“Unchecked, artificial intelligence exacerbates existing disparities and creates new roadblocks for already-marginalized groups, including communities of color and people with disabilities. When AI is developed or used in ways that don’t adequately take into account existing inequities or is used to make decisions for which it is inappropriate, we see real-life harms such as biased, harmful predictions leading to the wrongful arrest of Black people, jobs unfairly denied to women, and disparate targeting of children of color for removal from their families. The Blueprint for an AI Bill of Rights is an important step in addressing the harms of AI.”The Blueprint for an Artificial Intelligence Bill of Rights is designed to cover all AI-driven technology and automated systems that have the potential to impact the American public’s civil rights and liberties, equal opportunity, or access to critical resources or services. All five principles are described in detail on the White House website. The full blueprint can also be downloaded from the government website along with a guide on how to apply it to varying AI solutions.Image credits: Header photo licensed via Depositphotos.",0.0,0.0
583,https://techcrunch.com/2018/02/21/cognoas-ai-platform-for-autism-diagnosis-gets-first-fda-stamp/,Cognoa's AI platform for autism diagnosis gets first FDA stamp,"Cognoa has gained regulatory recognition for its machine learning software as a class II diagnostic medical device for autism — meaning the digital health startup is now positioned to submit an application for full FDA clearance.It’s a first but important regulatory step for a business that was founded back in 2014, and plays in a still nascent digital health space where untested ‘wellness’ apps are far more plentiful than medical technologies with robust data to prove out the efficacy of their interventions.Discussions with the FDA started in early 2017, says Cognoa CEO Brent Vaughan, adding that it’s hoping to gain full FDA clearance this year.He says the ultimate goal for the US startup is to become a standard part of domestic health insurance-covered medical provision — and for that FDA clearance is essential to opening the doors.We first covered the Cognoa at launch in 2014 and the following year when it was still being careful to describe its technology as a screening rather than a diagnostic system.It’s since gathered enough data to be confident in using the ‘D’ word — having run a pilot with 250,000 parents, offering free screening for their children so it could gather more data to refine its machine learning models.“We were lucky that we had investors,” says Vaughan. “There’s not a huge business model in providing free screening services to kids, right, because we were certainly never going to sell ads. That wasn’t the goal.“It took a little patience but in the process of providing free screening and at least showing parents how to navigate their way to the front of a line as more of an information service we were able to build the data models to support a development of a diagnostic device actually a couple of years sooner than we originally thought we would. So it ultimately paid off for us.”Cognoa has raised $20.4M to date. Its main investor is the Chinese private investment group Morningside. Vaughan tells TechCrunch it’ll likely be looking to raise another round by the end of this year.It has also conducted multiple studies over the last 2.5 years across the US, including blinded control trials and side-by-side comparisons of its different versions — working with children’s hospitals and secondary care centers. It now bills its technology as a “pediatric behavioral health diagnostics and digital therapeutics platform”.The initial machine learning model, which was targeted at screening for autism, was based on the work of Stanford pediatrics and psychiatry professor Dennis Wall. The model itself was built by combining and structuring existing datasets of behavioral observations on about 10,000 children.Though, as noted above, Cognoa has continued to refine its autism model with structured contributions from parents participating in the pilot and inputting data via its app. (Aka: If an AI service is free, you’re the training data.)[gallery ids=""1600569,1600568,1600566,1600567""]“In our last study we were able to come through with a sensitivity of greater than 90 per cent,” Vaughan tells TechCrunch. “In our first algorithm… targeting autism, we would find it over 90 per cent of the time — and when we said it was autism it was correct well over 80 per cent of the time.“What we see when we look in the data, and that we’re quite interested by, is when we say it’s autism or it looks like autism and it wasn’t… we were able to show [the FDA] that they were often very similarly related conditions.”Vaughan says a lot of the team’s early work focused on figuring out how to create a product that enables non-healthcare professionals (i.e. parents) to capture robust data in a reproducible way. “One of the… questions that came up quite early, even from early potential investors and clinicians, was can you actually get parents to give you the information on which you could base a clinical diagnostic decision? Can you get them to do this reproducibly without a clinician being in a room?… So we certainly had to address that.I remember sitting down with one venture capitalist who looked at me and said, you know what — you’re never going to find 5,000 parents that are going to do this.“I remember sitting down with one venture capitalist who looked at me and said, you know what — you’re never going to find 5,000 parents that are going to do this. And that are going to be able to do this reproducibly,” he continues. “Within a couple of years we were up over a quarter of a million parents that had actually done it — and we learned a lot about how to reproducibly collect information on which you can build a clinical diagnosis but collecting it outside of the clinical setting. Parents providing us information in their living room in the evening. So that was certainly one major step for us. And in doing that we showed that the unmet need was much, much bigger than we originally had estimated.”As well as aiming to support earlier diagnosis than parents might be able to get if they had to wait for specialist appointments for their child to be monitored in person, Cognoa’s platform provides guidance on actions (it calls them “activities”) parents can take themselves to help manage their children’s condition. Which in turn provides more opportunities for response data to be fed back so its models can keep learning and refining recommendations.While the first focus is autism, with the aim of trying to shrink intervention times to improve long term outcomes for children — given what Vaughan describes as a “well-documented” link between earlier intervention and better autism outcomes — the intent is to address other behavioral conditions too, in time, such as ADHD.“For us we see this — even the autism clearance that we’re looking forward to in the future — that’s just a step down the path of being able to be the platform that can diagnose an entire spectrum of these developmental conditions,” he says.Interestingly, Vaughan concedes that the learning element of AI-based technologies can cause unintended problems in healthcare service provision, saying some clinicians it talked to early on raised concerns that by widening access to autism screening the startup risked making an existing diagnosis bottleneck worse by increasing demand for specialist services without there being a parallel increase in resource to avoid creating even more of a backlog.Which is exactly the kind of serious, knock-on consequence that’s possible when unproven ‘disruptive’ technologies change existing dynamics and bring new pressures to bear on a critical and sensitive industry like healthcare. It also seems especially true of AI technologies which need to be fed with lots of data before they can learn to become really useful.So how to conduct responsible training of machine learning models presents something of an existential challenge for AI and healthcare startup initiatives — and one which has already opened up operational pitfalls for some very well resourced tech giants.“Back in 2014 and 2015 we were really starting down the path of let’s just prove that we can triage these kids and find them earlier. And a lot of people embraced that, but there was certainly some that were pretty thoughtful who said if you guys find the kids earlier and the problem in the system is that kids that are identified and referred to specialists for appointments are currently waiting between one and three years to get a diagnosis, aren’t you just going to be making the problem worse?” he says.“So then we had to sit down and say listen, step one is being able to show that we can just screen these kids. But longer term we think we can really aid in getting a faster diagnosis. But we were very careful to not say, publicly, that we thought that we could diagnose these kids because we thought it would just be too controversial. And the idea of using an AI-based platform, the idea of collecting information primarily from the parent, from the caregiver and from the child, that was pretty controversial.”Another change that’s being driven by AI-based software targeting the healthcare industry is to regulatory regimes — with regulators like the FDA needing to come up with new systems and processes for assessing and managing software designed to get better over time.“The FDA is struggling with how to regulate AI-based software because the idea of the FDA is they look at a version of a product and that product once cleared by the FDA does not change — and the idea of AI and machine learning, which is what our product is based on, is that it’s learning and it gets better,” says Vaughan, talking about its discussions with the FDA. “And so understanding with the FDA how we were going to control and document that learning — those were some of the discussions where we walked in with ideas but not very clear understanding what the outcome would be.”While he believes the FDA will likely take a case-by-case approach to the challenge of regulating AI platforms, he suggests companies will probably have to operate using a versioning system — whereby they restrict ongoing machine learning to the research lab, releasing a next version of a model into the wild only once the step change in their software has also gained regulatory approval.“It’s the algorithm part of the device that [the FDA] feel the strongest about in terms of how they regulate it,” he says. “And keep in mind this is evolving, and their thinking might also evolve on this, but for us they look at the algorithm part and we can certainly, in our software, lock down a current version of the algorithm. And we can allow that to not change in the production version of the product — and at the same time we can have a research arm that’s continuing to evolve. And you could start to think about versioning coming out in the future.”“So I think it’ll be a little bit more of a stair-step approach,” he adds. “With periodic reviews by the FDA. And I think that they’re in parallel trying to think of a way to streamline that approach going forward because of the flexibility that these products have. So I think it’ll be a little bit of a hybrid between continuous machine learning which seems quite difficult and the old style, which was quite waterfall.”This post was amended to correct Cognoa’s total funding figure after it told us CrunchBase‘s listing for it was out of date",2.0,0.0
314,https://www.eurogamer.net/microsoft-will-keep-call-of-duty-on-sony-platforms-as-long-as-theres-a-playstation-out-there-to-ship-to,"Microsoft will keep Call of Duty on Sony platforms ""as long as there's a PlayStation out there to shipÂ to""","Xbox boss Phil Spencer has made Microsoft's plainest promise yet around the future of Call of Duty on PlayStation platforms.Speaking to the Same Brain Youtube channel, Spencer pledged to keep releasing Call of Duty games on Sony's consoles ""as long as there's a PlayStation out there to ship to"".The future of Call of Duty on PlayStation has become a contentious topic for regulators such as the UK's Competition and Markets Authority (CMA), which is currently scrutinising Microsoft's planned $68n takeover of COD publisher Activision Blizzard.Watch on YouTube Eurogamer Newscast: Will Konami succeed bringing Silent Hill back from the dead?Microsoft has repeatedly said it will keep releasing Call of Duty games for the forseeable future - and previously promised Call of Duty would remain on PlayStation ""at least several more years"" beyond Sony's existing deal with Activision Blizzard. Still, regulators have questioned how long this will actually last, if and when Activision Blizzard is owned by Microsoft.Here's Spencer's latest quote on the subject in full:""We're not taking Call of Duty from PlayStation... That's not our intent,"" Spencer said. ""Our intent is not to do that and as long as there's a PlayStation out there to ship to, our intent is that we'll continue to ship Call of Duty on PlayStation - similar to what we've done with Minecraft since we owned that.""We've expanded the places where people can play Minecraft, we haven't reduced the places. And it's been good, it's been good for the Minecraft community - in my opinion - and we want to do the same when we think where Call of Duty can go over the years.""Another issue for regulators has been the competitive advantage Microsoft might gain from including Call of Duty in its Game Pass subscription service.If it did so, Microsoft could still keep releasing Call of Duty on PlayStation via its typical £70 upfront price, while alternatively offering it at no further cost to Xbox owners who have Game Pass already.""For Xbox itself, players who have invested in our console, the biggest addition you're going to see is some great games coming to Game Pass,"" Spencer continued, without mentioning Call of Duty specifically by name. ""This isn't going to be about pulling those communities off of those other platforms. But I want it to be a great place to see those games.""In September, PlayStation and Xbox traded blows over the future of Call of Duty following the announcement by the UK's CMA that it would further investigate Microsoft's $68bn Activision Blizzard takeover attempt.""Giving Microsoft control of Activision games like Call of Duty"" had ""major negative implications"", Sony said at the time.In response, Microsoft fired back: ""It makes zero business sense for Microsoft to remove Call of Duty from PlayStation given its market leading console position.""This latest promise from Spencer comes as the deal faces intense scrutiny, ahead of a final ruling from the UK's CMA in spring 2023.",0.0,0.0
226,https://techxplore.com/news/2022-10-retrofits-diesel-hydrogen.html,New system retrofits diesel engines to run on 90% hydrogen,"The hydrogen-diesel direct injection dual-fuel system developed at UNSW enables a traditional diesel engine to be retrofitted to run as a hydrogen-diesel hybrid engine. Credit: Prof. Shawn KookEngineers from UNSW Sydney have successfully converted a diesel engine to run as a hydrogen-diesel hybrid engine—reducing CO 2 emissions by more than 85% in the process.The team, led by Professor Shawn Kook from the School of Mechanical and Manufacturing Engineering, spent around 18 months developing the hydrogen-diesel direct injection dual-fuel system that means existing diesel engines can run using 90% hydrogen as fuel.The researchers say that any diesel engine used in trucks and power equipment in the transportation, agriculture and mining industries could ultimately be retrofitted to the new hybrid system in just a couple of months.Green hydrogen, which is produced using clean renewable energy sources such as wind and solar, is much more environmentally friendly than diesel.And in a paper published in the International Journal of Hydrogen Energy, Prof. Kook's team show that using their patented hydrogen injection system reduces CO 2 emissions to just 90 g/kWh—85.9% below the amount produced by the diesel powered engine.""This new technology significantly reduces CO 2 emissions from existing diesel engines, so it could play a big part in making our carbon footprint much smaller, especially in Australia with all our mining, agriculture and other heavy industries where diesel engines are widely used,"" says Prof. Kook.""We have shown that we can take those existing diesel engines and convert them into cleaner engines that burn hydrogen fuel.""Being able to retrofit diesel engines that are already out there is much quicker than waiting for the development of completely new fuel cell systems that might not be commercially available at a larger scale for at least a decade.""With the problem of carbon emissions and climate change, we need some more immediate solutions to deal with the issue of these many diesel engines currently in use.""High-pressure hydrogen direct injectionThe UNSW team's solution to the problem maintains the original diesel injection into the engine, but adds a hydrogen fuel injection directly into the cylinder.The collaborative research, performed with Dr. Shaun Chan and Professor Evatt Hawkes, found that specifically timed hydrogen direct injection controls the mixture condition inside the cylinder of the engine, which resolves harmful nitrogen oxide emissions that have been a major hurdle for commercialisation of hydrogen engines.The Hydrogen-Diesel Direct Injection Dual-Fuel System has been developed by a team from the UNSW Engine Research Laboratory led by Professor Shawn Kook (right), and including Xinyu Liu (back left) and Jinxin Yang (front left). Credit: Prof. Shawn Kook""If you just put hydrogen into the engine and let it all mix together you will get a lot of nitrogen oxide (NO x ) emissions, which is a significant cause of air pollution and acid rain,"" Prof. Kook says.""But we have shown in our system if you make it stratified—that is in some areas there is more hydrogen and in others there is less hydrogen—then we can reduce the NO x emissions below that of a purely diesel engine.""Importantly, the new Hydrogen-Diesel Direct Injection Dual-Fuel System does not require extremely high purity hydrogen which must be used in alternative hydrogen fuel cell systems and is more expensive to produce.And compared to existing diesel engines, an efficiency improvement of more than 26% has been shown in the diesel-hydrogen hybrid.That improved efficiency is achieved by independent control of hydrogen direct injection timing, as well as diesel injection timing, enabling full control of combustion modes—premixed or mixing-controlled hydrogen combustion.The research team hope to be able to commercialize the new system in the next 12 to 24 months and are keen to consult with prospective investors.They say the most immediate potential use for the new technology is in industrial locations where permanent hydrogen fuel supply lines are already in place.That includes mining sites, where studies have shown that about 30% of greenhouse-gas emissions are caused by the use of diesel engines, largely in mining vehicles and power generators.And the Australian market for diesel-only power generators is currently estimated to be worth around $765 million.""At mining sites, where hydrogen is piped in, we can convert the existing diesel engines that are used to generate power,"" says Prof. Kook.""In terms of applications where the hydrogen fuel would need to be stored and moved around, for example in a truck engine that currently runs purely on diesel, then we would also need to implement a hydrogen storage system to be integrated into our injection system.""I do think the general technology with regards to mobile hydrogen storage needs to be developed further because at the moment that is quite a challenge.""More information: Xinyu Liu et al, Direct injection of hydrogen main fuel and diesel pilot fuel in a retrofitted single-cylinder compression ignition engine, International Journal of Hydrogen Energy (2022). Journal information: International Journal of Hydrogen Energy Xinyu Liu et al, Direct injection of hydrogen main fuel and diesel pilot fuel in a retrofitted single-cylinder compression ignition engine,(2022). DOI: 10.1016/j.ijhydene.2022.08.149",0.0,0.0
266,https://www.cnbc.com/2022/10/02/how-deere-plans-to-build-a-world-of-fully-autonomous-farming-by-2030.html,How John Deere plans to build a world of fully autonomous farming by 2030,"Deere's autonomous 8R is the culmination of nearly two decades of work in automation, data analytics, GPS-guidance, internet-of-things connectivity and software engineering.Can John Deere become one of the leading AI and robotics companies in the world alongside Tesla and Silicon Valley technology giants over the next decade?That notion may seem incongruous with the general perception of the 185-year-old company as a heavy-metal manufacturer of tractors, bulldozers and lawnmowers painted in the signature green and yellow colors.But that is what the company sees in its future, according to Jorge Heraud, vice president of automation and autonomy for Moline, Illinois-based Deere, a glimpse of which was showcased at last January's Consumer Electronics Show in Las Vegas, where Deere unveiled its fully autonomous 8R farm tractor, driven by artificial intelligence rather than a farmer behind the wheel.The autonomous 8R is the culmination of Deere's nearly two decades of strategic planning and investment in automation, data analytics, GPS guidance, internet-of-things connectivity and software engineering. While a good deal of that R&D has been homegrown, the company also has been on a spree of acquisitions and partnerships with agtech startups, harvesting know-how as well as talent.""This comes from our realization that technology is going to drive value creation and increase productivity, profitability and sustainability for farmers,"" Heraud said.While Deere made a big splash at CES and intrigued the investment community, Stephen Volkmann, equity research analyst at Jefferies, said, ""We are very, very, very early in this process.""""The total global fleet of autonomous Deere tractors is less than 50 today,"" he added. And even though Deere's goal is to have a fully autonomous farming system for row crops in place by 2030, Volkmann said, ""in Wall Street time, that's an eternity.""For the time being, Deere is creating value and profits with well-established automated systems that can be retrofitted to its existing tractors, such as GPS-based self-steering and precision seeding that measures how deep and far apart to plant. Those steps have to be in place, Volkmann said, before you can put full autonomy around them.The autonomous 8R represents a giant leap in current agtech, not to mention the marketing benefit. ""Prior to its introduction at CES, everybody thought [full autonomy] was pie in the sky,"" said Scott Shearer, chair of the department of food, agricultural and biological engineering at Ohio State University.Around the world, Shearer said, there are probably 30 different autonomous tractor projects in the works, though none are commercially available. ""But when Deere, with 60% of the tractor market share in North America, comes out with one, that's when reality sets in,"" Shearer said.That reality reflects Deere's autonomy strategy. ""The AI we use involves computer vision and machine learning,"" Heraud said, science that was well underway at Silicon Valley startup Blue River Technology, which Deere bought in 2017 for $305 million — a deal that also brought on Blue River co-founder and CEO Heraud. Blue River's ""see and spray"" robotics platform utilizes dozens of sophisticated cameras and processors to distinguish weeds from crop plants when applying herbicides.Attached to the autonomous tractor are six pairs of stereo cameras that can ""see"" an obstacle in the field — whether it's a rock, a log or a person — and determine its size and relative distance. Images captured by the cameras are passed through a deep neural network that classifies each pixel in approximately 100 milliseconds and decides whether the tractor should keep moving or stop.""We've curated hundreds of thousands of images from different farm locations and under various weather and lighting conditions,"" Heraud said, ""so that with machine learning, the tractor can understand what it's seeing and react accordingly. This capability also allows the farmer, instead of being in the tractor, to operate it remotely while doing something else.""Heraud was referring to autonomous driving, another piece of Deere's agtech puzzle that came together when it purchased Bear Flag Robotics last year for $250 million. Also a Silicon Valley startup, launched in 2017, Bear Flag's autonomous navigation system can be retrofitted onto existing tractors. In the case of Deere's 8R model, a tractor which first went on the market in 2020, the latest version with autonomous capabilities uses technology from Blue River.Since the CES rollout, Deere has acquired AI assets from two other agtech pioneers. In April, Deere formed a joint venture with GUSS Automation, which has devised semi-autonomous orchard and vineyard sprayers. Using AI and IoT, multiple GUSS (Global Unmanned Spray System) sprayers can be remotely controlled by a single operator, running up to eight sprayers simultaneously from a laptop. GUSS can detect trees and determine how much to spray on each one, regardless of height or canopy size.A month later, Deere announced the acquisition of numerous patents and other intellectual property from AI startup Light, according to The Robot Report. Light's depth-perception platform improves upon existing stereo-vision systems by using additional cameras, mimicking the structure of a human eye to enable more accurate 3D vision. Deere plans to integrate Light's platform into future versions of its autonomous farm equipment.To keep a close eye on other agtech R&D, Deere has established a Startup Collaborator program to test innovative technologies with customers and dealers without a more formal business relationship. ""The hope is that they find the diamonds before they become obvious to [competitors] and keep them in the fold,"" Volkmann said. Among the current crop are Four Growers, a Pittsburgh-based startup providing robotic harvesting and analytics for high-value crops, starting with greenhouse tomatoes, and Philadelphia-based Burro, which is producing small, autonomous robots that can assist farm workers with various conveyance tasks.Not surprisingly, Deere's biggest competitors have been developing automation and autonomy for its farm machinery, too. AGCO, whose brands include Massey Ferguson and Fendt, ""has been automating farming operations since the mid-1990s,"" said Seth Crawford, senior vice president and general manager of the Duluth, Georgia-based company's precision agriculture and digital division. ""We're at a stage we call supervised autonomy, where we still have someone in the cab of the machine,"" he said. ""The buzz is around fully autonomous operations, but where farmers are willing to pay for automation is feature by feature.""Whereas Deere is focused on adding full autonomy to its own farm equipment, AGCO is eying the wider retrofit market, Crawford said. ""In summer 2023, we'll have a performance-enhancing retrofit kit available for multiple brands of machines,"" he said. ""Where others say we bring you autonomy with a half-million-dollar tractor,"" he said, alluding to the price tag of Deere's 8R, ""we have kits that allow you to do that with your existing fleet. We see a huge opportunity with the installed base, where farmers want to adopt technology to enhance their outcomes, and yet don't want to flip their entire fleet and make that massive investment.""In 2016, Case IH, a subsidiary of CNH Industrial, headquartered in London, rolled up to the Farm Progress Show with what it called the Autonomous Concept Vehicle. The sleek prototype tractor, minus a driver's cab, hinted at the view of autonomy at the time. Fast forward six years, to September's Farm Progress Show, where Case IH unveiled its Trident 5550 autonomous applicator.",0.0,0.0
126,https://www.nbcnews.com/health/sexual-health/sexual-assault-emergency-visits-increased-rcna53171,"Sexual assault-related ER visits increased more than tenfold since 2006, study finds","Emergency department visits related to sexual assault increased more than tenfold over a span of 13 years, according to a new study that experts and advocates say reflects a growing cultural shift around confronting sexual assault.The research, published Thursday in JAMA Network Open, showed that those visits increased 1,533% from 2006 to 2019 — a jump from 3,600 annual visits to 55,200.The largest increase occurred between 2015 and 2016, when visits went from about 17,700 to 47,700, according to the findings.The study authors said their research represents the largest longitudinal study of sexual assault-related visits to emergency rooms in the U.S. The analysis relied on federal data from the Nationwide Emergency Department Sample, which tracks emergency department visits, as well as the FBI’s Uniform Crime Reporting Program, which compiles data from 18,000 law enforcement agencies.Keme Carter, an emergency physician and associate professor of medicine at the University of Chicago who has researched the medical treatment of sexual assault victims, said she, too, thinks the new research ""is and will continue to be a landmark study.""The authors speculated that a combination of factors drove the trend: an increased number of sexual assaults, population growth and awareness-raising social movements like #MeToo.""We’ve moved a long way, thankfully, in the acknowledgement that any time there’s non-consensual sexual activity, that is sexual assault,"" said study co-author Erica Marsh, a professor of obstetrics and gynecology at the University of Michigan Medical School.Scott Berkowitz, president and founder of the Rape, Abuse & Incest National Network, who was not involved with the study, called the results ""really encouraging.""""There’s been a huge incremental change in awareness over the last couple decades, which I think #MeToo really accelerated,"" he said.According to the data, most visits to emergency departments following sexual assault were by young adult women. Over 90% of the victims who visited emergency rooms were women, and young people between 18 and 25 accounted for over 40% of annual visits.Women and young people experience sexual assault at higher rates than other demographics, according to RAINN.Lower-income people were also an overrepresented group, the study found.The rise applied to men as well: Their share of assault-related ER visits rose from 3.9% in 2007 to slightly above 8% from 2016 to 2019, the study noted.About 1 in 33 American men have experienced an attempted or completed rape in their lifetime, compared to 1 in 6 women, according to RAINN.Among the study's other findings were that the share of assault victims who were admitted to the hospital after going to the ER decreased by 8.3%. That could be because cultural understandings of what constitutes sexual assault have expanded beyond encounters involving extreme physical violence.Additionally, the results showed that the rise in sexual assault-related visits to emergency departments outpaced the increase in reports to law enforcement. The latter grew 23% during the study period. The number of reports to law enforcement is much larger than emergency visits, though. In 2019, for example, there were more than 139,800 reports of sexual assault to law enforcement compared to 55,296 ER visits.Sexual assault overall makes up just 0.06% of emergency room visits, according to the study. The authors cited previous research suggesting that just 21% of sexual assault survivors seek medical care afterward.Marsh and Berkowitz both emphasized that medical care following an assault is crucial in order to test for and prevent sexually transmitted infections and viruses, as well as to collect evidence that a victim may want to provide to police.The new study comes with limitations, however. For one, the NEDS database that logs ER visits could represent patients who visited emergency departments more than once.The FBI data, meanwhile, relies on voluntary reports from law enforcement and narrow definitions of sexual assault, according to the study. And, of course, it does not capture sexual assaults that went unreported — which more than two in three do, according to RAINN.Also impacting the data, potentially, is a 2015 change in how the International Classification of Diseases, a diagnostic tool maintained by the World Health Organization, characterized sexual assault during the study period. Prior to 2015, the ICD offered only one code to describe adult sexual abuse; starting in 2015, it offered multiple, more specific codes.Furthermore, the study does not account for transgender and nonbinary people, who experience sexual violence at especially high rates, according to RAINN.",0.0,0.0
63,https://techcrunch.com/2022/11/05/laid-off-climate-tech-is-looking-for-talent-and-founders/,Laid off? Climate tech is looking for talent and founders,"As rumors rumbled that the U.S. Federal Reserve would hike rates once more — and when it followed through earlier this week — another round of layoffs hit the tech sector. Stripe, Opendoor, Chime, Zillow, Cerebral, Brex, and of course Twitter, among others, have already cut or are about to eliminate thousands of jobs.That’s bad news for employees today, but it might be good news for the climate in the near future.Before we get too far, let me say up front that getting laid off is terrible and not something I wish to happen to anyone. Not knowing where your paychecks will come from or what benefits you’ll receive is difficult in the best of times, and it’s far worse when economic signs are mixed or major life changes are looming. I am not at all trying to minimize what people go through when they’ve been laid off. It’s happened to me, and it sucks.But layoffs also offer a chance at a new beginning. Even before the recent waves of layoffs started washing over the tech industry, people were leaving their old jobs for new opportunities in climate tech.While this is a TechCrunch+ story, we made sure the paywall is below the key links in case you are job-hunting. Hugs — The TC+ team“One thing we’re seeing is really, really strong talent leaving larger companies,” Erin Price-Wright, a partner at Index Ventures, said at TechCrunch Disrupt, “because some of the financial upside for public tech companies or maybe even late-stage tech companies has sort of vaporized in the last few months. And people are like, ‘Well, I had these golden handcuffs, and that was preventing me from working on what I really care about. And I don’t have that anymore. So I’m going to take a risk and I’m going to do something.’”Climate tech has been booming relative to the rest of the market, with startups in the sector raising $5.6 billion in the first half of this year, short of 2021’s crazy hauls but still well ahead of 2020, the next previous record, according to PitchBook. Five years from now, PitchBook expects the climate tech market to be worth $1.4 trillion, a compound annual growth rate of 8.8%.All those companies are in desperate need of talent. Nearly every early-stage founder in the climate tech space I’ve spoken with in recent months went out of their way to mention that they’re hiring. Climatebase has thousands of jobs listed right now, and that’s just a portion of the climate tech companies with active listings.Shaun Abrahamson, co-founder of climate-focused Third Sphere, pointed out that his firm’s portfolio companies are currently hiring for over 400 positions. Breakthrough Energy Ventures’ portfolio companies are hiring for nearly 1,200 positions.Elsewhere, around 100 companies are using the climate career platform Terra.do to directly connect with applicants, chief business officer Nishant Mani told TechCrunch. The startup frequently runs virtual job fairs to match employees with employers, and business is booming. The platform’s user base is growing 50% month on month, and Mani is aiming to get 1,000 companies actively using the platform in the next six months.",0.0,0.0
574,https://techcrunch.com/2019/09/17/ironclad-raises-50m-series-c-round-for-its-digital-contracting-platform/,Ironclad raises $50M Series C round for its digital contracting platform,"Ironclad, a startup that makes it easier for legal teams to manage their contracts workflow, today announced that it has raised a $50 million Series C round led by Y Combinator Continuity, with participation from Emergence Capital, as well as existing investors including Accel and Sequoia Capital. This round brings Ironclad’s total funding to $83 million, according to Crunchbase.In addition to the new funding, Ironclad, which was part of Y Combinator’s Summer 2015 class, also today announced the launch of its Workflow Designer. This tool allows teams to easily create their own custom workflows based on their individual business processes and timelines. Setting up those workflows looks be a pretty straightforward process. After tagging the existing contract, teams can then set up their processes based on what’s in a specific document. If a contract is over a specific value, for example, they can add a payment clause, or set up an approval process based on that value.Workflow Designer complements the service’s existing tools for managing the contract life cycle and collaborating on legal documents.The company says it will use the new funding to expand into new geographies and expand its product.“This round and our continued momentum highlights how big the opportunity is to streamline contracting for every type of company in the world,” said Jason Boehmig, co-founder and CEO of Ironclad. “Our newest investors bring a depth of later-stage company experience and a vision for what cloud companies will look like in the future. Our new funding will fuel continued product innovations, like our new Workflow Designer, which is accelerating contracting time by 85% for our customers.”",2.0,0.0
157,https://interestingengineering.com/innovation/new-chip-transmits-record-breaking-184-petabits-data-per-second,New chip transmits a record breaking 1.84 petabits of data per second,"It saw the use of a photonic chip, a microchip containing two or more photonic components which form a functioning circuit. This technology detects, generates, transports, and processes light to divide a stream of data into thousands of separate channels and transmit them all at once over 7.9 kilometers.“First, the team split the data stream into 37 sections, each of which was sent down a separate core of the fibre-optic cable. Next, each of these channels was split into 223 data chunks that existed in individual slices of the electromagnetic spectrum. This 'frequency comb' of equidistant spikes of light across the spectrum allowed data to be transmitted in different colours at the same time without interfering with each other, massively increasing the capacity of each core,” explained New Scientist.In the past, we have witnessed data transfer rates of up to 10.66 petabits per second but they were created through the use of bulky inefficient and impractical equipment. This new and improved research sets a record for transmission using a single computer chip as a light source. The technology could see energy costs significantly slashed and bandwidths severely increased.Using dummy dataThe experiment used so much data that no computer today exists that could supply or receive this much information at this rate. The team had to therefore pass “dummy data” through all channels, says Jørgensen, and experiment on the output one channel at a time to ensure that it was all being sent and recovered adequately.",0.0,0.0
116,https://www.pcgamer.com/a-single-chip-has-managed-to-transfer-the-entire-internets-traffic-in-a-single-second/,A single chip has managed to transfer the entire internet's traffic in a single second,"Audio player loading…A single chip has managed to transfer over a petabit-per-second according to research by a team of scientists from universities in Denmark, Sweden, and Japan. That's over one million gigabits of data per second over a fibre optic cable, or basically the entire internet's worth of traffic.The researchers—A. A. Jørgensen, D. Kong, L. K. Oxenløwe—and their team successfully showed a data transmission of 1.84 petabits over a 7.9km fibre cable using just a single chip. That's not quite as fast as some other alternatives with larger, bulkier systems, which have reached up to 10.66 petabits, but the key here is scale: the proposed system is very compact.By splitting a data stream into 37 sections, one for each core of a fibre optic cable, and then further splitting each of those streams into 223 channels, the researchers were able to remove a great deal of interference that slows down optical systems and therefore deliver an internet's worth of data transmission using a single chip.""You could say the average internet traffic in the world is about a petabit per second. What we transmit is two times that,"" Jørgensen says in a comment on New Scientist (opens in new tab). ""It’s an incredibly large amount of data that we’re sending through, essentially, less than a square millimetre [of cable]. It just goes to show that we can go so much further than we are today with internet connections.""The researchers also theorise that such a system could support speeds of up to 100 petabits-per-second in massively parallel systems.The research paper (opens in new tab) relies on a bank of investigations into the concept of a single chip solution across multiple researchers and papers, including one by researchers in Australia called 'Ultra-dense optical data transmission over standard fibre with a single chip source (opens in new tab)'. Catchy.Your next machine (Image credit: Future) Best gaming PC (opens in new tab): The top pre-built machines from the prosBest gaming laptop (opens in new tab): Perfect notebooks for mobile gamingEssentially, high-speed data transmission that often requires a fibre optic cable and bulky equipment is now being miniaturised into a smaller on-chip package. Instead of multiple lasers in parallel, which come with their own set of challenges, it's possible to shrink a good deal of this equipment to the silicon level. And with that even remove some of the difficulties in sending massive data packages long distances and at high speeds.A big part of these new breakthroughs are microcombs, which are a way of generating constant and measurable frequencies of light. These are not only useful for shrinking down the requirements for a system such as this, but have also recently seen breakthroughs when added to CMOS chips (opens in new tab).In fact, a whole lot more could be added to a CMOS chip to make this whole system even more integrated, says Jørgensen. So if this seems fast and compact now, it's only a matter of time before an even more integrated, speedier version is developed. Stack up more of these devices into a single parallel system and you're talking mega-bandwidth from a single server rack.Basically, the internet has a whole lot more room to grow.",1.0,0.0
70,https://techcrunch.com/2022/10/05/7-investors-discuss-how-agtech-can-solve-agricultures-biggest-problems/,7 investors discuss how agtech can solve agricultureâs biggest problems,"Climate change and geopolitical instability are wreaking havoc on agriculture. To gauge how VCs are responding to these issues, we spoke with seven investors.For starters, rising greenhouse gas emissions are driving punishing droughts and storms, which are harming crops, exacerbating food insecurity and threatening countless livelihoods. At the same time, Russia’s invasion of Ukraine is rattling the world’s grain supply, driving up costs and further aggravating supply chains.Even as these and other crises hammer the multitrillion-dollar industry, startup investors see potential for huge returns with tech that could boost yields, slash emissions and mitigate waste.“There are opportunities to develop [and] adopt new technologies all along the food value chain that will impact key issues like food security and emissions,” Adam Anders, a managing partner at Anterra Capital, told TechCrunch. Among the areas where he sees the biggest potential impact, the investor cited improving plant genetics, boosting the shelf life of more products and putting digital tools in the hands of farmers.Consumer behavior is another piece of the proverbial puzzle as climate literacy increasingly alters how folks shop.“Over the last few years, we have seen skyrocketing interest in sustainability from consumers and food brands, and awareness over the negative impacts of agriculture continues to grow,” said Ting-Ting Liu, investor at Prosus Ventures. “People are not only paying more attention to agricultural-related emissions but also how much land and water is required to support the world’s food supply and the amount of runoff being generated,” she said.Liu argued that this demand is creating strong tailwinds for businesses that strive to address agriculture’s environmental impact, ultimately driving more capital into everything from cellular agriculture to methane reduction solutions for livestock.Still, agtech is not immune to some of the broader trends in venture.While the value of agtech VC deals rose to $11.4 billion in 2021 from $6.5 billion in 2020, several investors told TechCrunch they’ve noticed a slowdown in agtech deals this year amid the wider tech downturn of 2022.“2021 was a record year for VC across the board. In 2022, VC investments across the board are about 30% lower year on year, and I would expect a similar slowdown for agtech,” Monica Varman, a partner at G2 Venture Partners, told TechCrunch. “Over the medium to long term, however, I do expect agtech VC funding to grow, given supply chain challenges, traceability concerns and advancements in enabling technologies in synbio and robotics,” she added.Agtech investors are also still largely funding men. Out of the nearly $11 billion dispensed into agtech in 2021, 78% went to firms with all-male founders, according to PitchBook. The disparity has only worsened so far in 2022, rising to 81% (out of nearly $7.3 billion) as of September 14, per the data firm.To gauge whether (and how) VCs are responding to these issues and more, we reached out to:Brett Brohl, managing director, Techstars Farm to Fork, and managing partner, Bread and Butter VenturesAgtech VC deal value rocketed from $6.5 billion in 2020 to $11.4 billion in 2021. Will this sort of growth continue?It’s not going to continue in the short run largely because of macroeconomic factors you’re just not seeing — for example, many late-stage deals are going through recently — so in the short term, definitely not.In the long run, the sector has a tremendous amount of opportunity and room for innovation, so with time, you will see continued growth and investor focus on agtech.Agriculture is responsible for about a quarter of global GhG emissions. How has the climate crisis changed how you invest?It is a huge reason deal value skyrocketed in 2020 and 2021. Investors understand that this challenge creates an opportunity. Agtech is not as mainstream as many other sectors, so we need more eyeballs and capital. If you are making the food system more effective and efficient, you are making it more sustainable.We aren’t a big enough fund to finance a startup forever, and we depend on later-stage investors, so this attention and resulting influx of capital helps remove some risk from our portfolio.Which emerging technologies, such as cellular agriculture and AI-powered robots, have the greatest potential to impact key issues like food security and emissions in the next decade?We 100% believe in cellular agriculture and are also huge fans of the robotics space, especially robotics that solve very specific pain points and have low BOMs.“Automation and computer vision will be transformative for agriculture over the next decade, particularly as food production is moved closer to the point of consumption due to food security concerns.” Monica Varman, partner, G2 Venture PartnersWe also love the packaging space — lots of packaging goes into the transportation and movement of food. We’re also excited about anything to do with logistics, manufacturing or transportation that makes the food chain more sustainable.When investing in an agtech startup, which green flags do you look for? Are you open to backing founders who don’t have experience in the industry?Investing in agtech startups is no different from any other company. A great team can take a C- idea, pivot, iterate and make it work. But a C- founder will run any idea into the ground, regardless of how good it is.While founder-market fit can be a benefit to a company, great entrepreneurs are smart, have a great work ethic, are coachable and know how to surround themselves with people who make up for their weaknesses. So industry experience isn’t a requirement for us.Which areas of agtech have received the most attention from early-stage founders in recent years? In which areas would you like to see more work done or investments?The obvious answer is alternative proteins. So much capital has been invested and so many founders are building cool things in the space.I’d love to see more attention paid to things that are a bit downstream, such as manufacturing, logistics and the future of food retail. Over the last few years, you have seen traditional agtech investors move their thesis further downstream, so it is happening.I’m also really interested in fintech applications in the agriculture space, like what Traive and Milk Moovement are doing.What are you doing to fund underrepresented founders in agtech?We actively seek out investors, forums and networks that support underrepresented founders and invest or work with entrepreneurs that are a stage earlier than where we invest. We also maintain a diverse investment team — 75% of our fund are women.Finally, we hold open office hours for anyone every week and provide free public education through multiple channels to help founders level up.Before the invasion, Russia and Ukraine accounted for about 28% of wheat and 15% of corn exports globally. How has the Russian invasion of Ukraine affected agtech VC deal-making given its impact on the global supply chain and the world’s grain supply?I don’t think it’s done much to early-stage agtech founders or venture capital. The macroeconomic effect of the war has at least, in part, been a tightening of monetary supply, which will trickle down to early-stage startups. However, the impact has not been significant at early stages yet.Bayer bought Monsanto for $63 billion in 2018, and a year earlier, ChemChina acquired Syngenta for $43 billion. Today, Bayer’s market cap is less than that deal’s value, and China’s ambassador to Switzerland has called the Syngenta acquisition a bad deal for Beijing. Have the outcomes of these deals affected investors’ hopes for blowout late-stage exits?I wouldn’t call these acquisitions of “modern” agtech companies. Monsanto has been around for 100+ years, and Syngenta was formed over 20 years ago, and even then it was a spin-off. Additionally, these happened in 2017 and 2018. Investment in agtech has exploded since then, indicating that the market does not think these two acquisitions are indicative of underperforming venture investments.The outcomes of companies like Upside Foods, FBN and Indigo Ag will be far more important to the agtech ecosystem. Unfortunately, it’s a very tough market for late-stage companies right now, and that will slow exits and depress ROI on many venture investments, not just agtech deals.How do you prefer to receive pitches? What’s the most important thing a founder should know before they get on a call with you?I’m open to warm intros, thoughtful cold emails or pitches during my open office hours. If you’re pitching me on a call, the number one thing is to be yourself.Anything else you’d like to comment on?I think the blurred lines between food tech and agtech are really interesting. What is agtech? It’s not just farm inputs; there is a lot more to it and that, to me, is exciting.Monica Varman, partner, G2 Venture PartnersAgtech VC deal value rocketed from $6.5 billion in 2020 to $11.4 billion in 2021. Will this sort of growth continue?2021 was a record year for VC. In 2022, VC investments across the board are about 30% lower, and I would expect a similar slowdown for agtech.Over the medium and long term, however, I do expect agtech VC funding to rise given supply chain challenges, traceability concerns and advancements in enabling technologies in synbio and robotics.",0.0,0.0
72,https://techcrunch.com/2022/09/09/climate-tech-is-a-hot-investment-in-2022-next-five-years-could-be-even-hotter/,Climate tech is a hot investment in 2022 â next five years could be even hotter,"Climate tech is a hot investment in 2022 — next five years could be even hotterDespite whispers of a downturn earlier this year, investors continue to express confidence in climate tech. Though numbers are down compared with 2021, a year that many agree is an outlier in the VC world, they’re on track to beat 2020 as the second hottest year for investment.What’s more, deal counts and values were up in the second quarter of this year compared with the first, suggesting that the slowdown has more or less skipped climate tech.Though deal count is down nearly 19% compared with last year, it was up 15.4% in the second quarter, according to a PitchBook analysis. Total market deal value, down year over year, was up significantly in Q2, and the average value per deal has held steady at $23.6 million, more than triple what it was five years ago.In some ways, those modest numbers could be interpreted as a slight cooldown. But the sector is probably just taking a breather given its near-term potential. Just five years from now, PitchBook estimates the climate tech market will near $1.4 trillion, representing a compound annual growth rate of 8.8%.With that kind of growth coming down the pike, there are a lot of different bets to place in the climate tech sector, but a few stand out for their early-stage potential and favorable tailwinds.",0.0,0.0
530,https://www.medicalnewstoday.com/articles/menopause-low-fat-plant-based-diet-may-improve-hot-flash-symptoms,"Menopause: Low fat, plant-based diet may improve hot flash symptoms by 88%","Share on Pinterest New research suggests that a low fat, plant-based diet rich in soy may help reduce hot flash symptoms and promote weight loss. Kelvin Murray/Getty Images A new study suggests that a low fat, plant-based diet rich in soy is as effective as hormone replacement therapy (HRT) for reducing hot flashes.The 12-week trial found that a plant-rich diet reduced moderate to severe hot flashes by 88%.The diet may have also helped women lose 8 pounds on average and improved their quality of life.Some experts say the study isn’t robust enough and that HRT is still the best option for reducing severe hot flashes.More research is needed to determine the impact of diet on reducing menopausal symptoms like hot flashes. A recent study reported that a plant-based, soy-rich diet could alleviate menopausal symptoms with the same effectiveness as hormone replacement therapy (HRT). The Women’s Study for the Alleviation of Vasomotor Symptoms (WAVS) trial found that this food-based approach reduced moderate to severe hot flashes by 88%. HRT has been shown to improve these symptoms by 70%–90%. Moreover, trial participants lost an average of 8 pounds during the 12-week study. Lead researcher Dr. Neal Barnard, president of the Physicians Committee for Responsible Medicine and adjunct professor at the George Washington University School of Medicine, said in a news release: “We do not fully understand yet why this combination works but it seems that these three elements are key— avoiding animal products, reducing fat, and adding a serving of soybeans. Our results mirror the diets of places in the world, like pre-Westernized Japan and modern-day Yucatán Peninsula, where a low fat, plant-based diet including soybeans is more prevalent and where postmenopausal women experience fewer symptoms.” These findings were recently published in Menopause: The Journal of the North American Menopause Society.Hot flash symptoms and nutrition Vasomotor symptoms include recurrent hot flashes, night sweats, and blood pressure fluctuations. Medical News Today discussed this study with Dr. G. Thomas Ruiz, the obstetrics and gynecology lead at MemorialCare Orange Coast Medical Center in Fountain Valley, CA. He was not involved in this research. Dr. Ruiz explained that vasomotor symptoms arise primarily from changes in the hypothalamic-pituitary-ovarian axis, which regulates sex hormone secretions. The hypothalamus, located in the center of the brain, helps control the internal thermostat. Fluctuating and decreasing hormone levels during menopause cause disruption in the hypothalamus. Hot flashes happen as the brain area is trying to reset its temperature, Dr. Ruiz shared.Effects of a low fat, plant-based diet on menopause symptoms Dr. Barnard and his research team recruited postmenopausal women ages 40 to 65 years for a parallel-design study in September 2020 and February 2021. Out of 1,662 respondents, 71 remained for the final data analysis. An intervention group followed a low fat, vegan diet with half a cup of cooked, nongenetically modified soybeans a day for 12 weeks. A control group made no dietary changes. Both groups took a vitamin B12 supplement daily and were asked not to take any other supplements, change medications, or exercise regimens. A mobile application recorded the frequency and severity of hot flashes. Participants completed the Menopause-Specific Quality of Life survey to record vasomotor, physical, psychosocial, and sexual symptoms. Why limit healthy fats? The study’s recommended diet was partially inspired by a traditional Japanese diet emphasizing plant-based foods, soy products, and low amounts of oils. MNT asked Dr. Barnard about limiting even “healthy” oils and fats, such as nuts and avocados: “The fat in nuts and avocados is healthier than the fat in dairy products and meat. The former are low in saturated fat, and the latter are loaded with it. But we often reduce fat of all kinds in our research studies. Oils and fats — ‘good’ or ‘bad’ — tend to interfere with weight loss [and] loss of excess weight seems to help with hot flashes.” “Oils and fats modify estrogen activity. During the study, we did find that those women who carefully avoided oily foods seemed to have faster benefits,” Dr. Barnard added.Certain foods reduce moderate to severe hot flashes The intervention diet may have resulted in significantly reduced menopausal symptoms. The total hot flash frequency in the fall cohort (September 2020) dropped by 78% in the intervention group and decreased by 39% in the control group. Moderate to severe hot flashes in the spring cohort (February 2021) intervention group fell by 88%, while the control saw a decrease of 34%. Women with seven or more hot flashes per day at the start of the study experienced a 93% reduction in symptoms in the intervention group. The control group had 36% fewer symptoms at the end of the study. The researchers found that reducing fat consumption and increasing fiber intake correlated with reduced severe hot flashes. The intervention group members lost an average of 7.93 pounds, while the control group participants lost one-half a pound on average.Limitations to menopause research Dr. Ruiz saw the cohort study design as a disadvantage. He argued that a double-blind study is “really the only way to come up with an observation that may be medically meaningful.” “A healthy diet will help you overall because it will make [you] feel better in general,” Dr. Ruiz said, adding that people who regularly eat healthily are also more likely to exercise as well. Dr. Ruiz added that the study’s small sample increased the possibility of a “huge placebo effect.” The study’s authors did admit that placebo effects could not be ruled out. It should also be noted that several of the study’s co-authors received compensation from the Physicians Committee for Responsible Medicine for their contributions. “When the results are very strong and consistent, a smaller sample can prove the effect,” Dr. Barnard said. “In this case, the 88% drop in moderate-to-severe hot flashes is enormous, and statistically, there is less than 1 [in] 1000 that this is due to chance. Our sample of 84 women was more than double the size needed to prove the effect.”Areas for future study Dr. Barnard hopes that future investigations will assess this study’s dietary approach for other conditions that cause hot flashes. For instance, he said that people with breast cancer or prostate cancer deal with hot flashes. To date, they have limited options for relief. “In both cases, a low fat vegan diet, plus soybeans, would be exactly the diet they should have clinically,” Dr. Barnard said.",0.0,0.0
109,https://www.vice.com/en/article/qjkwem/a-scientist-just-mathematically-proved-that-alien-life-in-the-universe-is-likely-to-exist,A Scientist Just Mathematically Proved That Alien Life In the Universe Is Likely to Exist,"ABSTRACT breaks down mind-bending scientific research, future tech, new discoveries, and major breakthroughs. See More →Humans have spent centuries wondering if we are alone in the universe, or if there are alien beings somewhere in the vast reaches of space. Given that Earth remains the only planet that we know supports life—and we are not even sure how it arose here—it remains challenging to assess the odds that extraterrestrial life exists based on this lonely sample size of one.These limitations in our knowledge prompted the theoretical physicist Brandon Carter to propose decades ago that the presence of life on Earth does not indicate that the mysterious process of abiogenesis, in which living organisms arise from inanimate matter, is more or less likely to occur on other planets. Now, a mathematician has revisited this idea and come to a very different conclusion with a more optimistic view about the existence of alien life.AdvertisementDuring the 1970s, Carter developed an influential series of arguments based on this “selection effect” of our own existence. This view suggests that humans, as a species that lives on a planet where life emerged, cannot make objective inferences about the possibility that life may be present on other worlds, in part because we have no idea if Earth is typical of planets that might host life. For this reason, we cannot exclude the possibility that Earth may be the only world in the universe that supports living beings.This argument is widely accepted in the scientific community. But now, Daniel Whitmire, an astrophysicist who teaches mathematics at the University of Arkansas, has presented a new challenge to Carter’s assumptions that suggests “the occurrence of abiogenesis on Earth-like planets is not rare,” according to a recent study published in the International Journal of Astrobiology.Whitmire told Motherboard over email that up until last year, he was one of countless researchers who thought that the Carter argument was “unassailable.” But he started to have doubts about its foundations during the peer review process for a different paper, when an anonymous reviewer offered an analogy between abiogenesis and human conception that inspired Whitmire to counter these long-held assumptions.In order to rethink Carter’s assertion that we can’t judge if abiogenesis on Earth was easy or hard, Whitmire draws a comparison to his own existence, noting that he is here regardless of whether his conception, or origin, was easy or hard. For the purposes of this thought experiment, conception would be “hard” if contraception was used, and “easy” if it was not used. The basic idea is that, rather than a person’s existence not telling us anything about whether conceiving them was easy or hard, it can be shown mathematically that it was most likely easy.Advertisement“The Conception analogy stuck in my mind and ultimately I came to believe that the Carter argument must be wrong,” Whitmire said. “But at that point I didn't know why it was wrong.”To tug on this thread, Whitmire developed a mathematics-based argument that builds on the analogy with the help of the so-called “old evidence problem” in Bayesian Confirmation Theory, which concerns the incorporation of newly-acquired data into existing hypotheses.The details are pretty complicated, but the gist is that while Carter holds that old evidence (i.e. the existence of life on Earth) has no influence on the probability of its occurrence elsewhere, Whitmire’s paper attempts to show that, actually, this “old evidence” does in fact increase the probability of it occurring in the first place. Under this novel framework, both abiogenesis on Earth and Whitmire’s conception are more likely to have been easy than hard, which suggests that life on other planets may be common.These ideas are a bit heady, and Whitmire notes that they might not actually have that much of an impact on anyone’s hopes or doubts about the probability of alien life existing somewhere in space.“My opinion is that what many scientists believe about life and intelligent life in the universe is almost political or psychological,” Whitmire said. “If they want to believe life is rare they will point to the Carter argument or some other argument, like the statistical improbability of abiogenesis, to make their case.”AdvertisementWhitmire's formula. AB means abiogenesis, and LoE means life on Earth.Likewise, Whitmire added that those who want to believe life is abundant can find evidence for that position in other studies, including his new paper.“There is no reason that I know of (outside of my paper) for any objective optimism about abiogenesis being easy, yet this is the belief of most astrobiologists in spite of the Carter argument,” he said. “Perhaps my paper will give some objective credence to this subjective belief. That said, I think that arguments like mine and Carter's have some influence but the dominant attitude is that since none of the arguments are 100 percent, only future observations will decide.”Fortunately, we live in an era packed with exciting missions focused on the search for extraterrestrial life, both inside our solar system and beyond it. NASA’s Perseverance rover is currently searching for signs of ancient life on Mars, and future missions may scout out Jupiter’s moon Europa or Saturn’s moon Enceladus, which are both considered to be potentially habitable. Next-generation observatories, including the James Webb Space Telescope, have the capacity to spot signs of life (or biosignatures) on planets in other star systems, and astronomers are scanning the skies for messages from technologically advanced aliens.Of course, all of these efforts could come up short in the search for life beyond Earth. But just one detection of life beyond our planet—even if it were microbial, or long-extinct—would validate Whitmire’s new argument that abiogenesis is not rare in the universe.",0.0,0.0
499,https://techcrunch.com/2022/10/07/flyfeed-angel-round/,FlyFeed flies in the face of the global food crisis,"FlyFeed claims it signed more than $10 million worth of contracts and closed a $3 million round of investment to launch its first insect farm in Vietnam, in its push to produce low-cost, high-nutrient protein for human consumption.The company was founded less than a year ago and is targeting the three billion people who are facing food insecurity due to climate and global financial shifts. The production process uses organic leftovers as food for the black soldier fly (BSF) insects, which significantly reduces the final price of manufactured protein. As a bonus, it also helps reduce local food waste issues.“Five billion dollars invested in agtech in 2021 shows that the fragile global food chain, relying on exhaustible natural resources, faces new challenges and needs a change. In this case, insect proteins are an effective solution that can transform inedible resources into nutritious proteins. Supported by laboratory tests and approved by local authorities, we will open 10 farms in Asia and Africa by 2026 and contribute to solving the global food shortage crisis,” says Arseniy Olkhovskiy, CEO and founder of FlyFeed, in an interview with TechCrunch. “There are many things I find wrong with the world, but the fact that global hunger still exists is the most absurd. There are more than three billion people who cannot afford healthy food, and almost one billion live in food insecurity. The worst part is that this number continues to rise. Until we rethink our food chain, this won’t change because conservative agriculture isn’t designed to feed a growing population.”In the first instance, the insects will be used for animal feed and pet food, with future plans to include turning the insects into flour that can be used for human food in five years or so. The plan is for the first farm in Vietnam to produce 17.5+ thousand tons of insect products per year, including insect fat, protein flour and fertilizers, and process 40+ thousand tons of organic leftovers for BSF feed, gathered and processed for free by a partnership with local authorities.The $3 million angel round will be used to establish operations, further develop technological solutions and construct the first industrial-sized farm in Vietnam in 2023, producing affordable proteins, oils and fertilizers from insects.“With personal money invested and this seed round, we’ve been able to build an infrastructure that unlocks our scale. Our production technology was developed by our specialists and world-class engineering teams, we secured resources in Vietnam for construction and operations, we signed over $10 million in pre-contracts to verify demand and validate our product development strategy, and we built an A-class team and advisory board to support the company,” says Olkhovskiy. “FlyFeed’s goal is to feed 250 million people annually, providing nutritious and wholesome food to those who don’t have access to it or can’t afford it. This means 250 million more people can live healthier and happier lives and focus on what matters to them. And all of these while helping nature instead of harming it and providing other companies producing food with sustainable nutrients and fertilizers.”",0.0,0.0
573,https://techcrunch.com/2020/01/13/atrium-layoffs/,"Atrium lays off lawyers, explains pivot to legal tech","Seventy-five-million-dollar-funded legal services startup Atrium doesn’t want to be the next company to implode as the tech industry tightens its belt and businesses chase margins instead of growth via unsustainable economics. That’s why Atrium is laying off most of its in-house lawyers.Now, Atrium will focus on its software for startups navigating fundraising, hiring and collaborating with lawyers. Atrium plans to ramp up its startup advising services. And it’s also doubling down on its year-old network of professional service providers that help clients navigate day-to-day legal work. Atrium’s laid-off attorneys will be offered spots as preferred providers in that network if they start their own firm or join another.“It’s a natural evolution for us to create a sustainable model,” Atrium co-founder and CEO Justin Kan tells TechCrunch. “We’ve made the tough decision to restructure the company to accommodate growth into new business services through our existing professional services network,” Kan wrote on Atrium’s blog. He wouldn’t give exact figures, but confirmed that more than 10 but less than 50 staffers are impacted by the change, with Atrium having a headcount of 150 as of June.The change could make Atrium more efficient by keeping fewer expensive lawyers on staff. However, it could weaken its $500 per month Atrium membership that included some services from its in-house lawyers that might be more complicated for clients to get through its professional network. Atrium will also now have to prove the its client-lawyer collaboration software can survive in the market with firms paying for it rather than it being bundled with its in-house lawyers’ services.“We’re making these changes to move Atrium to a sustainable model that provides high-quality services to our clients. We’re doing it proactively because we see the writing on the wall that it’s important to have a sustainable business,” Kan says. “That’s what we’re doing now. We don’t anticipate any disruption of services to clients. We’re still here.”Founded in 2017, Atrium promised to merge software with human lawyers to provide quicker and cheaper legal services. Its technology can help automatically generate fundraising contracts, hiring offers and cap tables for startups while using machine learning to recommend procedures and clauses based on anonymized data from its clients. It also serves like a Dropbox for legal, organizing all of a startup’s documents to ensure everything’s properly signed and teams are working off the latest versions without digging through email.The $500 per month Atrium membership offered this technology plus limited access to an in-house startup lawyer for consultation, plus access to guide books and events. Clients could pay extra if they needed special help such as with finalizing an acquisition deal, or access to its Fundraising Concierge service for aid with developing a pitch and lining up investor meetings.Kan tells me Atrium still has some in-house lawyers on staff, which will help it honor all its existing membership contracts and power its new emphasis on advising services. He wouldn’t say if Atrium is paid any equity for advising, or just cash. The membership plan may change for future clients, so lawyer services are provided through its professional network instead.“What we noticed was that Atrium has done a really good job of building a brand with startups. Often what they wanted from attorneys was…advice on ‘how to set my company up,’ ‘how to set my sales and marketing team up,’ ‘how to get great terms in my fundraising process,’ ” so Atrium is pursuing advising, Kan tells me. “As we sat down to look at what’s working and what’s not working, our focus has been to help founders with their super-hero story, connect them with the right providers and advisors, and then helping quarterback everything you need with our in-house specialists.”LawSites first reported Saturday that Atrium was laying off in-house lawyers. A source tells TechCrunch that Atrium’s lawyers only found out a week ago about the changes, and they’ve been trying to pitch Atrium clients on working with them when they leave. One Atrium client said they weren’t surprised by the changes because they got so much legal advice for just $500 per month, which they suspected meant Atrium was losing money on the lawyers’ time as it was so much less expensive than competitors. They also said these cheap legal services rather than the software platform were the main draw of Atrium, and they’re unsure if the tech on its own is valuable enough.One concern is Atrium might not learn as quickly about which services to translate into software if it doesn’t have as many lawyers in-house. But Kan believes third-party lawyers might be more clear and direct about what they need from legal technology. “I feel like having a true market for the software you’re building is better than having an internal market,” he says. “We get feedback from the outside firms we work with. I think in some ways that’s the most valuable feedback. I think there’s a lot of false signals that can happen when you’re the both the employer and the supplier.”It was critical for Atrium to correct course before getting any bigger, given the fundraising problems hitting late-stage startups with poor economics in the wake of the WeWork debacle and SoftBank’s troubles. Atrium had raised a $10.5 million Series A in 2017 led by General Catalyst alongside Kleiner, Founders Fund, Initialized and Kindred Ventures. Then in September 2018, it scored a huge $65 million Series B led by Andreessen Horowitz.Raising even bigger rounds might have been impossible if Atrium was offering consultations with lawyers at far below market rate. Now it might be in a better position to attract funding. But the question is whether clients will stick with Atrium if they get less access to a lawyer for the same price, and whether the collaboration platform is useful enough for outside law firms to pay for.Kan had gone through tough pivots in the past. He had strapped a camera to his head to create content for his live-streaming startup Justin.tv, but wisely recentered on the 3% of users letting people watch them play video games. Justin.tv became Twitch and eventually sold to Amazon for $970 million. His on-demand personal assistant startup Exec had to switch to just cleaning in 2013 before shutting down due to rotten economics.Rather than deny the inevitable and wait until the last minute, with Atrium Kan tried to make the hard decision early.",0.0,0.0
83,https://www.theregister.com/2022/10/28/microsoft_nadella_2022_pay_karma/,Microsoft boss Nadella's compensation pack swells 10% to $55m,"Relying on the karmic forces of the universe is clearly working out for Microsoft chairman and CEO Satya Nadella, judging by his expanding compensation package.The exec, who landed the role in 2014 and has presided over some monumental growth figures, particularly during the pandemic, scooped up a total of $54.946 million, up 10 percent on a year earlier, according to Microsoft's Proxy Statement 2022.Nadella's base salary was unchanged at $2.5 million, and stock awards sat at $42.269 million, up from $33 million the year before. Non-equity incentive plan compensation fell to $10.06 million from $14.2 million. The final element, classified as ""all other compensation"", was $110,250, of which $100,000 was charitable gifts.Some 96 percent of this near $55 million package was performance-based, versus 71 percent in 2021.Microsoft grew revenue 18 percent to $198.3 billion in the year ended June 30, 2022, including a 32 percent jump in its cloud division to $91.2 billion. Operating profit was up 19 percent to $83.4 billion and net income grew by the same percentage to $72.7 billion.When Nadella took over the organization, Microsoft turned over $86.8 billion in sales, net income was $22.1 billion, and earnings per share were $2.63. At the time the report was written, EPS was $9.65.""Shareholders expressed a desire to ensure the ongoing retention and motivation of Mr Nadella and the independent members of the Board continue to have high confidence in Mr Nadella's exceptional leadership of Microsoft,"" it said.Microsoft's growth has slowed in the past year as it has for many peers following a stall in economies around the world. Microsoft's share price has fallen 32 percent in the last 12 months.The median pay for Microsoft staffers was $190,302 in fiscal 2022. ""Based on this information, for fiscal year 2022 the ratio of the annual total compensation of our CEO to the annual total compensation of the median employee was 289 to 1.""Anyone among that workforce wanting a pay rise would do well to remember what Nadella said during his first months as CEO, when he spoke to an audience at the Grace Hopper Celebration of Women in Computing event.He said women should try to avoid asking for a raise and simply rely on ""karma."" Nadella added: ""It's not really about asking for a raise, but knowing and having faith that the system will give you the right raise.""Days later he admitted he was ""inarticulate"" about women asking for a raise and said closing the gender pay gap was important.According to the Microsoft 2022 Diversity and Inclusion report, out yesterday, women working for the company earned 90 cents for each dollar that men made, according to median unadjusted pay stats. ®",0.0,0.0
15,https://www.cbsnews.com/miami/news/scientists-warn-south-florida-coastal-cities-will-be-affected-by-sea-level-rise/,Scientists warn South Florida coastal cities will be affected by sea level rise,"MIAMI - Sea level rise is increasing at a dramatic rate. Scientists at the University of Miami warn that if we don't act soon, coastal cities and towns will slowly diminish.Scientists say a few decades from now, downtown Miami will be underwater.The tide is coming in and eventually it's not going to go back out,"" says Dr. Harold Wanless, a Geologist and Professor of Geography and Sustainable Development at University of Miami""Climate change is real. This isn't something that might happen,"" he says. ""The problem is, sea level is rising at an accelerating rate now because of ice melting in Greenland and Antarctica. So for now what is just a high tide - a rare high tide.. is going to become a frequent high tide,"" he says.So what does that mean for us? According to Dr. Wanelss's research, by the year 2060, nearly 60% of Miami-Dade county will be underwater.""Now since the ice melt started we're up to a rate of almost two feet per century,"" he says.Scientists say greenhouse gases like methane, nitrous oxide and carbon dioxide are the root of the problem.""Carbon dioxide, that's the main one. It's the one that every time you burn oil, gas, coal, wood.. you're taking carbon that was stored in the earth and you're converting it to CO2. Over 90% of the extra heat we've created is transferred to the ocean. So global warming is really about warming the ocean,"" he explains.Wanless say not only do we have to stop putting greenhouse gases into the atmosphere, we have to remove the gases already out there. Otherwise, he says, our coastal paradise won't last forever.""It's a beautiful place to live right now but it is so vulnerable,"" he adds.Get Outlook for iOS",0.0,0.0
591,https://techcrunch.com/2020/08/28/femtech-poised-for-growth-beyond-fertility/,Femtech poised for growth beyond fertility,"The market for female-focused health products (aka “femtech”) is set for growth via segmentation, per an analyst note from PitchBook which identifies opportunities for entrepreneurs to target a growing number of health issues that specifically affect women or affect women in a specific way — broadening out from a traditional focus on reproductive health.Femtech remains a “significantly underdeveloped” slice of healthtech, according to the analysis, which highlights the disparity between how much women spend annually on medical expenses — estimated at ~$500 billion — versus how little healthcare R&D is targeted specifically at women’s health issues (a mere 4%).Last year the global market for female-focused health products generated $820.6 million, per the note, and is estimated to reach at least $3 billion by the end of 2030. It says femtech posted $592.1 million in VC investment in 2019, slightly down on 2018’s $620.3 million. But so far this year it’s racked up $376.2 million in VC across 57 deals — putting it on pace to match 2019’s funding levels.Areas of growth opportunity PitchBook sees for femtech outside its traditional focus on reproductive health are: Endometriosis, a painful disorder of the womb lining affecting one in 10 women; what it calls “personalized and female-oriented approaches to general health & disease management,” with a specific focus on heart health, pain management, and diabetes and weight management within that; and the life-stage transition of menopause.“While we still view femtech as a niche industry, we believe secular drivers could help propel new growth opportunities in the space,” write analysts Kaia Colban and Andrew Akers. “These include the increasing representation of women in the venture-backed technology community, rising awareness and acceptance of women’s health issues, and the growing prevalence of infectious diseases among women in some countries in Africa and Asia.“Furthermore, while the majority of femtech products have traditionally focused on reproductive health, we believe new approaches to women’s health research will help open the door to new products and services.”Expansion of the vertical is being driven by universal growth of the personalized medicine industry — which PitchBook notes is expected to reach $3.2 trillion by 2025, registering a CAGR of 10.6% over the forecast period.While the massive underrepresentation of women in the venture community goes a long way to explaining the relative lack of attention investors have paid to products addressing women’s health — with the note acknowledging pitching to male investors remains a challenge for femtech startups — it suggests investors have also been cool on the subcategory because of a relatively poor track record of “sizable” exits.“Only six femtech exits were completed in 2019; however, this still represents a 64% increase in exit value compared to 2018,” it writes. “The largest exits in recent years include Progyny’s $130M IPO and Procter & Gamble’s acquisition of This is L. for $100M. Progyny’s stock has roughly doubled in the eight months since it went public.”PitchBook says it expects just 14% of VC to go toward female-founded startups this year — further noting that only 17% of startups have at least one female founder. (For femtech startups the figure is considerably higher — yet still only 69% of those PitchBook tracks; NB, this does not include startups building products targeted at women where there isn’t a medical need, such as skincare & beauty etc.)“However, we believe these barriers may be subsiding as male investors begin to recognize the femtech market opportunity and as the VC world becomes more gender-diverse,” it adds, noting that female-founded companies deliver over twice as much per dollar invested than their male-owned counterparts, which it reckons could help to turn more investors’ heads.Other key industry growth drivers the note points to are a conducive regulatory environment; a rise in preventative medicine & holistic health; and advancements in health technology that have made personalized products more accessible and affordable, such as AI and “cloud-based infomatics.”On the M&A front, PitchBook notes this is most common for femtech startups in the general health & wellness category. And while most remain single-product companies, it says it expects a maturing femtech industry to lead to product diversification — “potentially driven by M&A” — noting recent examples of pregnancy-focused apps tapping into the menopause market, which it says suggests an expanding opportunity for fertility startups.",0.0,0.0
389,https://elifesciences.org/articles/80315,Transient cell-in-cell formation underlies tumor relapse and resistance to immunotherapy,"We then set out to understand what signaling cascade governs cell-in-cell structures. Initially, we sought to test if the observed results were cell fusion. Thus, we incubated tumor cells whose cytosols were labeled with either Wasabi or tdTomato with tumor-reactive T cells. Confocal analysis indicated that each cell type in the cell-in-cell formation maintained its cytoplasm, and no mix between colors was detected (Figure 6—figure supplement 1). Furthermore, long-term follow-up of cell dissemination from this structure indicated that each cell maintains its initial single labelling color (Figure 6—video 1 and Figure 6—figure supplement 1). To corroborate this, we also incubated tumor cells whose membrane, nucleus, and F-actin were labeled with different fluorophores. Similarly, each cell in this formation was separated and maintained the integrity of its original cell components (Figure 6A). Given the similarity of this formation to entosis, we used ROCK inhibitor, which is the key regulator of this process. Indeed, blocking ROCK almost completely prevented T cell-mediated cell-in-cell formation (Figure 6B, C). We then tested whether the molecular machinery reported to mediate tumor spontaneous entosis applies to govern the current cell-in-cell structure. However, we observed no increase or changes in the cellular localization of phosphorylated β catenin, E-cadherin, and phosphorylated integrin β1 (26) (Figure 6—figure supplement 1) suggesting other mediators promote this entosis. Furthermore, there was no reduction in cell-in-cell formation upon blocking of E- and N- cadherins, or inhibition of Wnt signaling (Figure 6D–E). In sharp contrast, disruption of actin filaments, blocking of mRNA synthesis or protein production completely abrogated tumor cells’ capacity to form a cell-in-cell formation, suggesting that the structure requires de novo synthesis of genes (Figure 6D–E).Figure 6 with 2 supplements with 2 supplements see all Download asset Open asset STAT3 and EGR1 signaling govern T cell-mediated cell-in-cell tumor formation. (A) Representative images of B16F10, co-expressing Lifeact-GFP and H2b-tdTomato or MyrPalm-tdTomato and H2b-GFP, following incubation with gp100-reactive T cells. (B) Mean percentage of cell-in-cell tumor formations in B16F10 following overnight incubation with gp100-reactive CD8+ T cells with or without ROCK inhibitor (n=3). (C) Representative images of cell-in-cell tumor formations in B16F10 following overnight incubation with gp100-reactive CD8+ T cells with or without ROCK inhibitor. (D) Mean percentage of cell-in-cell tumor formations in B16F10 cells following overnight incubation with specific inhibitors and reactive CD8+ T cells (n=4). (E) Representative images of B16F10 cells treated with inhibitors and incubated overnight with gp100-reactive CD8+ T cells. (F) Significantly increased genes in B16F10 cells incubated with T cell-derived granules (Lyso) or isolated directly from relapsed tumors (Tumor), compared to B16F10 control cells (WT) (Bottom) and relative expression of the top 25 genes (Top) (n=3). (G) STAT3 and EGR1 expression levels in B16F10 cells isolated directly from relapsed tumors (Tumor) and after incubation with T-cell-derived granules (Lyso) compared to B16F10 control cells (WT) (n=3) (H) Mean percentage and representative images of cell-in-cell tumor formations in B16F10 48 hours after transfection with STAT3-T2A-iRFP670, EGR1-T2A-GFP or both (n=3). (I) Mean percentage of apoptotic B16F10, transfected with STAT3-T2A-iRFP670, EGR1-T2A-GFP or both, following incubation with tumor reactive T cells (n=3). (J) Mean percentage of cell-in-cell tumor formations in B16F10, transfected with siRNA, following incubation with tumor reactive T cells or T cells secreted granules. (K–L) B16F10 tumor size in mice treated with gp100-reactive T cells (ACT) (K) or Dc adjuvant and anti-TRP1 antibodies (L) with or without Stattic (n=4). Orange arrowheads indicate Stattic treatments and black arrowheads indicate injection of immunotherapies. All experiments were repeated independently at least three times. Statistical significance was calculated using ANOVA with Tukey’s correction for multiple comparisons (**denotes p<0.01, *** denotes p<0.001, **** denotes p<0.0001). Error bars represent standard error. Scale bars = 20 μm. Figure 6—source data 1 Significantly elevated genes in both B16F10 cells incubated with T cell secreted granules and tumor cells sorted from treated animals, related to Figure 6. https://cdn.elifesciences.org/articles/80315/elife-80315-fig6-data1-v1.xlsx Download elife-80315-fig6-data1-v1.xlsx Figure 6—source data 2 STAT3 and EGR1 pathways regulate cell-in-cell tumor formation, related to Figure 6. https://cdn.elifesciences.org/articles/80315/elife-80315-fig6-data2-v1.xlsx Download elife-80315-fig6-data2-v1.xlsx Figure 6—source data 3 Log2 expression of genes related to cancer pathways in tumor cells sorted from treated animals compared to B16F10 WT, reated to Figure 6. https://cdn.elifesciences.org/articles/80315/elife-80315-fig6-data3-v1.xlsx Download elife-80315-fig6-data3-v1.xlsxTo assess what genes govern this formation, we compared the gene signature of untreated B16F10 cells, to cell-in cell formation induced following incubation with T-cell-derived secreted granules and to that of tumor cells sorted from in vivo five days after immunotherapy. Over 400 genes were increased in cell-in-cell formation induced by T cell secreted granules compared to untreated B16F10 cells, 215 of which were also upregulated by the tumor cells sorted from treated animals (Figure 6F, ). KEGG analysis further indicated that multiple signaling cascades, including the JAK/STAT3 axis and FGF-receptors downstream pathways, are enriched in cell-in-cell formation generated in vivo, with approximately 80 significantly elevated genes relating to these pathways (Figure 6—figure supplement 1, ). Indeed, EGR1 and STAT3 expression was significantly elevated in cell-in-cell tumors (Figure 6G). Both mice and human tumors incubated with reactive T cells had elevated their p-STAT3 levels, in comparison to untreated tumor cells (Figure 6—figure supplement 1), suggesting this mechanism is conserved across species. Since these results may also reflect adaptation to the tumor microenvironments, we next corroborate the necessity of these factors to cell-in-cell formation ex vivo. Overexpression of either STAT3 or EGR1 was sufficient to induce cell-in-cell formation without additional stimulation (Figure 6H). Furthermore, these cells were significantly more resistant to killing by CD8+ T cell, compared to sham transfected cells (Figure 6I). We also tested if inhibiting these genes would reduce cell-in-cell tumor formation. Inhibition of STAT3 and EGR1, but not MAPK3 and EGR2, significantly abrogated the capacity of tumor cells to form cell-in-cell structures upon incubation with IFNγ-stimulated T cells and with T cell secreted granules (Figure 6J and Figure 6—figure supplement 1). In order to integrate cell-in-cell inhibition to an in vivo therapy, we first tested the effect of small molecule inhibitors on tumor cell formation. We found that inhibition of STAT3, or EGR pathway, completely prevented cell-in-cell formation upon incubation with reactive T cells or T cell-secreted granules (Figure 6—figure supplement 1). Since blocking EGR1 also reduced T cell viability, we then set out to establish a treatment protocol that combines STAT3 inhibition (which also inhibits T cell activity) and immunotherapy. To this end, mice bearing palpable tumors were injected with Stattic or with PBS for two consecutive days. On the second day, we sub-lethally irradiated the mice and injected them with 5 × 106 gp100-reactive T cells and IL-2. In another model, we treated mice for two days with Stattic, followed by treatments with anti-CD40, TNFα, and anti-TRP1. Recurrent tumors were treated with the same regimen. In both models, injection of Stattic alone had no effect on tumor growth. We found, however, that injection of Stattic prior to administration of immunotherapy partially restored the responsiveness of tumors that re-occur following immunotherapies (Figure 6K–L). While tumor cell sensitization may be a result from multiple mechanisms, these results stress the benefit of combining immunotherapy with STAT3 inhibition.",0.0,0.0
470,https://techcrunch.com/2022/09/01/to-reach-fintechs-next-level-infrastructure-providers-must-address-these-pain-points/,"To reach fintechâs next level, infrastructure providers must address these pain points","We’ve all seen the headlines: Fintech is struggling. Since last year, valuations are down 70%-80%, deal activity is down 67% and layoffs have plagued many former industry favorites.But fintech is resilient. Innovation continues to drive new developments in lending, payments, crypto and, in particular, infrastructure, showing that the industry still has lots of room for growth. And even though investment activity decreased this year, it still remains well above where it was in 2019 and 2020.Infrastructure providers have a unique opportunity to be a bright spot amidst all the doom and gloom. Over the years, infrastructure has enabled fintech companies and non-financial services companies alike to seamlessly integrate financial products into their platforms.However, as the market grew crowded, infrastructure providers have started competing over who can develop the least expensive product and sign the most fintech companies. The infrastructure market is overlooking a pivotal opportunity to build additional product capabilities that address pain points arising from the struggles of fintech.Infrastructure providers can help connect fintech companies with incumbent banks so that they can both reap the benefits of the interest rate environment.Infrastructure providers must reprioritize and find a way to grow their capabilities for their current customers instead of just signing new ones. To do this, they’ll have to take a closer look at the problems those customers deal with on a daily basis. What does a fintech company do when it’s under a fraud attack? What does a new compliance order in the U.K. mean for their business? How do they retain customers who are terrified by news of skyrocketing interest rates and inflation?These are the questions the leaders of the fintech industry face daily, and infrastructure providers need to understand how they can help answer them.Identifying and addressing pain pointsThe influx of prodigious amounts of cash in the financial infrastructure sector has crowded the space with newcomers. Addressing specific fintech pain points is not only a way to help the fintech industry out; it’s also a way for infrastructure providers to differentiate themselves and show that they provide real value.International coverageThe draw of additional customers and revenue streams has caused fintech companies to explore international waters. In an increasingly globalized world, international coverage is no longer optional.Infrastructure providers must meet their customers’ appetite for global growth by ensuring that their platform is available in countries outside the U.S. They also need to ensure their platform helps fintech companies stay compliant with rapidly changing global regulations — more on that below.Regulatory scrutiny",0.0,0.0
229,https://techxplore.com/news/2022-09-communication-less-scheme-microgrid-setup-recovery.html?utm_source=nwletter&utm_medium=email&utm_campaign=daily-nwletter,"Communication-less scheme streamlines microgrid setup, simplifies recovery","NREL's communication-less microgrid method allows grid frequency to vary across a wider range than normal. Devices watch the frequency and adjust their power output according to the frequency's changes. Credit: NRELDuring a power outage or after a disaster, it is hard to beat the simplicity of a diesel generator. Just supply fuel and start it up—so easy, anyone could do it. Renewable microgrids, on the other hand, are not so simple, with their suite of controls, software, and asset coordination. But the beauty of renewables is that fuel is free and already available on-site, even in remote disaster areas.The National Renewable Energy Laboratory (NREL) has now published a description of the improvised controls that saved NREL during its own outage, which could make microgrids easy and low cost where they are needed most.The publication, titled ""Unleashing the Frequency: Multi-Megawatt Demonstration of 100% Renewable Power Systems with Decentralized Communication-less Control Scheme,"" describes a microgrid approach that sidesteps the central controller—an expensive and complicated component—and its reliance on communications, instead using native controls of battery, solar, and wind systems.""NREL's approach makes it possible to assemble devices into a microgrid without arduous configuration, relying on just renewable energy and amateur electrical experience—perfect for recoveries in a pinch,"" said Przemyslaw Koralewicz, NREL engineer and co-developer of the communication-less method.A low-cost recovery resourceWhen NREL experienced a surprise power outage, the laboratory had few options for recovery: No microgrid controller and no preconfigured setup. Just a large battery, solar panels, and wind turbines. Other campuses—or districts, neighborhoods, and homes—could find themselves in similar circumstances, and during an outage is no time to be fumbling with complicated configurations. Like NREL, communities can now implement a resilient microgrid off the cuff, using controls that exist on essentially any energy resource.While microgrids are an apparent answer for recovery and resilience, the costs of a controller present a barrier to communities. In 2019, NREL found that microgrid controllers have a mean cost of $155,000/megawatt, potentially putting resilient microgrids out of reach for vulnerable areas.Besides costs, controllers introduce a tangle of communications and system settings, often opaque, proprietary, and designed to suit particular scenarios. These features can be useful for minimizing energy use and costs, but recoveries often call for a quick-and-ready option. NREL's method prioritizes fail-safe startup, foregoing elaborate programs and communications in favor of exceedingly basic controls, while still allowing more advanced designs to be built on top.Developers of the communication-less microgrid method observe the NREL Flatirons Campus' battery energy storage systems. Credit: Dennis Schroeder, NRELHow does it work?NREL's scheme is decentralized—the devices do not exchange data or issue commands (i.e., they are ""communication-less""). Instead, devices self-regulate using system frequency as the common language. In short, a battery or other power source forms the grid by supplying power at a set frequency. Other generators like solar panels and wind turbines follow the grid by watching frequency and changing their power accordingly.The method is nothing too new—so-called ""droop"" controls are familiar in standard fossil fuel generators—which is part of the appeal. The NREL researchers showed that the method works with 100% renewable energy, can be scaled, and is feasible with most any energy device.What is innovative is that NREL's method frees the grid frequency from a tight 60 hertz (Hz). Unbound by mechanical rotation, the microgrid frequency can take a wider range. In fact, that range is precisely how the devices coordinate without communicating: As frequency rises past 60 Hz, generators reduce power. At even higher frequencies, the generators reduce their power further, rebalancing the frequency around 60 Hz. The system self-stabilizes, never overcharging the batteries or underserving the loads.If this sounds more difficult than a diesel generator, it might be. It still requires some device programming and parameter setting, which are detailed in the report.""NREL's method is the very first step in a design that could become the standard for fail-safe microgrids,"" Koralewicz said. ""Our communication-less method could be natively configured in future devices or possibly certified for easy access by operators. With standardized adoption, microgrids of any type—military bases, hospital backups, even networked districts—could count on an unfailing foundation to their day-to-day operations.""The frontier of renewable energy systemsAt the frontier of power systems, engineers are addressing the technical matters of operating the grid with mostly renewables. Outstanding questions relate to inverters, which are the power electronic devices that interface renewable energy to the grid, and particularly, how inverters can form the grid in ways that fossil-based resources traditionally have. The UNIFI consortium is taking on the inverter challenge with the combined effort of dozens of research institutions, led by NREL.NREL's communication-less method is one example of a grid-forming strategy, the sort that will be needed as systems push toward higher levels of renewables. In proposing the method, NREL is breaking ground into some of the trickier topics that confront UNIFI and power systems everywhere, such as how to handle grid protection and which controls should be essential on grid-forming devices. The authors approach these questions in the report, offering one direction that future energy systems can take on the path to decarbonization.",0.0,0.0
383,https://health.ucdavis.edu/news/headlines/worlds-first-stem-cell-treatment-for-spina-bifida-delivered-during-fetal-surgery--/2022/10,Worldâs first stem cell treatment for spina bifida delivered during fetal surgery,"Download the media kit, which contains still photos, interviews and B-roll video, at https://ucdavis.health/mediakitThree babies have been born after receiving the world’s first spina bifida treatment combining surgery with stem cells. This was made possible by a landmark clinical trial at UC Davis Health. The one-of-a-kind treatment, delivered while a fetus is still developing in the mother’s womb, could improve outcomes for children with this birth defect. Launched in the spring of 2021, the clinical trial is known formally as the “CuRe Trial: Cellular Therapy for In Utero Repair of Myelomeningocele.” Thirty-five patients will be treated in total. The three babies from the trial that have been born so far will be monitored by the research team until 30 months of age to fully assess the procedure’s safety and effectiveness. The first phase of the trial is funded by a $9 million state grant from the state’s stem cell agency, the California Institute for Regenerative Medicine (CIRM). Emily with baby Robbie, 15 days after her birth. “This clinical trial could enhance the quality of life for so many patients to come,” said Emily, the first clinical trial participant who traveled from Austin, Tex. to participate. Her daughter Robbie was born last October. “We didn’t know about spina bifida until the diagnosis. We are so thankful that we got to be a part of this. We are giving our daughter the very best chance at a bright future.” Spina bifida, also known as myelomeningocele, occurs when spinal tissue fails to fuse properly during the early stages of pregnancy. The birth defect can lead to a range of lifelong cognitive, mobility, urinary and bowel disabilities. It affects 1,500 to 2,000 children in the U.S. every year. It is often diagnosed through ultrasound. While surgery performed after birth can help reduce some of the effects, surgery before birth can prevent or lessen the severity of the fetus’s spinal damage, which worsens over the course of pregnancy. “I’ve been working toward this day for almost 25 years now,” said Diana Farmer, the world’s first woman fetal surgeon, professor and chair of surgery at UC Davis Health and principal investigator on the study.I’ve been working toward this day for almost 25 years now.” — Diana FarmerThe path to a future cureAs a leader of the Management of Myelomeningocele Study (MOMS) clinical trial in the early 2000s, Farmer had previously helped to prove that fetal surgery reduced neurological deficits from spina bifida. Many children in that study showed improvement but still required wheelchairs or leg braces.Farmer recruited bioengineer Aijun Wang specifically to help take that work to the next level. Together, they launched the UC Davis Health Surgical Bioengineering Laboratory to find ways to use stem cells and bioengineering to advance surgical effectiveness and improve outcomes. Farmer also launched the UC Davis Fetal Care and Treatment Center with fetal surgeon Shinjiro Hirose and the UC Davis Children’s Surgery Center several years ago.Farmer, Wang and their research team have been working on their novel approach using stem cells in fetal surgery for more than 10 years. Over that time, animal modeling has shown it is capable of preventing the paralysis associated with spina bifida.It’s believed that the stem cells work to repair and restore damaged spinal tissue, beyond what surgery can accomplish alone.Preliminary work by Farmer and Wang proved that prenatal surgery combined with human placenta-derived mesenchymal stromal cells, held in place with a biomaterial scaffold to form a “patch,” helped lambs with spina bifida walk without noticeable disability.“When the baby sheep who received stem cells were born, they were able to stand at birth and they were able to run around almost normally. It was amazing,” Wang said.When the team refined their surgery and stem cells technique for canines, the treatment also improved the mobility of dogs with naturally occurring spina bifida.A pair of English bulldogs named Darla and Spanky were the world’s first dogs to be successfully treated with surgery and stem cells. Spina bifida, a common birth defect in this breed, frequently leaves them with little function in their hindquarters.By their post-surgery re-check at 4 months old, Darla and Spanky were able to walk, run and play.The world’s first human trialWhen Emily and her husband Harry learned that they would be first-time parents, they never expected any pregnancy complications. But the day that Emily learned that her developing child had spina bifida was also the day she first heard about the CuRe trial.For Emily, it was a lifeline that they couldn’t refuse.Emily with Diana Farmer and baby Robbie.Participating in the trial would mean that she would need to temporarily move to Sacramento for the fetal surgery and then for weekly follow-up visits during her pregnancy.After screenings, MRI scans and interviews, Emily received the life-changing news that she was accepted into the trial. Her fetal surgery was scheduled for July 12, 2021, at 25 weeks and five days gestation.Farmer and Wang’s team manufactures clinical grade stem cells – mesenchymal stem cells – from placental tissue in the UC Davis Health’s CIRM-funded Institute for Regenerative Cures. The cells are known to be among the most promising type of cells in regenerative medicine.The lab is a Good Manufacturing Practice (GMP) Laboratory for safe use in humans. It is here that they made the stem cell patch for Emily’s fetal surgery.“It’s a four-day process to make the stem cell patch,” said Priya Kumar, the scientist at the Center for Surgical Bioengineering in the Department of Surgery, who leads the team that creates the stem cell patches and delivers them to the operating room. “The time we pull out the cells, the time we seed on the scaffold, and the time we deliver, is all critical.”A first in medical historyDuring Emily’s historic procedure, a 40-person operating and cell preparation team did the careful dance that they had been long preparing for.After Emily was placed under general anesthetic, a small opening was made in her uterus and they floated the fetus up to that incision point so they could expose its spine and the spina bifida defect. The surgeons used a microscope to carefully begin the repair.Then the moment of truth: The stem cell patch was placed directly over the exposed spinal cord of the fetus. The fetal surgeons then closed the incision to allow the tissue to regenerate.“The placement of the stem cell patch went off without a hitch. Mother and fetus did great!” Farmer said.The team declared the first-of-its-kind surgery a success.Delivery dayOn Sept. 20, 2021, at 35 weeks and five days gestation, Robbie was born at 5 pounds, 10 ounces, 19 inches long via C-section.“One of my first fears was that I wouldn’t be able to see her, but they brought her over to me. I got to see her toes wiggle for the first time. It was so reassuring and a little bit out of this world,” Emily said.This experience has been larger than life and has exceeded every expectation. I hope this trial will enhance the quality of life for so many patients to come.” — EmilyFor Farmer, this day is what she had long hoped for, and it came with surprises. If Robbie had remained untreated, she was expected to be born with leg paralysis.“It was very clear the minute she was born that she was kicking her legs and I remember very clearly saying, ‘Oh my God, I think she’s wiggling her toes!’” said Farmer, who noted that the observation was not an official confirmation, but it was promising. “It was amazing. We kept saying, ‘Am I seeing that? Is that real?’”Both mom and baby are at home and in good health. Robbie just celebrated her first birthday.The CuRe team is cautious about drawing conclusions and says a lot is still to be learned during this safety phase of the trial. The team will continue to monitor Robbie and the other babies in the trial until they are 6 years old, with a key checkup happening at 30 months to see if they are walking and potty training.“This experience has been larger than life and has exceeded every expectation. I hope this trial will enhance the quality of life for so many patients to come,” Emily said. “We are honored to be part of history in the making.”Related links",0.0,0.0
167,https://techcrunch.com/2016/08/30/vr-on-the-battlefield-to-the-couch-and-back-again-sort-of/,"VR on the battlefield, to the couch and back again â sort of","Fifteen years ago, a team of scientists working at Johns Hopkins University was asked to do what seemed like the impossible: Design a headset that would create an image so immersive and realistic that it would allow anyone to experience what it feels like to be in a car — before that car actually exists. One of the most popular sedans in the U.S. was born this way.It wasn’t until a couple of years ago that the popularity of virtual reality technology really took off. With video games, VR found a home in the world’s living room. Gamers were able to experience imaginary worlds, all from the comfort of their couches. There’s no sign of this slowing down: Business Insider estimates that shipments of VR headsets will grow at 99 percent annually between 2015 and 2020.Indeed, VR is finding widespread adoption in design, education and new forms of entertainment almost every day. You’ve probably been hearing about it online, in the news and on social media. But before VR hit the mainstream, it was first and foremost an incredibly important resource for our armed forces — and still is today.After decades of perfecting VR in military applications, we are finally making this concept of “inhabiting” a computer-generated environment work for home users. And, ironically, VR is going back out to the battlefield — but instead of training fighters, it’s being used to save the world from zombies.VR’s start on the real-world battlefieldFor years, high-end VR technology has helped soldiers. If it was too dangerous or too expensive, you trained in VR. You could learn the layout of buildings before setting foot into a dangerous situation. You could train to operate machinery and weapons, acclimate to new social situations and treat PTSD. Your team could train in battlefield simulations to help reduce casualties. Many of the immersive features that make VR so compelling today were honed in these early days in military applications.Georgia-based Motion Reality has been training first responders, law enforcement and military personnel for many years. A wide-area, high-end tracking system determines the position of multiple trainees and their weapons in a large space. Motion Reality then uses this information to provide a training experience in hostile situations.The key ingredients that make VR so compelling are the same regardless if you are saving the world in an arcade or preparing for a real-life battlefield.The technology used by Motion Reality and others for military training has been critical to bringing VR to public spaces. While the popularity of VR has skyrocketed over the past year, it’s still inaccessible to many. Some don’t want to spend the money to buy high-end gaming PCs. Others don’t have the space in their homes to experience VR beyond a seated encounter. By bringing VR out of the home, the industry has infinite possibilities and new momentum.VR is coming to a public space near youFor the first time, VR is hitting our public theme parks, arcades and movie theaters. An estimated two-dozen VR rollercoasters have debuted this summer in theme parks across North America, Europe and Asia. And companies like Zero Latency and The Void are debuting arcade-like experiences that mix real life and VR.For decades, the industry has been building up the necessary knowledge and tools to take VR to the mainstream. The key ingredients that make VR so compelling are the same regardless if you are saving the world in an arcade or preparing for a real-life battlefield. Even more importantly, the technological requirements of public venues are almost identical to those used in military training. They require sophisticated multi-player tracking, easy cleaning between users, untethered experience functions and more.Zero Latency, an emerging VR company out of Australia, uses wireless weapons and VR headsets powered by powerful backpack computers to allow for untethered walking in a simulated VR theme park. This has been deployed in the SEGA Joypolis park in Tokyo. These systems track the movements of visitors in the game space and allow them to interact with their environment. With the addition of powerful fans and directional audio, users receive a full sensory experience while completing missions. Sound similar?VR will continue to advance in all application areas: gaming, enterprise, military and public entertainment — but the full, simulated sensory experience that was born out of military VR is what is truly going to take VR out of the living room and into our lives.From sci-fi concept to a true part of our reality, the VR market has undergone an incredible transformation. It might be hard to imagine being able to step into a completely virtual, foreign world during your next visit to Disney World or at your daughter’s next birthday party — but it’s coming sooner than you think. Some, including myself, would argue that it is already here.",0.0,0.0
125,https://www.nbcnewyork.com/news/national-international/the-world-is-running-out-of-helium-worrying-doctors/3918574/,"The World is Running Out of Helium, Worrying Doctors","A global helium shortage has doctors worried about one of the natural gas’s most essential, and perhaps unexpected, uses: MRIs.Strange as it sounds, the lighter-than-air element that gives balloons their buoyancy also powers the vital medical diagnostic machines. An MRI can’t function without some 2,000 liters of ultra-cold liquid helium keeping its magnets cool enough to work. But helium — a nonrenewable element found deep within the Earth’s crust — is running low, leaving hospitals wondering how to plan for a future with a much scarcer supply.Get Tri-state area news and weather forecasts to your inbox. Sign up for NBC New York newsletters.“Helium has become a big concern,” said Mahadevappa Mahesh, professor of radiology at the Johns Hopkins School of Medicine Baltimore. “Especially now with the geopolitical situation.”Helium has been a volatile commodity for years. This is especially true in the U.S., where a Texas-based federal helium reserve is dwindling as the government tries transferring ownership to private markets.Until this year, the U.S. was counting on Russia to ease the tight supply. An enormous new facility in eastern Russia was supposed to supply nearly one-third of the world’s helium, but a fire last January derailed the timeline. Although the facility could resume operations any day, the war in Ukraine has, for the most part, stopped trade between the two countries.Read the full story here at NBCNews.com.",0.0,0.0
285,https://techcrunch.com/2009/01/26/avenger-laser-weapon-knocks-uav-out-of-the-air/,Avenger Laser weapon knocks UAV out of the air,"Gosh, these lasers grow up so darn quick! It seems just yesterday that the Avenger’s predecessor, the Advanced Tactical Laser, was being tested on those cute little Hercules transports. And then all that fussing about the Free Electron Laser!Pretty soon they’re going to be taking it for its first ride on a 747 — you’re going to want to have the camera ready! And then take out the SD card once you’re done and swallow it because they’re going to need to confiscate your camera, sir. Orders.Can you say “plausible deniability?” I knew you could!",0.0,0.0
549,https://edition.cnn.com/2022/09/19/world/nasa-artemis-1-cryo-test-preview-scn/index.html,NASAâs Artemis I mega moon rocket prepares for prelaunch test,"Sign up for CNN’s Wonder Theory science newsletter. Explore the universe with news on fascinating discoveries, scientific advancements and more.CNN —The Artemis I mega moon rocket is gearing up for another test Wednesday before its next launch attempt to journey around the moon and back.The Artemis I cryogenic demonstration test began with fueling at 7:30 a.m. ET Wednesday.Since the second scrubbed launch attempt of the uncrewed Artemis I mission on September 3, engineers have replaced two seals on an interface for the liquid hydrogen fuel line between the rocket and mobile launcher, according to NASA officials. These seals were associated with a large hydrogen leak that led to the scrub of the launch attempt.Engineers found an indentation on the seal on an 8-inch (20-centimeter) quick disconnect line for hydrogen, said Mike Sarafin, Artemis mission manager, at a Monday NASA press conference.The team did not recover any piece of debris, but the dent was clear and pointed to a problem that contributed to the hydrogen leak, Sarafin said.The indentation on the seal was under 0.01 inch (0.3 millimeter), but it allowed pressurized gas to leak through, something that can be very dangerous given the flammability of hydrogen when it meets air. The team believes the dent was associated with the leak, but the results of the test could confirm it. They have since replaced the seal.On September 3, the large hydrogen leak was between two and three times the accepted limit, Sarafin said.Testing ‘kinder’ proceduresThe purpose of the cryogenic demonstration is to test the seals and use updated, “kinder and gentler” loading procedures of the supercold propellant, which is what the rocket would experience on launch day.Unlike the wet dress rehearsals, the previous tests of Artemis I that simulated every stage leading up to launch, the cryo test focuses on a very specific aspect in the countdown: loading supercold liquid oxygen and liquid hydrogen into the rocket’s core stage and upper stage.The Orion spacecraft and rocket boosters remained unpowered during the test, and the team does not intend to go into terminal count, or the final 10 minutes that occur in the countdown before launch, said Jeremy Parsons, deputy manager for NASA’s Exploration Ground Systems Program at Kennedy Space Center.The kinder and gentler loading procedure is to minimize pressure spikes and thermal spikes witnessed during prior launch attempts.“It’s going to be a very slow, steady ramp,” Parsons said. “So (we’re) really just trying to slowly introduce some of those thermal differences and reduce thermal and pressure shock.”Liquid oxygen is relatively dense, about the density of water, and it is pumped into the rocket. Meanwhile, hydrogen is very light, so it is moved using pressure rather than being pumped, said Tom Whitmeyer, deputy associate administrator for NASA’s common exploration systems development.The new loading operations will use a slower rate of pressure with more gradual temperature changes, Whitmeyer said.The call to stations for the test, when all of the teams associated with the mission arrive at their consoles and report they’re ready, begins today at 3 p.m. ET. The mission team anticipates receiving a “go” to begin loading the rocket with propellant around 7 a.m. ET on Wednesday. If all goes well, the team expects the test to be completed by 3 p.m. ET that day, Parsons said.The test will also include an engine bleed, which chills the engines for launch. The mission team scrubbed the first Artemis I launch attempt on August 29 largely due to an issue with a faulty sensor that occurred during this bleed.So far, the forecast looks promising for the test. The Artemis team is receiving daily briefings about Hurricane Fiona in case it has any impact on whether or not the rocket stack needs to be rolled back into the Vehicle Assembly Building, a process that can take three days.Preparing for launchIf the cryo test goes well, the next launch attempt could take place on Tuesday, September 27, with a 70-minute window that opens at 11:37 a.m. ET. The mission managers will meet to discuss the test results on September 25 to assess the potential launch date.If Artemis I launches on September 27, it would go on a 39-day mission and return to Earth on November 5. Another backup launch date is possible on October 2. While these launch dates are recommended by NASA, the team ultimately depends on a decision by the US Space Force, which would need to issue a waiver for the launch.The US Space Force, an arm of the military, still oversees all rocket launches from the United States’ East Coast, including NASA’s Florida launch site, and that area is known as the Eastern Range.The officials at the range are tasked with making sure there’s no risk to people or property with any launch attempt.The Artemis team continues to have “productive and collaborative” discussions with the Eastern Range, NASA officials said, and NASA is sharing additional detailed information requested by the Space Force for review.The team is taking things one step at a time and wants to get through the test before other decisions are made, Whitmeyer said.“We’re going to go when we’re ready,” Sarafin said. “But in terms of the reward of flying this flight, we have said from the outset that this is the first in an increasingly complex series of missions, and it is a purposeful stress test of the rocket.”The inaugural mission of the Artemis program will kick off a phase of NASA space exploration that intends to land diverse astronaut crews at previously unexplored regions of the moon – on the Artemis II and Artemis III missions, slated for 2024 and 2025, respectively – and eventually deliver crewed missions to Mars.",0.0,0.0
326,https://www.alternet.org/2022/10/meta-tiktok-stop-the-steal/,Meta and TikTok busted for 'actively pushing' 'Stop the Steal 2.0' on eve of Brazil's presidential election,"As Brazilians prepare to vote in Sunday's decisive presidential runoff, a report published Saturday revealed that social media giants Meta—Facebook's parent company—and TikTok are driving traffic to content promoting a military coup to overthrow Brazil's democracy.The report—entitled Stop the Steal 2.0: How Meta and TikTok Are Promoting a Coup—was published by the San Francisco-based activist group SumOfUs and asserts that ""on the eve of the second vote in Brazil's most important election in decades, Meta and TikTok continue to put the integrity of the election on the line through their disastrous recommendation systems.""The publication comes ahead of Sunday's second-round contest between far-right incumbent Jair Bolsonaro—who has said he may not accept the outcome of the election if he loses–and former leftist President Luiz Inácio Lula da Silva. Aggregate polling showed the two candidates in a statistical dead heat on Friday.According to the new report:Meta claims that Brazil is a priority region and that the company is committed to enforcing policies and practices that uphold the integrity of the vote. But not only does SumOfUs' previous research show that the platforms are awash with conspiracy theories about the election, claims of electoral fraud, and calls for a military coup, this research report sets out how Facebook's recommender systems are actively pushing users towards this content.Far-right extremists, who are openly agitating for a military coup, are operating freely on Meta's platforms, and Meta is not only allowing them to spread their message and recruit new members, but the platform's algorithms are prioritizing anti-democratic groups, accounts, and posts. The report also looked at the role TikTok is playing in tackling the growing problem of election disinformation on its platform, and found its moderation lacking...The findings confirm civil society organizations' worst fears, that platforms like Facebook and Instagram are enabling bad actors to organize and recruit new members, just as it did in the U.S. 2020 elections, which ended in violent insurrectionists storming the U.S. Capitol on January 6th.""At this point, it is safe to say that Meta has become Bolsonaro's official disinformation machine,"" SumOfUs campaign director Flora Rebello Arduini said in a statement. ""This is not Meta's first time wreaking havoc on democracy and Brazilians deserve better from this multi-billion dollar company.""""As this report shows,"" she added, ""TikTok needs to up its game and not follow Meta's lead in fueling the disinformation crisis in Brazil.""On Saturday evening, SumOfUs activists projected an image of Meta co-founder and CEO Mark Zuckerberg setting the Brazilian flag alight with the message ""Meta is destroying Brazilian democracy"" at Kings Cross tube station in London, just around the corner from Meta's U.K. headquarters.The new report comes amid warnings and acts of right-wing political violence. While no motive has yet been announced, on Friday local São Paulo-area politician Reginaldo Camilo dos Santos, a prominent supporter of da Silva and the left-wing Workers' Party running for Congress, was assassinated in a drive-by shooting near his home in Jandira.Agência Pública, an independent Brazilian investigative journalism outlet, reported earlier this month that from August 16 and the end of the first round on October 2, there were at least 148 cases of electoral violence across the country.A separate report published last week by the anti-corruption and human rights organization Global Witness revealed that YouTube approved 100% of Brazilian election misinformation ads submitted for approval, while Facebook accepted around half of such submissions.",0.0,0.0
386,https://gizmodo.com/herpes-virus-cancer-treatment-rp2-1849574410,A Cancer-Fighting Version of Herpes Shows Promise in Early Human Trial,"Scientists may be able to turn a long-time germ foe into a cancer-fighting ally, new research this week suggests. In preliminary data from a Phase I trial, a genetically modified version of the herpes virus has shown promise in treating difficult-to-eradicate tumors, with one patient having experienced a complete remission for 15 months so far. Much more research will be needed to confirm the treatment’s early success, however.The viral treatment is known as RP2 and is a genetically engineered strain of herpes simplex 1, the virus responsible for most cases of oral herpes in humans, as well as some cases of genital herpes. Developed by the company Replimune, RP2 is designed to work on two fronts. Injected directly into the tumor, the virus is supposed to selectively infect and kill certain cancer cells. But it also blocks the expression of a protein known as CTLA-4 produced by these cells, and it hijacks their machinery to produce another molecule called GM-CSF. The net result of these cellular changes is to weaken the cancer’s ability to hide from and fend off the immune system.In a Phase I trial conducted by scientists at The Institute of Cancer Research and The Royal Marsden NHS Foundation Trust in the UK, RP2 was given as the only treatment to nine patients with advanced cancers that failed to respond to other therapies; it was also given in combination with another immunotherapy drug to 30 patients. Three patients on RP2 alone appeared to respond to the treatment, meaning their cancers shrank or stopped growing, and seven patients on the combination therapy responded as well. One patient in particular, with a form of carcinoma along his salivary gland, has shown no signs of cancer for at least 15 months after treatment with RP2 alone. There were no life-threatening adverse events reported in the trial, with the most common symptoms post-treatment being fever, chills, and other flu-like illness.AdvertisementThe findings, presented this week at the 2022 European Society for Medical Oncology Congress (ESMO), are preliminary, since they’ve yet to be vetted through the formal peer review process. They’re also based on a very small sample size, meaning that any results should be taken with caution. But Phase I trials aren’t intended to show that a treatment is effective, only that it’s safe enough for humans to take. So the fact that some people with seemingly incurable cancers already appear to be responding to RP2, the team argues, is a very good sign that it can live up to its potential.“Our study shows that a genetically engineered, cancer-killing virus can deliver a one-two punch against tumors—directly destroying cancer cells from within while also calling in the immune system against them,” said lead author Kevin Harrington, professor of Biological Cancer Therapies at The Institute of Cancer Research, in a statement from the organization.Scientists have been hopeful about cancer-fighting viruses for a long time. But it’s only recently that this hope has finally been starting to pay off. In 2015, the first viral therapy was approved in the U.S. for certain advanced cases of melanoma. This May, scientists in California launched a Phase I clinical trial of their anticancer virus, called Vaxinia. Other companies are developing their own candidates, either alone or in combination with other treatments. And Replimune is developing two other candidates based on their modified herpes virus.While many experimental therapies ultimately fail to cross the finish line and reach the public, it’s possible at least some of these viruses could one day become a new standard cancer treatment.",0.0,0.0
186,https://religionmediacentre.org.uk/news/the-future-of-religion-in-britain/,The future of religion in Britain: a rise in Islam as Christianity declines. And then thereâs magic â¦,"A leading academic predicts Britain will see the continuing decline of Christianity, the resurgence of fundamentalism, the rise of non-religion, the emergence of British Islam and a flourishing interest in “magic”.Professor Linda Woodhead, speaking at the Religion Media Centre’s annual lecture in London, gave the context to the 2021 census results on religion, which are due to be published next month or in November.She said the census was expected to show a fall in those identifying as Christian in England and Wales — from 72 per cent in 2001, to 59 per cent in 2011, — to perhaps below 50 per cent this time.Second, she said a steady rise in the number identifying as “none”, having no religion, increased from 15 per cent in 2001, to 25 per cent in 2011, with predictions that this could rise to 33 per cent this time.And third, a steady rise in the number of those identifying as Muslim went from 3 per cent in 2001 to 5 per cent in 2011, and would perhaps increase to 8 per cent this time.Woodhead, the F. D. Maurice professor and head of the department of theology and religious studies at King’s College London, has written widely on religion in society.During her lecture at St Bride’s Church, Fleet Street, she offered four predictions for the future of religion in the coming decades, building on work from the 1970s and 1980s that had proved remarkably prescient.Her method for analysing which religious movements and phenomena would survive, was to judge them against five signs of vitality: intellectual understanding of the metaphysical, continuing institutional practices, community and belonging, ethics and values, and spirituality connecting with the sacred.She used this method to understand four trends in the religious life of people in Britain, to suggest which would thrive or die. The trends identified are: fundamentalism, winning the battle, but losing the war; Muslims finding their place, or Islam finding its place; magic and the decline of religion; and the fire sale of the churches and the growth of non-religion.“Fundamentalism has had a fantastic 30 years, maybe 60 years in all the world religions and in virtually all the churches in Britain,” she suggested. Espousing “plain facts” such as the bodily resurrection of Jesus, combined with moral puritanism was inherently exclusive: “We’ve got the truth. You haven’t.”Fundamentalism had captured the churches — and the media. In many media interviews when she started talking about versions of Christianity, the response of the reporter was that this was “too wishy-washy” and was not real religion.Fundamentalism had won the battle but lost the war, she said. Revivals had not stemmed the relentless decline of Christianity, in fact the post-war strict moral stands against divorce, remarriage, women’s equality and LGBTQ+ rights had turned Christianity into a toxic brand and the next generation did not want to be associated with it.There had been a failure of liberal Christianity to provide an intellectual theology, credible answers on matters of belief, so it had lost its cultural capital. She said Christians in this country were just as liberal in their ethics as the general population: Anglicans were indistinguishable from the general population in their ethical views on such issues as euthanasia, divorce, and abortion. But their leaders were reacting against ideas that were absolutely dominant.Another trend, she explained, was the “fire sale” of the “cultural property” of the churches and the growth of non-religion.This meant that different secular organisations had siphoned off work in education and knowledge. Other providers had offered similar services, not connected to a religious name. The churches’ rituals, values, beliefs, practices, community had come apart.Challenged to state the importance of faith action on the front line of welfare support, for example after the Grenfell tower fire, she said this function was a charitable role and not a lot to do with religion.Charities with religious foundations had tried to wipe this from their branding. Association with faith caused charities problems of legitimacy with the statutory authorities, funders and their beneficiaries, whose fear of proselytization or conversion had to be overcome.But it was the very serious failure over values that indicated the decline of Christianity would continue.“For a majority religion to offend deeply against people’s moral sensibility — that’s a very, very serious failure. The churches have failed so dramatically as moral authorities, with the abuse scandals being just the latest nail in that coffin.” – Professor Linda WoodheadProfessor Woodhead observed that the result was a free-for-all in the area of values leadership, with schools, businesses and universities publishing values statements and then trying to embody and enforce them.Queen Elizabeth II was a valued leader of much greater stature than any Christian leader in the country, she said. It was a big question as to how self-sacrifice and love of others would be underpinned after her death.Into this void created by failures over morals and new providers taking away work, non-religion had grown. It was just a label used in surveys and the census, the professor said. Its meaning could be gleaned by looking at the context in which it developed from 1992 to date.Professor Woodhead did, however, identify two areas of strong growth over the next decades. One is British Islam, or British Muslims, finding their place.She said Islam in Britain was not really visible until the 1970s. The first generation from south Asia had to create their infrastructure from scratch — mosques, halal butchers and schools. The second generation set up civil society organisations and charities.Now British Muslims were finding their voice with Muslim MPs and confident young people entering higher education, mixing with the many different ethnic Muslim communities and creating a new cultural kind of British Islam with food, clothing, music, and creative places.“British Muslim cultural output is cool around the world and is getting a global profile,” she said. On her list of how to judge whether a movement had vital signs, she said British Islam ticked all the boxes for community, institutions and spirituality.The key challenge was keeping it intellectually healthy. There were now centres of Islamic studies in many universities, with moves to study metaphysics and theology, and not just Islamic law.Asked about fears that a rise in the British Muslim population would stoke a backlash with alarmist headlines, Professor Woodhead said: “It’s about becoming the most vital part of religion in this country. That’s a very frightening prospect to a lot of people who don’t know about Islam.”And finally her prediction is for the continuing fascination and flourishing of magic — fairy beliefs, ghosts, omens, popular prophecies, village healers, wise women, souls and the afterlife — alongside a decline in religion.She said: “More of my students and Gen Z as a whole are actively interested in astrology and tarot. They access it on apps on their phone. And those who want to go deeper into intellectually read widely, they listen to podcasts, they go to festivals, they might join a pagan group or a Wiccan group.”Such fascination had probably been there in every society in every age. But the difference now was that it had lost its stigma. People spoke to one another about it. “Paganism has grown and diversified and created lots of different sub-cultures, both right wing, and left wing, and it’s vital and many young people are involved,” she said.“Paganism has grown and diversified and created lots of different sub-cultures, both right wing, and left wing, and it’s vital and many young people are involved” – Professor Linda WoodheadProfessor Woodhead has noticed that magic has crept into the wider culture, with words like chi, spirit, energy in common use. The word for death has changed: now it is “passing”, a spiritualist word. Angel statues in graveyards have been joined by butterflies signifying new life, windmills so the spirit can catch the soul, with “dream-catchers” hanging in trees.She predicted that magic would continue to be vital and, on her tick box assessing the strength of religion, it was strong in most areas.Magic was ridiculed for being superficial and shallow but, she said, the reverse was true. It was the subject of deep reflection and was much better dealing with evolution or science and cosmology, using ideas around cycles of birth and death, life and growth. Everything was energy. The planet was Gaia.“My thesis is that about one in five, about 20 per cent of people, in any generation, in any era in any society other than where there is religious repression, are devoutly interested engaged in religion, magic or spirituality. And it doesn’t ever really change. I think they were always in minority. And I think they will always continue to be in minority.”",0.0,0.0
308,https://www.theverge.com/2022/10/28/23427577/apple-union-maryland-letter-benefits-contract,Appleâs first unionized workers say the company is withholding new benefits,"Organizers at Apple’s Towson Town Center store in Maryland claim that the company isn’t telling the whole truth when it comes to withholding benefits from workers at the location. As the company’s first retail location to unionize in the US pushes to negotiate a contract, workers say it’s making it difficult for them to bargain for their benefits.In a letter addressed to Tim Cook, the negotiating committee says they’re disappointed to learn the company won’t be offering workers at the location some new health and education benefits that are rolling out to other retail employees. The union also says that Apple has been spreading “misinformation” by saying workers would have to bargain for those benefits to be included in their contract.“Apple management has not yet provided our union with any details about the new benefits”“There is crucial context missing in this communication around the process of change within a unionized store and the fact that we can, and we will include these (and any new benefits) in our collective bargaining contract proposal,” says the letter, which you can read in full below. However, the union also claims that Apple has made it difficult to bargain for those benefits by not sharing “any details” about them.Apple didn’t respond to The Verge’s multiple requests for comment on the union’s accusations.The union, known as IAM CORE (CORE stands for Coalition of Organized Retail Employees, and the organization is partnered with the International Association of Machinists and Aerospace Workers), won its union election by an almost two to one margin in June. Since then, workers at other locations say the company has continued to oppose unionization efforts, with the Communications Workers of America filing complaints about Apple’s behavior in New York and Oklahoma.Notably, the reports about Apple withholding benefits came out days before the Oklahoma store was scheduled to hold its union election, which IAM CORE’s letter says was a “calculated” move. If it was, it didn’t work: workers at Penn Square store in Oklahoma City voted to unionize in a 56-32 vote.Still, there are still ongoing union drives at Apple stores in New York and Atlanta, where the threat of withheld benefits could sway votes or even stall the process of holding an election entirely. The union involved with the campaign in Atlanta canceled the vote in May, saying Apple had made it impossible to hold a fair election.Earlier this month, Bloomberg broke the news about Apple’s push to withhold benefits at Towson and provided some details about exactly what workers might be missing out on; the list included a free Coursera subscription, prepaid tuition at some colleges (versus the reimbursement model Apple usually uses), and new healthcare plan options. The publication cited Harvard Law School professor Benjamin Sachs, who said that there was nothing stopping the company from offering those benefits to unionized employees.Wilma Liebman, a chairperson for the National Labor Relations Board, told Bloomberg that the company’s move to block benefits could be a violation of labor law, saying it was “hard to see how they could come up with a legitimate reason for the timing other than to influence the outcome of the election.” According to the NLRB’s site, employers also aren’t allowed to “refuse to furnish information the union requests that is relevant to the bargaining process.”",0.0,0.0
280,https://www.reuters.com/lifestyle/science/meet-japans-cyborg-cockroach-coming-disaster-area-near-you-2022-09-21/,"Meet Japan's cyborg cockroach, coming to disaster area near you","SAITAMA, Japan, Sept 22 (Reuters) - If an earthquake strikes in the not too distant future and survivors are trapped under tonnes of rubble, the first responders to locate them could be swarms of cyborg cockroaches.That's a potential application of a recent breakthrough by Japanese researchers who demonstrated the ability to mount ""backpacks"" of solar cells and electronics on the bugs and control their motion by remote control.Kenjiro Fukuda and his team at the Thin-Film Device Laboratory at Japanese research giant Riken developed a flexible solar cell film that's 4 microns thick, about 1/25 the width of a human hair, and can fit on the insect's abdomen.The film allows the roach to move freely while the solar cell generates enough power to process and send directional signals into sensory organs on the bug's hindquarters.The work builds upon previous insect-control experiments at Nanyang Technological University in Singapore and could one day result in cyborg insects that can enter hazardous areas much more efficiently than robots.""The batteries inside small robots run out quickly, so the time for exploration becomes shorter,"" Fukuda said. ""A key benefit (of a cyborg insect) is that when it comes to an insect's movements, the insect is causing itself to move, so the electricity required is nowhere near as much.""[1/5] A Madagascar hissing cockroach, mounted with a ""backpack"" of electronics and a solar cell that enable remote control of its movement, is pictured during a photo opportunity at the Thin-Film Device Laboratory of Japanese research institution Riken in Wako, Saitama Prefecture, Japan September 16, 2022. REUTERS/Kim Kyung-Hoon 1 2 3 4 5Fukuda and his team chose Madagascar hissing cockroaches for the experiments because they are big enough to carry the equipment and have no wings that would get in the way. Even when the backpack and film are glued to their backs, the bugs can traverse small obstacles or right themselves when flipped over.The research still has a long way to go. In a recent demonstration, Riken researcher Yujiro Kakei used a specialized computer and wireless Bluetooth signal to tell the cyborg roach to turn left, causing it to scramble in that general direction. But when given the ""right"" signal, the bug turned in circles.The next challenge is miniaturising the components so that the insects can move more easily and to allow for mounting of sensors and even cameras. Kakei said he constructed the cyborg backpack with 5,000 yen ($35) worth of parts purchased at Tokyo's famed Akihabara electronics district.The backpack and film can be removed, allowing the roaches to go back to life in the lab's terrarium. The insects mature in four months and have been known to live up to five years in captivity.Beyond disaster rescue bugs, Fukuda sees broad applications for the solar cell film, composed of microscopic layers of plastic, silver, and gold. The film could be built into clothing or skin patches for use in monitoring vital signs.On a sunny day, a parasol covered with the material could generate enough electricity to charge a mobile phone, he said.($1 = 143.3100 yen)Writing by Rocky Swift Editing by Mark HeinrichOur Standards: The Thomson Reuters Trust Principles.",0.0,0.0
14,https://www.cnbc.com/2022/09/17/china-testing-floating-car-that-uses-magnets-to-hover-at-143-mph.html,China is testing a magnet-powered floating car that goes up to 143 miles per hourâtake a look,"If you've ever imagined a future filled with flying cars, your dream might be getting slightly closer to reality.Chinese researchers at Southwest Jiaotong University in Chengdu, Sichuan province, performed road tests last week for modified passenger cars that use magnets to float 35 millimeters above a conductor rail, according to Chinese state news agency Xinhua.The researchers outfitted the sedans with powerful magnets on the vehicle floors, allowing them to levitate over a conductor rail nearly five miles in length. Eight cars in total were tested, with one test reaching speeds of roughly 143 miles per hour, according to the report.A video posted to Twitter by a Chinese journalist shows the vehicles floating — albeit bumpily — along the track:Xinhua says the tests were run by government transportation authorities to study safety measures for high-speed driving. But Deng Zigang, one of the university professors who developed the vehicles, told the state news agency that using magnetic levitation for passenger vehicles has the potential to reduce energy usage and increase the vehicles' range.That could be useful for the electric vehicle industry's issues with ""range anxiety,"" or when consumers fear they won't be able to complete a trip in an electric vehicle without running out of power.",0.0,0.0
427,https://www.psypost.org/2022/10/study-finds-twelvefold-higher-mortality-risk-among-psychopathic-female-offenders-64037,Study finds twelvefold higher mortality risk among psychopathic female offenders,"New research highlights the health dangers associated with an antisocial lifestyle. A study of psychopathic female offenders revealed a mortality risk that was 12 times higher compared to the general population. The findings were published in the journal Frontiers in Psychiatry.Antisocial personality disorder (ASPD) is a condition defined by antisocial behavior, aggression and impulsivity, and a lack of concern for others. People with ASPD are often involved in criminal activity and tend to experience difficulty forming long-term relationships. In its extreme form, ASPD is often referred to as psychopathy.A body of past research has revealed high rates of premature death among people with ASPD, presumably due to the dangerous lifestyle associated with the disorder. Research in men has additionally found that the degree of psychopathy matters — as psychopathy increases, life expectancy decreases.Study author Olli Vaurio and colleagues conducted a study to investigate whether mortality risk may differ between men and women with psychopathy. The researchers note that psychopathy manifests differently in men and women, which could lead to gender differences in mortality risk. For example, psychopathic women are less likely to display physical aggression and more likely to show relational or verbal aggression compared to psychopathic men.To study the risk of mortality in psychopathic women, the researchers obtained data from a sample of female criminal offenders and compared this to national mortality rates. The sample included 57 Finnish women who had undergone forensic psychiatric evaluation for having committed severe crimes. For the current analysis, participants were excluded if they met criteria for a major mental illness like schizophrenia or delusional disorder.Based on their scores on the Psychopathy Checklist-Revised (PCL-R), the women were categorized into one of two groups: low psychopathy (41 women) and high psychopathy (16 women). The women were followed for between 17 and 25 years, and during the follow-up period, 6 deaths occurred in the high psychopathy group, and 16 deaths occurred in the low psychopathy group. The average age at the time of death was 52.7 years old.The researchers obtained mortality data collected from Statistics Finland, for the years 1984–2013. They then calculated the ratio of observed to expected number of deaths for both the low and high psychopathy groups. It was found that both groups had higher mortality compared to the general Finnish population.Mortality was especially high in the high psychopathy group, where it was twelve times higher than in the general population. For the low psychopathy group, mortality was more than six times higher than in the general population. In line with previous research conducted among psychopathic men, mortality risk increased with higher PCL-R scores.Death by natural causes was more common than death by unnatural causes. For the high psychopathy group, this included cancer (2 cases), cerebrovascular disease (1 case), and liver disease (1 case).The authors discuss how some of these fatalities may relate to an antisocial lifestyle. For example, psychopathy involves an impulsivity and recklessness which may influence health behaviors. This may lead to higher rates of cigarette smoking and alcohol consumption, which can lead to lung and liver disease. More generally, a volatile lifestyle may lead to fewer healthcare visits.“Although effective treatment options for adult antisocial psychopaths are scarce, many of those suffering from its consequences could benefit from information about common health issues and targeted measures to alleviate them,” Vaurio and colleagues say. “There is also some evidence that early interventions, such as parent management training (PMT) or adequate treatment of conduct disorder, may be beneficial in preventing the possible later life complications in children and young people (CYP) at risk of psychopathy.”Overall, the findings support past evidence that antisocial personality is tied to increased mortality. Notably, the sample size of the study was small, with only 16 psychopathic women. Future studies with larger samples may help unearth differences in mortality risk between men and women with psychopathy.The study, “Female Psychopathy and Mortality”, was authored by Olli Vaurio, Markku Lähteenvuo, Hannu Kautiainen, Eila Repo-Tiihonen, and Jari Tiihonen.",0.0,0.0
426,https://www.psypost.org/2022/10/study-finds-brain-changes-associated-with-adhd-remission-64139,Study finds brain changes associated with ADHD remission,"A recent study published in NeuroImage: Clinical used state-of-the-art neuroimaging techniques to determine what brain changes may cause childhood ADHD to go into remission. Christienne Damatac and colleagues looked at brain changes in those diagnosed with ADHD over 16 years. Their findings suggest that improved hyperactivity and inattentiveness symptoms result from increased white matter density in the brain region known as the left corticospinal tract. Additionally, reduced ADHD symptoms were associated with more neural connections in the same region.ADHD is a common childhood diagnosis. However, some are fortunate enough to grow out of the challenging symptoms by adulthood, and others never do. Understanding why this is so may lead to important innovations in treating the disorder. One hypothesis is that the malfunctioning parts of the brain that result in ADHD symptoms are never able to repair themselves. Instead, for some, as the brain develops, other regions take over the responsibilities of the damaged areas. Damatac and colleagues were curious if this was so and if these changes would persist over time.Fifty-five individuals with an ADHD diagnosis in the experimental condition were examined four times over 16 years. The neuroimaging techniques used are known as diffusion tensor imaging, diffusion-weighted imaging, and fixel-based analysis. At the time of the first scans, participants were between 6 and 18 years old.The research team found that as their subjects aged, those that went into ADHD remission experienced changes in white matter that were not seen in those who did not go into remission and the healthy non-ADHD controls. Moreover, these brain differences persisted well into adulthood.Brain changes like those found here are assumed to result from experience. For example, if an individual becomes blind and then learns to read braille, the brain will change in response to this new and necessary skill. In addition, areas of the brain once responsible for processing sight may take up other jobs to help the blind person navigate the world. These findings of this study indicate that as the brains of those with ADHD mature, some individuals may repetitively engage in strategies that compensate for symptoms. These repetitive behaviors may result in the brain changes seen in those who went into remission.For children with ADHD, this research implies that remission may be possible if strategies that help to compensate for deficits are frequently practiced. Further, it suggests that investing in support in the school setting and educating parents on strategies could help pave the way to long-term remission.Damatac and team acknowledges that their imaging techniques changed over time, which may have had unknown consequences for the data. Second, some of the original participants dropped out, and those left may not be as representative as the original sample. Finally, the sample size was too small to claim cause and effect; there may be other factors that led to persistent ADHD.These limitations aside, this research provides neurological evidence that consistent use of strategies to cope with ADHD symptoms may be a way out. Findings like this are sure to be used to support better funding and education for those helping children with ADHD.The study, “Longitudinal changes of ADHD symptoms in association with white matter microstructure: A tract-specific fixel-based analysis“, was authored by Christienne Damatac, Sourena Soheili-Nezhad, Guilherme Blazquez Freches, Marcel Zwiers, Sanne de Bruijn, Seyma Ikde, Christel M. Portengen, Amy Abelmann, Janneke Dammers, Daan van Rooij, Sophie Akkermans, Jilly Naaijen, Barbara Franke, Jan Buitelaa, Christian Beckmann, and Emma Sprooten.",0.0,0.0
294,https://interestingengineering.com/innovation/farming-robot-lasers-200000-weeds-per-hour,"This new farming robot uses lasers to kill 200,000 weeds per hour","Proven benefits for weed cropping“We’ve proven the effectiveness of our laserweeding technology and the immense benefits it offers farmers, including healthier crops and soil, decreased herbicide use, and reduced chemical and labor costs,” said Carbon Robotics CEO and Founder, Paul Mikesell.“To best serve farmers’ needs, we’ve adapted the design of our product, but will still leverage our proven laserweeding technology. Our mission has always been to provide farmers with the most effective tools, and the strong demand for LaserWeeders is evidence we’re helping them solve a serious problem.”The new machine features 30 industrial CO2 lasers, more than 3 times the lasers in Carbon Robotics’ self-driving Autonomous LaserWeeder. Growers who use the device are seeing up to 80 percent savings in weed management costs, with a break-even period of two to three years.Better yet, the new model integrates effortlessly into existing farming infrastructures while covering more ground and solving problems associated with spraying, hand weeding, and mechanical weeding.The machine also boasts sophisticated artificial intelligence technology that enables the robot to instantly identify, target, and eliminate weeds using thermal energy while continuously rolling. Furthermore, it features a lighting system that enables the LaserWeeder to operate day or night in almost all weather conditions.""Grimmway Farms is dedicated to protecting natural resources and the environment while optimizing crop yield and soil health,” said Jeff Morrison, director of innovation & new technology at Grimmway Farms.",0.0,0.0
114,https://www.theglobeandmail.com/opinion/article-the-catastrophic-threat-of-thawing-permafrost-hangs-over-us-all/,The catastrophic threat of thawing permafrost hangs over us all,"Attendees at a permafrost conference in Dawson City, Yukon, inspect a creek bank in the Klondike where ice-rich terrain has been washed away by placer mining. Climate change threatens to unlock the carbon in sediments such as this.Julien SchroderRichard Littlemore is a Vancouver-based journalist, consultant, speechwriter, and co-author of Climate Cover-up: The Crusade to Deny Global Warming.The Klondike capital of Dawson City is one of the best places in Canada to contemplate the catastrophic consequences of thawing permafrost. Or, if you’d rather, it might be a place to ignore the implications entirely, and with confidence that you are not alone in doing so. It depends on how closely you want to look – or how desperately you want to look away.Most of Dawson – like 30 per cent to 50 per cent of Canada – is underlain by permafrost, which scientists define as ground that has remained frozen, winter and summer, for at least two years. The notion may seem chilly, even forbidding, in the south, but many northerners call permafrost “our concrete.” They use it as a base for roads and bridges, as the foundation for homes, churches and businesses. In the words of Steve Kokelj, a Carleton University geographer and one of the deans of the Canadian permafrost community, it’s “the glue that holds the northern landscape together.”But if the promising prefix “perma-” suggests that this essential base is going to remain frozen forever, you might be disappointed. Thanks to climate warming, which a recent study by the Finnish Meteorological Institute showed is advancing in the North at up to seven times the global average, permafrost is thawing at an accelerating rate.Which means that stuff is starting to break. The Northwest Territories Association of Communities said in 2017 that its annual bill for permafrost-related repairs was already $51-million – a big additional tax for a small population (44,800). And it’s going to get worse. A January study in Nature Reviews Earth & Environment predicted that permafrost-related damage will affect 30 per cent to 50 per cent of all northern infrastructure by 2050.That’s obviously bad news for everyone who lives in one of the houses that is riding a permafrost thaw slump into the sea. But there is an even greater threat that hangs over us all.According to Sue Natali from the Woodwell Climate Research Center in Woods Hole, Mass., there is currently between 1.4 trillion and 1.6 trillion metric tonnes of carbon trapped in northern circumpolar permafrost, the remains of plants and animals that, over many thousands of years, died and slipped below the surface, where they have remained frozen ever since. For scale, that’s roughly twice as much carbon as is currently contained in the world’s atmosphere, three times as much as in all the forests on Earth.And when the permafrost thaws and micro-organisms start chowing down on all that suddenly available carboniferous material, those microbes wind up breathing out the greenhouse gas (GHG) carbon dioxide (CO2) or the even more powerful methane.Next comes the truly dangerous turn, the self-reinforcing feedback that could become an irreversible global tipping point. The warming atmosphere hastens the thaw of the permafrost, which belches up more greenhouse gases, which further accelerates the warming – and so on into the crisis-ridden future. The short- to medium-term impact of this “permafrost carbon feedback” loop remains speculative and controversial but by one estimate, based on calculations from the U.S. National Oceanic and Atmospheric Administration’s 2019 Arctic report card, Canadian permafrost could be emitting greenhouse gases by 2050 at a rate equal to all of the country’s current human output. If we were including those GHG emissions in our national totals (we’re not), that would mean we would have to double our emission reductions and/or carbon-capture efforts to reach the federal government’s widely heralded target of net zero by 2050. It hardly bears considering.In the slightly longer term, an overview paper published this month in the Annual Review of Environment and Resources reported that by the end of the century, even middling forecasts show that northern permafrost will be emitting carbon at a rate higher than the current output of any country other than China.A drone's-eye view of the Yukon wilderness. Much of the land in this area lies on permafrost hundreds of thousands of years old that was never scoured by glaciers.Julien SchroderWhich brings us back to Dawson, where in late August the foremost permafrost experts in the country gathered with an unprecedented contingent of First Nations delegates for the North Yukon Permafrost Conference.It is, again, a fitting venue. The fabled home of the Klondike Gold Rush, Dawson transformed in the late 1890s from a Dene community of a few hundred to a bacchanalian metropolis of up to 30,000 miners, revellers and hangers-on before crashing back down to its current permanent population of fewer than 2,000.Honouring that history, the town presents as something of a theme park – though, because it is curated by Parks Canada as a National Historic Site, it looks more quaint than Disneyfied. By municipal decree, all the downtown building fronts must remain “in conformity with the architectural and landscape … style common in Dawson during and immediately following the ‘Gold Rush.’”At a distance, the effect is pretty convincing. The landscape part is easy – 1890s-style dirt roads and rickety wooden boardwalks where the sidewalks might be. This is also robustly practical. The heaving permafrost and winter temperatures that frequently dip below -40 would quickly turn pavement or sidewalk concrete to rubble.The buildings appear similarly authentic, as long as you don’t peek behind the facades to see the ones that are, in fact, corrugated-metal Quonset huts with false fronts. If you were to lift the skirts of the actual buildings, you also would find that nearly all of them are sitting on “cribbing,” beams and posts that can be shimmed and adjusted year after year to remain level, despite the permafrost decline. You don’t have to wander far from the main streets to see drunken, slewing (and ultimately dangerous) structures that have not been kept up.“Most of us are used to relevelling our buildings quite a bit,” says Dawson Mayor Bill Kendrick. It’s more difficult, though – and even more expensive – to manage some of the other infrastructure, he says, offering the example of the sewer and water lines that snapped a few years ago, thanks to a four-foot, permafrost-driven “deflection” along Sixth Avenue.These historic buildings in Dawson, shown in the mid-2000s, are smushing together as the permafrost thaws.Chris BeacomSome of Dawson's more picturesque buildings, as seen at 2018's Canada Day parade.Darryl Dyck/The Canadian PressSo people in Dawson are hypersensitized to the local effects of permafrost – the geohazard. But many seem to actively ignore the implications of permafrost carbon feedback. Far from trying to protect the permafrost, to keep excess carbon in the ground, many dozens of placer mines are working tirelessly to destroy the permafrost layer, to get access to the gold that still lurks in Klondike gravel. The miners, usually in operations of four to six people, set up in creek beds and spray water at the banks, blowing off any surface flora and the layers of permafrost ice, soils and fossilized material to get to the good stuff. Then they sluice out the gold, thereafter covering the landscape with washed-gravel tailings that, from the plane coming in from Whitehorse, look like castings from Dune-sized sandworms.According to the Yukon government manager of surficial geology, Jeff Bond, there are roughly 150 placer mining operations in the Dawson region, generating 90 per cent of the 80,000 ounces of gold that come out of the Yukon every year. At current gold prices, about $2,200 an ounce, that’s roughly $160-million worth of income, an estimated 87 per cent of which stays in the local economy. As Mayor Kendrick says, “When COVID devastated tourism, mining helped us weather the storm.”Here, then, is an analogy for the whole climate-change dilemma: what you know versus what you don’t want to know. As in southern Canada, where governments set emission-reduction targets and then invest in oil sands pipelines or promote oil and gas developments, there is always the tension between an uncertain threat tomorrow and a reliable income today.Against that tension, the Dawson permafrost conference was set up as a multifaceted act of reconciliation. First, of course, was the challenge of engaging and reconciling with the Indigenous people on whom the climate effects are having the most immediate and, often, devastating impact. Carleton University’s Chris Burn, another giant in the Canadian permafrost panoply, describes First Nations people in the North as “the last group who are not removed from the environment.” He says, “They realize that they are facing an existential problem, not just an interesting intellectual exercise.” Dr. Burn is also beloved in these parts as an academic who came to the Yukon to research permafrost in 1982 and has been coming back almost every summer since. Unlike too many academic researchers, who fly in with thousands of dollars of equipment and head straight into the field, neither tapping the locals for their insights nor sharing any knowledge gained in the process, Dr. Burn recognized early that “the observations of the people who actually live here are always more interesting than those I can make myself.” As if to drive home the point, 40 years later, he still gets ribbed for the unlikely riverbank location of his first camp.So, in preparing for this conference, Dr. Burn and others from the Canadian Permafrost Association (CPA) invited First Nations to participate as co-organizers. Three First Nations accepted: the Trʼondëk Hwëchʼin, the Vuntut Gwichen, and the Na-cho Nyak Dun.The outcome, according to current CPA president Kumari Karunaratne, was “amazing.” Knowing that a third of the people in the room would be First Nations elders, the scientists accepted a challenge to avoid jargon-filled, insider presentations. “They’re not dumbing it down,” Dr. Karunaratne said, “but they’re breaking it down enough to be understood.” And in the multidisciplinary world of permafrost science, that turned out to be a boon for other scientists, as well.Participants at the Dawson permafrost conference listen to scientist Antoni Lewkowicz and Peggy Kormandy, a Tr'ondëk Hwëch'in elder, describe the Moosehide Slide north of town.Julien SchroderThat signals the second point of reconciliation – the drawing together of the permafrost science community and, especially, the co-ordination of permafrost research.Like other dangerous climate forcings, the permafrost threat is so dispersed that no single jurisdiction can claim or exercise responsibility. Scientists, distributed among many institutions – and many countries – tend to work in isolation and, in Canada certainly, funding agencies prioritize short-term capital-intensive research projects, resisting long-term or operating grants. As a result, the Canadian permafrost research community has been relying on what University of Montreal geographer Oliver Sonnentag calls “a coalition of the willing,” in which “co-ordination is not funded and every person, every project is disconnected.”Thanks to at least three initiatives, however, that may be about to change.The first is being led by Carleton University geographer Stephan Gruber, who is the principal investigator for the Natural Sciences and Engineering Research Council Permafrost Partnership Network (NSERC PermafrostNet), which unites researchers from 11 universities, and partners with government agencies, industry, and Indigenous communities to monitor, predict and adapt to permafrost thaw and its consequences.Dr. Natali and the Woodwell Center are driving an even larger research and co-ordination project called Permafrost Pathways, which is building a comprehensive international monitoring network to improve tracking and modelling of Arctic permafrost and carbon fluxes – i.e., how much carbon is being emitted from permafrost as opposed to that which is being absorbed as new plant material dies and is frozen in the annual cycle. Dr. Natali and company are working to partner with local leaders and to provide local and national policy makers with the data they need to fill gaps in monitoring and modelling permafrost thaw.As mentioned above, permafrost emissions are not currently included in national carbon budgets, which means that emission-reduction targets negotiated at the 2015 Paris climate conference could be way off the mark as the world seeks to keep global warming from exceeding catastrophic levels.The bad news in the Permafrost Pathways project comes in the sudden and unfortunate departure of Russia from international permafrost science collaboration, thanks to the diplomatic break driven by the Ukraine war. Two-thirds of the world’s permafrost lies within Russian borders, so permafrost researchers in the rest of the world are eager to restore the flow of scientific information.In the meantime, there may be a greater opportunity to focus on Canadian monitoring and the Woodwell team has now engaged Dr. Sonnentag, who will be taking a leave from his University of Montreal teaching duties, beginning Jan. 1, to serve as a liaison to the Canadian research community.The Cascade Institute at Royal Roads University is launching a third co-ordination project, called the Permafrost Carbon Feedback Intervention Roadmap, again seeking to expand the conversation and reduce the scientific uncertainties that some policy makers use as a rationale to delay action.Even without working through the next stage of monitoring and analysis, however, Dr. Natali bridles at the continuing policy delay. She says, “Uncertainty is just a range of possibilities. It shouldn’t frustrate action.”She also points out that we already understand the range of consequences and says that we should be making decisions based on the high end of the range, precisely because the possible consequences are so huge. (Dr. Gruber calls permafrost carbon feedback “a trillion-dollar question for coastal cities.”)Dr. Natali concludes that, in the long run, “The science will give us the numbers. For decisions, we need the wisdom to come together as human communities.”Jimmy Johnny, a Na-Cho Nyak Dun elder, speaks at the Dawson conference.Julien SchroderOne of the most popular sources of wisdom in Dawson was a Na-Cho Nyak Dun elder named Jimmy Johnny, a presenter in a panel discussion on climate-change adaptation. Mr. Johnny is a short, wiry and quietly mirthful character who has spent his life as a horse wrangler, having gotten his first job as a guide-outfitter in 1958. And he dresses the part: cowboy boots, hat, leather vest and blue jeans that stay up out of pure stubbornness, there being too little flesh on Mr. Johnny’s bones to stop them from falling down.He told a story of a recent hunting trip in which a pack horse named Big Blue fell into a huge permafrost sinkhole: “Right before my eyes, he disappeared.” Tapping the strength of all hands and a couple of other horses, Mr. Johnny worked to pull Big Blue out, but the sloppy hole was too constricted and the horse too panicked. Facing a terrible decision, Mr. Johnny walked to a high point and phoned the horse’s owner – for permission, or maybe for his blessing. But the owner just said, “Jimmy, you’re the trail boss. You do what you have to do.”Mr. Johnny walked back to his own horse and, to the consternation of the southern hunters in the party, he pulled a .30-30 rifle from his saddle. “And then I walked around behind the horse, so he didn’t have to see.”But Big Blue was neither inattentive nor new to the world of hunters. When Mr. Johnny cocked the rifle – “click, click” – the horse bounded upward, not clear of the hole, but far enough that they were able to wrestle him the rest of the way.The moderator for the adaptation panel was a Na-Cho Nyak Dun adviser named John Meikle, who noted that there is now ample evidence of the risks we all face from climate change, and the urgency of the call to action, concluding, “Maybe it’s time to take a lesson from Big Blue and imagine Jimmy Johnny standing behind you with a .30-30.”It’s a rough metaphor, but the head-nodding and mirthless laughter that greeted Mr. Meikle’s comment suggest that, in this room, at least, there is wary consensus about the looming implications of climate change generally and permafrost specifically: Even if we’re not yet capable of jumping out of the hole, it might be time to stop digging.Editor’s note: (Nov. 1, 2022): An earlier version of this article incorrectly said Woodwell Climate Research Center is linked to Harvard. This version has been corrected.What is permafrost, and what happens when it melts across Canada?",0.0,0.0
85,https://www.theregister.com/2022/08/24/google_jupiter_network_mirrors/,How Google uses mirrors to dynamically reconfigure its networks,"Google has scaled its network capacity from over one petabit per second to beyond six petabits per second since 2015, and some of that growth has come from switches that bounce optical signals off an array of mirrors to redirect traffic.As our sibling site The Next Platform reported in 2015, Google calls its datacenter networking tech Jupiter, which uses a mixture of merchant silicon and custom code to connect the kit that runs Search, YouTube, Gmail, the G-cloud, and plenty more besides.On Tuesday, the advertising giant published a paper and summary explaining the last decade or so of work on Jupiter.The headline figures in both documents detail 5x higher speed and capacity, 30 percent reduction in capex, and 41 percent reduction in power consumption.Plenty of those improvements are the result of Optical Circuit Switches (OCSes) that use mirrors mounted on Micro-ElectroMechanical Systems (MEMS) to map an optical fiber input port to an output port dynamically.And, yup, we're aware that MEMS-based, and non-MEMS, optical mirror switching has existed for computer networks for years and years. What's cool here is the density and throughput Google says it has developed, and now documented, for its own globe-spanning use.Well, we found it interesting, anyway.How Google's mirror-filled optical switch moves traffic ... Source: Google. Click to enlargeIn Google's switches, a signal reaches a ""fiber collimator array"" that offers 136 physical I/O paths, or individual fibers. An incoming signal emerges from one of those fibers, then bounces off a splitter before hitting a MEMS device that has 136 micro mirrors. The MEMS device moves in two dimensions and reflects the signal to one of the 136 fibers in the outgoing collimator array.The tech was needed because Google wanted its network to ""support heterogeneous network elements in a 'pay as you grow' model, adding network elements only when needed and supporting the latest generation of technology incrementally.""That means ""allowing the incremental addition of network capacity – even if of a different technology than previously deployed – to deliver a proportional capacity increase and native interoperability for the entire building of devices.""Achieving that vision is not easy because Google's datacenter networks need to be deployed ""at the scale of an entire building – perhaps 40MW or more of infrastructure.""""Further, the servers and storage devices deployed into the building are always evolving, for example moving from 40Gbit/sec to 100Gbit/sec to 200Gbit/sec and today 400Gbit/sec native network interconnects. Therefore, the datacenter network needs to evolve dynamically to keep pace with the new elements connecting to it.""Google also recognizes that its network is not a single entity.""Datacenter networks are inherently multi-tenant and continuously subject to maintenance and localized failures,"" Google's description, from infrastructure VP Amin Vahdat, explained. ""A single datacenter network hosts hundreds of individual services with varying levels of priority and sensitivity to bandwidth and latency variation.""""For example, serving web search results in real time might require real-time latency guarantees and bandwidth allocation, while a multi-hour batch analytics job may have more flexible bandwidth requirements for short periods of time,"" Vahdat stated. ""Given this, the datacenter network should allocate bandwidth and pathing for services based on real-time communication patterns and application-aware optimization of the network.""That kind of dynamic reconfiguration also helps resilience.""Ideally, if ten percent of network capacity needs to be temporarily taken down for an upgrade, then that ten percent should not be uniformly distributed across all tenants, but apportioned based on individual application requirements and priority,"" Vahdat explains.But networks are hardwired to do certain things well, and even Google's software-defined networking can only do so much to reconfigure them to adapt to new requirements.MEMS and OCS also make it possible to upgrade and reconfigure networks without having to rewire (or re-fiber) a datacenter.Vahdat concluded that its network ""delivers 50x less downtime than the best alternatives we are aware of.""So, take that, Cisco, Juniper, Arista, and pals. And for the rest of us, take comfort that this stuff usually trickles down over time – as happened with Kubernetes and cloud-inspired consumption based IaaS models. ®",0.0,0.0
90,https://www.theguardian.com/science/2022/oct/19/next-pandemic-may-come-from-melting-glaciers-new-data-shows,"Next pandemic may come from melting glaciers, new data shows","The next pandemic may come not from bats or birds but from matter in melting ice, according to new data.Genetic analysis of soil and lake sediments from Lake Hazen, the largest high Arctic freshwater lake in the world, suggests the risk of viral spillover – where a virus infects a new host for the first time – may be higher close to melting glaciers.The findings imply that as global temperatures rise owing to climate change, it becomes more likely that viruses and bacteria locked up in glaciers and permafrost could reawaken and infect local wildlife, particularly as their range also shifts closer to the poles.For instance, in 2016 an outbreak of anthrax in northern Siberia that killed a child and infected at least seven other people was attributed to a heatwave that melted permafrost and exposed an infected reindeer carcass. Before this, the last outbreak in the region had been in 1941.To better understand the risk posed by frozen viruses, Dr Stéphane Aris-Brosou and his colleagues at the University of Ottawa in Canada collected soil and sediment samples from Lake Hazen, close to where small, medium and large amounts of meltwater from local glaciers flowed in.Next, they sequenced RNA and DNA in these samples to identify signatures closely matching those of known viruses, as well as potential animal, plant or fungal hosts, and ran an algorithm that assessed the chance of these viruses infecting unrelated groups of organisms.The research, published in Proceedings of the Royal Society B, suggested that the risk of viruses spilling over to new hosts was higher at locations close to where large amounts of glacial meltwater flowed in – a situation that becomes more likely as the climate warms.The team did not quantify how many of the viruses they identified were previously unknown – something they plan to do in the coming months – nor did they assess whether these viruses were capable of triggering an infection.However, other recent research has suggested that unknown viruses can, and do, loiter in glacier ice. For instance, last year, researchers at Ohio State University in the US announced they had found genetic material from 33 viruses – 28 of them novel – in ice samples taken from the Tibetan plateau in China. Based on their location, the viruses were estimated to be approximately 15,000 years old.In 2014, scientists at France’s National Centre for Scientific Research in Aix-Marseille managed to revive a giant virus they isolated from Siberian permafrost, making it infectious again for the first time in 30,000 years. The study’s author, Jean-Michel Claverie, told the BBC at the time that exposing such ice layers could be “a recipe for disaster”.Sign up to First Edition Free daily newsletter Archie Bland and Nimo Omer take you through the top stories and what they mean, free every weekday morning Privacy Notice: Newsletters may contain info about charities, online ads, and content funded by outside parties. For more information see our Newsletters may contain info about charities, online ads, and content funded by outside parties. For more information see our Privacy Policy . We use Google reCaptcha to protect our website and the Google Privacy Policy and Terms of Service apply.Even so, Aris-Brosou’s team cautioned that predicting a high risk of spillover was not the same as predicting actual spillovers or pandemics. “As long as viruses and their ‘bridge vectors’ are not simultaneously present in the environment, the likelihood of dramatic events probably remains low,” they wrote.On the other hand, climate change is predicted to alter the range of existing species, potentially bringing new hosts into contact with ancient viruses or bacteria.“The only take-home that we can confidently put forward is that as temperatures are rising, the risk of spillover in this particular environment is increasing,” said Aris-Brosou. “Will this lead to pandemics? We absolutely don’t know.”Also unclear is whether the potential for host switching identified in Lake Hazen is unique within lake sediments. “For all we know, it could be the same as the likelihood of host switching posed by viruses from the mud in your local pond,” said Arwyn Edwards, the director of the Interdisciplinary Centre for Environmental Microbiology at Aberystwyth University.However, “we do urgently need to explore the microbial worlds all over our planet to understand these risks in context,” he said. “Two things are very clear now. Firstly, that the Arctic is warming rapidly and the major risks to humanity are from its influence on our climate. Secondly, that diseases from elsewhere are finding their way into the vulnerable communities and ecosystems of the Arctic.”",0.0,0.0
81,https://www.theverge.com/2022/9/30/23378231/usb-rebranding-2022-logos-gbps-wattage-charging-transfer-speeds-simplification-usb4-superspeed,USB kills off SuperSpeed branding as it tries to simplify its ubiquitous connector,"The SuperSpeed USB branding is no more thanks to a new set of guidelines currently being rolled out by the USB Implementers Forum (USB-IF), the body that manages and maintains the USB standard.It’s part of a rebranding initiative that the organization kicked off last year with the introduction of a new series of packaging, port, and cable logos. But with its latest set of branding and logo guidelines it’s going even further, simplifying its legacy branding and signaling the end of the decade-old SuperSpeed branding. If the name doesn’t ring any bells, then that’s probably because you (like most other people) simply referred to it by its USB 3 version number. Alongside it, the USB-IF is also ditching USB4 as a consumer-facing brand name.An old Certified SuperSpeed logo. Photo by The VergeThe changes came into effect this quarter, and could start appearing on products and packaging as early as by the end of the year, according to the USB-IF’s president and chief operating officer Jeff Ravencraft. But any products that were certified prior to the shift will still be able to use the old brand names.In a Zoom call, Ravencraft explains that the new branding is designed to prioritize what the standards can actually do, rather than the USB version they’re based on. “As we started to update our branding we did a lot of focus group studies with many different types of consumers,” he tells The Verge, “and none of those people understood the messaging and the branding, and they don’t understand revision control or spec names.”The new range of USB packaging and device logos, no “SuperSpeed” or “USB4” branding in sight. Image: USB-IF“What consumers want to know — and what we learned — is they want to know two things: What’s the highest data performance level the product can achieve? And what’s the highest power level I can get or drive from this product,” he says. “That’s all they want to know.”So, instead of referring to USB devices by a version number or vague name like “SuperSpeed,” the USB-IF wants companies to use branding that reflects these all-important specs. “SuperSpeed USB 5Gbps” and “SuperSpeed USB 10Gbps” are now just “USB 5Gbps” and “USB 10Gbps” respectively, while “USB4 40Gbps” and “USB4 20Gbps” are becoming “USB 40Gbps” and “USB 20Gbps.”Branding for certified USB Type-C cables is also being updated. Rather than simply listing their data transfer speeds, cables will also (for the most part) have to list the charging wattage they’re capable of carrying. So a cable can’t just be branded as being a 40Gbps cable as with last year’s guidelines, it’ll now also have to list a charging speed like 60W or 240W.It’s important to note that using these brandnames is far from mandatory. They apply to USB devices certified by the USB-IF, but these only cover a fraction of the total number of USB products out on the market. That’s because unlike specifications like Thunderbolt 4, which manufacturers have to license directly from Intel, USB is an open standard that anyone is free to use. That’s allowed it to become as ubiquitous as it is, but means the USB-IF is all-but-powerless to stop companies from building USB products that don’t use the specification properly. And no one’s going to stop them from branding a device as USB4 Version 2, or offer no branding at all.Certified cables will now need to show maximum wattage alongside data transfer speeds, unless they’re using the older Hi-Speed standard. Image: USB-IFThe underlying USB version numbers aren’t going anywhere. But while manufacturers and OEMs still have to wrap their heads around specs like USB4 Gen3x2 and USB4 Version 2, the USB-IF doesn’t want customers to care what version number their devices or cables are using. Yes, USB4 Version 2.0 is a terrible name, but the idea is that most consumers should end up seeing it branded as USB 80Gbps.This branding applies regardless of the specific USB port being used, whether it’s old fashioned USB Type-A, microUSB, or USB Type-C. But naturally the higher performance logos will only be applicable to USB Type-C, which is the only connector to support transfer speeds over 10Gbps.Putting the two most important specs front-and-centerA key exception to all these rules is USB Hi-Speed, more commonly known by its version number USB 2.0, which maxes out at a now achingly slow 480Mbps. But the USB-IF’s reasoning is that if it were to be completely consistent, and brand USB 2.0 ports as “USB 480Mbps,” then it’d risk confusing customers who might see the branding next to a “USB 5Gbps” device and wrongly assume it’s faster because of the higher number. Original USB 1.0 branding is also unaffected by this year’s changes.As my former colleague Chaim Gartenberg wrote last year, even with new simplified branding the situation is still far from perfect. Ideally we wouldn’t need half a dozen different logos to describe all the variations of a single connector. But Ravencraft argues that it wouldn’t make sense to force every manufacturer to support the highest specs.“A USB printer will never be USB4 Version 2,” he says. “There’s no need for it, and no one’s going to put the cost of this higher end technology into a printer or a keyboard or a mouse.” Instead, the “billions” of devices on the market that only need the transfer speeds of older standards like USB 2.0 (ahem, sorry, USB Hi-Speed) can continue to use them.There’ll still be lots of different USB versions out thereThe new branding guidelines also don’t cover absolutely everything that a USB cable can do. There’s no information on resolutions or refresh rates if you need a cable that’s going to carry a DisplayPort video signal, nor is there anything to say how a cable might handle taking a PCIe signal. The logos are focused on the USB-IF’s own standards like USB Power Delivery. That also means they don’t offer the same guarantees if you need support for a competing fast-charging standard like Qualcomm’s Quick Charge.",0.0,0.0
76,https://www.nature.com/articles/s41591-022-02012-w,Association of step counts over time with the risk of chronic disease in the,"We examined the association between step count volume and intensity across the entire spectrum of human disease using commercial activity monitors linked to an individual’s EHR. We identified consistent and statistically significant associations between activity levels and incident diabetes, hypertension, GERD, MDD, obesity and sleep apnea. Taking more steps each day was related to lower risk of developing these chronic diseases. Higher step counts were associated with protection from obesity in a high-risk population (BMI 25–29 kg m–2). Step count was positively correlated with step intensity, regardless of the bout cadence definition. The relation of step counts with disease risk persisted for diabetes, GERD, MDD and sleep apnea even when adjusting for step intensity. Step intensity was also significantly associated with these outcomes. These data provide new, empiric evidence of activity levels associated with chronic disease risk and suggest that integration of commercial wearables data into the EHR may be valuable to support clinical care.Our findings are consistent with previous literature describing associations between step counts and adverse events10,11. A systematic review by Hall et al.10 found that taking more steps per day was related to lower risk of all-cause mortality, cardiovascular events and incident diabetes. The National Health and Nutrition Examination Survey study, which quantified steps over a 7-day monitoring period and assessed mortality over an average of 10.1 years, found a 51% lower mortality at 8,000 steps per day compared with 4,000 steps per day1. Similar results were reported from a middle-aged, biracial cohort with 7 days of monitoring and over 10 years of follow-up time5. A prospective cohort study conducted in 3,055 community-dwelling adults aged over 70 years found a similar nonlinear relation between daily steps and risk of developing diabetes, where the risk leveled off at 8,000 steps per day12. It is notable that step count thresholds associated with risk of mortality and cardiometabolic disease in prior studies are similar to step count thresholds associated with a wide variety of previously unreported phenotypes in our study. These results suggest that a single step count target of approximately 8,000–9,000 steps per day may be suitable to reduce risk of many common conditions.Our study design and analytic approach differed from prior studies in important ways that make our results new and clinically relevant. First, prior studies assessed step counts over a single, short (usually 7 days) monitoring period with activity data between the baseline monitoring period and outcomes assessment, often many years later. Short monitoring periods are prone to an observer effect and may not accurately reflect true short- and long-term activity behavior13. In contrast, our models accounted for changes in steps over the entirety of an individual’s monitoring period (median of 4 years) rather than a brief snapshot. Second, prior studies have focused on a narrow set of outcomes (for example, mortality, diabetes and cardiovascular disease) ascertained at a single timepoint remote from the initial monitoring period. Our study used a hypothesis-generating phenome-wide association study approach, examining the association between step counts and the human phenome. In this manner, several new associations emerged including GERD, sleep apnea and MDD, which would likely go unidentified if disease phenotypes were selected a priori. Lastly, our analysis permitted incident disease to emerge at any point during clinical care rather than a prespecified follow-up time as performed in most cohort studies. One may speculate that this approach is more accurate with respect to the timing of incident disease and refines the temporal association between longitudinal activity and incident disease.The findings of this study should be viewed in the context of several limitations. We were not able to account for daily step variations between different types of Fitbit models14 and seasonal differences15 as well as the occurrence of the COVID-19 pandemic because device data were not available at the time of analyses and data were date-shifted to protect privacy of participants. The characteristics of our study sample may limit the generalizability of our findings to more diverse populations. The majority of our cohort was relatively young, female, white and college-educated, and only included participants who owned Fitbit devices. Further, participants engaged in more steps per day (median 7,731 steps per day) than the average steps per day values reported for adults in the USA aged over 60 years16, suggesting that the analytical cohort in this study was more active. The fact that we were able to detect robust associations between steps and incident disease in this active sample suggests even stronger associations may exist in a more sedentary population. Therefore, further studies are needed including participants who are historically under-represented in biomedical research and those with activity levels that more closely mirror the general community.Our data do not account for nonstepping activity such as swimming or cycling, such nonstepping movement is better captured via waveform or raw accelerometry and may provide additional insight into the association between physical activity and clinical diagnoses. Further, this study was observational in nature; therefore, causation should not be inferred. We acknowledge the potential for reverse causation in which the existence of a condition leads to taking fewer steps rather than the reverse. We attempted to mitigate this concern by focusing only on incident conditions and excluding any incident disease that emerged in the first 6 months of the monitoring period. Further, there is a potential for unmeasured confounding in our analyses because we were not able to account for an exhaustive list of potential confounders such as job status, environmental factors and differences in the usage patterns between participants over time17. Future studies are needed to investigate the impact of user behavior on health outcomes. Additionally, findings from exploratory logistic regression that did not find an association between steps per day and other outcomes such as cardiovascular diseases should be viewed with caution given that the analytical sample was relatively young, reported fewer outcomes and had limited follow-up. We excluded 15.4–16.0% (varies based on the outcome) of months due to fewer than 15 valid days of data in the Cox models. This missingness seems acceptable in comparison with prior studies which considered data to be valid if activity was captured on at least 3 out of 7 days (that is, up to 57% missing data)18. Lastly, we also acknowledge the limitations of using EHR data for outcomes ascertainment and the potential lack of specificity of diagnostic codes. It is possible that conditions are coded improperly, not coded at all or not recognized in the clinic. Nonetheless, our results reflect use of diagnostic codes in clinical practice across various medical systems, including large regional medical centers and federally qualified health centers.Despite these limitations, the sources of data for our study are unique and offer an example of the potential clinical value of linking wearables data to the EHR. Published activity studies almost exclusively used research-grade actigraphs to measure steps and/or activity counts. In contrast, our data derive from commercially available devices. Although some fidelity is lost between research-grade and commercial devices, data from the latter are highly generalizable to a large portion of the public who own such devices. Activity data in this study date to the creation of a Fitbit account by the user. Therefore, the risk of an observer effect in this cohort is negligible because much of the activity data was collected before the participant consented to All of Us.These findings may have important clinical and public health implications. We were unable to identify any published studies that investigated the association of physical activity data from a wearable device to health outcomes, defined using an individual’s EHR. Therefore, this study provides important new evidence that integration of these data sources is feasible and may provide valuable and actionable information for clinicians. Clinicians could monitor activity trends and provide evidence-based anticipatory guidance for activity tailored to an individual’s clinical characteristics and risk profile. For example, our data suggest that an individual with a BMI of 28 kg m–2 (can lower their risk of obesity 64% (95% CI 51, 80) by increasing steps from approximately 6,000 steps to 11,000 steps per day (Fig. 3). Although validation of these results is important, such data provide a necessary first step toward the development of personalized activity prescriptions. Further, wearables can also be used as an adjunct tool to encourage patients to engage in physical activity by allowing them to set, measure and track goals19. Finally, self-reported physical activity or exercise interventions may have potential beneficial effects to lower the incidence of depression20 and lower the severity of obstructive sleep apnea and associated comorbidities21. Therefore, these results provide support for the need for further research to examine the effect of real-world, unstructured physical activity to prevent or mitigate the effects of such conditions, including some previously unidentified activity-disease associations (for example, GERD).In summary, using the data from AoURP, higher daily step counts were associated with reduced risk of several common, chronic diseases, including diabetes, hypertension, GERD, MDD, obesity and sleep apnea. This association between step counts over time and incident chronic diseases was consistent even after adjusting for potential covariates, including baseline steps per day and step intensity. Step intensity was also significantly associated with these incident diseases, although the relationships were less consistent than with step counts. These findings provide a new, robust source of evidence in support of the physical activity guidelines to prevent the risk of developing chronic diseases. If validated, these results may offer an evidence-base for refining activity recommendations based on an individual’s risk profile. This study also provides an example of the potential clinical value of linking data from commercially available wearables to the EHR.",0.0,0.0
313,https://www.theguardian.com/technology/2022/oct/24/tiktok-election-misinformation-voting-politics,âWe risk another crisisâ: TikTok in danger of being major vector of election misinformation,"In the final sprint to the US midterm elections the social media giant TikTok risks being a major vector for election misinformation, experts warn, with the platform’s huge user base and its design making it particularly susceptible to such threats.Preliminary research published last week from digital watchdog Global Witness and the Cybersecurity for Democracy team at New York University suggests the video platform is failing to filter large volumes of election misinformation in the weeks leading up to the vote.TikTok approved 90% of advertisements featuring election misinformation submitted by researchers, including ads containing the wrong election date, false claims about voting requirements, and rhetoric dissuading people from voting.TikTok has for several years prohibited political advertising on the platform, including branded content from creators and paid advertisements, and ahead of midterm elections has automatically disabled monetization to better enforce the policy, TikTok’s global business president, Blake Chandlee, said in a September blog post. “TikTok is, first and foremost, an entertainment platform,” he wrote.But the NYU study showed TikTok “performed the worst out of all of the platforms tested” in the experiment, the researchers said, approving more of the false advertisements than other sites such as YouTube and Facebook.The findings spark concern among experts who point out that – with 80 million monthly users in the US and large numbers of young Americans indicating the platform is their primary source of news – such posts could have far reaching consequences.Yet the results come to little surprise, those experts say. During previous major elections in the US, TikTok had far fewer users, but misinformation was already spreading widely on the app. TikTok faced challenges moderating misinformation about elections in Kenya and the war in Ukraine.And the company, experts say, is doing far too little to rein in election lies spreading among its users.“This year is going to be much worse as we near the midterms,” said Olivia Little, a researcher who co-authored the Media Matters report. “There has been an exponential increase in users, which only means there will be more misinformation TikTok needs to proactively work to stop or we risk facing another crisis.”A crucial testWith Joe Biden himself warning that the integrity of American elections is under threat, TikTok has announced a slew of policies aimed at combatting election misinformation spreading through the app.The company laid out guidelines and safety measures related to election content and launched an elections center, which “connect[s] people who engage with election content” to approved news sources in more than 45 languages.“To bolster our response to emerging threats, TikTok partners with independent intelligence firms and regularly engages with others across the industry, civil society organizations, and other experts,” said Eric Han, TikTok’s head of US safety, in August.In September, the company also announced new policies requiring government and politician accounts to be verified and said it would ban videos aimed at campaign fundraising. TikTok added it would block verified political accounts from using money-making features available to influencers on the app, such as digital payments and gifting.TikTok has laid out guidelines and launched an elections center to combat misinformation on the app. Photograph: Nicolas Asfouri/AFP/Getty ImagesStill, experts have deep concerns about the spread of election falsehoods on the video app.Those fears are exacerbated by TikTok’s structure, which makes it difficult to investigate and quantify the spread of misinformation. Unlike Twitter, which makes public its Application Programming Interface (API), software that allows researchers to extract data from platforms for analysis, or Meta, which offers its own internal search engine called Crowdtangle, TikTok does not offer tools for external audits.However, independent research as well as the platform’s own transparency reports highlight the challenges it has faced in recent years moderating election-related content.TikTok removed 350,000 videos related to election misinformation in the latter half of 2020, according to a transparency report from the company, and blocked 441,000 videos containing misinformation from user feeds globally.The internet non-profit Mozilla warned in the run-up to Kenya’s 2022 election that the platform was “failing its first real test” to stem dis- and misinformation during pivotal political moments. The non-profit said it had found more than 130 videos on the platform containing election-related misinformation, hate speech and incitement against communities before the vote, which together gained more than 4m views.“Rather than learn from the mistakes of more established platforms like Facebook and Twitter, TikTok is following in their footsteps,” Mozilla researcher Odanga Madung wrote at the time.Why TikTok is so vulnerable to misinformationPart of the reason TikTok is uniquely susceptible to misinformation lies in certain features of its design and algorithm, experts say.Its For You Page, or general video feed, is highly customized to users’ individual preferences via an algorithm that’s little understood, even by its own staff. That combination lends itself to misinformation bubbles, said Little, the Media Matters researcher.“TikTok’s hyper-tailored algorithm can blast random accounts into virality very quickly, and I don’t think that is going to change anytime soon because it’s the reason it has become such a popular platform,” she said.Meanwhile, the ease with which users’ remix, record and repost videos – few of which have been fact-checked – allows misinformation to spread easily while making it more difficult to remove.TikTok’s video-exclusive content brings up additional moderation hurdles, as artificial intelligence processes may find it more difficult to automatically scrape video content for misinformation compared to text.A report from Harvard’s Shorenstein Center on Media found that design features on the app make it an easy pathway for misinformation. Photograph: Paula Bronstein/APSeveral recent studies have highlighted how those features have exacerbated the spread of misinformation on the platform. When it comes to TikTok content related to the war in Ukraine, for example, the ability to “remix media” without fact-checking it has made it difficult “even for seasoned journalists and researchers to discern truth from rumor, parody and fabrication”, said a recent report from Harvard’s Shorenstein Center on Media.That report cited other design features in the app that make it an easy pathway for misinformation, including that most users post under pseudonyms and that, unlike on Facebook, where users’ feeds are filled primarily with content from friends and people they know, TikTok’s For You Page is largely composed of content from strangers.Some of these problems are not unique to TikTok, said Marc Faddoul co-director of Tracking Exposed, a digital rights organization investigating TikTok’s algorithm.Studies have shown that algorithms across all platforms are optimized to detect and exploit cognitive biases for more polarizing content, and that any platform that relies on algorithms rather than a chronological newsfeed is more susceptible to disinformation. But TikTok is the most accelerated model of an algorithmic feed yet, he said.At the same time, he added, the platform has been slow in coming to grips with issues that have plagued its peers like Facebook and Twitter for years.“Historically, TikTok has characterized itself as an entertainment platform, denying they host political content and therefore disinformation, but we know now that is not the case,” he said.Young user base is particularly at riskExperts say an additional cause for concern is a lack of media literacy among TikTok’s largely young user base. The vast majority of young people in the US use TikTok, a recent Pew Research Center report showed. Internal data from Google revealed in July that nearly 40% of Gen Z – the generation born between the late 1990s and early 2000s – globally uses TikTok and Instagram as their primary search engines.In addition to being more likely to get news coverage from social media, Gen Z also has far higher rates of mistrust in traditional institutions such as the news media and the government compared with past generations, creating a perfect storm for the spread misinformation, said Helen Lee Bouygues, president of the Reboot Foundation, a media literacy advocacy organization.“By the nature of its audience, TikTok is exposing a lot of young children to disinformation who are not trained in media literacy, period,” she said. “They are not equipped with the skills necessary to recognize propaganda or disinformation when they see it online.”Donald Trump supporters share a laugh after filming a dance for TikTok at his campaign event in Macon, Georgia, on 16 October 2020. Photograph: Dustin Chambers/ReutersThe threat is amplified by the sheer amount of time spent on the app, with 67% of US teenagers using the app for an average of 99 minutes per day. Research conducted by the Reboot Foundation showed that the longer a user spends on an app the less likely they are to distinguish between misinformation and fact.To enforce its policies, which prohibit election misinformation, harassment, hateful behavior, and violent extremism, TikTok says it relies on “a combination of people and technology” and partners with factcheckers to moderate content.The company directed questions to this blogpost regarding election misinformation measures, but declined to share how many human moderators it employs.Bouygues said the company should do far more to protect its users, particularly young ones. Her research shows that media literacy and in-app nudges towards fact-checking could go a long way when it comes to combating misinformation. But government action is needed to force such changes.“If the TikToks of the world really want to fight fake news, they could do it,” she said. “But as long as their financial model is keeping eyes on the page, they have no incentive to do so. That’s where policymaking needs to come into play.”",0.0,0.0
193,https://arstechnica.com/tech-policy/2022/10/comcast-wants-internet-users-to-pay-more-because-customer-growth-has-stalled/,Comcast wants Internet users to pay more because customer growth has stalled,"Comcast has a problem—it isn't signing up many new broadband customers. But Comcast also has a solution—get more money from existing subscribers.Comcast failed to add any broadband customers in Q2 2022, holding steady at 32,163,000 residential and business Internet customers combined. In its Q3 earnings report released yesterday, Comcast said it gained only 14,000 broadband users in the latest quarter. Comcast also lost 561,000 video customers and 316,000 VoIP phone customers.That's why Comcast executives focused on ARPU (average revenue per user) in an earnings call yesterday. With new customers few and far between, Comcast is aiming for growth in the average amount each existing customer pays.""We expect ARPU growth will continue to be the primary driver of our residential broadband revenue growth in the near term,"" Comcast President and CFO Michael Cavanagh said.Comcast could get more customers by expanding into new territory or by connecting homes in neighborhoods where some people are stuck without broadband even though their neighbors have Comcast Internet service. But Comcast seems content to stick with its current territory and often refuses to provide new hookups unless homeowners pay tens of thousands of dollars upfront—or even $210,000, as described in one of our recent stories.CEO doesn’t expect much subscriber growthComcast CEO Brian Roberts said the nation's largest cable company is ""still in a challenging environment in terms of depressed move activity and increased competition from new entrants."" Robert said there are four primary drivers of growth in Comcast's cable division: ""residential broadband units, residential broadband ARPU, wireless, and business services.""Advertisement""While we don't anticipate residential broadband units to be a significant driver for now, we expect to maintain healthy growth in the other three, leading to continued strong financial performance at cable for the foreseeable future,"" Roberts said. Cavanagh said that ""broadband revenue increased 5.7 percent driven by growth in ARPU and in our customer base compared to last year. Broadband ARPU increased 3.7 percent year over year, consistent with the growth rate in the second quarter.""Comcast also discussed ARPU growth in its earnings call three months ago, suggesting that price increases helped boost per-user revenue in Q2. ""In broadband alone, we had really healthy ARPU growth, 3.6 percent, half being rate-driven, the other half just how we manage tier mix,"" Comcast cable division CEO David Watson said at the time.Meanwhile, Roberts emphasized yesterday that Comcast is ""returning a substantial amount of capital to our shareholders. We pay nearly $5 billion in dividends per year, and we bought back $9.5 billion of our shares year-to-date through the third quarter.""Broadband revenueBroadband revenue was $6.135 billion during the three-month period. That amounts to about $63.55 monthly per subscriber, but includes both business and residential accounts. The Q3 2022 broadband revenue is up from $6.107 billion in Q2 2022, and up from $5.8 billion since Q3 2021.Comcast has multiple ways of getting more money from existing subscribers. That includes selling mobile plans—Comcast added 333,000 wireless lines in the quarter, hitting 4.95 million wireless lines in total. Wireless revenue increased 30.8 percent, reaching $789 million. Comcast also sells home security services.But the Roberts and Cavanagh statements referred specifically to ""broadband ARPU,"" suggesting they want to keep raising broadband bills. That could include increases to basic monthly rates, boosts to fees that raise the cost above advertised prices, or requiring subscribers to purchase the $25-per-month xFi Complete add-on in order to get unlimited data and higher upload speeds.",0.0,0.0
61,https://techxplore.com/news/2022-11-window-coating-cool-energy.html,Clear window coating could cool buildings without using energy,"This window film (held in fingers at top left) keeps rooms bright and cool by allowing visible light to pass in while reflecting invisible infrared and ultraviolet sunlight and radiating heat into outer space. Credit: Adapted from ACS Energy Letters 2022, DOI: 10.1021/acsenergylett.2c01969As climate change intensifies summer heat, demand is growing for technologies to cool buildings. Now, researchers report in ACS Energy Letters that they have used advanced computing technology and artificial intelligence to design a transparent window coating that could lower the temperature inside buildings, without expending a single watt of energy.Studies have estimated that cooling accounts for about 15% of global energy consumption. That demand could be lowered with a window coating that could block the sun's ultraviolet and near-infrared light—the parts of the solar spectrum that typically pass through glass to heat an enclosed room. Energy use could be reduced even further if the coating radiates heat from the window's surface at a wavelength that passes through the atmosphere into outer space. However, it's difficult to design materials that can meet these criteria simultaneously and can also transmit visible light, meaning they don't interfere with the view. Eungkyu Lee, Tengfei Luo and colleagues set out to design a ""transparent radiative cooler"" (TRC) that could do just that.The team constructed computer models of TRCs consisting of alternating thin layers of common materials like silicon dioxide, silicon nitride, aluminum oxide or titanium dioxide on a glass base, topped with a film of polydimethylsiloxane. They optimized the type, order and combination of layers using an iterative approach guided by machine learning and quantum computing, which stores data using subatomic particles. This computing method carries out optimization faster and better than conventional computers because it can efficiently test all possible combinations in a fraction of a second. This produced a coating design that, when fabricated, beat the performance of conventionally designed TRCs in addition to one of the best commercial heat-reduction glasses on the market.In hot, dry cities, the researchers say, the optimized TRC could potentially reduce cooling energy consumption by 31% compared with conventional windows. They note their findings could be applied to other applications, since TRCs could also be used on car and truck windows. In addition, the group's quantum computing-enabled optimization technique could be used to design other types of composite materials.More information: High-Performance Transparent Radiative Cooler Designed by Quantum Computing, ACS Energy Letters (2022). Journal information: ACS Energy Letters High-Performance Transparent Radiative Cooler Designed by Quantum Computing,(2022). DOI: 10.1021/acsenergylett.2c01969",0.0,0.0
587,https://techcrunch.com/2017/06/05/birth-control-app-nurx-now-delivers-to-the-contraceptive-deserts-of-texas/,Birth control app Nurx now delivers to the âcontraceptive desertsâ of Texas,"About half the counties in Texas don’t have the number of public clinics required to meet the contraceptive needs of the population. So Nurx, an at-home birth control delivery app, decided to give women in the state the option to get birth control whenever they want and without ever needing to step into a clinic or even physically see a doctor.Starting today, those in the Lone Star State will be able to tap the Nurx app and get contraceptives delivered straight to their door.While Texas isn’t the only state with a giant “contraceptive desert,” or an area without at least 1 clinic to every 1,000 women in need of publicly funded contraception, it is certainly the biggest area of land in the United States not meeting these needs.And with Trumpcare looming, and Trump’s recent “Religious Freedom” order, which allows businesses to deny birth control coverage based on religious reasons, many women could lose access to their publicly funded birth control pills and even more publicly funded clinics could go under, leaving a large and vulnerable population wide open to other, possibly dangerous methods of preventing birth.While there are plenty of birth control delivery services out on the market, such as Maven, The Pill Club, Lemonaid and BirthControlBuzz, I had a hard time finding any that delivered in Texas (get at me if you do). That’s not to say they won’t at some point, as each of them could easily open up shop in this area, but it does seem Nurx, which is not a free birth control delivery service, but does provide the pills at a reasonable cost, may have discovered a goldmine of people in need, for the time being.For instance, a little more than half of all pregnancies in Texas were unplanned in 2015, costing taxpayers $2.9 billion that year. However, according to a Guttmacher Institute report, the total gross public savings from preventing unintended pregnancies would have been $2.14 billion if women and couples could be empowered to prevent them. Couple that with the teen birth rate in Texas, which sharply declined by 56 percent over the last two decades, thanks in large part to contraceptives, according to the National Campaign to Prevent Teen and Unplanned Pregnancy.Couple that with an additional estimate of more than 19 million women living in these “contraceptive deserts” nationwide and it’s easy to see adding these types of services could save money at the state level by removing middlemen and increasing access, as well as provide a lucrative area for Nurx and other birth control delivery apps to tap.",0.0,0.0
206,https://www.pv-magazine.com/2022/10/27/new-solar-capacity-10-times-cheaper-than-gas-says-rystad/,"New solar capacity 10 times cheaper than gas, says Rystad","Building new solar capacity in Europe could be 10 times cheaper than continuing to operate gas-fired power plants in the long-term, according to a new study by Norway-based research company Rystad Energy.Europe has seen skyrocketing gas prices since the drop in Russian gas exports, with spot prices on the Netherlands-based Title Transfer Facility (TTF) rising to an average €134 ($135.15)/MWh so far this year. Rystad forecasts prices will stabilize at around €31 per MWh by 2030, which puts the LCOE of existing gas-fired plants closer to €150 per MWh.“This is still three times more than the LCOE of new solar PV facilities. For gas-fired plants to continue being competitive, gas prices would need to fall closer to €17 per MWh and carbon prices would need to fall to €10 per tonne, which is currently unthinkable,” the company said in a statement.Popular content“Gas will continue to play an important role in the European energy mix for some time to come, but unless something fundamental shifts, then simple economics, as well as climate concerns, will tip the balance in favor of renewables,” said Carlos Torres Diaz, head of power at Rystad Energy.If gas funds were invested in renewables instead, Europe could replace gas with solar and onshore wind power generation by 2028, when total capacity would reach 333 GW, Rystad forecasts. This estimate assumes a weighted average capital cost for the technologies of €1.3 per watt, as well as a two-year pre-development phase.",0.0,0.0
512,https://www.eurekalert.org/news-releases/968532,US food insufficiency spiked by 25% after monthly Child Tax Credits expired,"In the months after the advance federal Child Tax Credit cash payments ended in December 2021, low-income families with children struggled the most to afford enough foodContact:Jillian McKoy, jpmckoy@bu.eduMichael Saunders, msaunder@bu.eduMichelle Falinski , Michelle.Falinski@bmc.org##In the months after the advance federal Child Tax Credit cash payments ended in December 2021, low-income families with children struggled the most to afford enough food. Black, Latino, Indigenous, and immigrant families were also disproportionately impacted by the loss of the cash relief benefit.When Congress failed to renew advance Child Tax Credit (CTC) payments last year, public health experts feared that the loss of this monthly federal pandemic relief benefit would push millions of families and children in America back into poverty and hunger.Now, a new study led by researchers at Boston University School of Public Health (BUSPH) and Boston Medical Center (BMC) reveals that in the months after this policy ended, there was a substantial increase in the percentage of US households with children that could not afford enough food to eat in a seven-day period—a situation known as food insufficiency.Published in the journal JAMA Network Open, the study found that food insufficiency increased by approximately 25 percent among families with children from January 2022 to July 2022, after they stopped receiving monthly CTC payments on January 15, 2022. The monthly cash benefits were a cornerstone of the Biden administration’s American Rescue Plan, providing an estimated 92 percent of US households up to $3,000 per child ages 6 to 17 and up to $3,600 per child under age 6 from July 2021 to December 2021, with half of the credit amount distributed as advance monthly payments.The study is the first to measure the impact of the expired benefits on food insufficiency among households, and it follows the researchers’ previous study in JAMA Network Open, which showed that the CTC expansion reduced food insufficiency by 26 percent in 2021, findings that President Biden cited during the White House Conference on Hunger, Nutrition, and Health in late September.This increase in food insufficiency is an urgent problem, particularly among households with children, as poor nutrition uniquely affects the health and well-being of growing children, the researchers say.“This significant increase in food insufficiency among families with children is particularly concerning for child health equity, as child health, development, and educational outcomes are strongly linked to their family’s ability to afford enough food,” says study lead and corresponding author Allison Bovell-Ammon, director of policy and communications at Children’s HealthWatch, headquartered at BMC. “Even brief periods of deprivation during childhood can have lasting impacts on a child.”As Congress negotiates a year-end tax relief package, the researchers urge lawmakers to pass a fully refundable and inclusive advance CTC that ensures that all families with children across the US are able to afford enough food to keep their children healthy.“The six short months of these Child Tax Credit advanced payments clearly made a big difference for American families, a permanent expansion would be a game-changer for reducing child poverty for good,” says study senior author Paul Shafer, assistant professor of health law, policy & management at BUSPH. “There is more to do to make sure that very low-income families actually get the monthly payments, prompting efforts like GetCTC.org, but a permanent expansion allows resources and awareness to build around the policy in a way that short-term fixes don’t.”For the study, the researchers examined nationally representative census data on demographic characteristics, employment, social supports, and food insufficiency among nearly 600,000 household families, from July 2021 to July 2022 (the period before and after expiration of the CTC monthly payments).The findings also indicate that the expiration of the CTC exacerbates racial and economic inequities in consistent access to adequate and healthy food. The study showed that low-income households experienced the greatest increases in food insufficiency after the advance payments ended in January—particularly in the spring, after many families likely depleted the second half of their CTC credits issued in a lump sum payment after tax filings. The analysis showed that single-adult, non-Hispanic Black, and Hispanic households—groups that historically have faced greater hardships around food access—also experienced greater food insufficiency after losing their advance CTC payments.“Black, Latino, Indigenous, and immigrant families in the US consistently experience food insecurity—a broader measure that assesses quantity, quality, and variety of food —at higher rates than White families as a result of current and historical marginalization and systemic racism,” Bovell-Ammon says.The expanded CTC in 2021 reduced racial inequities by ensuring access to the credit for predominantly Black, Latino, and Indigenous children who were previously excluded from the full benefits of the CTC, she says.Immigrant families also experienced significant barriers to CTC access, says study coauthor Stephanie Ettinger de Cuba, research associate professor of health law, policy & management at BUSPH and executive director of Children’s HealthWatch. “These barriers were due in part to specific eligibility exclusions, but they also occurred even when immigrant families were eligible. Following the expiration of the payments at the end of 2021, the gains in racial equity were eroded, potentially further exacerbating racial and health inequities and increasing distrust.”This study was also coauthored by Nicole C. McCann and Martha Mulugeta, PhD students in Health Services Research at BUSPH; and Julia Raifman, assistant professor of health law, policy & management at BUSPH.**About Boston University School of Public HealthFounded in 1976, Boston University School of Public Health is one of the top five ranked private schools of public health in the world. It offers master's- and doctoral-level education in public health. The faculty in six departments conduct policy-changing public health research around the world, with the mission of improving the health of populations—especially the disadvantaged, underserved, and vulnerable—locally and globally.About Boston Medical CenterBoston Medical Center (BMC) is a private, not-for-profit, 514-bed, academic medical center that is the primary teaching affiliate of Boston University School of Medicine. It is the largest and busiest provider of trauma and emergency services in New England. BMC offers specialized care for complex health problems and is a leading research institution, receiving more than $110 million in sponsored research funding in fiscal year 2021. It is the 13th largest funding recipient in the U.S. from the National Institutes of Health among independent hospitals. WellSense Health Plan was founded in 1997 as Boston Medical Center HealthNet Plan, now one of the top ranked Medicaid MCOs in the country, as a non-profit managed care organization. Boston Medical Center and Boston University School of Medicine are partners in Boston HealthNet – 12 community health centers focused on providing exceptional health care to residents of Boston. For more information, please visit http://www.bmc.org.",0.0,0.0
262,https://www.euronews.com/next/2022/10/06/amazon-and-alphabet-unit-wing-begin-drone-deliveries-in-parts-of-the-us,Amazon and Alphabet unit Wing begin drone deliveries in parts of the US,"A drone lands and drops off a bag of snacks in the backyard of a Texas house. The bottle of soda has condensation beads on it – it’s still chilled.Drone deliveries have finally become a reality in parts of the United States, and for some users, they arrive in less than 15 minutes.Several drone delivery services including Amazon, Alphabet-owned Wing and Israeli start-up Flytrex have started operating in the country after receiving a green light from the Federal Aviation Administration.Wing says it delivers by drone in about 10 minutes and that its services can help reduce road congestion.""It's more environmentally friendly. These are all electric drones that use very little power,"" said Jacob Demmitt, Wing's marketing and communication manager in the US.""It's also significantly cheaper. You can have a pilot sitting in downtown Dallas, watching flights all over the entire metro (area) someday"".Tiffany Bokhari lives in Frisco, Texas. She first tested Wing's drone delivery app out of curiosity, and she did it again when she needed a band-aid.It's now the third time a drone brings her the light goods she ordered from her smartphone – in this case, snacks and that cold soda.""I think it's better to be delivered by drone versus car because it's helpful for the environment, you know. It saves gas, and money, and saves the environment,"" she said.For now, Wing’s 4.5 kg drone can load food and small products weighing up to 1 kg.Supporters of airborne drop-offs claim that electric drones are more efficient and safer than conventional deliveries done by fossil fuel-powered cars.""Drones don't get tired. They don't try to text while driving. They don't drink and drive…You just get much better service,"" Flytrex CEO Yariv Bash told AFP.For more on this story, watch the video in the media player above.",0.0,0.0
168,https://techcrunch.com/2016/09/09/military-veterans-provide-a-new-competitive-advantage-for-tech-companies/,Military veterans provide a new competitive advantage for tech companies,"Ask any Silicon Valley CEO what some of their biggest challenges are and you likely will hear “finding and retaining great people.” Tech is booming, yet even now that valuations and financing rounds are coming back to earth, it remains incredibly hard to attract and keep talent amid a competitive ecosystem where there are so many companies going after massive ideas.A few companies, however, have figured out a competitive advantage through a relatively untapped source of talent: military veterans — and the idea is starting to catch on.While the tech industry has been rapidly expanding, the U.S. has seen large numbers of military veterans returning to or looking to enter the private sector. Tech companies can’t find enough skilled people, and veterans are looking for exciting careers to utilize their skills. It should be the perfect match.But as I talked to a number of veterans looking for jobs in the tech industry, many were frustrated that employers often didn’t know how to interpret the relevance of their skills or appreciate their capacity for such all-purpose skills as rapid learning, leadership and pure smarts.That realization nearly three years ago led me to cold-call a group called VetsinTech. I’m not a military veteran myself, but I wanted to help; as a venture capitalist, I get to work with a lot of people in tech companies. At the time, VetsinTech was just a small operation with a mission to help train, connect and find jobs for military veterans wanting careers in tech.What happened next inspired all of us. Led by the indefatigable Katherine Webster and a host of champions from the tech community, such as Craig Newmark and Craig Mullaney (to be clear, you don’t have to be named “Craig” to help veterans, but we don’t mind the name either), VetsinTech started hosting career networking events with top tech employers. This included training workshops, mentor sessions and even hackathons to introduce to some of the most exciting tech companies across the country talented men and women who had served in our armed forces. Katherine pointed out recently that over the next five years, approximately one million servicemen and women will return to the workforce.Military veterans are growing and, in some cases, transforming their careers at technology companies.We also found that veterans make some of the best entrepreneurs. A 2011 Small Business Administration (SBA) study concluded that “veterans are at least 45 percent more likely than those with no active-duty military experience to be self-employed.” Mark Rockefeller, CEO and co-founder of StreetShares (and a veteran) noted that one organization has produced more business owners than any other: the U.S. military.So we ran entrepreneurship programs to mentor, educate and network veterans. We even launched a new national initiative out of a White House and Joining Forces working group that we named “VetCap” (capital for veterans), with a workshop program to teach veterans where and how to raise capital for their businesses.A number of titans in the tech world have stepped up, such as Marc Benioff, the founder and CEO of Salesforce. They have a great heart for helping veterans, but they’re also doing it to bring exceptional people into their companies. For a while, these efforts went unnoticed, but that is changing, and a growing number of companies are seeing this competitive advantage in talent acquisition.LinkedIn recently worked with VetsinTech to sponsor an employer meet-up at Ten-X. In May, Joining Forces, under the leadership of First Lady Michelle Obama and Dr. Jill Biden, convened tech companies and announced “110,000 new hiring commitments and nearly 60,000 new training commitments for veterans and military spouses over the next five years, primarily in the fields of aerospace, telecommunications and tech.”VetsinTech and its partners, like Intuit, Salesforce, Microsoft, Palo Alto Networks, Cisco, HPE, Ten-X and Accenture, were all in attendance to support the Joining Forces initiative. Palo Alto Networks and VetsinTech piloted a cybersecurity training program for veterans. Salesforce is running a training program for veterans called VetForce. Facebook has hosted a couple of hackathons for veterans, including the first ever hackathon for female veterans.Overall, VetsinTech has grown to 12 veteran-led chapters across the U.S. in just three years, and gained support from more than 20 top tech companies to hire veterans and develop training programs.Military veterans are growing and, in some cases, transforming their careers at technology companies in Silicon Valley and the rest of the country. There is more work to do, and still far too many qualified veterans looking for an opportunity. But if there’s one thing the tech industry is good at, it’s recognizing the power of extraordinary people, and tech companies have started to tap into a new talent source that will bolster them for the next big innovations ahead.",0.0,0.0
183,https://pubmed.ncbi.nlm.nih.gov/35952344/,"Walking or body weight squat ""activity snacks"" increase dietary amino acid utilization for myofibrillar protein synthesis during prolonged sitting","Access DeniedYour access to the NCBI website at www.ncbi.nlm.nih.gov has been temporarily blocked due to a possible misuse/abuse situation involving your site. This is not an indication of a security issue such as a virus or attack. It could be something as simple as a run away script or learning how to better use E-utilities, http://www.ncbi.nlm.nih.gov/books/NBK25497/, for more efficient work such that your work does not impact the ability of other researchers to also use our site. To restore access and understand how to better interact with our site to avoid this in the future, please have your system administrator contact info@ncbi.nlm.nih.gov.",0.0,0.0
569,https://techcrunch.com/2022/03/01/zero-systems-gets-12m-series-a-to-bring-automation-to-professional-services/,Zero Systems gets $12M Series A to bring automation to professional services,"Zero SystemsZero SystemsThey came up with an AI-driven system that can identify work product on a lawyer’s work systems like their inbox or messaging apps, classify it according to client and project and then move the different kinds of information into adjacent systems such as a document management system or a time management system. The idea was to eliminate a lot of the dreary manual tasks that are part of every lawyer’s day.They came up with an AI-driven system that can identify work product on a lawyer’s work systems like their inbox or messaging apps, classify it according to client and project and then move the different kinds of information into adjacent systems such as a document management system or a time management system. The idea was to eliminate a lot of the dreary manual tasks that are part of every lawyer’s day.“We focused on the high value processes where a cognitive component was required to mimic the decision making process of a human user,” company co-founder and CEO Alex Babin explained.“We focused on the high value processes where a cognitive component was required to mimic the decision making process of a human user,” company co-founder and CEO Alex Babin explained.For lawyers, that starts with governance and properly filing content as it relates to the client and project they’re working on, and moving it into a document management system or client management system automatically. Next, it looks at time management and tracking the lawyer’s time in an automated way and finally it includes a security component to help keep all of that information secure.For lawyers, that starts with governance and properly filing content as it relates to the client and project they’re working on, and moving it into a document management system or client management system automatically. Next, it looks at time management and tracking the lawyer’s time in an automated way and finally it includes a security component to help keep all of that information secure.The system largely targets unstructured data like documents, emails, messages, files and so forth where they live on a laptop, smartphone or other device with the goal of organizing information automatically. It’s worth noting that the solution is installed in the customers’ facilities, rather than in the cloud, says Gevorg Karapetyan, the startup’s CTO and co-founder.The system largely targets unstructured data like documents, emails, messages, files and so forth where they live on a laptop, smartphone or other device with the goal of organizing information automatically. It’s worth noting that the solution is installed in the customers’ facilities, rather than in the cloud, says Gevorg Karapetyan, the startup’s CTO and co-founder.This is partly for security reasons and to meet the requirements of their customers, but also because the data gets processed at the point of ingestion on the edge device the professional is using. “So basically, we bring machine learning and data processing to where the data is, not the other way around. We don’t see that as a limitation, but as a feature in our use case,” he said.This is partly for security reasons and to meet the requirements of their customers, but also because the data gets processed at the point of ingestion on the edge device the professional is using. “So basically, we bring machine learning and data processing to where the data is, not the other way around. We don’t see that as a limitation, but as a feature in our use case,” he said.Over time, they realized the solution would also work for financial services and consulting professionals, who used similar types of systems that would work well with the classification system they had created.Over time, they realized the solution would also work for financial services and consulting professionals, who used similar types of systems that would work well with the classification system they had created.The company launched the product two and a half years ago. It is making headway with the AmLaw 100, the largest law firms in the United States, with 11 customers online using the product and another 10 piloting it. They went from around 25 employees at the beginning of last year to almost 80 by the end of the year, more than tripling head count.The company launched the product two and a half years ago. It is making headway with the AmLaw 100, the largest law firms in the United States, with 11 customers online using the product and another 10 piloting it. They went from around 25 employees at the beginning of last year to almost 80 by the end of the year, more than tripling head count.Babin says that as they build the company and add people, they are focused on building a diverse company, not only because it’s the right thing to do, but because clients expect it. He says part of that is looking outside of tech for people with skills which might be applicable to their mission.Babin says that as they build the company and add people, they are focused on building a diverse company, not only because it’s the right thing to do, but because clients expect it. He says part of that is looking outside of tech for people with skills which might be applicable to their mission.“We bring in people from other industries who want to go into tech, and give them an opportunity to learn a job, which I believe is very, very important. So that’s how we address things because there’s so much we can learn from different cultures, different different backgrounds,” he said.“We bring in people from other industries who want to go into tech, and give them an opportunity to learn a job, which I believe is very, very important. So that’s how we address things because there’s so much we can learn from different cultures, different different backgrounds,” he said.As Zero has gained traction, it required more capital, and today announced a $12 million Series A to help keep building out the platform. Today’s round was led by Streamlined Ventures with participation from 468 Capital, AltaIR Capital, PBJ Capital, Gutbrain Ventures, s16vc, AiSprouts VC, Paul Grewal and others.As Zero has gained traction, it required more capital, and today announced a $12 million Series A to help keep building out the platform. Today’s round was led by Streamlined Ventures with participation from 468 Capital, AltaIR Capital, PBJ Capital, Gutbrain Ventures, s16vc, AiSprouts VC, Paul Grewal and others.",0.0,0.0
118,https://www.ox.ac.uk/news/2022-10-21-remote-digital-platform-working-great-if-you-live-city-oxford-study,"Remote digital platform working is great, if you live in a city - Oxford study","COVID-19 saw the rapid acceleration of workplace information and communication technologies, and the promise of remote work leading to work opportunities more evenly distributed between country and city and internationally.But the new research, published in journal PLOS One, reveals remote work conducted via online labour platforms - such as Fiverr, Freelancer and UpWork - mirrors the geographical and skills-based polarisation of labour markets, rather than spreading work more evenly.If you live in a cosmopolitan area of a developed country, you are much more likely to be employed through the digital platforms Dr Fabian BrasemannThe Oii’s Dr Fabian Brasemann, lead author of the paper says, ‘Working from anywhere is not a technical problem anymore, thanks to digitally enabled remote work. But it remains an economic-institutional one. The remote labour market is globally polarised between countries, between urban and rural areas within countries, and in particular, between job types. So, if you live in a cosmopolitan area of a developed country, you are much more likely to be employed through the digital platforms.’According to the report, ‘Countries are globally divided: North American, European, and South Asian remote platform workers attract most jobs, while many Global South countries participate only marginally….remote jobs are pulled to large cities; rural areas fall behind.’He maintains today’s findings point toward the connection between skills and place-bound institutions as enablers – even of remote work. People with access to specialised education, vocational training and local business opportunities – in other words urban dwellers – will be more likely to have in-demand, digital skills. They will find ample opportunities in the remote labour market. People who do not have the same access to enabling institutions – in other words, people in rural regions – tend not to have the most relevant digital skills. They will have a hard time finding good remote jobs.Many Global South countries participate only marginally….remote jobs are pulled to large cities; rural areas fall behindThe report states, ‘The data shows that most countries in the Global South are only marginally connected to the global web of remote work in the platform labour market. Within countries, we find that remote work flows to urban centres. These are the places where highly skilled labour is concentrated. The economic tale of the ’booming metropolis’ and the ’broken provincial city’ plays out fully in the platform economy.’Key findings reveal the global polarisation in remote labour markets:The majority of remote platform work comes from metropolitan areas in high-income countries such as North America, West Europe and AustraliaMost remote platform workers are located in urban areas in East Europe, South Asia and the PhilippinesMany countries in the Global South only marginally participate in the remote labour marketMost of the high-value remote work goes to metropolitan areas: remote platform workers in capital regions earned between 24% and 53% more per hour than their counterparts in other regions.We believe remote work can become an instrument of economic empowerment and growth...Only in regions that flourish locally, remote workers can succeed globallyThe paper recommendsPlatform apprenticeships for new remote workers: - assign first online jobs randomly to people without experience to build up their initial credibilityGovernment-led digital work programmes: - Embedding online work programmes in rural areas into larger economic and labour market development schemesFoster enablers of remote work: - investments in reliable internet access, local employment opportunities and skill-building opportunities in rural areasIncorporate remote platform work into governmental processes: - advertising short-term remote jobs on platforms while promoting living wagesConnect rural remote worker communities to global network flows: – set up co-working spaces and physical meeting points for platform workers to help with knowledge exchange and skill-buildingDr Braesemann concludes, ‘We believe remote work can become an instrument of economic empowerment and growth. But, for this to happen, remote work needs to be embedded in broader economic and labour market development schemes, supporting disadvantaged regions to invest in local skill development and infrastructure. Only in regions that flourish locally, remote workers can succeed globally.’",0.0,0.0
87,https://www.thelancet.com/journals/lanchi/article/PIIS2352-4642(22)00254-1/fulltext,Continuation of gender-affirming hormones in transgender people starting puberty suppression in adolescence: a cohort study in the Netherlands,"BackgroundIn the Netherlands, treatment with puberty suppression is available to transgender adolescents younger than age 18 years. When gender dysphoria persists testosterone or oestradiol can be added as gender-affirming hormones in young people who go on to transition. We investigated the proportion of people who continued gender-affirming hormone treatment at follow-up after having started puberty suppression and gender-affirming hormone treatment in adolescence.MethodsIn this cohort study, we used data from the Amsterdam Cohort of Gender dysphoria (ACOG), which included people who visited the gender identity clinic of the Amsterdam UMC, location Vrije Universiteit Medisch Centrum, Netherlands, for gender dysphoria. People with disorders of sex development were not included in the ACOG. We included people who started medical treatment in adolescence with a gonadotropin-releasing hormone agonist (GnRHa) to suppress puberty before the age of 18 years and used GnRHa for a minimum duration of 3 months before addition of gender-affirming hormones. We linked this data to a nationwide prescription registry supplied by Statistics Netherlands (Centraal Bureau voor de Statistiek) to check for a prescription for gender-affirming hormones at follow-up. The main outcome of this study was a prescription for gender-affirming hormones at the end of data collection (Dec 31, 2018). Data were analysed using Cox regression to identify possible determinants associated with a higher risk of stopping gender-affirming hormone treatment.Findings720 people were included, of whom 220 (31%) were assigned male at birth and 500 (69%) were assigned female at birth. At the start of GnRHa treatment, the median age was 14·1 (IQR 13·0–16·3) years for people assigned male at birth and 16·0 (14·1–16·9) years for people assigned female at birth. Median age at end of data collection was 20·2 (17·9–24·8) years for people assigned male at birth and 19·2 (17·8–22·0) years for those assigned female at birth. 704 (98%) people who had started gender-affirming medical treatment in adolescence continued to use gender-affirming hormones at follow-up. Age at first visit, year of first visit, age and puberty stage at start of GnRHa treatment, age at start of gender-affirming hormone treatment, year of start of gender-affirming hormone treatment, and gonadectomy were not associated with discontinuing gender-affirming hormones.InterpretationMost participants who started gender-affirming hormones in adolescence continued this treatment into adulthood. The continuation of treatment is reassuring considering the worries that people who started treatment in adolescence might discontinue gender-affirming treatment.FundingNone.",0.0,0.0
101,https://techcrunch.com/2022/03/21/to-raise-a-fund-this-agtech-outfit-built-a-content-company-first-now-it-has-60-million-to-put-to-work/,"To raise a fund, this agtech outfit built a content company first (now it has $60 million to put to work)","Rob Leclerc has the kind of pedigree that investors tend to like: He has a master’s degree in computer science from the University of Calgary and a Ph.D. in computational biology from Yale. In fact, 10 years ago, what he really wanted to do with his degrees was to find and fund agriculture-related projects that tackle climate change.Rob Leclerc has the kind of pedigree that investors tend to like: He has a master’s degree in computer science from the University of Calgary and a Ph.D. in computational biology from Yale. In fact, 10 years ago, what he really wanted to do with his degrees was to find and fund agriculture-related projects that tackle climate change.But a decade ago, “agtech” wasn’t yet a category, and that was problematic when it came to pitching investors on the concept of an investment fund that Leclerc would run with partner Michael Dean, with whom Leclerc had previously operated an agribusiness in West Africa for several years.But a decade ago, “agtech” wasn’t yet a category, and that was problematic when it came to pitching investors on the concept of an investment fund that Leclerc would run with partner Michael Dean, with whom Leclerc had previously operated an agribusiness in West Africa for several years.At the time, “there were a handful of businesses” relating to agtech that investors were aware of, Leclerc said. Think Climate Corp and Impossible Foods and the smart machinery company Blue River. But Climate Corp hadn’t yet sold to Monsanto forAt the time, “there were a handful of businesses” relating to agtech that investors were aware of, Leclerc said. Think Climate Corp and Impossible Foods and the smart machinery company Blue River. But Climate Corp hadn’t yet sold to Monsanto for“The overarching problem was narrative,” Leclerc said.  “People didn’t care about it.”“The overarching problem was narrative,” Leclerc said.  “People didn’t care about it.”He and Dean might have just given up; instead, they started a San Francisco-based content company calledHe and Dean might have just given up; instead, they started a San Francisco-based content company called“We thought if we could get people excited about food and [agriculture], maybe we’d be in a position to [raise a fund later],” Leclerc said. It was a smart bet. Fast forward and after posting more than 4,000 articles to the site and garnering 90,000 subscribers to the site’s weekly newsletter, Leclerc said“We thought if we could get people excited about food and [agriculture], maybe we’d be in a position to [raise a fund later],” Leclerc said. It was a smart bet. Fast forward and after posting more than 4,000 articles to the site and garnering 90,000 subscribers to the site’s weekly newsletter, Leclerc saidIt’s a huge step up from previous funds that Leclerc and company began raising several years ago – beginning with their newsletter readers. “We first raised a $2.5 million friends-and-family fund,” he said, “but then five months later, we needed more money, so we raised $2 million, then six months later, we raised $5 million.” And so on. It wasn’t the most conventional way to raise money, but AgFunder had this “massive subscriber base” to which it could talk directly about its fundraising efforts, Leclerc said, “and the belief that we know what we’re doing and can spot companies started a lot of conversations that we wouldn’t have had otherwise. It became a structural advantage.”It’s a huge step up from previous funds that Leclerc and company began raising several years ago – beginning with their newsletter readers. “We first raised a $2.5 million friends-and-family fund,” he said, “but then five months later, we needed more money, so we raised $2 million, then six months later, we raised $5 million.” And so on. It wasn’t the most conventional way to raise money, but AgFunder had this “massive subscriber base” to which it could talk directly about its fundraising efforts, Leclerc said, “and the belief that we know what we’re doing and can spot companies started a lot of conversations that we wouldn’t have had otherwise. It became a structural advantage.”The strategy isn’t unprecedented. Leclerc said he was partly inspired by Michael Arrington, the founder of TechCrunch, who built a brand around entrepreneurship, then used the strength of that brand to launch an investing career. Meanwhile, Arrington was preceded in his path by investor Jason Calacanis, who earlier founded a media company, and more recent examples are beginning to emerge routinely. Among them: Londoner Harry Stebbings used his “Twenty Minute VC” podcast as a springboard into the venture world last year, and Nik Milanović, the author of a two-year-old newsletter called “This Week in Fintech,” in January launched anThe strategy isn’t unprecedented. Leclerc said he was partly inspired by Michael Arrington, the founder of TechCrunch, who built a brand around entrepreneurship, then used the strength of that brand to launch an investing career. Meanwhile, Arrington was preceded in his path by investor Jason Calacanis, who earlier founded a media company, and more recent examples are beginning to emerge routinely. Among them: Londoner Harry Stebbings used his “Twenty Minute VC” podcast as a springboard into the venture world last year, and Nik Milanović, the author of a two-year-old newsletter called “This Week in Fintech,” in January launched anStill, newsletter subscribers –  no matter how deep their pockets –  don’t invest tens of millions of dollars in a team without seeing some results first. And AgFunder (which has since broadened its LP base) already has some about which to brag. Among the 60 companies to so far receive a check from AgFunder was the autonomous tractor startup Bear Flag Robotics, which sold to John Deere last year forStill, newsletter subscribers –  no matter how deep their pockets –  don’t invest tens of millions of dollars in a team without seeing some results first. And AgFunder (which has since broadened its LP base) already has some about which to brag. Among the 60 companies to so far receive a check from AgFunder was the autonomous tractor startup Bear Flag Robotics, which sold to John Deere last year forIf you’re curious about how much the firm owned in each of these companies, keep guessing. AgFunder – which tends to write checks of $500,000 as a starting point but also just wrote a check for $3 million – doesn’t think about ownership targets or look to own a specific percentage in a company, Leclerc said. While his team has used special purpose vehicles to maintain their pro rata in several companies, including a still-private molecular coffee company calledIf you’re curious about how much the firm owned in each of these companies, keep guessing. AgFunder – which tends to write checks of $500,000 as a starting point but also just wrote a check for $3 million – doesn’t think about ownership targets or look to own a specific percentage in a company, Leclerc said. While his team has used special purpose vehicles to maintain their pro rata in several companies, including a still-private molecular coffee company calledAs for criteria, AgFunder looks broadly across the food and “ag value chain,” Leclerc said. It also invests broadly geographically, with bets in India, Brazil, Mexico and Indonesia, among other places.As for criteria, AgFunder looks broadly across the food and “ag value chain,” Leclerc said. It also invests broadly geographically, with bets in India, Brazil, Mexico and Indonesia, among other places.It’s lot of ground to cover, so the outfit relies heavily on itsIt’s lot of ground to cover, so the outfit relies heavily on itsYet AgFunder has other sources of deal flow, too, and one of these is, yes, that newsletter readership. Indeed, asked about how it found that coffee company Atomo — which says its product producesYet AgFunder has other sources of deal flow, too, and one of these is, yes, that newsletter readership. Indeed, asked about how it found that coffee company Atomo — which says its product produces“An LP who’d followed us for a long time on AgFunder News wrote us, saying, ‘You probably see a lot of things; this company you should check out.’ So we did,” Leclerc said.“An LP who’d followed us for a long time on AgFunder News wrote us, saying, ‘You probably see a lot of things; this company you should check out.’ So we did,” Leclerc said.",0.0,0.0
103,https://www.world-nuclear-news.org/Articles/Application-submitted-for-US-molten-salt-research,Application submitted for US,"Application submitted for US molten salt research reactor19 August 2022ShareAbilene Christian University (ACU) has applied to the US Nuclear Regulatory Commission (NRC) for a construction licence for a molten salt research reactor (MSRR), to be built on its campus in Abilene, Texas, as part of the Nuclear Energy eXperimental Testing (NEXT) laboratory. ​ACU plans for the MSRR to achieve criticality by December 2025.The Science and Engineering Research Centre at Abilene, which will house the MSRR (Image: ACU)The planned reactor would be an up to 1 MWt, graphite-moderated, fluoride salt flowing fluid (fuel dissolved in the salt) research reactor. The MSRR will be used for on-campus nuclear research and training opportunities for faculty, staff and students in advanced nuclear technologies. The reactor will significantly expand the university's salt reactor research and development infrastructure, supporting US molten salt reactor design, development, deployment and market penetration.​​In March 2020, ACU submitted to the NRC a Letter of Intent to apply for a construction permit for a non-power molten salt reactor. In July 2020, it submitted a Regulatory Engagement Plan related to this project.ACU has now submitted its construction licence application - including a Preliminary Safety Analysis Report (PSAR) and an Environmental Review - to the NRC on 15 August.According to ACU, the move represents the first application for a new US research reactor of any kind in more than 30 years, as well as the first-ever university application for an advanced research reactor.The NRC will now conduct an acceptance review to determine if ACU's application is complete. It will then develop a review schedule and initiate a formal technical review of the project.ACU said it currently expects to complete construction of the MSRR at the earliest six months after issuance of the construction permit and latest by 48 months after issuance of the construction permit.The ACU-led NEXT Research Alliance (NEXTRA) - which also includes the Georgia Institute of Technology, Texas A&M University and the University of Texas-Austin - is working with a USD30.5 million research agreement sponsored by Natura Resources, with USD21.5 million going to ACU and the remaining USD9 million to the other consortium universities. The NEXTRA partnership was established to design, build and license the first-ever MSRR.ACU recently contracted Teledyne Brown Engineering (TBE) to perform Front End Engineering Design services for the MSRR. TBE is the prime contractor to ACU, providing preliminary design services (developing designs, sizes, specification and estimated costs) for the reactor.TBE said once it has completed preliminary design and engineering studies in the initial contract, follow-on work will include detailed design, reactor and systems manufacturing, site integration and installation.Researched and written by World Nuclear NewsRelated topics",0.0,0.0
102,https://www.zdnet.com/article/criminals-are-using-gps-jammers-to-hijack-trucks-and-down-drones/,GPS jammers are being used to hijack trucks and down drones: How to stop them,"By PopTika -- ShutterstockSatellite navigation and tracking via GPS has become a critical link in the world's rapidly growing logistics and freight carrying ecosystem. Companies use GPS to track trucks and keep them on time and their cargo secure.Little wonder, then, that criminals are turning to cheap GPS jamming devices to ransack the cargo on roads and at sea, a problem that's getting worse but may be ameliorated with a new generation of safety technology designed to overcome threats from jamming.In case you aren't a master criminal or a secret agent, here's some background. The core problem for any system using GPS is that the signals are extremely weak, an inevitable byproduct of the vast distances those signals need to travel. Jammers work by overpowering GPS signals by emitting a signal at the same frequency, just a bit more powerful than the original. The typical jammers used for cargo hijackings are able to jam frequencies from up to 5 miles away rendering GPS tracking and security apparatuses, such as those used by trucking syndicates, totally useless.In Mexico, jammers are used in some 85% of cargo truck thefts. Statistics are harder to come by in the United States, but there can be little doubt the devices are prevalent and widely used. Russia is currently availing itself of the technology to jam commercial planes in Ukraine.As we've covered, the proliferating commercial drone sector is also prey to attack. Drones often rely on GPS for navigation as well as security tracking, making them especially vulnerable. Drones equipped with back-up methods still often rely on GPS for positioning, navigation, and stabilization, making jammers a way to take a drone down and potentially cause harm to life and property. During a light show in Hong Kong in 2018, a jamming device caused 46 drones to fall out of the sky, raising public awareness of the issue.Technologies are emerging to counter this problem. A company called infiniDome has developed an anti-jamming solution that is compatible with almost any GPS-based telematics unit, a catch-all term for the technologies trucking companies use to track and monitor their assets on the road. InfiniDome's ""OtoSphere"" is a small add-on device created for commercial GNSS receivers, providing protection and increasing the resiliency of GPS devices against jamming attacks. By identifying and preventing instances of jamming, fleet operators are able to prevent cargo theft.Other companies, such as Sepentrio, are also taking GPS jamming in drone applications seriously with integrated sensor solutions.In the meantime, governments are hoping to fight back through regulation, although that may be a losing battle. Mexico passed an anti-jamming law in late 2020, allowing for penalties of 12-15 years in prison for persons caught using such devices while committing crimes.Nevertheless, jammers remain widely available online, where they can be purchased for as little as $50.",0.0,0.0
150,https://www.sciencenews.org/article/seabirds-typhoons-shearwaters-survival,Some seabirds survive typhoons by flying into them,"Some seabirds don’t just survive storms. They ride them.Streaked shearwaters nesting on islands off Japan sometimes head straight toward passing typhoons, where they fly near the eye of the storm for hours at a time, researchers report in the Oct. 11 Proceedings of the National Academy of Sciences. This strange behavior — not reported in any other bird species — might help streaked shearwaters (Calonectris leucomelas) survive strong storms.Birds and other animals living in areas with hurricanes and typhoons have adopted strategies to weather these deadly storms (SN: 10/2/15). In recent years, a few studies using GPS trackers have revealed that some ocean-dwelling birds — such as the frigatebird (Fregata minor) — will take massive detours to avoid cyclones.This is an understandable strategy for birds that spend most of their time at sea where “there is literally nowhere to hide,” says Emily Shepard, a behavior ecologist at Swansea University in Wales. To find out whether shearwaters also avoid storms, she and her colleagues used 11 years of tracking data from GPS locators attached to the wings of 75 birds nesting on Awashima Island in Japan.By combining this information with data on wind speeds during typhoons, the researchers discovered that shearwaters that were caught out in the open ocean when a storm blew in would ride tailwinds around the edges of the storm. However, others that found themselves sandwiched between land and the eye of a strong cyclone would sometimes veer off their usual flight patterns and head toward the center of the storm.Flight path As Typhoon Cimaron moved across the Sea of Japan (black track) in August 2018, GPS trackers monitored the movements of 32 streaked shearwaters (Calonectris leucomelas) just off the coast of Japan. The tracking data show three birds (seen here in red and teal) flew toward the eye of the storm through some of the highest winds. Two other birds (light green) began heading toward the eye as the storm swept past. Tracking streaked shearwaters during Typhoon Cimaron E. Lempidakis et al/PNAS 2022 ( CC BY NC-ND 4.0Of the 75 monitored shearwaters, 13 flew to within 60 kilometers of the eye — an area Shepherd calls the “eye socket,” where the winds were strongest — for up to eight hours, tracking the cyclone as it headed northward. “It was one of those moments where we couldn’t believe what we were seeing,” Shepard says. “We had a few predictions for how they might behave, but this was not one of them.”The shearwaters were more likely to head for the eye during stronger storms, soaring on winds as swift as 75 kilometers per hour. This suggest that the birds might be following the eye to avoid being blown inland, where they risk crashing onto land or being hit by flying debris, Shepard says.While this is the first time this behavior has been spotted in any bird species, flying with the winds could be a common tactic for preserving energy during cyclones, says Andrew Farnsworth, an ornithologist at Cornell University who was not involved in the study. “It might seem counterintuitive,” he says. “But from the perspective of bird behavior, it makes a lot of sense.”",0.0,0.0
196,https://apnews.com/article/british-politics-technology-europe-boris-johnson-civil-service-b3f505a4ecf8bf11e4b89fea2113583d,UK politicians demand probe into Liz Truss phone hack claim,"FILE - Britain's Foreign Secretary Liz Truss leaves a Cabinet meeting at 10 Downing Street in London, Tuesday, April 19, 2022. The British government insisted Sunday, Oct. 30, 2022 it has robust cybersecurity for government officials, after a newspaper reported that former Prime Minister Liz Truss’ phone was hacked while she was U.K. foreign minister. (AP Photo/Alastair Grant, File)FILE - Britain's Foreign Secretary Liz Truss leaves a Cabinet meeting at 10 Downing Street in London, Tuesday, April 19, 2022. The British government insisted Sunday, Oct. 30, 2022 it has robust cybersecurity for government officials, after a newspaper reported that former Prime Minister Liz Truss’ phone was hacked while she was U.K. foreign minister. (AP Photo/Alastair Grant, File)LONDON (AP) — The British government insisted Sunday it has robust cybersecurity for government officials, after a newspaper reported that former Prime Minister Liz Truss’ phone was hacked while she was U.K. foreign minister.The Mail on Sunday said that the hack was discovered when Truss was running to become Conservative Party leader and prime minister in the summer. It said the security breach was kept secret by then-Prime Minister Boris Johnson and the head of the civil service.The newspaper, citing unnamed sources, said Russian spies were suspected of the hack. It said the hackers gained access to sensitive information, including discussions about the Ukraine war with foreign officials, as well as private conversations between Truss and a political ally, former Treasury chief Kwasi Kwarteng.The U.K. government spokesperson declined to comment on security arrangements, but said it had “robust systems in place to protect against cyber threats,” including regular security briefings for ministers.ADVERTISEMENTOpposition parties demanded an independent investigation into the hack, and into the leak of the information to a newspaper.“Was Liz Truss’s phone hacked by Russia, was there a news blackout and if so why?” said Liberal Democrat foreign affairs spokesperson Layla Moran. “If it turns out this information was withheld from the public to protect Liz Truss’ leadership bid, that would be unforgivable.”Labour Party law-and-order spokesperson Yvette Cooper said “the story raises issues around cybersecurity.”“It’s why cybersecurity has to be taken so seriously by everyone across government, the role of hostile states,” she told Sky News. “But also the allegations about whether a Cabinet minister has been using a personal phone for serious government business, and serious questions about why this information or this story has been leaked or briefed right now.”",0.0,0.0
580,https://techcrunch.com/2018/09/05/mccarthyfinch-ai-services-platform-automates-tedious-legal-tasks/,McCarthyFinch AI services platform automates tedious legal tasks,"McCarthyFinch sounds a bit like a law firm — and with good reason. The startup has developed an AI as a Service platform aimed at the legal profession. This week, it’s competing in the 2018 TechCrunch Disrupt Battlefield in San Francisco.The company began life as a project at a leading New Zealand law firm, MinterEllisonRuddWatts. They wanted to look at how they could take advantage of AI to automate legal processes to make them more efficient, cost-effective and faster, according to company president Richard DeFrancisco.“They were working on leveraging technology to become the law firm of the future, and they realized there were some pretty tremendous gaps,” he explained. They found a bunch of Ph.Ds working on artificial intelligence who worked with more than 30 lawyers over time to address those gaps by leveraging AI technology.That internal project was spun out as a startup last year, emerging as an AI platform with 18 services. MinterEllison, along with New Zealand VC Goat Ventures, gave the fledgling company US$2.5 million in pre-seed money to get started.The company looked at automating a lot of labor-intensive tasks related to legal document review and discovery such as document tagging. “Lawyers spend a lot of time tagging things with regards to what’s relevant and not relevant, and it’s not a good use of their time. We can go through millions of documents very quickly,” DeFrancisco said. He claims they can lower the time it takes to tag a set of documents in a lawsuit from weeks to minutes.[gallery ids=""1705643,1705649,1705647,1705648,1700421,1700422,1700423,1700424,1700425,1700426,1700427,1700428,1700429""]He says that one of their key differentiators is their use of natural language processing (NLP), which he says allows the company to understand language and nuance to interpret documents with a high level of accuracy, even when there are small data sets. Instead of requiring thousands of documents to train their models, which he says law firms don’t have time to do, they can begin to understand the gist of a case in as little as two or three documents with 90 percent accuracy, based on their tests.They don’t actually want to sell their platform directly to law firms. Instead, they hope to market their artificial intelligence skills as a service to other software vendors with a legal bent who are looking to get smarter without building their own AI from scratch.“What we are doing is going to technology service providers and talking to them about using our solution. We have restful APIs to integrate into their technology and do a Powered By-model,” DeFrancisco explained.The startup currently has 10 trials going on. While he couldn’t name them, he did say that they include the largest law firm in Europe, largest global provider of legal information and the fastest growing SaaS company in history. They are also working on agreements with large systems integrators including Deloitte and Accenture to act as resellers of their solution.While they are based in New Zealand, they plan to open a U.S. office in the Los Angeles area shortly after Disrupt. The engineering team will remain in New Zealand, and DeFrancisco will build the rest of the company in the U.S as it seeks to expand its reach. They also plan to start raising their next round of funding.",0.0,0.0
142,https://www.scientificamerican.com/article/a-supersmeller-can-detect-the-scent-of-parkinsons-leading-to-an-experimental-test-for-the-illness/,"A Supersmeller Can Detect the Scent of Parkinsonâs, Leading to an Experimental Test for the Illness","A Scottish woman named Joy Milne made headlines in 2015 for an unusual talent: her ability to sniff out people afflicted with Parkinson’s disease, a progressive neurodegenerative illness that is estimated to affect nearly a million people in the U.S. alone. Since then a group of scientists in the U.K. has been working with Milne to pinpoint the molecules that give Parkinson’s its distinct olfactory signature. The team has now zeroed in on a set of molecules specific to the disease—and has created a simple skin-swab-based test to detect them.Milne, a 72-year-old retired nurse from Perth, Scotland, has hereditary hyperosmia, a condition that endows people with a hypersensitivity to smell. She discovered that she could sense Parkinson’s with her nose after noticing her late husband, Les, was emitting a musky odor that she had not detected before. Eventually, she linked this change in scent to Parkinson’s when he was diagnosed with the disease many years later. Les passed away in 2015.In 2012 Milne met Tilo Kunath, a neuroscientist at the University of Edinburgh in Scotland, at an event organized by the research and support charity Parkinson’s UK. Although skeptical at first, Kunath and his colleagues decided to put Milne’s claims to the test. They gave her 12 T-shirts, six from people with Parkinson’s and six from healthy individuals. She correctly identified the disease in all six cases—and the one T-shirt from a healthy person she categorized as having Parkinson’s belonged to someone who went on to be diagnosed with the disease less than a year later.Subsequently, Kunath, along with chemist Perdita Barran of the University of Manchester in England and her colleagues, has been searching for the molecules responsible for the change in smell that Milne can detect. The researchers used mass spectrometry to identify types and quantities of molecules in a sample of sebum, an oily substance found on the skin’s surface. They discovered changes to fatty molecules known as lipids in people with Parkinson’s.In their latest study, published on September 7 in the American Chemical Society journal JACS Au, the researchers revealed the results of using a simple skin-swab-based test to detect the lipid signature that is indicative of Parkinson’s. By comparing sebum samples from 79 people with Parkinson’s and 71 people without the illness, the team zeroed in on a set of large lipids that could be detected in a matter of minutes using a special type of mass spectrometry in which substances are rapidly transferred from a swab to an analyzer using just a piece of paper.“I think it’s a very promising set of biomarkers,” says Blaine Roberts, a biochemist at Emory University, who wasn’t involved in the work. He adds that one of the big open questions that remains is how exacting this test can be. While the authors of the September 7 study reported the detailed chemical profile of the unique Parkinson’s signature, they did not include an assessment of its accuracy. According to Barran, based on not-yet-published data, their test appears to be able to determine whether an individual has Parkinson’s with more than 90 percent accuracy.Tiago Outeiro, a neuroscientist at the University of Göttingen in Germany, who was not involved with the research, says the sebum-based swab test is novel and has clear advantages, such as the ease of sample collection. Outeiro wonders whether people with diseases that share symptoms and pathologies with Parkinson’s disease, such as multiple system atrophy, also have similar chemical markers.The team is now working with local hospitals to determine whether this sebum-based test can also be conducted in clinical labs—a key step toward determining whether it can be used as a diagnostic tool. Ultimately, Barran says, the hope is to use the test to help identify individuals who have been referred to their neurologists by their general practitioner for suspected Parkinson’s so they can receive a faster diagnosis. Currently, there are thousands of people waiting to see a neurologist in the U.K.’s National Health Service, and it will take an estimated two years to clear that list, Barran says. A skin-swab test could enable those patients to mail in skin swabs to be analyzed in the hospital laboratory and pinpoint those who need help most urgently. Barran’s research team is approaching people on the waiting list to see if they are willing to take part in a trial to see whether such skin-swab tests could prove effective in helping to speed up the triage process.Barran and her colleagues are also collaborating with a group at Harvard University to determine whether sebum-based biomarkers are detectable in people who have constipation, a reduced sense of smell or other early signs of Parkinson’s but have not yet received a diagnosis.Milne has inspired groups elsewhere to search for biomarkers based on the disease’s olfactory signature. This year researchers in China published a paper describing an electronic nose—an artificial-intelligence-based sensor modeled after the olfactory system—that sniffs out molecules present in the sebum of patients with Parkinson’s disease. Other groups in China, the U.K. and elsewhere have also been training dogs to sniff out the disease.Parkinson’s may not be the only disease Milne has a nose for. She’s also reported noticing a unique smell in people with Alzheimer’s, cancer, and tuberculosis and is working with scientists to see whether a specific olfactory signature of those diseases can be deduced.For Milne, the hope is that this work will ultimately benefit patients with these conditions. “My husband suffered from [Parkinson’s] for 21 years after his diagnosis, but he had it many years before that,” Milne told Scientific American in 2015. “I would like to see that people don’t suffer the way he suffered.”",0.0,0.0
564,https://techcrunch.com/2022/07/08/this-startup-hopes-to-get-us-to-net-zero-via-its-platform-to-construct-wooden-buildings/,This startup hopes to get us to net zero via its platform to construct wooden buildings,"This startup hopes to get us to net zero via its platform to construct wooden buildingsOne of the stunning facts that’s emerged over the last few years — especially as VCs and startups have turned their attention toward the climate crisis — is that our cities produce an enormous amount of CO 2 : In fact, buildings are responsible for around 40% of global CO 2 emissions. But of course, the problem is that cities are unlikely to stop building, and growiing.Some estimates say that if global urban growth continues at its current pace, then we’d build a New York City every month for the next 40 years. So if we could reduce this amount or transition, this growth to “net zero” (or better), we’d would do to a lot alleviate the impending, and disastrous, affects of climate change. This is why we are seeing so many new climate funds appear, which are concentrating on the built environment.A large part of this problem is that concrete and steel are just not sustainable materials, unlike (say) timber.Now, “011h“, based out of Barcelona, thinks it might have the answer.Currently, the building processes that use manual labor and usustainalble materials don’t pass muster, so if you can standardize and digitize the building process to make it repeatable and scalable (says 011h) while shifting sustainable materials — like mass timber — you can allow architects, builders, developers and investors to make net-zero buildings faster, cheaper and more sustainable.It all sounds lovely in theory, but in fact 011h says it has already completed such a project with Renta Corporación, a publicly traded developer, where the “embodied carbon” of the building was reduced by more than 90% compared to conventional methods, while construction timelines were reduced by 35%. This has led to three more major projects being commissioned.No doubt partly as a result of this, 011h has now raised a significant €25 million in Series A funding. The funding round was led by Redalpine, accompanied by Seaya Andromeda and Breega, with the participation of Aldea Ventures, among others. Previous investors also joined the round, including Giuseppe Zocco, Foundamental and A/O Proptech, which accelerates 011h’s ambition to create a sustainably built world.The funding will be used to further develop 011h’s platform, building system and team, initially focusing on Spain, then internationally.Lucas Carné, co-founder and co-CEO of 011h, said the impact of reducing the carbon footprint of building can’t be iunderestimated: “If the embodied carbon of every building were reduced by more than 90%, this would reduce 10% of annual global CO 2 emissions, this is equivalent to three gigatonnes of CO 2 every year. In real terms, this is almost 2x more carbon than completely transitioning from petrol to electric vehicles; and is equivalent to eliminating 1 billion domestic gas boilers,” he told me.Harald Nieder, general partner of Redalpine, added in a statement: “At Redalpine, we believe that there are massive opportunities around sustainability. In fact, the opportunities are such that we are not looking for marginal improvements of the status quo. We are looking for teams that are aiming to have a real impact, worthy of the global challenges we are facing. Construction is both one of the most unsustainable industries and one of the least digital and the 011h vision is exactly what we were looking to support.”",0.0,0.0
428,https://www.psypost.org/2022/10/unique-therapy-that-alters-memory-processes-could-reduce-psychological-disturbances-following-romantic-betrayal-64138,Unique therapy that alters memory processes could reduce psychological disturbances following romantic betrayal,"A novel technique that uses a beta blocker to interfere with memory reconsolidation shows promise in the treatment of adjustment disorder following romantic betrayal, according to new research published in the Journal of Affective Disorders.Adjustment disorder is a condition that can occur in response to a significant life event or change. While it is normal to feel some degree of anxiety or distress in such situations, people with adjustment disorder experience more intense and long-lasting symptoms that interfere with their ability to cope. These may include difficulty sleeping, depressed mood, social withdrawal, and difficulty concentrating. In severe cases, adjustment disorder can lead to self-harm or suicidal thoughts.“There is no recognized empirically-based treatment for adjustment disorders,” said study author Alain Brunet, a clinical psychologist and psychiatry professor at McGill University. “This is an oddity. We were interested in determining if the good clinical results we had obtained in treating PTSD with Reconsolidation Therapy applied to a broader set of trauma-like conditions, hence our interest for adjustment disorder.”“Romantic Betrayal (a form of adjustment disorder) seemed like an interesting topic to study because, first, it is very distressing. Second, it is one of the most common reason why individuals seek professional help. Finally, there is very little help available for romantically betrayed individuals who do not wish to return with their partner.”Propranolol is a beta blocker that is often prescribed for high blood pressure, migraines, and certain anxiety disorders. But the drug has also been shown to weaken the emotional tone of memories by blocking adrenergic pathways.“Reconsolidation Therapy consist in recalling a bad memory under the influence of propranolol with the help of a trained therapist,” Brunet explained. “This treatment approach is a translational treatment stemming from the research in neuroscience which stipulates that a recalled memory needs to be saved again to long-term memory storage in order to persist. Interfering with the storage process will yield a degraded (less emotional) memory.”In the new study, Brunet and his colleagues recruited adults who met the DSM-5 criteria for adjustment disorder. The participants had all experienced a romantic betrayal event, such as infidelity, that occurred during a monogamous long-term relationship.The researchers asked the participants to write a first-person narrative of their romantic betrayal/abandonment event. The participants were told to focus on the most emotionally provocative aspects of the event and to include stress-related reactions, such as feeling tense, trembling, and sweating. During treatment sessions, the participants ingested propranolol before reading their narrative out loud once. Fifty-five participants completed at least one treatment session, while 48 completed all five sessions.To assess clinically significant symptoms, the participants completed a widely used questionnaire known as the Impact of Event Scale — Revised (IES-R) before, during, and after the treatment phase. The researchers observed a large drop in IES-R scores immediately following the first treatment. The declines in IES-R scores continued over the course of the treatment phase. Thirty-five participants who completed a follow-up survey provided evidence that the improvements in symptom endured up to 4 months.“Our study suggests that Reconsolidation Therapy works with adjustment disorder, in that it is clearly superior to a wait-list group (subjects were their own control),” Brunet told PsyPost. “The magnitude of the pre-post treatment improvement compares to results we obtained in our PTSD research.”Brunet said he was surprised by how high the IES-R scores were prior to treatment. “Looking at the severity of symptoms, were surprised at how painful adjustment disorder can be,” the researcher explained. “Adjustment disorder is no ‘wimpy’ disorder. This is clearly a misconception.”The study utilized a within-subjects open-label design, which limits the ability to draw strong conclusions about causality. However, the findings provide an important foundation for future research. “In spite of its moderate size, the study is important in that it provides the treatment ‘effect sizes’ required to launch a placebo-controlled randomized controlled trial,” Brunet said.The study, “Treatment of adjustment disorder stemming from romantic betrayal using memory reactivation under propranolol: A open-label interrupted time series trial“, was authored by Michelle Lonergan, Daniel Saumier, Sereena Pigeon, Pierre E. Etienne, and Alain Brunet.",0.0,0.0
465,https://techcrunch.com/2022/08/29/meet-the-judges-for-the-minneapolis-minn-techcrunch-live-pitch-off/,Meet the judges for the Minneapolis TechCrunch Live pitch-off,"TechCrunch Live is hosting a special, extended event focused on the great city of Minneapolis, Minnesota on September 7. I hope you can join us. We have an agenda packed with insiders who can speak to the growing startup ecosystem in the Twin Cities. But for the pitch-off, we’ve recruited two outsiders to judge the local startups: Mahati Sridhar, vice president, Rise of the Rest Seed Fund and Sarah Hinkfuss, partner, Bain Capital Ventures.Both Mahati and Sarah offer considerable investment and startup experience. We’re thrilled to have their participation.To help highlight what the city has to offer, we’re enlisting the help of local startups! Like past City Spotlights, this one will feature a pitch-off with local Minneapolis startups pitching to VCs. The winner gets fast-tracked into Startup Battlefield 200, which includes free exhibition space at TechCrunch Disrupt 2022. Applications are closed, but everyone can register for the event here.Mahati Sridhar, vice president, Rise of the Rest Seed FundMahati is a vice president on the investment team at Revolution’s Rise of the Rest Seed Fund. She joined the firm in 2021 and focuses on sourcing, due diligence and supporting existing portfolio companies. Prior to joining Revolution, Mahati was an associate at Bull City Venture Partners, a Durham-based venture capital fund where she worked on seed and Series A software and internet investments in the Southeast and Mid-Atlantic. Mahati is also a Venture for America Fellow and served her fellowship in Charlotte where she helped launch CFV Ventures, an early-stage fintech-focused venture fund. She started her career in Investment Banking at SunTrust Robinson Humphrey where she worked on the healthcare coverage team. Mahati received a B.S. in Business Administration from UNC-Chapel Hill and an MBA from Columbia Business School. Mahati originally hails from Raleigh but currently calls New York City home.Sarah Hinkfuss, partner, Bain Capital VenturesSarah Hinkfuss works with growth-stage founders across both application software and fintech. She is particularly interested in backing founders who have personal experience in the market they are creating. Ms. Hinkfuss joined Bain Capital in 2020 as a vice president on the Tech Opportunities team. Prior to joining Bain Capital, Ms. Hinkfuss worked as an associate in KKR’s Growth Equity group in San Francisco. Prior to that she was a senior vice president at Applied Predictive Technologies, an enterprise SaaS company acquired by Mastercard in 2015. Ms. Hinkfuss received an MBA from Stanford Graduate School of Business, where she was an Arjay Miller Scholar and Siebel Scholar. She graduated cum laude with a BA in Economics and Environmental Science and Public Policy from Harvard College, where she was a Hoopes Prize recipient and Weatherhead Research Fellow.AgendaTechCrunch Live in Minneapolis, MinnesotaRaising capital outside of the coasts with Anna Mason (Rise of the Rest Seed Fund) + Andrew Leone (Dispatch)Andrew Leone’s Dispatch provides businesses with an on-demand courier delivery service. Headquartered in the greater Minneapolis, Minnesota area, the startup is quickly becoming a shining star in the area’s exploding startup ecosystem. It’s the type of startup that captures the attention of local investors, but outsiders as well including Anna Mason, managing partner at Revolution’s Rise of the Rest fund.Who’s writing checks in MSP with Mary Grove (Bread & Butter Fund) and Justin Kaufenberg (Rally Ventures)A panel on the growth opportunities for Minnesota from the perspective of VC funds – what’s needed in the market, what are they funding right, where startups should look for funding.Building a fintech company with Atif Siddiqi (Branch) and Ryan Broshar (Matchstick Ventures)Minneapolis has a growing number of fintech companies, and Branch is among the best positioned. Hear from its CEO and founder Atif Siddiqi and one of the company’s early investors, Ryan Broshar, managing director and partner at Matchstick Ventures.Pitch-offJudges: Mahati Sridhar and Sarah Hinkfuss",0.0,0.0
338,https://www.businessinsider.com/reports-tiktok-big-brother-type-surveillance-prompt-calls-for-investigation-2022-10?international=true&r=US&IR=T,Pressure mounts for regulators to investigate TikTok over potential 'Big Brother-type surveillance' after reports of plans to track Americans' locations,"Forbes reported TikTok's parent company, ByteDance, planned to use the app to surveil Americans.Top editors give you the stories you want — delivered right to your inbox each weekday. Loading Something is loading. Thanks for signing up! Access your favorite topics in a personalized feed while you're on the go. download the app Email address By clicking ‘Sign up’, you agree to receive marketing emails from Insider as well as other partner offers and accept our Terms of Service and Privacy PolicyPublic Citizen on Thursday urged lawmakers and the FTC to investigate TikTok and ByteDance.The consumer rights group joins a growing chorus of bipartisan calls to investigate the Beijing-based company.Public Citizen in a letter on Thursday urged lawmakers and the Federal Trade Commission to investigate the TikTok app and its parent company, ByteDance, joining a growing number of bipartisan calls to investigate reports that the Beijing-based company planned to use the video-based social media app to surveil specific Americans.After reviewing internal materials, Forbes reported last week that ByteDance's Internal Audit team was planning to use location information gathered from US users of the TikTok app for surveillance of two American citizens who were not employees of the app. While accessing user location data is allowed for purposes like targeting ads or preventing fraudlent activity, the company's surveillance plans were not related to these user-approved purposes, according to the outlet.Representatives for ByteDance and TikTok did not immediately respond to Insider's requests for comment about the Public Citizen letter, but in a statement previously provided to Insider's Travis Clark a TikTok spokesperson denied the app has been used to ""target"" members of the US government, activists, public figures or journalists and said it ""does not collect precise GPS location information from US users.""In its Thursday letter, the nonprofit consumer rights group Public Citizen urged the FTC to investigate and ""take immediate action against ByteDance and Tiktok"" if the reports of surveillance are substantiated.""This threatens a Big Brother-type surveillance that is antithetical to democratic values, may threaten individuals' personal security and violates the most basic societal expectations about personal privacy,"" the letter written by Robert Weissman, president of Public Citizen, read. ""That there are a few disturbing precedents for platforms tracking individuals exacerbates rather than diminishes the concern about the Forbes report... Such a practice could put our privacy, physical safety, and national security at risk.""Lawmakers and privacy advocates alike expressed similar concern following the Forbes report. Sen. Marsha Blackburn, a Republican from Tennessee who has previously been critical of TikTok's ties to China, tweeted it was ""not surprising"" the company planned to surveil US users and advocated for a national privacy law. Alan Butler, executive director and president of the Electronic Privacy Information Center (EPIC), echoed the concerns about user privacy and called for stronger location data protections.Earlier this summer, Sens. Mark Warner, a Virginia Democrat, and Marco Rubio, a Florida Republican, called for a separate FTC investigation after BuzzFeed News reported that sensitive data from US users was repeatedly accessed by ByteDance staff in China, despite the company's assurances that US user data was stored in the states and was inaccessible abroad.""We write in response to public reports that individuals in the People's Republic of China (PRC) have been accessing data on U.S. users, in contravention of several public representations, including sworn testimony in October 2021,"" the senators wrote in a letter addressed to FTC Chair Lina Khan. ""In light of this new report, we ask that your agency immediately initiate a Section 5 investigation on the basis of apparent deception by TikTok, and coordinate this work with any national security or counter-intelligence investigation that may be initiated by the U.S. Department of Justice.""The app's links to the Chinese government have long spurred concerns over propaganda, fake news, and data privacy — with the Trump administration in 2020 even proposing a total ban of TikTok. In 2021, the Biden administration promised a security review of foreign-owned apps, but has yet to publish its results.""It is critical that you act with urgency to uncover the full extent of individually targeted surveillance practices, if any, and hold these companies accountable for any misconduct,"" Public Citizen's letter read.",0.0,0.0
568,https://techcrunch.com/2020/10/28/priori-series-a/,Priori raises $6.3M to help large companies hire outside legal help,"Priori Legal, a startup rethinking the way that large corporations hire outside counsel, has raised $6.3 million in Series A funding.Founded by CEO Basha Rubin and CPO Mirra Levitt (who met while classmates at Yale Law School), Priori launched as a legal marketplace for small and medium businesses before finding its current model in 2016.Rubin explained that although Fortune 500 companies have their own in-house legal teams, they still spend an average of $150 million a year on outside legal counsel. And finding that counsel can be an arduous process — a consumer goods company, for example, might need to hire lawyers in all 50 states.So by creating a marketplace of vetted lawyers (it says it only accepts 10% of applicants), by running a bidding process for the work and by streamlining the billing and on-boarding process, the startup can save companies an average of 60% of the money they spend on outside counsel and reduce the search time by 80%.“We don’t get involved in the substance of the lawyer-client relationship,” Levitt added. “We are not a law firm, we don’t do any of the legal work. Our innovation is focused entirely on the process of rapidly identifying the right talent and, once the matter is up and running, making billing seamless.”There are currently more than 1,500 lawyers in the marketplace, representing all 50 states in the U.S., as well as 47 countries and 700 practice proficiencies. Levitt said that while the first lawyers to join the platform were usually independent or worked at small firms that might not previously had access to these kinds of clients, there are now larger firms signing up as well.And Rubin said interest in Priori has only grown during the pandemic and the resulting economic downturn. Companies are trying to do “more with less,” and “part of our value proposition is fundamentally cost savings.” For example, she noted that client spending on the platform has increased 200% in the last year.“We began to see so much inbound demand that we would log onto Slack at 11pm and the entire team would be working,” she said. “We have a truly extraordinary team, but a) that’s not sustainable from a human perspective, and b) we saw an opportunity to really grow dramatically if we could throw resources at it.”The Series A comes from Hearst Corporation (also a Priori customer), Great Oaks Venture Capital, Jambhala, Tim Steinert (former general counsel of Alibaba Group), Mindset Ventures, Bridge Venture Fund and Orrick’s Legal Technology Fund.In addition to growing the team, Rubin said that the new funding will allow Priori to expand its network of lawyers, especially internationally.“From a product perspective, we’re really building out our use of data throughout the platform,” Levitt said, adding that the company plans to use machine learning to improve attorney vetting, matchmaking, bidding, project scoping and more.",0.0,0.0
511,https://nypost.com/2022/10/28/uber-eats-threatens-to-suspend-customers-account-for-ordering-alcohol-too-often/,Uber Eats threatens to suspend customerâs account for ordering alcohol too often,"Uber Eats is keeping an eye on how many alcohol orders you place – and one customer is not happy about being called out for having “a few”.An email sent to an unidentified Australian customer – who then shared it on Reddit – said: “Our systems indicate you’ve placed a few alcohol orders over the past few weeks.”It went on to say if the “ordering pattern” continued a hold may be put on the customer’s account or it could be raised for further review.“Experts recommend that no more than 10 standard drinks are consumed each week,” Uber advised.news.com.au understands Uber Eats began sending these alerts in August and does not specify maximum alcohol ordering limits to discourage users from over-ordering.The email shared a link to DrinkWise. Uber has had a partnership with the not-for-profit organization since 2016 when it launched a campaign against drunk driving and furthered its involvement in 2018 when Uber Eats first launched alcohol delivery in Melbourne, Australia.An Uber Eats delivery driver is required to scan a customer’s ID in the app to ensure they are over the age of 18 and check they are not visibly intoxicated before handing over an order.The driver is paid by Uber to return the alcohol to the store if a person is underage or visibly intoxicated.The Uber Eats customer posted the email to Reddit. @menotyoutoo/RedditThe unimpressed recipient of the email said they got an “alcohol order or two” a week.Some labeled it “lazy risk mitigation” and claimed Uber was only “looking after itself”.“These corporations jumping on these charitable causes to feign care is sickening,” one person criticized. “Alcoholism is a genuine issue but the way to solve it isn’t some vaguely threatening email from a delivery company.”Another added: “The charity partnership thing is an easy way of looking like they care and ‘fixing’ the problem.”“What would be better is ‘we noticed you’ve ordered a lot of alcohol, here’s some support services you can look into if you need it’. Not threatening them to close their account,” wrote a third.Some suggested restricting how much alcohol someone could buy a week for their health was ironic given there was no limit on junk food orders.“Yet order two dozen creme donuts, six triple cheeseburgers with extra cheese sauce, a kilo of fully-loaded cheese fries, four tubs of Ben & Jerry’s, six liters of Coke and you’re good to go,” one said.“But order 100 big macs, no problem sir, seems perfectly healthy,” another wrote.One user argued the effect of unhealthy foods was not comparable.“They both absolutely have an impact on the health system, but no one’s killing a group of kids with their 4WD because they’re driving under the influence of a triple cheeseburger,” they wrote.Start your day with all you need to know Morning Report delivers the latest news, videos, photos and more. Enter your email address Please provide a valid email address. By clicking above you agree to the Terms of Use and Privacy Policy. Thanks for signing up!Never miss a story. Check out more newslettersUber told news.com.au it was committed to ensuring responsible alcohol consumption.“This includes frequent communication to encourage moderation, educating consumers about the government guidelines, implementing ID and sobriety checks, and incorporating alcohol ordering limits,” the company said.“If a customer’s order exceeds the limits, they will be notified in the app and unable to check out. This is to ensure we can make safe, smart, and responsible decisions about alcohol consumption together.”A year ago it was revealed popular alcohol delivery service Jimmy Brings was being investigated over whether it breached liquor laws in relation to the June 2018 death of a man who reportedly spent $15,000 with the company over three years, including daily orders in the weeks leading up to his death.Almost 300 orders reportedly included several bottles of alcohol delivered almost daily, including two that were identical and placed within 10 minutes of each other, in the fortnight prior to the 49-year-old man’s death.Liquor & Gaming New South Wales, Australia confirmed to news.com.au on Friday it did not identify any breaches of the liquor laws that were in place at the time in 2018 and the investigation was closed.However, the New South Wales, Australia Government has since introduced new laws.“The new laws have made it mandatory for all delivery drivers to undertake the responsible service of alcohol training and to keep records of all refused deliveries,” a spokesman said.It is also now an offense to deliver to an intoxicated person with a maximum penalty of $7,000.New South Wales now has the strongest express alcohol delivery laws in the country.",0.0,0.0
593,https://techcrunch.com/2021/05/25/acuitymd-raises-7m-to-better-track-the-evolving-world-of-medical-hardware/,AcuityMD raises $7M to better track the evolving world of medical hardware,"In a world defined by tons of noise and little signal, startups that make it easier for consumers to make a choice just make sense. Career Karma helps students pick a tech bootcamp, Stackin’ helps millennials navigate the world of neobank and savings apps and a new Boston-based company is helping doctors keep track of the most up-to-date medical devices on the market.AcuityMD, founded in 2019 by Mike Monovoukas, Lee Smith and Robert Coe, is an enterprise software company that wants to unlock the often siloed world of medical device data. And to do so, it landed a $7 million seed round this week, led by Benchmark.As part of the deal, Benchmark GP Eric Vishria will join AcuityMD’s board of directors. Ajax Health, which closed $100 million in 2019 to back medtech companies, also participated in the round. With seed capital, Monovoukas said that AcuityMD plans to double its eight-person team by the end of the year, and invest heavily in one specific area: “product, product, product.”AcuityMD is a data platform that tracks the entire medical device lifecycle — from the sale of an item to a patient’s outcome after a surgery. It aggregates industry and market data on individual medical devices to give a metadata of sorts on a singular product.“There are thousands of products being launched each year and so it’s almost impossible for a surgeon, after they’ve graduated fellowship or residency to keep track of the latest and greatest medical technology out there,” Monovoukas said. “We view this as a software and coordination problem, where you have all this data out there and it’s inefficient in getting to the decision-maker.”Monovoukas experienced inefficiencies in medical device management firsthand when a family member needed to go through a series of surgeries.“What was fascinating to me is that the manufacturer holds a lot of information about what to use, [and] sometimes that didn’t get disseminated to the right surgeon at the right point of time,” he said. “The fundamental realization I had was that the information flow in this industry was a little bit broken…It wasn’t an issue of being competent doctors or surgeons, but a lack of information transfer, which is kind of crazy in a data-driven world.”So, the entrepreneur, who worked at Bain & Company as well as a medical device company before that, began thinking of how to use data to make medical devices more responsive to long-term patient outcomes. While doctors were a key stakeholder set to benefit from more information, AcuityMD’s team landed on selling to device manufacturers as their key customer.Now, part of that reason might be because hospitals and doctors are notoriously a pain to sell to. The other reason, Monovoukas tells me, is that performance data on medical devices is a key signal that sales teams within manufacturers can use to beef up, and better target, their pitches. The co-founder explained how manufacturers want visibility into the market for their products, ranging from data on where high-volume surgeons might need one of their devices to long-term outcomes on certain devices over time.The data could help a sales rep pre-emptively figure out how targeting 10 surgeons for a specific product impacts the manufacturer financially and in context with the rest of the market.AcuityMD is teeing itself up to become a real-time database of medical devices. Long-term, it could position itself as a Same Day Shipping service connecting manufacturers to surgeons in high-demand and vital transactions. Monovaukus says that while logistics and inventory is a “visceral” problem for the medical device industry, it doesn’t have a solution in place yet. He could see the startup getting to a point in the future where they can predict inventory levels required at each facility — similar to how some companies like Medinas, co-founded by Chloe Alpert, operate and manage within hospital systems.But for now, AcuityMD thinks it can best use its platform and millions of venture-backed capital outside the provider system. It sources a lot of its data on hospitals and surgeons from Medicare CMS and insurance companies, so leaving no action required on the end of providers.A challenge will be making sure those data sources are good enough to extract true signals. The startup is still defining good.“I heard someone once say that any digital health company eventually becomes a healthcare data company,” he said. “We’re approaching things a little bit differently.”",0.0,0.0
484,https://www.cell.com/iscience/fulltext/S2589-0042(22)01513-9,Observed electric charge of insect swarms and their contribution to atmospheric electricity,"Further information and requests for resources and reagents should be directed to and will be fulfilled by the lead contact, Ellard Hunting, [email protected]Observations were carried out at our field station at the University of Bristol, School of Veterinary Sciences, Langford United Kingdom, which is equipped with an electric field monitor to continuously measure atmospheric PG (Boltek EFM 100 Field Mill, calibrated in a capacitor plat setup). This site features several honeybee hives that are used for research. In the event of overcrowding of a beehive, the original queen leaves the hive with a fraction of the workers (on average around 12,000 bees) (), resulting in occasional swarming events near PG measuring equipment at our study site. When honeybees swarm, they usually cluster on a limb of a tree for several days while scout bees search for suitable cavities to nest in. After an appropriate nest is found, the swarm will collectively migrate. An electric field monitor was placed near the swarm. A camera (AKASO V50×, 30 fps) was positioned next to the field mill with an upward orientation to record the swarm in flight ( Figure 1 B). A second electric field monitor was placed in an open field, 50m away from the other electric field monitor and swarm to ascertain any dynamics in the electric field monitor was caused by the presence of a swarm. For about three minutes, part of the swarm passed over the electric field monitor.Modelling of electric fields was performed using finite element analysis within COMSOL Multiphysics® v. 5.4 (COMSOL AB, Stockholm, Sweden) utilising the “Electrostatics” interface within the “AC/DC” module. The three-dimensional geometry consisted of a 60 m × 60 m x 40 m (length, width, height) cuboid within which the model operated. The two runs made for differently sized and charged ellipsoids represented insect swarms of honeybees and locusts. The honeybee swarm was represented as an ellipsoid with semi-axes 2 m x 1 m x 0.5 m ellipsoid at a height of 3 m, and the locust swarm an ellipsoid with semi-axes 4 m x 1 m x 1 m at a height of 15 m. The swarm charge was distributed evenly as a volume charge within the ellipsoids, with the total charge calculated respectively as the sum of 500 bees each carrying +100 pC (order of magnitude from ()) and 1000 locusts carrying +850 pC each. An approximately 8 m tall deciduous tree was included in each model to provide scale and an electrical landmark for comparison (). The remainder of the model domain was assigned as air. The upper surface of this air column was given an electrical potential typical of a 40 m altitude in fair-weather conditions (+4 kV), with the bottom surface defined as zero potential, equivalent to the established surface (first meter) atmospheric potential gradient of 100 V/m (). The surface of the tree was also defined as ground (). Meshing of the geometry was physics-controlled, set to “extremely fine”. The relative permittivity, ε, was defined as ε= 12 for living trees (), ε= 1 for air, and ε= 80 inside the insect swarms (likely an overestimate, based on the permittivity of water). Model outputs presented for this study were produced by plotting data from two-dimensional slices through the centre of the three-dimensional dataset.Quantification and statistical analysisThe video recording capturing the swarm event was cropped to a 500 by 220-pixel window to remove foreground objects obstructing the view of the swarm and was analysed using a custom script in Python 3.8.1. The video was converted to black and white pixels such that the background was white and any non-background objects, comprising the swarm, were black. The ratio of black to white pixels was calculated for each frame of the video resulting in a proxy measure for bee density, defined as relative pixel density here. At points during the swarm’s passage, flowering heads of grass entered the frame, increasing the relative pixel density. Such affected data were therefore removed. The relative pixel densities were filtered by a moving mean over 10 data points (corresponding to 0.5 s) to emphasise the long-term trend of the data. These data were compared to data collected by the electric field monitor using cross correlation and linear regression in PAST v.4. Since insect charges can be expected to influence PGs directly, data were aligned (zero lag) based on the highest cross correlation coefficient.",0.0,0.0
485,https://techcrunch.com/2021/09/14/agbiome-lands-166m-for-safer-crop-protection-technology/,AgBiome lands $116M for safer crop protection technology,"AgBiome, developing products from microbial communities, brought in a $116 million Series D round as the company prepares to pad its pipeline with new products.The company, based in Research Triangle Park, N.C., was co-founded in 2012 by a group including co-CEOs Scott Uknes and Eric Ward, who have known each other for over 30 years. They created the Genesis discovery platform to capture diverse microbes for agricultural applications, like crop protection, and screen the strains for the best assays that would work for insect, disease and nematode control.“The microbial world is immense,” said Uknes, who explained that there is estimated to be a trillion microbes, but only 1% have been discovered. The microbes already discovered are used by humans for things like pharmaceuticals, food and agriculture. AgBiome built its database in Genesis to house over 100,000 microbes and every genome in every microbe was sequenced into hundreds of strains.The company randomly selects strains and looks for the best family of strains with a certain activity, like preventing fungus on strawberries, and creates the product.Its first fungicide product, Howler, was launched last year and works on more than 300 crop-disease combinations. The company saw 10x sales growth in 2020, Uknes told TechCrunch. As part of farmers’ integrated pest program, they often spray fungicide applications 12 times per year in order to yield fruits and vegetables.Due to its safer formula, Howler can be used as the last spray in the program, and its differentiator is a shorter re-entry period — farmers can spray in the morning and be able to go back out in the field in the afternoon. It also has a shorter pre-harvest time of four hours after application. Other fungicides on the market today require seven days before re-entry and pre-harvest, Uknes explained.AgBiome aims to add a second fungicide product, Theia, in early 2022, while a third, Esendo was submitted for Environmental Protection Agency registration. Uknes expects to have 11 products, also expanding into insecticides and herbicides, by 2025.The oversubscribed Series D round was co-led by Blue Horizon and Novalis LifeSciences and included multiple new and existing investors. The latest investment gives AgBiome over $200 million in total funding to date. The company’s last funding round was a $65 million Series C raised in 2018.While competitors in synthetic biology often sell their companies to someone who can manufacture their products, Uknes said AgBiome decided to manufacture and commercialize the products itself, something he is proud of his team for being able to do.“We want to feed the world responsibly, and these products have the ability to substitute for synthetic chemicals and provide growers a way to protect their crops, especially as consumers want natural, sustainable tools,” he added.The company has grown to over 100 employees and will use the new funding to accelerate production of its two new products, building out its manufacturing capacity in North America and expanding its footprint internationally. Uknes anticipates growing its employee headcount to 300 in the next five years.AgBiome anticipates rolling up some smaller companies that have a product in production to expand its pipeline in addition to its organic growth. As a result, Uknes said he was particular about the kind of investment partners that would work best toward that goal.Przemek Obloj, managing partner at Blue Horizon, was introduced to the company by existing investors. His firm has an impact fund focused on the future of food and began investing in alternative proteins in 2016 before expanding that to delivery systems in agriculture technology, he said.Obloj said AgBiome is operating in a $60 billion market where the problems include products that put toxic chemicals into the ground that end up in water systems. While the solution would be to not do that, not doing that would mean produce doesn’t grow as well, he added.The change in technology in agriculture is enabling Uknes and Ward to do something that wasn’t possible 10 years ago because there was not enough compute or storage power to discover and sequence microbes.“We don’t want to pollute the Earth, but we have to find a way to feed 9 billion people by 2050,” Obloj said. “With AgBiome, there is an alternative way to protect crops than by polluting the Earth or having health risks.”",0.0,0.0
255,https://www.cbsnews.com/news/robots-pick-strawberries-california/,"""The robot is doing the job"": Robots help pick strawberries in California amid drought, labor shortage","California produces about 90% of the nation's strawberries, but severe drought and worker shortages are threatening the fruit. One company is hoping to change that with the power of robots.Eric Adamson's company is behind a strawberry robotic revolution. He said they're programmed to think on their own, with cameras that sense texture and color.""People think robots have been around forever, but they're actually very, very new, especially robots that make decisions and are autonomous,"" Adamson said.They work in a hydroponic field, which is a type of farming that can use up to 90% less water than traditional methods.As good as they are, though, they're hardly foolproof.""We expect we'll make mistakes and we'll expect things will break,"" he said.Adamson said the robots pick with 95% accuracy.And it's not just the robots that are learning. Jeanpol Rodriguez, who used to work in the fields, now manages the robots picking strawberries. He said he didn't know anything about robotics before entering this new role.""The robot is doing the job. I'm like — I'm cool!"" Rodriguez told CBS News.Adamson said this is a way that ""we can create jobs with higher wages and with higher skill development.""Adamson said his goal is to expand beyond just strawberry picking.""We hope to have hundreds and hundreds of robots around the world's leading farms, picking table grapes, peppers, cucumbers, blackberries, raspberries,"" he told CBS News.",0.0,0.0
486,https://cosmosmagazine.com/science/antibiotic-potato-fungal-infections/,New antibiotic hiding in diseased potatoes thwarts fungal infections in plants and humans,"Antibiotic resistance is a worry for human and plant health alike. The more we use existing antibiotics in clinical settings and in agriculture, the more antibiotic resistance develops. Without new antibiotic compounds, we will struggle to treat once-controlled diseases in both humans and plants.Exciting new research from Europe details the discovery of a new antifungal antibiotic called solanimycin hiding within a bacteria which causes disease in potatoes.Most therapeutic antibiotics actually come from soil microbes, so this discovery broadens the search for new compounds to plant-based microorganisms.“We have to look more expansively across much more of the microbial populations available to us,” said Dr. Rita Monson a microbiologist at the University of Cambridge and one of the study’s authors.Blackleg in potatoes one of the symptoms of Dickeya solani. Credit: Liudmyla Liudmyla/Getty ImagesThe bacteria itself, known as Dickeya solani, has been known for over 15 years, with another antibiotic called oocydin A originally isolated from the bacteria and used as an effective fungicide against many plant ailments.Get an update of science stories delivered straight to your inbox. Get a daily dose of science Get a weekly Cosmos Catch-upFrom this, and a sequencing of the bacterium’s genome, the researchers realised the potential for other antibiotic compounds to be hiding in the background. When they switched off the genes responsible for producing oocydin A and when the bacteria were within an acidic background – such as that found inside a potato – it would switch on genes responsible for creating solanimycin.“It’s an antifungal that we believe that will work by killing fungal competitors, and the bacteria benefit so much from this,” said Monson. “But you don’t turn it on unless you’re in a potato.”Antiobiotic resistance: an arms race going on millions of yearsComputer illustration of Candida fungi (yeast). C. albicans is found on the skin and mucous membranes of the mouth, genitals, respiratory and digestive tracts. Credit: Kateryna Koc/Science Photo/Library/Getty ImagesSolanimycin has been demonstrated to act against fungal disease in both plants and also on a common organism known as Candida albicans, which is present inside the body naturally, but can become out of control and cause dangerous infections.Monson and colleagues want to understand more about solanimycin and how it works, so they have teamed up with chemists to investigate the molecular structure in detail. From there, they hope to progress to testing the compound in plant and animal models.",0.0,0.0
495,https://singularityhub.com/2022/10/26/from-pitless-cherries-to-softer-kale-this-startup-is-using-crispr-to-make-better-produce/,"From Pitless Cherries to Softer Kale, This Startup Is Using CRISPR to Make Better Produce","Ninety percent of American adults don’t eat enough fruits and vegetables, opting for fast food and processed foods instead. Cost, flavor, and convenience are all factors in this imbalance, but as health statistics show, we should be working harder to reverse our dietary trends.A startup called PairWise is out to help change the way we eat by making fruits and vegetables more appealing. The company is zeroing in on traits that may deter people from consuming produce and tweaking those traits using CRISPR gene editing. Their hope is that the resulting products will not only pique consumers’ interest, but keep them healthy and keep them coming back. Tom Adams, PairWise cofounder and CEO, shared details about the company and its products in an interview.CRISPR’d ProduceCRISPR was first used to edit bacterial DNA in 2012. Since then, scientists have used the tool to edit the genomes of crops, animals, and even humans, and have begun testing it as a means of curing inherited conditions from blindness to muscular dystrophy and other genetic diseases.CRISPR is made up of a synthesized sequence of guide RNA that matches a target DNA sequence—that is, the portion of DNA to be altered—and a Cas enzyme. Once in a cell’s nucleus, the guide RNA links up with the target DNA sequence. The Cas enzyme cuts the DNA at that point, and the cell repairs the cut. The repairs can either knock out a gene, inactivating it, or insert a new sequence.Modifying a gene that encodes for a given trait either eliminates or alters that trait; in the case of fruits and vegetables, say, the bitterness of mustard greens or the seeds in blackberries. Given that the genomes of PairWise products are modified, some consumers may want to know whether the fruits and vegetables are classified as genetically modified organisms (GMOs).The short answer is no. The USDA doesn’t regulate gene-edited plants as long as their traits could have occurred through traditional breeding methods or a whim of nature. The CRISPR technique PairWise uses involves manipulating genes that exist naturally in a given species’ genome. “The changes PairWise has made in our greens are no different than what can be achieved through conventional breeding, contain no foreign DNA, and therefore are not considered GMOs,” Adams said.GMOs, on the other hand, can contain genes from other species, and wouldn’t come about naturally even after decades of traditional breeding. Bt crops, for example, are engineered to contain a natural form of pesticide derived from bacteria, which means they don’t need to be sprayed with chemical pesticides.Adams pointed out that the anti-GMO sentiment out there isn’t necessarily about resistance to the technology itself. “There’s a lot of reasons GMOs may be less popular, and one of them is that people didn’t feel there was transparency,” he said. “Most of the products that fall under the category GMO are things that get added to foods as ingredients, and nobody knew when they were getting it and when they weren’t, and it created this stigma.”He wants PairWise to take a more proactive and transparent approach. “We’re going to be very clear about the processes we’re using to create the products, and it’s your choice whether you like the benefits or you’re worried about the technology,” he said.Next-Gen ProduceThe first product PairWise will bring to market is a milder-tasting version of mustard greens. “Almost four years ago, we were searching for things we could do that were amenable to the technology but also were addressing a consumer need,” Adams said.The company’s market research found that people often ended up buying romaine lettuce even after saying they’d prefer kale or another green because of their greater nutritional value. “People want healthy salads, but they keep buying romaine because they’re used to the flavor,” Adams said. Ease of preparation is a factor too.Mustard greens, Adams told me, are a relative of kale, but they taste like horseradish when you bite into them. Two components come together that react and cause the horseradish flavor. PairWise used CRISPR-Cas12a to edit the green’s genome and remove one of those components. “It’s really just removing something that the plant doesn’t need for survival and doesn’t contribute to the nutritional benefits,” Adams said. The mustard greens have already been approved by the FDA and will start being sold in California and the Pacific Northwest in early 2023 under the brand Conscious Foods.The company’s not stopping there, though; they have multiple fruit and veggie improvement projects underway.One is a softer version of kale. If you’ve ever made a kale salad from the stuff that comes still on the stalk, you know it’s labor-intensive: there’s the washing, the de-stemming, the chopping, the massaging… (that’s right, massaging!). PairWise kale will retain all of the leafy green’s nutritional properties, but have a texture more like lettuce, making it easier to prepare and eat.Another is seedless berries, including blackberries and raspberries. Hate how those tiny seeds get stuck in your teeth, always in the hardest-to-reach places? CRISPR to the rescue.One of the company’s most intriguing projects, in my opinion, is pitless cherries.“I love cherries, but they’re a pain to eat,” Adams said. “Your fingers are all red when you’re done with a few of them, and if there’s not a trash can nearby you don’t know what to do with the pit.” I asked him how it’s possible to grow a cherry—or any other stone fruit, like plums, peaches, or apricots—without the pit, as it connects to the fruit’s stem and is its lifeline to the tree.“It’s easiest to think about it like a seedless grape,” he said. “It actually still has a seed in it, but the seed has lost its hard outer shell. There’s still that nutritious plant embryo that’s normally protected by the shell, we’re just making it so it’s all edible.” If they succeed, eating pitless cherries will be a different experience altogether; isn’t having to remove the pit the only thing keeping us from stuffing handfuls of the scrumptious fruit into our mouths at once?A Whole New PlantWhen it comes to cherries, it’s not just the end product PairWise is focusing on. Currently 90 percent of sweet cherries are grown in Washington state, where there’s little to no rain in the summer. The fruit is highly sensitive to changes in moisture and can only thrive in a dry climate; this specificity and the fact that the fruit needs to be shipped from the far northwest corner of the country pushes up its price. But what if cherries could grow in, say, Michigan, or Kansas, or Vermont?“We think we understand the genetics well enough that we could modify the architecture of the tree so that it’s more like a blueberry bush,” Adams said. “And then you can grow them in more environments and put them at less risk.”PairWise is also trying to alter the way blackberries grow. The moisture sensitivity has already been taken care of by nature, as has the bush-not-tree situation—but the bushes have thorns, and thorns make fruit hard to harvest. The company is working on cutting out the thorns.Here’s an idea: blueberry-sized cherries without a pit that grow on bushes without thorns in any climate. Seems like a product that would need a whole new name, and heck if I have any suggestions. (Not to mention, it probably wouldn’t occur naturally no matter how many generations you waited.)Getting HealthierBe it softer kale, pitless cherries, or thornless bushes, PairWise’s mission is to create a healthier world by taking away barriers to eating fresh produce. “We’re interested in anything that moves the needle on the fact that only 10 percent of Americans eat the recommended amounts of fruits and vegetables,” Adams said. “It really doesn’t change very much just by telling people they should eat more of them. Our idea is, you need to take down the barriers.”It’s certainly a noble aim. But how likely is engineered produce to play an instrumental role in changing consumers’ habits, or in attracting a previously-veggie-averse demographic? People who already buy and eat kale on a regular basis may opt for a smoother kale 2.0, but people who have never bought kale may not be so easily swayed by a newfangled version of the green.Adams believes there’s a consumer base out there who will benefit from products like PairWise’s. “There are people who are looking for a healthy lifestyle,” he said. “And they’re looking for something different in salads. We’re coming in with a new category: a nutritious green that still tastes good.”Physical traits of produce may be one barrier that deters people from buying them, but cost is equally important (if not more so). With years of research and development going into CRISPR’d produce, my assumption was that it won’t be affordable. Ten dollars for a bag of lettuce-like kale? No thanks.Not the case, according to Adams. “There’s a fairly wide range of pricing within the salad space. We expect to be in the top quartile of the pricing, but we’re not going to be above it,” he said. Production of PairWise greens, he added, is actually quite cost-competitive with other types of salad greens.Based on marketing activation events the company ran over the summer in Seattle, Austin, and Palo Alto, the outlook for their first product looks pretty rosy. They gave away bags of salad (which were clearly labeled as being gene-edited) consisting of red- and green-leaf mustard greens, and asked people to complete a short survey about it. Adams estimated that more than 6,000 people tried the salads, and over 90 percent responded that they were “very motivated” or “somewhat motivated” to buy the product.A New Green Revolution?Helping people make healthier dietary choices is just one benefit that CRISPR could bring to produce. Its possibilities are wide-ranging, as evidenced by PairWise’s work to create fruit trees that can grow in different climates and yield food that’s easier to harvest. It’s not unlike Norman Borlaug’s work back in the 1940s to create a high-yield wheat seed that was resistant to stem rust—a project that ended up saving millions of people from hunger and famine.The difference is that technology has taken over the painstaking, time-consuming steps Borlaug had to slog through, like pollinating and inspecting thousands of plants by hand (a hundred and ten thousand in just one growing season! Talk about labor-intensive).Adams sees PairWise’s work similarly and believes CRISPR holds all sorts of possibilities for a new frontier of engineered foods. “We’re doing the same thing as traditional plant breeders, but it’s just faster,” he said. “We could create a lot more resilience for the whole food system.”Image Credit: Anrita from Pixabay",0.0,0.0
496,https://techcrunch.com/2022/03/14/supplant-series-b/,SupPlant is an Internet of Trees solution dramatically reducing irrigation needs for thirsty crops,"Agtech startupAgtech startupIn a world where under-watering has far more damaging results than over-watering, a non-tech-enabled farmer may be tempted to keep the soil wetter than it needs to — wasting a tremendous amount of precious water in the process. By carefully measuring the plants, and pairing their status with weather and soil data, it can give very precise watering needs. The company just raised $27 million to continue fertilizing and watering its own growth trajectory.In a world where under-watering has far more damaging results than over-watering, a non-tech-enabled farmer may be tempted to keep the soil wetter than it needs to — wasting a tremendous amount of precious water in the process. By carefully measuring the plants, and pairing their status with weather and soil data, it can give very precise watering needs. The company just raised $27 million to continue fertilizing and watering its own growth trajectory.When the agricultural revolution happened 12,000 years ago, farmers started tracking how crops grew based on various weather patterns and broad-stroke variability in weather forecasting, etc. A lot of these patterns are being disrupted by climate change.When the agricultural revolution happened 12,000 years ago, farmers started tracking how crops grew based on various weather patterns and broad-stroke variability in weather forecasting, etc. A lot of these patterns are being disrupted by climate change.“The ability to make“The ability to makeThe company has two products: a software-only solution and a hardware-and-software product. The hardware product measures one plant per 25 acres or so, and uses this data to extrapolate the needs of all the crops in the field. The solution uses five different sensors — deep soil, shallow soil, trunk, leaf and fruit. Each of the sensors feeds data into an algorithm, which also takes into consideration weather patterns, weather forecasts, soil information and other proprietary data, to give advice about how to water crops strategically over the next 10 to 14 days.The company has two products: a software-only solution and a hardware-and-software product. The hardware product measures one plant per 25 acres or so, and uses this data to extrapolate the needs of all the crops in the field. The solution uses five different sensors — deep soil, shallow soil, trunk, leaf and fruit. Each of the sensors feeds data into an algorithm, which also takes into consideration weather patterns, weather forecasts, soil information and other proprietary data, to give advice about how to water crops strategically over the next 10 to 14 days.“We learned the specific patterns of the trunk and — later on the season — of the fruit itself through tweaking the irrigation recommendations that we’re giving. Our system learns the optimal patterns and irrigation regimes. It keeps the plant and fruit on the maximized growth pattern that the plant is capable of,” explains Ben Ner. “From there, it starts to get into specifics of their specific regimes to increase sugar levels. For wine grape growers, for example, you want to stress the plant at a certain time, three weeks from now, to encourage the plant to accumulate sugar. The more sugar in the grape, the better the wine. Basically, the end result is dramatic enhancements of yields. Our main goal is to increase and enhance produce, but the byproduct is that we save a lot of water.”“We learned the specific patterns of the trunk and — later on the season — of the fruit itself through tweaking the irrigation recommendations that we’re giving. Our system learns the optimal patterns and irrigation regimes. It keeps the plant and fruit on the maximized growth pattern that the plant is capable of,” explains Ben Ner. “From there, it starts to get into specifics of their specific regimes to increase sugar levels. For wine grape growers, for example, you want to stress the plant at a certain time, three weeks from now, to encourage the plant to accumulate sugar. The more sugar in the grape, the better the wine. Basically, the end result is dramatic enhancements of yields. Our main goal is to increase and enhance produce, but the byproduct is that we save a lot of water.”The company closed a $27 million round led byThe company closed a $27 million round led byIn addition to the hardware-based product, the company recently launched an API product, a sensor-less technology that has served 500,000 maize farmers in Kenya over the last season. SupPlant is making its technology available to these smallholder farmers by changing the basic concept of irrigation methods. The new technology is designed for the world’s 450 million small growers. In 2022, SupPlant’s aim is to get more than a million African and Indian smallholders on its platform.In addition to the hardware-based product, the company recently launched an API product, a sensor-less technology that has served 500,000 maize farmers in Kenya over the last season. SupPlant is making its technology available to these smallholder farmers by changing the basic concept of irrigation methods. The new technology is designed for the world’s 450 million small growers. In 2022, SupPlant’s aim is to get more than a million African and Indian smallholders on its platform.The SupPlant app can help farmers figure out how to respond to extreme weather events to help give plants as good a chance to thrive as possible.The SupPlant app can help farmers figure out how to respond to extreme weather events to help give plants as good a chance to thrive as possible.The SupPlant app can help farmers figure out how to respond to extreme weather events to help give plants as good a chance to thrive as possible.“After a couple of years on the market, and with tens of thousands of sensors deployed, we have millions of irrigation events, covering more than 33 crops, with over 200 varieties in any geography you can imagine, and in every climate condition you can imagine. So the fundamental value of the product today is the fact that we own the most unique database of irrigation on Earth. The hardware will be an enabler for that,” explains Ben Ner. Obviously, the hardware solution is more accurate than software alone, but as the company gathers more and more data, it is able to extrapolate how various crops will perform. “Our main markets — that is, where most of the sales teams are located — are Australia, Mexico, South Africa and Argentina. We are just on the verge after a super successful proof-of-concept, of signing 100% of the dates in UAE. That comprises 2.1 million trees. Our solution enables the UAE to save 70% of its water consumption. The amount that we are able to save per tree is the consumption of 10 people in the Emirates — one of the aridest places on Earth.”“After a couple of years on the market, and with tens of thousands of sensors deployed, we have millions of irrigation events, covering more than 33 crops, with over 200 varieties in any geography you can imagine, and in every climate condition you can imagine. So the fundamental value of the product today is the fact that we own the most unique database of irrigation on Earth. The hardware will be an enabler for that,” explains Ben Ner. Obviously, the hardware solution is more accurate than software alone, but as the company gathers more and more data, it is able to extrapolate how various crops will perform. “Our main markets — that is, where most of the sales teams are located — are Australia, Mexico, South Africa and Argentina. We are just on the verge after a super successful proof-of-concept, of signing 100% of the dates in UAE. That comprises 2.1 million trees. Our solution enables the UAE to save 70% of its water consumption. The amount that we are able to save per tree is the consumption of 10 people in the Emirates — one of the aridest places on Earth.”Update: A previous version of this article listed total funds raised at $45 million. That has been corrected to $46 million.Update: A previous version of this article listed total funds raised at $45 million. That has been corrected to $46 million.",0.0,0.0
497,https://techcrunch.com/2022/10/10/agriwebbs-software-seeks-to-boost-yields-lower-environmental-impacts-for-farmers-and-ranchers/,"AgriWebbâs software seeks to boost yields, lower environmental impacts for farmers and ranchers","AgriWebb is on a mission to help livestock producers feed the world efficiently, profitably and sustainably by providing its comprehensive, ground-truth database for beef production worldwide.The Australian startup, which builds a livestock management platform for ranchers and farmers, wants to digitize farm records and the meat production process from the cow to the consumer and drive the industry’s animal and environmental welfare transparency.The startup said today it has raised another $6.8 million of funding led by Germin8 Ventures and iSelect Fund. In total, AgriWebb has raised $27 million in Series B and about $29.3 million since its inception in 2014. It did not disclose its valuation when asked.Its app allows users to visualize their operations and give insights on animals and grazing, including the best grass location and which animals gain weight. On top of that, it lets ranchers improve their sustainable land management for better profits and leverage the on-farm data they’re recording to make more intelligent business decisions, according to the company.AgriWebb claims more than 16,000 farmers and ranchers globally are using its cloud-based platform and managing approximately 19 million animals on over 136 million acres of grazing land across the globe, including Australia, the U.S. and the U.K.The global beef market is estimated at $500 billion, but the pure farm management software market in its core geographies is estimated at around $3.5 billion, the company executive chairman Justin Webb told TechCrunch. AgriWebb’s key markets include Australia — where more than 15% of the national herd is managed using its platform — the U.K. and the U.S. Additionally, AgriWebb has partnerships in Brazil and South Africa, Webb said.Unlike most competitors who act as a point solution focused on one or two areas of farm management, AgriWebb’s platform brings together animal management, grazing management and team communication; task and compliance management; and daily record-keeping in one place, Webb explained. “Its grazing insights enable ranchers to maximize productivity, eliminate waste, and validate grazing and animal management decisions in a way that other record-keeping systems can’t touch,” Webb pointed out.Webb founded AgriWebb with John Fargher (chief revenue officer) and Kevin Baum (chief executive officer) in 2014. In Australia, the three founders discovered that farmers were not only interested in the advantages of technology but were also desperately cobbling their own solutions with scrappy spreadsheets and notebooks.“Livestock producers deserve better technology to help them maximize their business and consumers need more reliable provenance for the animal and environmental welfare of their food,” Webb said. “AgriWebb has always been about serving the farmers, and this round of funding doesn’t change our mission; it simply magnifies it.”The latest funding will be used for the international expansion of AgriWebb to ranchers and farmers in the U.S., the U.K., and Latin America, both directly and via partnerships. AgriWebb has secured customers in 28 of the 50 states since its U.S. launch in 2021 and plans to continue rapidly expanding. In addition, the latest funding will enable the company to establish its database.Apart from the funding, AgriWebb recently joined two project proposals to the USDA CSC program, one led by American Farmland Trust and the other by Farm Journal’s Trust in Food initiative, Webb said. Both aim to improve the U.S. beef supply chain’s climate footprint and scale regenerative agriculture practices, Webb continued. One project is focused on improving transparency in the beef supply chain and understanding the GHG impact of different practices; the second aims to scale the adoption of practices through payments for practice changes.“There’s a misconception that agriculture is at odds with climate, but the importance of sustainability and implementing sustainable practices is far from lost on farmers and producers,” Webb said. “In fact, the long-term sustainability and viability of their land are of utmost importance. Talk to any landholder and you’ll understand their long-term goal is to pass on their land in better condition to the next generation. Sustainable and regenerative practices can and do exist in tandem with productive and profitable farms, and we remain steadfast in our endeavor to support producers now and in the future through data that measures, manages and improves the sustainability of the food supply chain from farm to plate.”The company raised its first Series B from investors, including Telus Ventures, Grosvenor Food & AgTech and the Clean Energy Finance Corporation in January 2021.“AgriWebb fits with Germin8’s thesis to invest in the full-stack enterprise software companies within AgTech that bring essential enterprise value to farmers in alignment with practices that are sustainable,” said managing partner at Germin8 Ventures Michael Lavin. “There are very few software offerings capable of accelerating the regenerative agriculture practices our climate stands to benefit from, and even fewer that target livestock production rather than being at odds with it.”",0.0,0.0
291,https://news.sky.com/story/worms-saliva-found-to-break-down-plastic-in-major-pollution-breakthrough-12712583,Worm's saliva found to break down plastic in major pollution breakthrough,"A worm could be the answer to solving the problem of what to do about one of the commonest forms of plastic pollution.Spanish researchers have found that chemicals in the saliva of the wax worm can break down polyethylene, a particularly hard-wearing material.Their research found that exposing the plastic to the creature's saliva caused it to degrade as much in a single hour as several years worth of normal exposure to the elements.Wax worms, the larvae of the wax moth, usually feed on the tough wax bees use to make honeycombs and are actually considered pests by beekeepers.The study, published in the journal Nature Communications, discovered that two enzymes in the worm's saliva - which it uses to break down the wax - also break down the plastic.For plastic to degrade, oxygen needs to penetrate the plastic's molecules, known as polymers, a process known as oxidation.The research found that the enzymes in the saliva caused this process to occur in a matter of hours without any need to pre-treat the plastic by exposing it to heat or radiation.Polyethylene is the most widely used plastic in the world and responsible for vast amounts of pollution.First created in 1933, it is inexpensive, hard wearing and doesn't interact with food, making it widely used.AdvertisementSpecifically designed to be hard to break down, it can remain intact for decades.Please use Chrome browser for a more accessible video player 0:38 A shoreline in Guatemala is completely awash with plastic waste.Enzymes have been produced syntheticallyHowever, this breakthrough could be set to change that with molecular biologist Federica Bertocchini of the Spanish National Research Council (CSIC), who led the study, saying it was ""changing the paradigm of plastic biodegradation"".She went on to explain that they had not only found out which enzymes break down the plastic, but had also managed to produce them synthetically, avoiding the need to use billions of wax worms to do the job.Read more:'Jaw-dropping' amount of plastic thrown away by British households every year revealedMicroplastics found in human blood for first time after scientists make 'concerning finding'Doing it that way would have several practical drawbacks and would also generate a large amount of carbon dioxide as the worms metabolise the polyethylene.Plastic use has skyrocketed over the past 30 years, with hundreds of millions of tons ending up as waste every year, and less than 10% of that being recycled.In March this year, the United Nations approved a landmark agreement to create the world's first global plastic pollution treaty after talks in Nairobi, with the goal of having a legally binding deal finalised by 2024.Subscribe to ClimateCast on Spotify, Apple Podcasts, or Spreaker.",0.0,0.0
357,https://www.technologyreview.com/2022/10/12/1061204/human-brain-cells-transplanted-baby-rats-brains/,Human brain cells transplanted into baby ratsâ brains grow and form connections,"“It’s an important step forward in progress into [understanding and treating] brain diseases,” says Julian Savulescu, a bioethicist at the National University of Singapore, who was not involved in the study. But the development also raises ethical questions, he says, particularly surrounding what it means to “humanize” animals.Sergiu Pașca at the University of Stanford has been working for more than a decade with neural organoids—small clumps of neurons, grown in a dish, that resemble specific brain regions. These organoids are often created from human skin cells, which are first made into stem cells. The stem cells can then be encouraged to form neurons in the lab, under the right conditions. The resulting organoids can be used to study how brain cells fire and communicate—and how they malfunction in some disorders.But there’s only so much a clump of cells in the lab can tell you. When it comes down to it, these cells don’t really replicate what is happening in our brains—which is why Pașca and many others in the field avoid the commonly used term “mini-brains”. The organoid cells can’t form the same complex connections. They don’t fire in the same way, either. And they aren’t as big as the cells in our brains. “Even when we kept human neurons for hundreds of days … we noticed that human neurons don’t grow to the size to which a human neuron in a human brain would grow,” says Pașca.It is also impossible to tell how changes to neurons in the lab might lead to symptoms of a neuropsychiatric disorder. If cells in a dish show a change in their shape, the way they fire, or the proteins they make, what does that mean for a person’s memory or behavior, for example?To get around these issues, Pașca and his colleagues transplanted organoids into the brains of living rats—specifically, newborn rats. The brains of very young animals undergo extensive growth and rewiring as they develop. Neurons transplanted at such an early stage should have the best chance of being integrated with the rats’ own brain circuits, Pașca reasoned.Building brain organoidsThe team used organoids made from skin cells. These cells were made into stem cells in the lab before being encouraged to form layers of cells that resemble those in the human cortex, the folded outer part of the brain that contains regions responsible for thought, vision, hearing, memory, and sensing the environment, among other things. This process took around two months in the lab.The resulting three-dimensional organoids were then injected into the brains of days-old rats through an incision in the skull. The organoids were transplanted into the sensory cortex, a region that plays a role in helping animals sense their environment.Within four months, brain scans showed that the organoids had grown to around nine times their original volume—and made up around a third of one brain hemisphere. The cells appeared to have formed connections with rat brain cells and been incorporated into brain circuits.",0.0,0.0
172,https://arstechnica.com/tech-policy/2022/11/us-senator-seeks-antitrust-review-of-apartment-price-setting-software/,US senator seeks antitrust review of apartment price-setting software,"ProPublica is a Pulitzer Prize-winning investigative newsroom. Sign up for The Big Story newsletter to receive stories like this one in your inbox.The chair of a U.S. Senate committee asked the Federal Trade Commission on Tuesday to review whether a Texas-based property tech company’s rent-setting software violates antitrust laws.The move comes after ProPublica published an investigation on October 15 into RealPage’s pricing software, which suggests new rents daily to landlords for all available units in a building. Critics say the software may be helping big landlords operate as a cartel to push rents above competitive levels in some markets.“Alarmingly, recent reporting by ProPublica highlighted that RealPage’s algorithm-based price optimization software, YieldStar, is being used by a growing number of property managers and landlords, potentially impacting pricing and the supply of homes in the rental market,” said the letter signed by US Sen. Sherrod Brown, the Ohio Democrat who chairs the Senate Committee on Banking, Housing, and Urban Affairs. “Renters should have the power to negotiate fairly priced housing, free from illicit collusion and deceptive pricing techniques.”RealPage’s software applies a complex set of mathematical rules to a vast trove of data collected by the company from landlords who are its clients. That data includes the otherwise private data of nearby competitors.“Troublingly, ProPublica reported that a former RealPage executive stated that the data could give insight into how competitors within a half-mile or mile radius are pricing their units,” said the letter, which was addressed to FTC chair Lina Khan.RealPage has said the data fed into its pricing tool is anonymized and aggregated. It said the company “uses aggregated market data from a variety of sources in a legally compliant manner.”In a statement Tuesday, the company said it had not seen the letter, “but we are always willing to engage with policy stakeholders to ensure they have the facts about the competitive dynamics of the housing market and the value and benefits that RealPage creates for renters and housing providers.”Critics say the use of private data is one of the reasons the software invites scrutiny from antitrust enforcers such as the FTC. RealPage also claims its analytics “balance supply and demand to maximize revenue growth.” And the company organizes forums for competitors to meet and discuss aspects of its software, including its pricing algorithms. One legal expert told ProPublica that such collaborations “could raise an antitrust red flag.”AdvertisementIn one neighborhood in Seattle, ProPublica found, 70 percent of apartments were overseen by just 10 property managers, all of which used pricing software sold by RealPage in at least some of their buildings.The Senate letter said the recent reporting on RealPage “raises serious concerns about collusion in the rental market.” It said “the FTC should review whether rent setting algorithms that analyze rent prices through the use of competitors’ private data, such as YieldStar, violate antitrust laws.”RealPage said previously that its revenue management software prioritizes a property’s own internal supply and demand dynamics over external factors such as competitors’ rents. The software helps eliminate the risk of collusion that could occur with manual pricing, which often relies on phone surveys of competitor prices, the company said.An FTC spokesperson said the agency does not comment on letters or requests from Congress.The letter also raised concerns that the pricing software is potentially restricting the supply of apartments. It said that the national rental vacancy rate was just 5.6% at the end of 2021, the lowest since 1984. Even in the tight market, however, it said, there are reports that RealPage’s algorithm sometimes encourages property owners to keep units vacant or push tenants out to increase profits.The letter cited ProPublica’s story, which quoted from a 2017 earnings call with RealPage’s then-CEO, Steve Winn. He explained how one large property company found it could increase profits by raising rents and leaving more apartments vacant.Winn has not responded to requests for comment.“Intentionally holding units vacant, when there are so few homes available, decreases a consumer’s negotiating power and exacerbates the housing shortage,” the letter said.RealPage’s influence over apartment pricing has grown substantially in recent years, following its 2017 acquisition of its biggest pricing competitor, software called Lease RentOptions, or LRO, from The Rainmaker Group. RealPage was pricing 1.5 million units at the time, and the purchase allowed it to double that number. The Department of Justice’s antitrust division took a close look at the merger, but allowed it to proceed.By 2020, RealPage had expanded its number of clients to 31,700 across all its products, which also include accounting, lease management and other software. Private equity firm Thoma Bravo bought RealPage last year for $10.2 billion. It now calls its pricing software AI Revenue Management.After ProPublica published its investigation, a group of tenants filed a lawsuit against RealPage and nine of the country’s biggest landlords, alleging they were colluding to artificially inflate rents.A RealPage spokesperson has denied the allegations and said the company “will vigorously defend against the lawsuit.” She declined to comment further, saying the company does not comment on pending litigation.",0.0,1.0
288,https://www.newswise.com/articles/engineers-discover-new-process-for-synthetic-material-growth-enabling-soft-robots-that-grow-like-plants,"Engineers discover new process for synthetic material growth, enabling soft robots that grow like plants","Newswise — An interdisciplinary team of University of Minnesota Twin Cities scientists and engineers has developed a first-of-its-kind, plant-inspired extrusion process that enables synthetic material growth. The new approach will allow researchers to build better soft robots that can navigate hard-to-reach places, complicated terrain, and potentially areas within the human body.The paper is published in the Proceedings of the National Academy of Sciences of the United States of America (PNAS), a peer-reviewed, multidisciplinary, high-impact scientific journal.“This is the first time these concepts have been fundamentally demonstrated,” said Chris Ellison, a lead author of the paper and professor in the University of Minnesota Twin Cities Department of Chemical Engineering and Materials Science. “Developing new ways of manufacturing are paramount for the competitiveness of our country and for bringing new products to people. On the robotic side, robots are being used more and more in dangerous, remote environments, and these are the kinds of areas where this work could have an impact.”Soft robotics is an emerging field where robots are made of soft, pliable materials as opposed to rigid ones. Soft growing robots can create new material and “grow” as they move. These machines could be used for operations in remote areas where humans can’t go, such as inspecting or installing tubes underground or navigating inside the human body for biomedical applications.Current soft growing robots drag a trail of solid material behind them and can use heat and/or pressure to transform that material into a more permanent structure, much like how a 3D printer is fed solid filament to produce its shaped product. However, the trail of solid material gets more difficult to pull around bends and turns, making it hard for the robots to navigate terrain with obstacles or winding paths.The University of Minnesota team solved this problem by developing a new means of extrusion, a process where material is pushed through an opening to create a specific shape. Using this new process allows the robot to create its synthetic material from a liquid instead of a solid.“We were really inspired by how plants and fungi grow,” said Matthew Hausladen, first author of the paper and a Ph.D. student in the University of Minnesota Twin Cities Department of Chemical Engineering and Materials Science. “We took the idea that plants and fungi add material at the end of their bodies, either at their root tips or at their new shoots, and we translated that to an engineering system.”Plants use water to transport the building blocks that get transformed into solid roots as the plant grows outward. The researchers were able to mimic this process with synthetic material using a technique called photopolymerization, which uses light to transform liquid monomers into a solid material. Using this technology, the soft robot can more easily navigate obstacles and winding paths without having to drag any solid material behind it.This new process also has applications in manufacturing. Since the researchers’ technique only uses liquid and light, operations that use heat, pressure, and expensive machinery to create and shape materials might not be needed.“A very important part of this project is that we have material scientists, chemical engineers, and robotic engineers all involved,” Ellison said. “By putting all of our different expertise together, we really brought something unique to this project, and I’m confident that not one of us could have done this alone. This is a great example of how collaboration enables scientists to address really hard fundamental problems while also having a technological impact.”The research was funded by the National Science Foundation.In addition to Ellison and Hausladen, the research team included University of Minnesota Department of Chemical Engineering and Materials Science researchers Boran Zhao (postdoctoral researcher) and Lorraine Francis (College of Science and Engineering Distinguished Professor); and University of Minnesota Department of Mechanical Engineering researchers Tim Kowalewski (associate professor) and Matthew Kubala (graduate student).Watch a video of a soft growing robot navigating a tortuous path.Watch a video explaining the idea behind the plant-inspired research.",0.0,1.0
489,https://edition.cnn.com/2022/09/17/business-food/purple-tomato-gmo-scn-trnd/index.html,"A new, genetically modified purple tomato may hit the grocery market stands","CNN —It tastes like a tomato, smells like a tomato, and even looks (mostly) like a tomato. There’s just one catch: It’s purple.The USDA has approved a genetically modified purple tomato, clearing the path for the unique fruit to be sold in American stores next year.“From a plant pest risk perspective, this plant may be safely grown and used in breeding,” the agency said in a September 7 news release.The approval moves the purple tomato one step closer to widespread distribution. In addition to its unique color, the purple tomato also has health benefits and a longer shelf life than garden variety red tomatoes, scientists say.The tomato was developed by a team of scientists, including British biochemist Cathie Martin, who is a professor at the University of East Anglia and a project leader at the John Innes Centre in Norwich, England.Martin worked on pigment production in flowers for over 20 years, she told CNN. “I wanted to start projects where we could look and see whether there were health benefits for this particular group of pigments,” she said.The pigments that drew Martin’s interest are anthocyanins, which give blueberries, blackberries and eggplants their rich blue-purple hues. With funding from a German consortium, she decided to engineer tomatoes that were rich in anthocyanins, hoping to “increase the antioxidant capacity” of the fruits.By comparing regular tomatoes to the engineered purple tomatoes, she would be able to easily identify whether the anthocyanins were linked to any specific health benefits.To engineer the purple tomatoes, the scientists used transcription factors from snapdragons to trigger the tomatoes to produce more anthocyanin, creating a vibrant purple color.Martin and her colleagues published the first results of their research in 2008 in an article in Nature Biotechnology.The results were “stunning,” she said. Cancer-prone mice that ate the purple tomatoes lived around 30% longer than those that ate normal tomatoes, according to the study.Martin said there are “many explanations” as to why anthocyanin-rich tomatoes may have health benefits. There are “probably multiple mechanisms involved,” she said. “It’s not like a drug, where there’s a single target. It’s about them having antioxidant capacity. It also may influence the composition of the microbiome, so it’s better able to deal with digestion of other nutrients.”And in 2013, Martin and colleagues released a study that found the purple tomatoes had double the shelf life of their red cousins.Martin established a spinout company, Norfolk Plant Sciences, to bring the purple tomatoes to market. Nathan Pumplin, the CEO of Norfolk’s US-based commercial business, told CNN that the purple tomato “strikes a cord with people in this very basic way.”The distinctive purple color means that “it takes no imagination to see that it’s different,” Pumplin said. “It really allows people to make a choice.”FDA approval and commercialization are next stepsIn the past, forays into genetically modified foods have often focused on engineering crops that are more sustainable to produce, he added. But for consumers, the benefits of eating a genetically modified food are murky.“It’s very abstract, hard to understand,” Pumplin said. “But a purple tomato – you either choose or choose not to consume.” The difference between the GMO (Genetically Modified Organism) product and the non-modified tomato are stark – and the possible health benefits for consumers are also clear.Pumplin says that consumers are “warming up” to genetically modified foods across the world.“We look at the problems facing our society as far as sustainability, climate change, health tied to diet and nutrition, and what’s clear from the response from our announcement is that it’s a really important topic to a lot of people,” he said. “I’m encouraged that a lot of people are starting to relook at biotechnology in light of the important challenges.”At the same time, “GMOs are not a silver bullet,” he said. “It’s one tool in our toolbox as plant scientists, as scientists, agronomists, to improve the food production system.”The next steps for the purple tomato are FDA approval and commercialization, Pumplin said. “We need to breed excellent, delicious purple tomatoes. We need to work with producers to produce them and distribute them.”Norfolk will begin to launch limited test markets in 2023 to identify which consumers are most interested in purple tomatoes.As for the taste? The purple tomato is indistinguishable from your standard red tomato, Pumplin said.“It tastes like a great tomato,” he said.",0.0,2.0
204,https://newatlas.com/energy/aeromine-rooftop-wind/,Rooftop wind system delivers 150% the energy of solar per dollar,"Aeromine says its unique ""motionless"" rooftop wind generators deliver up to 50% more energy than a solar array of the same price, while taking up just 10% of the roof space and operating more or less silently. In independent tests, they seem legit.Distributed energy generation stands to play a growing part in the world's energy markets. Most of this currently comes in the form of rooftop solar, but in certain areas, wind could definitely play a bigger part. Not every spot is appropriate for a bladed wind turbine, though, and in this regard, University of Houston spinoff Aeromine Technologies has designed a very different, very tidy form of rooftop wind energy capture that looks like it could be a real game-changer.As with traditional wind turbines, size is key. So while Aeromine's wind energy boxes take up a relatively small footprint on your roof, they're still pretty bulky. The wings themselves are maybe 10 feet (3 m) high, at a rough guess, and looking at the latest imagery they're now sitting on top of boxes that might add another 6 ft (1.8 m) or more to their height – so they're no shrinking violets. On the other hand, they don't create the noise, or the constantly moving visual distraction of a regular, bladed turbine, so they may prove to be less unwelcome in populated areas.They work differently too – kind of like a set of race-car spoiler wings sandwiched together facing each other, with a round pole in between them. Angled into the wind, these stationary wings generate a low pressure vacuum in the center of the device, which sucks air through perforations either in the wings themselves or in the round pole, which also aids in accelerating the ambient airflow over the wings.(rendered image) the design places a couple of racecar spolier-like wings in a sandwich orientation, to create a low-pressure vacuum that sucks air through from below. The turbine is thus kept out of harm's way AeromineSo where's the turbine? Depending on the installation, it can either be at the bottom of that central pole, surrounded by a duct, or in more compact designs that sit right down on the roof instead of up on top of a box, the fan can be down in the roof of the building itself, in a pipe connecting either to that central pole or to hollow chambers in the perforated wings. Either way, the wings create a low-pressure zone, air is sucked through a tube to fill that low-pressure zone, and Aeromine places a relatively small, cheap internal propeller (perhaps 36 inches/91 cm in diameter) in that tube to run a generator.It's very quiet, very safe and very cheap to build; you don't need any fancy materials like carbon fiber, there's nothing special about the fan itself, and the whole thing comes apart for transport and a relatively simple construction process on site.Aeromine hasn't yet nominated a standard capacity for its devices in their latest iteration – indeed, we had to go digging to find much information at all about the device. But in a solution presented to the AFWERX Reimagining Energy challenge in January 2021, these units were each rated for 5 kW – pretty close to the output of a typical 21-panel, household rooftop solar system. Multiple units can of course be run along the leading edge of a building, spaced around 15 ft (4.6 m) apart, and each unit in this (now outdated) AFWERX challenge promised to generate around 14.3 MWh annually. Just for perspective, my 6.5-kW home rooftop solar system makes somewhere around 9 MWh a year.Aeromine Wind-Harvesting Unit, installed as a pilot trial on top of BASF's manufacturing facilities in Wyandotte, Michigan. We expect the large box at the bottom will disappear in commercial applications, with the air intake and turbine running below the roof line AeromineThe potential here is pretty clear; solar and wind work well in a complementary fashion. Solar's only generating during the sunniest hours, wind can be 24 hours but is totally dependent on conditions. The small rooftop footprint of an Aeromine system makes it possible to cover the rest of the roof in solar panels, then get some on-site battery storage happening and run a decent-sized business more or less off the grid.So what are the downsides? Well, these things need to be installed in spots where the wind direction is pretty constant, because they don't angle themselves to catch a breeze – and they probably never will, since they're designed to be such a cost-conscious machine. Their height might make them a visual or civic planning issue in some areas, and what's more, they'll cast shadows, which will block the sun from reaching rooftop PV panels unless the building is oriented such that the sun comes from one side and the wind from the other. So there's certainly going to be a limited number of places where they'll work optimally in a hybrid system.But that's about it at first glance. They're certainly cheaper, hardier, safer and less intrusive than windmill-style designs, and they offer a highly-accessible way to introduce reliable wind energy into a distributed power system.(Rendered image) Many Aeromine units can be run together, with proper spacing, and there's plenty of rooftop left for solar panels to run a hybrid system AeromineBefore getting too excited about any strange new wind energy tech, it's always worth revisiting Mike Barnard's excellent checklist to weed out dodgy wind power claims. Written in 2013, it's as relevant as ever today as more and more money flows into clean energy tech.Aeromine fares well against the Barnard test. With the University of Houston behind it, it has also submitted its gear to the gold-standard Sandia National Laboratories for testing – indeed Sandia has been involved directly in the development. It claims to harvest no more than 1/3 to 1/2 of the Betz limit of potential wind energy.A technical performance analysis prepared in partnership with Sandia, using wind tunnels at Texas Tech University, states that ""by sweeping a large area of wind with a reliable design, AeroMINEs overcome the challenges that have plagued other distributed wind solutions and have hindered distributed wind from playing a significant role in energy markets."" The report also notes a boost in energy extraction, coupled with some aerodynamic instability, when the airflow reaches the device from higher angles of attack.Aeromine motionless wind unitAeromine says that BASF is testing the system at its manufacturing plant in Wyandotte, Michigan – although it doesn't say how many units have been installed, or of what capacity. Hunting through the satellite overlays in Google Maps, it seems that the pilot test unit in the video above is situated right here, judging by the unique markings on the roof – but the satellite image isn't recent enough to show the wind power system, so we can't figure out much more.We expect this extra-tall unit sitting on a box is simply a temporary prototype designed to be super-easy to add and remove, where the final product will sit flush against the roof and have its piping and turbine installed under the surface. We wish Aeromine would be more forthcoming in its marketing.Either way, despite the limited information the company is willing to release at this point, this looks like it could be an impressive step forward for distributed rooftop wind energy. We hope Aeromine proves capable of scaling this tech up and making a serious contribution in the race to zero carbon.Check out a short video from Sandia below.R&D 100 Winner 2021: AeroMINE — Stationary Harvesting of Distributed Wind EnergySource: Aeromine via PR Newswire",0.0,2.0
